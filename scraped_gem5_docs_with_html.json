[
    {
        "url": "https://www.gem5.org/documentation",
        "title": "gem5 Documentation",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Jason Lowe-Power<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"gem5-documentation\">gem5 Documentation</h1>\n<h2 id=\"gem5-bootcamp-2024\">gem5 Bootcamp 2024</h2>\n<p>As of gem5 v24.0, the most comprehensive, up to date guide for learning how to use gem5 is the\nmaterial from the <a href=\"https://bootcamp.gem5.org/\">summer 2024 gem5 bootcamp</a>.</p>\n<h2 id=\"learning-gem5\">Learning gem5</h2>\n<p><strong>Notice: Many parts of Learning gem5 are outdated. Some sections of Learning gem5 have been updated for gem5 v24.1 based on content from the 2024 gem5 bootcamp, but others have not. Proceed with caution!</strong></p>\n<p><a href=\"learning_gem5/introduction/\">Learning gem5</a> gives a prose-heavy introduction to using gem5 for computer architecture research written by Jason Lowe-Power.\nThis is a great resource for junior researchers who plan on using gem5 heavily for a research project.</p>\n<p>It covers details of how gem5 works starting with <a href=\"learning_gem5/part1/simple_config\">how to create configuration scripts</a>.\nIt then goes on to describe <a href=\"learning_gem5/part2/environment\">how to modify and extend</a> gem5 for your research including <a href=\"learning_gem5/part2/helloobject\">creating <code class=\"language-plaintext highlighter-rouge\">SimObjects</code></a>, <a href=\"learning_gem5/part2/events\">using gem5\u2019s event-driven simulation infrastructure</a>, and <a href=\"learning_gem5/part2/memoryobject\">adding memory system objects</a>.\nIn <a href=\"learning_gem5/part3/MSIintro\">Learning gem5 Part 3</a> the <a href=\"/documentation/general_docs/ruby\">Ruby cache coherence model</a> is discussed in detail including a full implementation of an MSI cache coherence protocol.</p>\n<p>More Learning gem5 parts are coming soon including:</p>\n<ul>\n<li>CPU models and ISAs</li>\n<li>Debugging gem5</li>\n<li><strong>Your idea here!</strong></li>\n</ul>\n<p>Note: this has been migrated from learning.gem5.org and there are minor problems due to this migration (e.g., missing links, bad formatting).\nPlease contact Jason (jason@lowepower.com) or create a PR if you find any errors!</p>\n<h2 id=\"gem5-101\">gem5 101</h2>\n<p><a href=\"learning_gem5/gem5_101\">gem5 101</a> is a set of assignments mostly from Wisconsin\u2019s graduate computer architecture classes (CS 752, CS 757, and CS 758) which will help you learn to use gem5 for research.</p>\n<h2 id=\"gem5-api-documentation\">gem5 API documentation</h2>\n<p>You can find the doxygen-based documentation here: <a href=\"http://doxygen.gem5.org/release/current/index.html\">http://doxygen.gem5.org/release/current/index.html</a></p>\n<h2 id=\"other-general-gem5-documentation\">Other general gem5 documentation</h2>\n<p>See the navigation on the left side of the page!</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/thermal_model\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/learning_gem5/gem5_101/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/gem5-stdlib/develop-own-components-tutorial",
        "title": "No Title Found",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Bobby R. Bruce<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h2 id=\"developing-your-own-gem5-standard-library-components\">Developing your own gem5 standard library components</h2>\n<p><img alt=\"gem5 component library design\" src=\"/assets/img/stdlib/gem5-components-design.png\"/></p>\n<p>The above diagram shows the basic design of the gem5 library components.\nThere are four important abstract classes: <code class=\"language-plaintext highlighter-rouge\">AbstractBoard</code>, <code class=\"language-plaintext highlighter-rouge\">AbstractProcessor</code>, <code class=\"language-plaintext highlighter-rouge\">AbstractMemorySystem</code>, and <code class=\"language-plaintext highlighter-rouge\">AbstractCacheHierarchy</code>.\nEvery gem5 component inherits from one of these to be a gem5 component usable in a design.\nThe <code class=\"language-plaintext highlighter-rouge\">AbstractBoard</code> must be constructed by specifying an <code class=\"language-plaintext highlighter-rouge\">AbstractProcessor</code>, <code class=\"language-plaintext highlighter-rouge\">AbstractMemorySystem</code>, and an <code class=\"language-plaintext highlighter-rouge\">AbstractCacheHierarchy</code>.\nWith this design any board may use any combination of components which inherit from <code class=\"language-plaintext highlighter-rouge\">AbstractProcessor</code>, <code class=\"language-plaintext highlighter-rouge\">AbstractMemorySystem</code>, and <code class=\"language-plaintext highlighter-rouge\">AbstractCacheHierarchy</code>.\nFor example, using the image as a guide, we can add a <code class=\"language-plaintext highlighter-rouge\">SimpleProcessor</code>, <code class=\"language-plaintext highlighter-rouge\">SingleChannelDDR3_1600</code> and a <code class=\"language-plaintext highlighter-rouge\">PrivateL1PrivateL2CacheHierarchy</code> to an <code class=\"language-plaintext highlighter-rouge\">X86Board</code>.\nIf we desire, we can swap out the <code class=\"language-plaintext highlighter-rouge\">PrivateL1PrivateL2CacheHierarchy</code> for another class which inherits from <code class=\"language-plaintext highlighter-rouge\">AbstractCacheHierarchy</code>.</p>\n<p>In this tutorial we will imagine a user wishes to create a new cache hierarchy.\nAs you can see from the diagram, there are two subclasses which inherit from <code class=\"language-plaintext highlighter-rouge\">AbstractCacheHierarchy</code>: <code class=\"language-plaintext highlighter-rouge\">AbstractRubyCacheHierarchy</code> and <code class=\"language-plaintext highlighter-rouge\">AbstractClassicCacheHierarchy</code>.\nWhile you <em>can</em> inherit directly from <code class=\"language-plaintext highlighter-rouge\">AbstractCacheHierarchy</code>, we recommend inheriting from the subclasses (depending on whether you wish to develop a ruby or classic cache hierarchy setup).\nWe will inherit from the <code class=\"language-plaintext highlighter-rouge\">AbstractClassicCacheHierarchy</code> class to create a classic cache setup.</p>\n<p>To begin, we should create a new Python class which inherits from the <code class=\"language-plaintext highlighter-rouge\">AbstractClassicCacheHierarchy</code>.\nIn this example we will call this <code class=\"language-plaintext highlighter-rouge\">UniqueCacheHierarchy</code>, contained within a file <code class=\"language-plaintext highlighter-rouge\">unique_cache_hierarchy.py</code>:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">m5.objects</span> <span class=\"kn\">import</span> <span class=\"p\">(</span>\n    <span class=\"n\">Port</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.boards.abstract_board</span> <span class=\"kn\">import</span> <span class=\"n\">AbstractBoard</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.cachehierarchies.classic.abstract_classic_cache_hierarchy</span> <span class=\"kn\">import</span> <span class=\"p\">(</span>\n    <span class=\"n\">AbstractClassicCacheHierarchy</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">UniqueCacheHierarchy</span><span class=\"p\">(</span><span class=\"n\">AbstractClassicCacheHierarchy</span><span class=\"p\">):</span>\n\n\n    <span class=\"k\">def</span> <span class=\"nf\">__init__</span><span class=\"p\">()</span> <span class=\"o\">-&gt;</span> <span class=\"bp\">None</span><span class=\"p\">:</span>\n        <span class=\"n\">AbstractClassicCacheHierarchy</span><span class=\"p\">.</span><span class=\"n\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">get_mem_side_port</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">Port</span><span class=\"p\">:</span>\n        <span class=\"k\">pass</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">get_cpu_side_port</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">Port</span><span class=\"p\">:</span>\n        <span class=\"k\">pass</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">incorporate_cache</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">board</span><span class=\"p\">:</span> <span class=\"n\">AbstractBoard</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"bp\">None</span><span class=\"p\">:</span>\n        <span class=\"k\">pass</span>\n</code></pre></div></div>\n<p>As with every abstract base class, there are virtual functions which must be implemented.\nOnce implemented the <code class=\"language-plaintext highlighter-rouge\">UniqueCacheHierarchy</code> can be used in simulations.\nThe <code class=\"language-plaintext highlighter-rouge\">get_mem_side_port</code> and <code class=\"language-plaintext highlighter-rouge\">get_cpu_side_port</code> are declared in the <a href=\"https://github.com/gem5/gem5/blob/stable/src/python/gem5/components/cachehierarchies/classic/abstract_classic_cache_hierarchy.py\">AbstractClassicCacheHierarchy</a>, while <code class=\"language-plaintext highlighter-rouge\">incorporate_cache</code> is declared in the <a href=\"https://github.com/gem5/gem5/blob/stable/src/python/gem5/components/cachehierarchies/abstract_cache_hierarchy.py\">AbstractCacheHierarchy</a></p>\n<p>The <code class=\"language-plaintext highlighter-rouge\">get_mem_side_port</code> and <code class=\"language-plaintext highlighter-rouge\">get_cpu_side_port</code> functions return a <code class=\"language-plaintext highlighter-rouge\">Port</code> each.\nAs their name suggests, these are ports used by the board to access the cache hierarchy from the memory side and the cpu side.\nThese must be specified for all classic cache hierarchy setups.</p>\n<p>The <code class=\"language-plaintext highlighter-rouge\">incorporate_cache</code> function is the function which is called to incorporate the cache into the board.\nThe contents of this function will vary between cache hierarchy setups but will typically inspect the board it is connected to, and use the board\u2019s API to connect the cache hierarchy.</p>\n<p>In this example we assume the user is looking to implement a private L1 cache hierarchy, consisting of a data cache and instruction cache for each CPU core.\nThis has actually already been implemented in the gem5 stdlib as the <a href=\"https://github.com/gem5/gem5/blob/stable/src/python/gem5/components/cachehierarchies/classic/private_l1_cache_hierarchy.py\">PrivateL1CacheHierarchy</a>, but for this example we shall duplicate the effort.</p>\n<p>First we start by implementing the <code class=\"language-plaintext highlighter-rouge\">get_mem_side_port</code> and <code class=\"language-plaintext highlighter-rouge\">get_cpu_side_port</code> functions:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">m5.objects</span> <span class=\"kn\">import</span> <span class=\"p\">(</span>\n    <span class=\"n\">BadAddr</span><span class=\"p\">,</span>\n    <span class=\"n\">Port</span><span class=\"p\">,</span>\n    <span class=\"n\">SystemXBar</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.boards.abstract_board</span> <span class=\"kn\">import</span> <span class=\"n\">AbstractBoard</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.cachehierarchies.classic.abstract_classic_cache_hierarchy</span> <span class=\"kn\">import</span> <span class=\"p\">(</span>\n    <span class=\"n\">AbstractClassicCacheHierarchy</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">UniqueCacheHierarchy</span><span class=\"p\">(</span><span class=\"n\">AbstractClassicCacheHierarchy</span><span class=\"p\">):</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"bp\">None</span><span class=\"p\">:</span>\n        <span class=\"n\">AbstractClassicCacheHierarchy</span><span class=\"p\">.</span><span class=\"n\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span> <span class=\"o\">=</span> <span class=\"n\">SystemXBar</span><span class=\"p\">(</span><span class=\"n\">width</span><span class=\"o\">=</span><span class=\"mi\">64</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span><span class=\"p\">.</span><span class=\"n\">badaddr_responder</span> <span class=\"o\">=</span> <span class=\"n\">BadAddr</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span><span class=\"p\">.</span><span class=\"n\">default</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span><span class=\"p\">.</span><span class=\"n\">badaddr_responder</span><span class=\"p\">.</span><span class=\"n\">pio</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">get_mem_side_port</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">Port</span><span class=\"p\">:</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span><span class=\"p\">.</span><span class=\"n\">mem_side_ports</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">get_cpu_side_port</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">Port</span><span class=\"p\">:</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span><span class=\"p\">.</span><span class=\"n\">cpu_side_ports</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">incorporate_cache</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">board</span><span class=\"p\">:</span> <span class=\"n\">AbstractBoard</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"bp\">None</span><span class=\"p\">:</span>\n        <span class=\"k\">pass</span>\n</code></pre></div></div>\n<p>Here we have used a simple memory bus.</p>\n<p>Next, we implement the <code class=\"language-plaintext highlighter-rouge\">incorporate_cache</code> function:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">m5.objects</span> <span class=\"kn\">import</span> <span class=\"p\">(</span>\n    <span class=\"n\">BadAddr</span><span class=\"p\">,</span>\n    <span class=\"n\">Cache</span><span class=\"p\">,</span>\n    <span class=\"n\">Port</span><span class=\"p\">,</span>\n    <span class=\"n\">SystemXBar</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.boards.abstract_board</span> <span class=\"kn\">import</span> <span class=\"n\">AbstractBoard</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.cachehierarchies.classic.abstract_classic_cache_hierarchy</span> <span class=\"kn\">import</span> <span class=\"p\">(</span>\n    <span class=\"n\">AbstractClassicCacheHierarchy</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.cachehierarchies.classic.caches.l1dcache</span> <span class=\"kn\">import</span> <span class=\"n\">L1DCache</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.cachehierarchies.classic.caches.l1icache</span> <span class=\"kn\">import</span> <span class=\"n\">L1ICache</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.cachehierarchies.classic.caches.mmu_cache</span> <span class=\"kn\">import</span> <span class=\"n\">MMUCache</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">UniqueCacheHierarchy</span><span class=\"p\">(</span><span class=\"n\">AbstractClassicCacheHierarchy</span><span class=\"p\">):</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"bp\">None</span><span class=\"p\">:</span>\n        <span class=\"n\">AbstractClassicCacheHierarchy</span><span class=\"p\">.</span><span class=\"n\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span> <span class=\"o\">=</span> <span class=\"n\">SystemXBar</span><span class=\"p\">(</span><span class=\"n\">width</span><span class=\"o\">=</span><span class=\"mi\">64</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span><span class=\"p\">.</span><span class=\"n\">badaddr_responder</span> <span class=\"o\">=</span> <span class=\"n\">BadAddr</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span><span class=\"p\">.</span><span class=\"n\">default</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span><span class=\"p\">.</span><span class=\"n\">badaddr_responder</span><span class=\"p\">.</span><span class=\"n\">pio</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">get_mem_side_port</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">Port</span><span class=\"p\">:</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span><span class=\"p\">.</span><span class=\"n\">mem_side_ports</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">get_cpu_side_port</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">Port</span><span class=\"p\">:</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span><span class=\"p\">.</span><span class=\"n\">cpu_side_ports</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">incorporate_cache</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">board</span><span class=\"p\">:</span> <span class=\"n\">AbstractBoard</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"bp\">None</span><span class=\"p\">:</span>\n        <span class=\"c1\"># Set up the system port for functional access from the simulator.\n</span>        <span class=\"n\">board</span><span class=\"p\">.</span><span class=\"n\">connect_system_port</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span><span class=\"p\">.</span><span class=\"n\">cpu_side_ports</span><span class=\"p\">)</span>\n\n        <span class=\"k\">for</span> <span class=\"n\">cntr</span> <span class=\"ow\">in</span> <span class=\"n\">board</span><span class=\"p\">.</span><span class=\"n\">get_memory</span><span class=\"p\">().</span><span class=\"n\">get_memory_controllers</span><span class=\"p\">():</span>\n            <span class=\"n\">cntr</span><span class=\"p\">.</span><span class=\"n\">port</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span><span class=\"p\">.</span><span class=\"n\">mem_side_ports</span>\n\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">l1icaches</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n            <span class=\"n\">L1ICache</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"o\">=</span><span class=\"s\">\"32KiB\"</span><span class=\"p\">)</span>\n            <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">board</span><span class=\"p\">.</span><span class=\"n\">get_processor</span><span class=\"p\">().</span><span class=\"n\">get_num_cores</span><span class=\"p\">())</span>\n        <span class=\"p\">]</span>\n\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">l1dcaches</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n            <span class=\"n\">L1DCache</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"o\">=</span><span class=\"s\">\"32KiB\"</span><span class=\"p\">)</span>\n            <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">board</span><span class=\"p\">.</span><span class=\"n\">get_processor</span><span class=\"p\">().</span><span class=\"n\">get_num_cores</span><span class=\"p\">())</span>\n        <span class=\"p\">]</span>\n        <span class=\"c1\"># ITLB Page walk caches\n</span>        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">iptw_caches</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n            <span class=\"n\">MMUCache</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"o\">=</span><span class=\"s\">\"8KiB\"</span><span class=\"p\">)</span>\n            <span class=\"k\">for</span> <span class=\"n\">_</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">board</span><span class=\"p\">.</span><span class=\"n\">get_processor</span><span class=\"p\">().</span><span class=\"n\">get_num_cores</span><span class=\"p\">())</span>\n        <span class=\"p\">]</span>\n        <span class=\"c1\"># DTLB Page walk caches\n</span>        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">dptw_caches</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n            <span class=\"n\">MMUCache</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"o\">=</span><span class=\"s\">\"8KiB\"</span><span class=\"p\">)</span>\n            <span class=\"k\">for</span> <span class=\"n\">_</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">board</span><span class=\"p\">.</span><span class=\"n\">get_processor</span><span class=\"p\">().</span><span class=\"n\">get_num_cores</span><span class=\"p\">())</span>\n        <span class=\"p\">]</span>\n\n        <span class=\"k\">if</span> <span class=\"n\">board</span><span class=\"p\">.</span><span class=\"n\">has_coherent_io</span><span class=\"p\">():</span>\n            <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">_setup_io_cache</span><span class=\"p\">(</span><span class=\"n\">board</span><span class=\"p\">)</span>\n\n        <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">cpu</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">board</span><span class=\"p\">.</span><span class=\"n\">get_processor</span><span class=\"p\">().</span><span class=\"n\">get_cores</span><span class=\"p\">()):</span>\n\n            <span class=\"n\">cpu</span><span class=\"p\">.</span><span class=\"n\">connect_icache</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">l1icaches</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">].</span><span class=\"n\">cpu_side</span><span class=\"p\">)</span>\n            <span class=\"n\">cpu</span><span class=\"p\">.</span><span class=\"n\">connect_dcache</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">l1dcaches</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">].</span><span class=\"n\">cpu_side</span><span class=\"p\">)</span>\n\n            <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">l1icaches</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">].</span><span class=\"n\">mem_side</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span><span class=\"p\">.</span><span class=\"n\">cpu_side_ports</span>\n            <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">l1dcaches</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">].</span><span class=\"n\">mem_side</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span><span class=\"p\">.</span><span class=\"n\">cpu_side_ports</span>\n\n            <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">iptw_caches</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">].</span><span class=\"n\">mem_side</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span><span class=\"p\">.</span><span class=\"n\">cpu_side_ports</span>\n            <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">dptw_caches</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">].</span><span class=\"n\">mem_side</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span><span class=\"p\">.</span><span class=\"n\">cpu_side_ports</span>\n\n            <span class=\"n\">cpu</span><span class=\"p\">.</span><span class=\"n\">connect_walker_ports</span><span class=\"p\">(</span>\n                <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">iptw_caches</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">].</span><span class=\"n\">cpu_side</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">dptw_caches</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">].</span><span class=\"n\">cpu_side</span>\n            <span class=\"p\">)</span>\n\n            <span class=\"n\">int_req_port</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span><span class=\"p\">.</span><span class=\"n\">mem_side_ports</span>\n            <span class=\"n\">int_resp_port</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span><span class=\"p\">.</span><span class=\"n\">cpu_side_ports</span>\n            <span class=\"n\">cpu</span><span class=\"p\">.</span><span class=\"n\">connect_interrupt</span><span class=\"p\">(</span><span class=\"n\">int_req_port</span><span class=\"p\">,</span> <span class=\"n\">int_resp_port</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">_setup_io_cache</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">board</span><span class=\"p\">:</span> <span class=\"n\">AbstractBoard</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"bp\">None</span><span class=\"p\">:</span>\n        <span class=\"s\">\"\"\"Create a cache for coherent I/O connections\"\"\"</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">iocache</span> <span class=\"o\">=</span> <span class=\"n\">Cache</span><span class=\"p\">(</span>\n            <span class=\"n\">assoc</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">,</span>\n            <span class=\"n\">tag_latency</span><span class=\"o\">=</span><span class=\"mi\">50</span><span class=\"p\">,</span>\n            <span class=\"n\">data_latency</span><span class=\"o\">=</span><span class=\"mi\">50</span><span class=\"p\">,</span>\n            <span class=\"n\">response_latency</span><span class=\"o\">=</span><span class=\"mi\">50</span><span class=\"p\">,</span>\n            <span class=\"n\">mshrs</span><span class=\"o\">=</span><span class=\"mi\">20</span><span class=\"p\">,</span>\n            <span class=\"n\">size</span><span class=\"o\">=</span><span class=\"s\">\"1kB\"</span><span class=\"p\">,</span>\n            <span class=\"n\">tgts_per_mshr</span><span class=\"o\">=</span><span class=\"mi\">12</span><span class=\"p\">,</span>\n            <span class=\"n\">addr_ranges</span><span class=\"o\">=</span><span class=\"n\">board</span><span class=\"p\">.</span><span class=\"n\">mem_ranges</span><span class=\"p\">,</span>\n        <span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">iocache</span><span class=\"p\">.</span><span class=\"n\">mem_side</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">membus</span><span class=\"p\">.</span><span class=\"n\">cpu_side_ports</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">iocache</span><span class=\"p\">.</span><span class=\"n\">cpu_side</span> <span class=\"o\">=</span> <span class=\"n\">board</span><span class=\"p\">.</span><span class=\"n\">get_mem_side_coherent_io_port</span><span class=\"p\">()</span>\n</code></pre></div></div>\n<p>This completes the code we\u2019d need to create our own cache hierarchy.</p>\n<p>To use this code, a user can import it as they would any other Python module.\nAs long as this code is in gem5\u2019s python search path, you can import it.\nYou can also add <code class=\"language-plaintext highlighter-rouge\">import sys; sys.path.append(&lt;path to new component&gt;)</code> at the beginning of your gem5 runscript to add the path of this new component to the python search path.</p>\n<h2 id=\"contributing-your-component-to-the-gem5-stdlib\">Contributing your component to the gem5 stdlib</h2>\n<p>Before contributing your component, you will need to move it into the <code class=\"language-plaintext highlighter-rouge\">src/</code> directory so that it is compiled into the gem5 binary.</p>\n<h3 id=\"compiling-your-component-into-the-gem5-standard-library\">Compiling your component into the gem5 standard library</h3>\n<p>The gem5 standard library code resides in <code class=\"language-plaintext highlighter-rouge\">src/python/gem5</code>.\nThe basic directory structure is as follows:</p>\n<pre><code class=\"language-txt\">gem5/\n    components/                 # All the components to build the system to simulate.\n        boards/                 # The boards, typically broken down by ISA target.\n            experimental/       # Experimental boards.\n        cachehierarchies/       # The Cache Hierarchy components.\n            chi/                # CHI protocol cache hierarchies.\n            classic/            # Classic cache hierarchies.\n            ruby/               # Ruby cache hierarchies.\n        memory/                 # Memory systems.\n        processors/             # Processors.\n    prebuilt/                   # Prebuilt systems, ready to use.\n        demo/                   # Prebuilt System for demonstrations. (not be representative of real-world targets).\n    resources/                  # Utilities used for referencing and obtaining gem5-resources.\n    simulate/                   # A package for the automated running of gem5 simulations.\n    utils/                      # General utilities.\n</code></pre>\n<p>We recommend putting the <code class=\"language-plaintext highlighter-rouge\">unique_cache_hierarchy.py</code> in <code class=\"language-plaintext highlighter-rouge\">src/python/gem5/components/cachehierarchies/classic/</code>.</p>\n<p>From then you need to add the following line to <code class=\"language-plaintext highlighter-rouge\">src/python/SConscript</code>:</p>\n<pre><code class=\"language-scons\">PySource('gem5.components.cachehierarchies.classic',\n    'gem5/components/cachehierarchies/classic/unique_cache_hierarchy.py')\n</code></pre>\n<p>Then, when you recompile the gem5 binary, the <code class=\"language-plaintext highlighter-rouge\">UniqueCacheHierarchy</code> class will be included.\nTo use it in your own scripts you need only include it:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">gem5.components.cachehierarchies.classic.unique_cache_hierarchy</span> <span class=\"kn\">import</span> <span class=\"n\">UniqueCacheHierarchy</span>\n\n<span class=\"p\">...</span>\n\n<span class=\"n\">cache_hierarchy</span> <span class=\"o\">=</span> <span class=\"n\">UniqueCacheHierarchy</span><span class=\"p\">()</span>\n\n<span class=\"p\">...</span>\n\n</code></pre></div></div>\n<h3 id=\"gem5-code-contribution-and-review\">gem5 Code contribution and review</h3>\n<p>If you believe your addition to the gem5 stdlib would be beneficial to the gem5 community, you may submit it as a patch.\nPlease follow our <a href=\"/contributing\">Contributing Guidelines</a> if you have not contributed to gem5 before or need a reminder on our procedures.</p>\n<p>In addition to our normal contribution guidelines, we strongly advise you do the following to your stdlib contribution:</p>\n<ul>\n<li><strong>Add Documentation</strong>: Classes and methods should be documented using <a href=\"https://www.sphinx-doc.org/en/master/usage/restructuredtext/basics.html\">reStructured text</a>.\nPlease look over other source code in the stdlib to see how this is typically done.</li>\n<li><strong>Use Python Typing</strong>: Utilize the <a href=\"https://docs.python.org/3/library/typing.html\">Python typing module</a> to specify parameter and method return types.</li>\n<li><strong>Use relative imports</strong>: Within the gem5 stdlib, relative imports should be used to reference other modules/package in the stdlib (i.e., that contained in <code class=\"language-plaintext highlighter-rouge\">src/python/gem5</code>).</li>\n<li><strong>Format using black</strong>: Please format your Python code with <a href=\"https://pypi.org/project/black/\">Python black</a>, with 79 max line widths: <code class=\"language-plaintext highlighter-rouge\">black --line-length=79 &lt;file/directory&gt;</code>.\n<strong>Note</strong>: Python black does not always enforce line lengths.\nFor example, it will not reduce string lengths.\nYou may have to manually reduce the length of some lines.</li>\n</ul>\n<p>Code will be reviewed via <a href=\"https://github.com/gem5/gem5\">GitHub</a> like all other contributions.\nWe would, however, emphasize that we will not accept patches to the library for simply being functional and tested;\nwe require some persuasion that the contribution improves the library and benefits the community.\nFor example, niche components may not be incorporated if they are seen to be low utility while increasing the library\u2019s maintenance overhead.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/gem5-stdlib/x86-full-system-tutorial\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/gem5-stdlib/develop-stdlib-board\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/gem5-stdlib/develop-stdlib-board",
        "title": "No Title Found",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Jasjeet Rangi, Kunal Pai<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h2 id=\"how-to-create-your-own-board-using-the-gem5-standard-library\">How to Create Your Own Board Using the gem5 Standard Library</h2>\n<p>In this tutorial we will cover how to create a custom board using the gem5 Standard Library.</p>\n<p>This tutorial is based on the process used to make the <em>RiscvMatched</em>, a RISC-V prebuilt board that inherits from <code class=\"language-plaintext highlighter-rouge\">MinorCPU</code>. This board can be found at <code class=\"language-plaintext highlighter-rouge\">src/python/gem5/prebuilt/riscvmatched</code>.</p>\n<p>This tutorial will create a single-channeled DDR4 memory of size 2 GiB, a core using the MinorCPU and the RISC-V ISA though the same process can be used for another type or size of memory, ISA and core.</p>\n<p>Likewise, this tutorial will utilize the UniqueCacheHierarchy made in the <a href=\"https://www.gem5.org/documentation/gem5-stdlib/develop-own-components-tutorial\">Developing Your Own Components Tutorial</a>, though anyother cache hierarchy may be used.</p>\n<p>First, we start by importing the components and stdlib features we require.</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">typing</span> <span class=\"kn\">import</span> <span class=\"n\">List</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">m5.objects</span> <span class=\"kn\">import</span> <span class=\"p\">(</span>\n    <span class=\"n\">AddrRange</span><span class=\"p\">,</span>\n    <span class=\"n\">BaseCPU</span><span class=\"p\">,</span>\n    <span class=\"n\">BaseMMU</span><span class=\"p\">,</span>\n    <span class=\"n\">IOXBar</span><span class=\"p\">,</span>\n    <span class=\"n\">Port</span><span class=\"p\">,</span>\n    <span class=\"n\">Process</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n<span class=\"kn\">from</span> <span class=\"nn\">m5.objects.RiscvCPU</span> <span class=\"kn\">import</span> <span class=\"n\">RiscvMinorCPU</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.boards.abstract_system_board</span> <span class=\"kn\">import</span> <span class=\"n\">AbstractSystemBoard</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.boards.se_binary_workload</span> <span class=\"kn\">import</span> <span class=\"n\">SEBinaryWorkload</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.cachehierarchies.classic.unique_cache_hierarchy</span> <span class=\"kn\">import</span> <span class=\"p\">(</span>\n    <span class=\"n\">UniqueCacheHierarchy</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.memory</span> <span class=\"kn\">import</span> <span class=\"n\">SingleChannelDDR4_2400</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.processors.base_cpu_core</span> <span class=\"kn\">import</span> <span class=\"n\">BaseCPUCore</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.processors.base_cpu_processor</span> <span class=\"kn\">import</span> <span class=\"n\">BaseCPUProcessor</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.isas</span> <span class=\"kn\">import</span> <span class=\"n\">ISA</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.utils.override</span> <span class=\"kn\">import</span> <span class=\"n\">overrides</span>\n</code></pre></div></div>\n<p>We will begin development by creating a specialized CPU core for our board which inherits from an ISA-specific version of the chosen CPU.\nSince our ISA is RISC-V and the CPU type we desire is a MinorCPU, we will inherit from <code class=\"language-plaintext highlighter-rouge\">RiscvMinorCPU</code>.\nThis is done so that we can set our own parameters to tailor the CPU it to our requirements.\nIn our example will override a single parameter:  <code class=\"language-plaintext highlighter-rouge\">decodeToExecuteForwardDelay</code> (the default is 1).\nWe have called this new CPU core type <code class=\"language-plaintext highlighter-rouge\">UniqueCPU</code>.</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">class</span> <span class=\"nc\">UniqueCPU</span><span class=\"p\">(</span><span class=\"n\">RiscvMinorCPU</span><span class=\"p\">):</span>\n    <span class=\"n\">decodeToExecuteForwardDelay</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>\n</code></pre></div></div>\n<p>As <code class=\"language-plaintext highlighter-rouge\">RiscvMinorCPU</code> inherits from <code class=\"language-plaintext highlighter-rouge\">BaseCPU</code>, we can incorporate this into the standard library using <code class=\"language-plaintext highlighter-rouge\">BaseCPUCore</code>, a Standard Library wrapper for <code class=\"language-plaintext highlighter-rouge\">BaseCPU</code> objects (source code for this can be found at <code class=\"language-plaintext highlighter-rouge\">src/python/gem5/components/processors/base_cpu_core.py</code>).\nThe <code class=\"language-plaintext highlighter-rouge\">BaseCPUCore</code> takes the <code class=\"language-plaintext highlighter-rouge\">BaseCPU</code> as an argument during construction.\nErgo, we can do the following:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">core</span> <span class=\"o\">=</span> <span class=\"n\">BaseCPUCore</span><span class=\"p\">(</span><span class=\"n\">core</span><span class=\"o\">=</span><span class=\"n\">UniqueCPU</span><span class=\"p\">(),</span> <span class=\"n\">isa</span><span class=\"o\">=</span><span class=\"n\">ISA</span><span class=\"p\">.</span><span class=\"n\">RISCV</span><span class=\"p\">)</span>\n</code></pre></div></div>\n<!-- **Note**: `BaseCPU` objects require a unique `core_id` to be specified upon construction. -->\n<p>Next we must define our processor.\nIn the gem5 Standard Library a processor is a collection of cores.\nIn cases, such as ours, we can utilize the library\u2019s <code class=\"language-plaintext highlighter-rouge\">BaseCPUProcessor</code>, a processor which contains <code class=\"language-plaintext highlighter-rouge\">BaseCPUCore</code> objects (source code can be found in <code class=\"language-plaintext highlighter-rouge\">src/python/gem5/components/processors/base_cpu_processor.py</code>).\nThe <code class=\"language-plaintext highlighter-rouge\">BaseCPUProcessor</code> requires a list of <code class=\"language-plaintext highlighter-rouge\">BaseCPUCore</code>s.\nTherefore:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">processor</span> <span class=\"o\">=</span> <span class=\"n\">BaseCPUProcessor</span><span class=\"p\">(</span><span class=\"n\">cores</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">core</span><span class=\"p\">])</span>\n</code></pre></div></div>\n<p>Next we focus on the construction of the board to host our components.\nAll boards must inherit from <code class=\"language-plaintext highlighter-rouge\">AbstractBoard</code> and in most cases, gem5\u2019s <code class=\"language-plaintext highlighter-rouge\">System</code> simobject.\nTherefore, our board will inherit from <code class=\"language-plaintext highlighter-rouge\">AbstractSystemBoard</code> in this case; an abstract class that inherits from both.</p>\n<p>In order to run simulations with SE mode, we must also inherit from <code class=\"language-plaintext highlighter-rouge\">SEBinaryWorkload</code>.</p>\n<p>All <code class=\"language-plaintext highlighter-rouge\">AbstractBoard</code>s must specify <code class=\"language-plaintext highlighter-rouge\">clk_freq</code> (the clock frequency), the <code class=\"language-plaintext highlighter-rouge\">processor</code>, <code class=\"language-plaintext highlighter-rouge\">memory</code>, and the <code class=\"language-plaintext highlighter-rouge\">cache_hierarchy</code>.\nWe already have our processor, and will use the <code class=\"language-plaintext highlighter-rouge\">UniqueCacheHierarchy</code> for the <code class=\"language-plaintext highlighter-rouge\">cache_hierarchy</code> and a <code class=\"language-plaintext highlighter-rouge\">SingleChannelDDR4_2400</code>, with a size of 2GiB for the memory.</p>\n<p>We will call this the <code class=\"language-plaintext highlighter-rouge\">UniqueBoard</code> and it should look like the following:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">class</span> <span class=\"nc\">UniqueBoard</span><span class=\"p\">(</span><span class=\"n\">AbstractSystemBoard</span><span class=\"p\">,</span> <span class=\"n\">SEBinaryWorkload</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">__init__</span><span class=\"p\">(</span>\n        <span class=\"bp\">self</span><span class=\"p\">,</span>\n        <span class=\"n\">clk_freq</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"bp\">None</span><span class=\"p\">:</span>\n        <span class=\"n\">core</span> <span class=\"o\">=</span> <span class=\"n\">BaseCPUCore</span><span class=\"p\">(</span><span class=\"n\">core</span><span class=\"o\">=</span><span class=\"n\">UniqueCPU</span><span class=\"p\">(),</span> <span class=\"n\">isa</span><span class=\"o\">=</span><span class=\"n\">ISA</span><span class=\"p\">.</span><span class=\"n\">RISCV</span><span class=\"p\">)</span>\n        <span class=\"n\">processor</span> <span class=\"o\">=</span> <span class=\"n\">BaseCPUProcessor</span><span class=\"p\">(</span><span class=\"n\">cores</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">core</span><span class=\"p\">])</span>\n        <span class=\"n\">memory</span> <span class=\"o\">=</span> <span class=\"n\">SingleChannelDDR4_2400</span><span class=\"p\">(</span><span class=\"s\">\"2GiB\"</span><span class=\"p\">)</span>\n        <span class=\"n\">cache_hierarchy</span> <span class=\"o\">=</span> <span class=\"n\">UniqueCacheHierarchy</span><span class=\"p\">()</span>\n        <span class=\"nb\">super</span><span class=\"p\">().</span><span class=\"n\">__init__</span><span class=\"p\">(</span>\n            <span class=\"n\">clk_freq</span><span class=\"o\">=</span><span class=\"n\">clk_freq</span><span class=\"p\">,</span>\n            <span class=\"n\">processor</span><span class=\"o\">=</span><span class=\"n\">processor</span><span class=\"p\">,</span>\n            <span class=\"n\">memory</span><span class=\"o\">=</span><span class=\"n\">memory</span><span class=\"p\">,</span>\n            <span class=\"n\">cache_hierarchy</span><span class=\"o\">=</span><span class=\"n\">cache_hierarchy</span><span class=\"p\">,</span>\n        <span class=\"p\">)</span>\n</code></pre></div></div>\n<p>With the contructor complete, we must implement the abstract methods in <code class=\"language-plaintext highlighter-rouge\">AbstractSystemBoard</code>.\nIt is useful here to look at the source for <code class=\"language-plaintext highlighter-rouge\">AbstractBoard</code> in <code class=\"language-plaintext highlighter-rouge\">/src/python/gem5/components/boards/abstract_system_board.py</code>.</p>\n<p>The abstract methods you choose to implement or not will depend on what type of system you are creating.\nIn our example functions such as <code class=\"language-plaintext highlighter-rouge\">_setup_board</code>, are unneeded so we will implement them with <code class=\"language-plaintext highlighter-rouge\">pass</code>.\nIn other instances we will use <code class=\"language-plaintext highlighter-rouge\">NotImplementedError</code> for cases where a particular component/feature is not available on this board and an error should be returned if trying to access it.\nFor example, our board will have no IO bus.\nWe will therefore implement <code class=\"language-plaintext highlighter-rouge\">has_io_bus</code> to return <code class=\"language-plaintext highlighter-rouge\">False</code> and have <code class=\"language-plaintext highlighter-rouge\">get_io_bus</code> raise a <code class=\"language-plaintext highlighter-rouge\">NotImplementedError</code> if called.</p>\n<p>With the exception of <code class=\"language-plaintext highlighter-rouge\">_setup_memory_ranges</code>, we do not implement many of the features the <code class=\"language-plaintext highlighter-rouge\">AbstractSystemBoard</code> requires. The board should look like this:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">class</span> <span class=\"nc\">UniqueBoard</span><span class=\"p\">(</span><span class=\"n\">AbstractSystemBoard</span><span class=\"p\">,</span> <span class=\"n\">SEBinaryWorkload</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">__init__</span><span class=\"p\">(</span>\n        <span class=\"bp\">self</span><span class=\"p\">,</span>\n        <span class=\"n\">clk_freq</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"bp\">None</span><span class=\"p\">:</span>\n        <span class=\"n\">core</span> <span class=\"o\">=</span> <span class=\"n\">BaseCPUCore</span><span class=\"p\">(</span><span class=\"n\">core</span><span class=\"o\">=</span><span class=\"n\">UniqueCPU</span><span class=\"p\">(),</span> <span class=\"n\">isa</span><span class=\"o\">=</span><span class=\"n\">ISA</span><span class=\"p\">.</span><span class=\"n\">RISCV</span><span class=\"p\">)</span>\n        <span class=\"n\">processor</span> <span class=\"o\">=</span> <span class=\"n\">BaseCPUProcessor</span><span class=\"p\">(</span><span class=\"n\">cores</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">core</span><span class=\"p\">])</span>\n        <span class=\"n\">memory</span> <span class=\"o\">=</span> <span class=\"n\">SingleChannelDDR4_2400</span><span class=\"p\">(</span><span class=\"s\">\"2GiB\"</span><span class=\"p\">)</span>\n        <span class=\"n\">cache_hierarchy</span> <span class=\"o\">=</span> <span class=\"n\">UniqueCacheHierarchy</span><span class=\"p\">()</span>\n        <span class=\"nb\">super</span><span class=\"p\">().</span><span class=\"n\">__init__</span><span class=\"p\">(</span>\n            <span class=\"n\">clk_freq</span><span class=\"o\">=</span><span class=\"n\">clk_freq</span><span class=\"p\">,</span>\n            <span class=\"n\">processor</span><span class=\"o\">=</span><span class=\"n\">processor</span><span class=\"p\">,</span>\n            <span class=\"n\">memory</span><span class=\"o\">=</span><span class=\"n\">memory</span><span class=\"p\">,</span>\n            <span class=\"n\">cache_hierarchy</span><span class=\"o\">=</span><span class=\"n\">cache_hierarchy</span><span class=\"p\">,</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"o\">@</span><span class=\"n\">overrides</span><span class=\"p\">(</span><span class=\"n\">AbstractSystemBoard</span><span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"nf\">_setup_board</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"bp\">None</span><span class=\"p\">:</span>\n        <span class=\"k\">pass</span>\n\n    <span class=\"o\">@</span><span class=\"n\">overrides</span><span class=\"p\">(</span><span class=\"n\">AbstractSystemBoard</span><span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"nf\">has_io_bus</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">bool</span><span class=\"p\">:</span>\n        <span class=\"k\">return</span> <span class=\"bp\">False</span>\n\n    <span class=\"o\">@</span><span class=\"n\">overrides</span><span class=\"p\">(</span><span class=\"n\">AbstractSystemBoard</span><span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"nf\">get_io_bus</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">IOXBar</span><span class=\"p\">:</span>\n        <span class=\"k\">raise</span> <span class=\"nb\">NotImplementedError</span><span class=\"p\">(</span>\n            <span class=\"s\">\"UniqueBoard does not have an IO Bus. \"</span>\n            <span class=\"s\">\"Use `has_io_bus()` to check this.\"</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"o\">@</span><span class=\"n\">overrides</span><span class=\"p\">(</span><span class=\"n\">AbstractSystemBoard</span><span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"nf\">has_dma_ports</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">bool</span><span class=\"p\">:</span>\n        <span class=\"k\">return</span> <span class=\"bp\">False</span>\n\n    <span class=\"o\">@</span><span class=\"n\">overrides</span><span class=\"p\">(</span><span class=\"n\">AbstractSystemBoard</span><span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"nf\">get_dma_ports</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Port</span><span class=\"p\">]:</span>\n        <span class=\"k\">raise</span> <span class=\"nb\">NotImplementedError</span><span class=\"p\">(</span>\n            <span class=\"s\">\"UniqueBoard does not have DMA Ports. \"</span>\n            <span class=\"s\">\"Use `has_dma_ports()` to check this.\"</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"o\">@</span><span class=\"n\">overrides</span><span class=\"p\">(</span><span class=\"n\">AbstractSystemBoard</span><span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"nf\">has_coherent_io</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">bool</span><span class=\"p\">:</span>\n        <span class=\"k\">return</span> <span class=\"bp\">False</span>\n\n    <span class=\"o\">@</span><span class=\"n\">overrides</span><span class=\"p\">(</span><span class=\"n\">AbstractSystemBoard</span><span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"nf\">get_mem_side_coherent_io_port</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">Port</span><span class=\"p\">:</span>\n        <span class=\"k\">raise</span> <span class=\"nb\">NotImplementedError</span><span class=\"p\">(</span>\n            <span class=\"s\">\"UniqueBoard does not have any I/O ports. Use has_coherent_io to \"</span>\n            <span class=\"s\">\"check this.\"</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"o\">@</span><span class=\"n\">overrides</span><span class=\"p\">(</span><span class=\"n\">AbstractSystemBoard</span><span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"nf\">_setup_memory_ranges</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"bp\">None</span><span class=\"p\">:</span>\n        <span class=\"n\">memory</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">get_memory</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">mem_ranges</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">AddrRange</span><span class=\"p\">(</span><span class=\"n\">memory</span><span class=\"p\">.</span><span class=\"n\">get_size</span><span class=\"p\">())]</span>\n        <span class=\"n\">memory</span><span class=\"p\">.</span><span class=\"n\">set_memory_range</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">mem_ranges</span><span class=\"p\">)</span>\n</code></pre></div></div>\n<p>This concludes the creation of your custom board for the gem5 standard library.\nThe completed board is as follows:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">typing</span> <span class=\"kn\">import</span> <span class=\"n\">List</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">m5.objects</span> <span class=\"kn\">import</span> <span class=\"p\">(</span>\n    <span class=\"n\">AddrRange</span><span class=\"p\">,</span>\n    <span class=\"n\">BaseCPU</span><span class=\"p\">,</span>\n    <span class=\"n\">BaseMMU</span><span class=\"p\">,</span>\n    <span class=\"n\">IOXBar</span><span class=\"p\">,</span>\n    <span class=\"n\">Port</span><span class=\"p\">,</span>\n    <span class=\"n\">Process</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n<span class=\"kn\">from</span> <span class=\"nn\">m5.objects.RiscvCPU</span> <span class=\"kn\">import</span> <span class=\"n\">RiscvMinorCPU</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.boards.abstract_system_board</span> <span class=\"kn\">import</span> <span class=\"n\">AbstractSystemBoard</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.boards.se_binary_workload</span> <span class=\"kn\">import</span> <span class=\"n\">SEBinaryWorkload</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.cachehierarchies.classic.unique_cache_hierarchy</span> <span class=\"kn\">import</span> <span class=\"p\">(</span>\n    <span class=\"n\">UniqueCacheHierarchy</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.memory</span> <span class=\"kn\">import</span> <span class=\"n\">SingleChannelDDR4_2400</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.processors.base_cpu_core</span> <span class=\"kn\">import</span> <span class=\"n\">BaseCPUCore</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.processors.base_cpu_processor</span> <span class=\"kn\">import</span> <span class=\"n\">BaseCPUProcessor</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.isas</span> <span class=\"kn\">import</span> <span class=\"n\">ISA</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.utils.override</span> <span class=\"kn\">import</span> <span class=\"n\">overrides</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">UniqueCPU</span><span class=\"p\">(</span><span class=\"n\">RiscvMinorCPU</span><span class=\"p\">):</span>\n    <span class=\"n\">decodeToExecuteForwardDelay</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">UniqueBoard</span><span class=\"p\">(</span><span class=\"n\">AbstractSystemBoard</span><span class=\"p\">,</span> <span class=\"n\">SEBinaryWorkload</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">__init__</span><span class=\"p\">(</span>\n        <span class=\"bp\">self</span><span class=\"p\">,</span>\n        <span class=\"n\">clk_freq</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"bp\">None</span><span class=\"p\">:</span>\n        <span class=\"n\">core</span> <span class=\"o\">=</span> <span class=\"n\">BaseCPUCore</span><span class=\"p\">(</span><span class=\"n\">core</span><span class=\"o\">=</span><span class=\"n\">UniqueCPU</span><span class=\"p\">(),</span> <span class=\"n\">isa</span><span class=\"o\">=</span><span class=\"n\">ISA</span><span class=\"p\">.</span><span class=\"n\">RISCV</span><span class=\"p\">)</span>\n        <span class=\"n\">processor</span> <span class=\"o\">=</span> <span class=\"n\">BaseCPUProcessor</span><span class=\"p\">(</span><span class=\"n\">cores</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">core</span><span class=\"p\">])</span>\n        <span class=\"n\">memory</span> <span class=\"o\">=</span> <span class=\"n\">SingleChannelDDR4_2400</span><span class=\"p\">(</span><span class=\"s\">\"2GiB\"</span><span class=\"p\">)</span>\n        <span class=\"n\">cache_hierarchy</span> <span class=\"o\">=</span> <span class=\"n\">UniqueCacheHierarchy</span><span class=\"p\">()</span>\n        <span class=\"nb\">super</span><span class=\"p\">().</span><span class=\"n\">__init__</span><span class=\"p\">(</span>\n            <span class=\"n\">clk_freq</span><span class=\"o\">=</span><span class=\"n\">clk_freq</span><span class=\"p\">,</span>\n            <span class=\"n\">processor</span><span class=\"o\">=</span><span class=\"n\">processor</span><span class=\"p\">,</span>\n            <span class=\"n\">memory</span><span class=\"o\">=</span><span class=\"n\">memory</span><span class=\"p\">,</span>\n            <span class=\"n\">cache_hierarchy</span><span class=\"o\">=</span><span class=\"n\">cache_hierarchy</span><span class=\"p\">,</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"o\">@</span><span class=\"n\">overrides</span><span class=\"p\">(</span><span class=\"n\">AbstractSystemBoard</span><span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"nf\">_setup_board</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"bp\">None</span><span class=\"p\">:</span>\n        <span class=\"k\">pass</span>\n\n    <span class=\"o\">@</span><span class=\"n\">overrides</span><span class=\"p\">(</span><span class=\"n\">AbstractSystemBoard</span><span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"nf\">has_io_bus</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">bool</span><span class=\"p\">:</span>\n        <span class=\"k\">return</span> <span class=\"bp\">False</span>\n\n    <span class=\"o\">@</span><span class=\"n\">overrides</span><span class=\"p\">(</span><span class=\"n\">AbstractSystemBoard</span><span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"nf\">get_io_bus</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">IOXBar</span><span class=\"p\">:</span>\n        <span class=\"k\">raise</span> <span class=\"nb\">NotImplementedError</span><span class=\"p\">(</span>\n            <span class=\"s\">\"UniqueBoard does not have an IO Bus. \"</span>\n            <span class=\"s\">\"Use `has_io_bus()` to check this.\"</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"o\">@</span><span class=\"n\">overrides</span><span class=\"p\">(</span><span class=\"n\">AbstractSystemBoard</span><span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"nf\">has_dma_ports</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">bool</span><span class=\"p\">:</span>\n        <span class=\"k\">return</span> <span class=\"bp\">False</span>\n\n    <span class=\"o\">@</span><span class=\"n\">overrides</span><span class=\"p\">(</span><span class=\"n\">AbstractSystemBoard</span><span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"nf\">get_dma_ports</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Port</span><span class=\"p\">]:</span>\n        <span class=\"k\">raise</span> <span class=\"nb\">NotImplementedError</span><span class=\"p\">(</span>\n            <span class=\"s\">\"UniqueBoard does not have DMA Ports. \"</span>\n            <span class=\"s\">\"Use `has_dma_ports()` to check this.\"</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"o\">@</span><span class=\"n\">overrides</span><span class=\"p\">(</span><span class=\"n\">AbstractSystemBoard</span><span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"nf\">has_coherent_io</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">bool</span><span class=\"p\">:</span>\n        <span class=\"k\">return</span> <span class=\"bp\">False</span>\n\n    <span class=\"o\">@</span><span class=\"n\">overrides</span><span class=\"p\">(</span><span class=\"n\">AbstractSystemBoard</span><span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"nf\">get_mem_side_coherent_io_port</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">Port</span><span class=\"p\">:</span>\n        <span class=\"k\">raise</span> <span class=\"nb\">NotImplementedError</span><span class=\"p\">(</span>\n            <span class=\"s\">\"UniqueBoard does not have any I/O ports. Use has_coherent_io to \"</span>\n            <span class=\"s\">\"check this.\"</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"o\">@</span><span class=\"n\">overrides</span><span class=\"p\">(</span><span class=\"n\">AbstractSystemBoard</span><span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"nf\">_setup_memory_ranges</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"bp\">None</span><span class=\"p\">:</span>\n        <span class=\"n\">memory</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">get_memory</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">mem_ranges</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">AddrRange</span><span class=\"p\">(</span><span class=\"n\">memory</span><span class=\"p\">.</span><span class=\"n\">get_size</span><span class=\"p\">())]</span>\n        <span class=\"n\">memory</span><span class=\"p\">.</span><span class=\"n\">set_memory_range</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">mem_ranges</span><span class=\"p\">)</span>\n\n</code></pre></div></div>\n<p>From this you can create a runscript and test your board:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">unique_board</span> <span class=\"kn\">import</span> <span class=\"n\">UniqueBoard</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.resources.resource</span> <span class=\"kn\">import</span> <span class=\"n\">obtain_resource</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.simulate.simulator</span> <span class=\"kn\">import</span> <span class=\"n\">Simulator</span>\n\n<span class=\"n\">board</span> <span class=\"o\">=</span> <span class=\"n\">UniqueBoard</span><span class=\"p\">(</span><span class=\"n\">clk_freq</span><span class=\"o\">=</span><span class=\"s\">\"1.2GHz\"</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># As we are using the RISCV ISA, \"riscv-hello\" should work.\n</span><span class=\"n\">board</span><span class=\"p\">.</span><span class=\"n\">set_se_binary_workload</span><span class=\"p\">(</span><span class=\"n\">obtain_resource</span><span class=\"p\">(</span><span class=\"s\">\"riscv-hello\"</span><span class=\"p\">))</span>\n\n<span class=\"n\">simulator</span> <span class=\"o\">=</span> <span class=\"n\">Simulator</span><span class=\"p\">(</span><span class=\"n\">board</span><span class=\"o\">=</span><span class=\"n\">board</span><span class=\"p\">)</span>\n<span class=\"n\">simulator</span><span class=\"p\">.</span><span class=\"n\">run</span><span class=\"p\">()</span>\n</code></pre></div></div>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/gem5-stdlib/develop-own-components-tutorial\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/gem5-stdlib/local-resources-support\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/gem5-stdlib/hello-world-tutorial",
        "title": "No Title Found",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Bobby R. Bruce<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h2 id=\"building-a-hello-world-example-with-the-gem5-standard-library\">Building a \u201cHello World\u201d example with the gem5 standard library</h2>\n<p>In this tutorial we will cover how to create a very basic simulation using gem5 components.\nThis simulation will setup a system consisting of a single-core processor, running in Atomic mode, connected directly to main memory with no caches, I/O, or other components.\nThe system will run an X86 binary in syscall emulation (SE) mode.\nThe binary will be obtained from gem5-resources and which will print a \u201cHello World!\u201d string to stdout upon execution.</p>\n<p>To start we must compile the ALL build for gem5:</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\"># In the root of the gem5 directory</span>\nscons build/ALL/gem5.opt <span class=\"nt\">-j</span> &lt;number of threads&gt;\n</code></pre></div></div>\n<p>As of gem5 v24.1, the ALL build includes all Ruby protocols and all ISAs. If you are using a prebuilt gem5 binary, this step is not necessary.</p>\n<p>Then a new Python file should be created (we will refer to this as <code class=\"language-plaintext highlighter-rouge\">hello-world.py</code> going forward).\nThe first lines in this file should be the needed imports:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">gem5.components.boards.simple_board</span> <span class=\"kn\">import</span> <span class=\"n\">SimpleBoard</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.cachehierarchies.classic.no_cache</span> <span class=\"kn\">import</span> <span class=\"n\">NoCache</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.memory.single_channel</span> <span class=\"kn\">import</span> <span class=\"n\">SingleChannelDDR3_1600</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.processors.cpu_types</span> <span class=\"kn\">import</span> <span class=\"n\">CPUTypes</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.processors.simple_processor</span> <span class=\"kn\">import</span> <span class=\"n\">SimpleProcessor</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.isas</span> <span class=\"kn\">import</span> <span class=\"n\">ISA</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.resources.resource</span> <span class=\"kn\">import</span> <span class=\"n\">obtain_resource</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.simulate.simulator</span> <span class=\"kn\">import</span> <span class=\"n\">Simulator</span>\n</code></pre></div></div>\n<p>All these libraries are included inside the compiled gem5 binary.\nTherefore, you will not need to obtain them from elsewhere.\n<code class=\"language-plaintext highlighter-rouge\">from gem5.</code> indicates we are importing from the <code class=\"language-plaintext highlighter-rouge\">gem5</code> standard library, and the lines starting with <code class=\"language-plaintext highlighter-rouge\">from gem5.components</code> are importing components from the gem5 components package.\nThe <code class=\"language-plaintext highlighter-rouge\">from gem5.resources</code> line means we are importing from the resources package, and <code class=\"language-plaintext highlighter-rouge\">from gem5.simulate</code>, the simulate package.\nAll these packages, <code class=\"language-plaintext highlighter-rouge\">components</code>, <code class=\"language-plaintext highlighter-rouge\">resources</code>, and <code class=\"language-plaintext highlighter-rouge\">simulate</code> are part of the gem5 standard library.</p>\n<p>Next we begin specifying the system.\nThe gem5 library requires the user to specify four main components: the <em>board</em>, the <em>cache hierarchy</em>, the <em>memory system</em>, and the <em>processor</em>.</p>\n<p>Let\u2019s start with the <em>cache hierarchy</em>:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">cache_hierarchy</span> <span class=\"o\">=</span> <span class=\"n\">NoCache</span><span class=\"p\">()</span>\n</code></pre></div></div>\n<p>Here we are using <code class=\"language-plaintext highlighter-rouge\">NoCache()</code>.\nThis means, for our system, we are stating there is no cache hierarchy (i.e., no caches).\nIn the gem5 library the cache hierarchy is a broad term for anything that exists between the processor cores and main memory.\nHere we are stating the processor is connected directly to main memory.</p>\n<p>Next we declare the <em>memory system</em>:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">memory</span> <span class=\"o\">=</span> <span class=\"n\">SingleChannelDDR3_1600</span><span class=\"p\">(</span><span class=\"s\">\"1GiB\"</span><span class=\"p\">)</span>\n</code></pre></div></div>\n<p>There exists many memory components to choose from within <code class=\"language-plaintext highlighter-rouge\">gem5.components.memory</code>.\nHere we are using a single-channel DDR3 1600, and setting its size to 1 GiB.\nIt should be noted that setting the size here is technically optional.\nIf not set, the <code class=\"language-plaintext highlighter-rouge\">SingleChannelDDR3_1600</code> will default to 8 GiB.</p>\n<p>Then we consider the <em>processor</em>:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">processor</span> <span class=\"o\">=</span> <span class=\"n\">SimpleProcessor</span><span class=\"p\">(</span><span class=\"n\">cpu_type</span><span class=\"o\">=</span><span class=\"n\">CPUTypes</span><span class=\"p\">.</span><span class=\"n\">ATOMIC</span><span class=\"p\">,</span> <span class=\"n\">num_cores</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">isa</span><span class=\"o\">=</span><span class=\"n\">ISA</span><span class=\"p\">.</span><span class=\"n\">X86</span><span class=\"p\">)</span>\n</code></pre></div></div>\n<p>A processor in <code class=\"language-plaintext highlighter-rouge\">gem5.components</code> is an object which contains a number of gem5 CPU cores, of a particular or varying type (<code class=\"language-plaintext highlighter-rouge\">ATOMIC</code>, <code class=\"language-plaintext highlighter-rouge\">TIMING</code>, <code class=\"language-plaintext highlighter-rouge\">KVM</code>, <code class=\"language-plaintext highlighter-rouge\">O3</code>, etc.).\nThe <code class=\"language-plaintext highlighter-rouge\">SimpleProcessor</code> used in this example is a processor where all the CPU Cores are of an identical type.\nIt requires two arguments: the <code class=\"language-plaintext highlighter-rouge\">cpu_type</code>, which we set to <code class=\"language-plaintext highlighter-rouge\">ATOMIC</code>, and <code class=\"language-plaintext highlighter-rouge\">num_cores</code>, the number of cores, which we set to one.</p>\n<p>Finally we specify which <em>board</em> we are using:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">board</span> <span class=\"o\">=</span> <span class=\"n\">SimpleBoard</span><span class=\"p\">(</span>\n    <span class=\"n\">clk_freq</span><span class=\"o\">=</span><span class=\"s\">\"3GHz\"</span><span class=\"p\">,</span>\n    <span class=\"n\">processor</span><span class=\"o\">=</span><span class=\"n\">processor</span><span class=\"p\">,</span>\n    <span class=\"n\">memory</span><span class=\"o\">=</span><span class=\"n\">memory</span><span class=\"p\">,</span>\n    <span class=\"n\">cache_hierarchy</span><span class=\"o\">=</span><span class=\"n\">cache_hierarchy</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n</code></pre></div></div>\n<p>While the constructor of each board may vary, they will typically require the user to specify the <em>processor</em>, <em>memory system</em>, and <em>cache hierarchy</em>, as well as the clock frequency to use.\nIn this example we use the <code class=\"language-plaintext highlighter-rouge\">SimpleBoard</code>.\nThe <code class=\"language-plaintext highlighter-rouge\">SimpleBoard</code> is a very basic system with no I/O which only supports SE-mode and can only work with \u201cclassic\u201d cache hierarchies.</p>\n<p>At this point in the script we have specified everything we require to simulate our system.\nOf course, in order to run a meaningful simulation, we must specify a workload for this system to run.\nTo do so we add the following lines:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">binary</span> <span class=\"o\">=</span> <span class=\"n\">obtain_resource</span><span class=\"p\">(</span><span class=\"s\">\"x86-hello64-static\"</span><span class=\"p\">)</span>\n<span class=\"n\">board</span><span class=\"p\">.</span><span class=\"n\">set_se_binary_workload</span><span class=\"p\">(</span><span class=\"n\">binary</span><span class=\"p\">)</span>\n</code></pre></div></div>\n<p>The <code class=\"language-plaintext highlighter-rouge\">obtain_resource</code> function takes a string which specifies which resource, from <a href=\"/documentation/general_docs/gem5_resources\">gem5-resources</a>, is to be obtained for the simulation.\nAll the gem5 resources can be found on the <a href=\"https://resources.gem5.org\">gem5 Resources website</a>.</p>\n<p>If the resource is not present on the host system it\u2019ll be automatically downloaded.\nIn this example we are going to use the <code class=\"language-plaintext highlighter-rouge\">x86-hello-64-static</code> resource;\nan x86, 64-bit, statically compiled binary which will print \u201cHello World!\u201d to stdout.\nAfter specifying the resource we set the workload via the board\u2019s <code class=\"language-plaintext highlighter-rouge\">set_se_binary_workload</code> function.\nAs the name suggests <code class=\"language-plaintext highlighter-rouge\">set_se_binary_workload</code> is a function used to set a binary to be executed in Syscall Execution mode.</p>\n<p>You can see and search for available resources on the <a href=\"https://resources.gem5.org/\">gem5 resources website</a>.</p>\n<p>This is all that is required to setup your simulation.\nFrom this you simply need to construct and run the <code class=\"language-plaintext highlighter-rouge\">Simulator</code>:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">simulator</span> <span class=\"o\">=</span> <span class=\"n\">Simulator</span><span class=\"p\">(</span><span class=\"n\">board</span><span class=\"o\">=</span><span class=\"n\">board</span><span class=\"p\">)</span>\n<span class=\"n\">simulator</span><span class=\"p\">.</span><span class=\"n\">run</span><span class=\"p\">()</span>\n</code></pre></div></div>\n<p>As a recap, your script should look like the following:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">gem5.components.boards.simple_board</span> <span class=\"kn\">import</span> <span class=\"n\">SimpleBoard</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.cachehierarchies.classic.no_cache</span> <span class=\"kn\">import</span> <span class=\"n\">NoCache</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.memory.single_channel</span> <span class=\"kn\">import</span> <span class=\"n\">SingleChannelDDR3_1600</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.processors.cpu_types</span> <span class=\"kn\">import</span> <span class=\"n\">CPUTypes</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.processors.simple_processor</span> <span class=\"kn\">import</span> <span class=\"n\">SimpleProcessor</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.isas</span> <span class=\"kn\">import</span> <span class=\"n\">ISA</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.resources.resource</span> <span class=\"kn\">import</span> <span class=\"n\">obtain_resource</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.simulate.simulator</span> <span class=\"kn\">import</span> <span class=\"n\">Simulator</span>\n\n<span class=\"c1\"># Obtain the components.\n</span><span class=\"n\">cache_hierarchy</span> <span class=\"o\">=</span> <span class=\"n\">NoCache</span><span class=\"p\">()</span>\n<span class=\"n\">memory</span> <span class=\"o\">=</span> <span class=\"n\">SingleChannelDDR3_1600</span><span class=\"p\">(</span><span class=\"s\">\"1GiB\"</span><span class=\"p\">)</span>\n<span class=\"n\">processor</span> <span class=\"o\">=</span> <span class=\"n\">SimpleProcessor</span><span class=\"p\">(</span><span class=\"n\">cpu_type</span><span class=\"o\">=</span><span class=\"n\">CPUTypes</span><span class=\"p\">.</span><span class=\"n\">ATOMIC</span><span class=\"p\">,</span> <span class=\"n\">num_cores</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">isa</span><span class=\"o\">=</span><span class=\"n\">ISA</span><span class=\"p\">.</span><span class=\"n\">X86</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Add them to the board.\n</span><span class=\"n\">board</span> <span class=\"o\">=</span> <span class=\"n\">SimpleBoard</span><span class=\"p\">(</span>\n    <span class=\"n\">clk_freq</span><span class=\"o\">=</span><span class=\"s\">\"3GHz\"</span><span class=\"p\">,</span>\n    <span class=\"n\">processor</span><span class=\"o\">=</span><span class=\"n\">processor</span><span class=\"p\">,</span>\n    <span class=\"n\">memory</span><span class=\"o\">=</span><span class=\"n\">memory</span><span class=\"p\">,</span>\n    <span class=\"n\">cache_hierarchy</span><span class=\"o\">=</span><span class=\"n\">cache_hierarchy</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\"># Set the workload.\n</span><span class=\"n\">binary</span> <span class=\"o\">=</span> <span class=\"n\">obtain_resource</span><span class=\"p\">(</span><span class=\"s\">\"x86-hello64-static\"</span><span class=\"p\">)</span>\n<span class=\"n\">board</span><span class=\"p\">.</span><span class=\"n\">set_se_binary_workload</span><span class=\"p\">(</span><span class=\"n\">binary</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Setup the Simulator and run the simulation.\n</span><span class=\"n\">simulator</span> <span class=\"o\">=</span> <span class=\"n\">Simulator</span><span class=\"p\">(</span><span class=\"n\">board</span><span class=\"o\">=</span><span class=\"n\">board</span><span class=\"p\">)</span>\n<span class=\"n\">simulator</span><span class=\"p\">.</span><span class=\"n\">run</span><span class=\"p\">()</span>\n</code></pre></div></div>\n<p>It can then be executed with:</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>./build/ALL/gem5.opt hello-world.py\n</code></pre></div></div>\n<p>If you are using a pre-built binary, you can execute the simulation with:</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>gem5 hello-world.py\n</code></pre></div></div>\n<p>If setup correctly, the output will look something like:</p>\n<div class=\"language-text highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>info: Using default config\nGlobal frequency set at 1000000000000 ticks per second\nsrc/mem/dram_interface.cc:690: warn: DRAM device capacity (8192 Mbytes) does not match the address range assigned (1024 Mbytes)\nsrc/base/statistics.hh:279: warn: One of the stats is a legacy stat. Legacy stat is a stat that does not belong to any statistics::Group. Legacy stat is deprecated.\nboard.remote_gdb: Listening for connections on port 7005\nsrc/sim/simulate.cc:199: info: Entering event queue @ 0.  Starting simulation...\nsrc/sim/syscall_emul.hh:1117: warn: readlink() called on '/proc/self/exe' may yield unexpected results in various settings.\nsrc/sim/mem_state.cc:448: info: Increasing stack size by one page.\nHello world!\n</code></pre></div></div>\n<p>It should be obvious from this point that a <em>board\u2019s</em> parameters may be altered to test other designs.\nFor example, if we want to test a <code class=\"language-plaintext highlighter-rouge\">TIMING</code> CPU setup we\u2019d change our <em>processor</em> to:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">processor</span> <span class=\"o\">=</span> <span class=\"n\">SimpleProcessor</span><span class=\"p\">(</span><span class=\"n\">cpu_type</span><span class=\"o\">=</span><span class=\"n\">CPUTypes</span><span class=\"p\">.</span><span class=\"n\">TIMING</span><span class=\"p\">,</span> <span class=\"n\">num_cores</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">isa</span><span class=\"o\">=</span><span class=\"n\">ISA</span><span class=\"p\">.</span><span class=\"n\">X86</span><span class=\"p\">)</span>\n</code></pre></div></div>\n<p>This is all that is required.\nThe gem5 standard library will reconfigure the design as is necessary.</p>\n<p>As another example, consider swapping out a component for another.\nIn this design we decided on <code class=\"language-plaintext highlighter-rouge\">NoCache</code> but we could use another classic cache hierarchy, such as <code class=\"language-plaintext highlighter-rouge\">PrivateL1CacheHierarchy</code>.\nTo do so we\u2019d change our <code class=\"language-plaintext highlighter-rouge\">cache_hierarchy</code> parameter:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># We import the cache hierarchy we want.\n</span><span class=\"kn\">from</span> <span class=\"nn\">gem5.components.cachehierarchies.classic.private_l1_cache_hierarchy</span> <span class=\"kn\">import</span> <span class=\"n\">PrivateL1CacheHierarchy</span>\n\n<span class=\"p\">...</span>\n\n<span class=\"c1\"># Then set it.\n</span><span class=\"n\">cache_hierarchy</span> <span class=\"o\">=</span> <span class=\"n\">PrivateL1CacheHierarchy</span><span class=\"p\">(</span><span class=\"n\">l1d_size</span><span class=\"o\">=</span><span class=\"s\">\"32KiB\"</span><span class=\"p\">,</span> <span class=\"n\">l1i_size</span><span class=\"o\">=</span><span class=\"s\">\"32KiB\"</span><span class=\"p\">)</span>\n</code></pre></div></div>\n<p>Note here that <code class=\"language-plaintext highlighter-rouge\">PrivateL1CacheHierarchy</code> requires the user to specify the L1 data and instruction cache sizes to be constructed.\nNo other part of the design need change.\nThe gem5 standard library will incorporate the cache hierarchy as required.</p>\n<p>To recap on what was learned in this tutorial:</p>\n<ul>\n<li>A system can be built with the gem5 components package using <em>processor</em>, <em>cache hierarchy</em>, <em>memory system</em>, and <em>board</em> components.</li>\n<li>Generally speaking, components of the same type are interchangeable as much as is possible. E.g., different <em>cache hierarchy</em> components may be swapped in and out of a design without reconfiguration needed in other components.</li>\n<li><em>boards</em> contain functions to set workloads.</li>\n<li>The resources package may be used to obtain prebuilt resources from gem5-resources.\nThese are typically workloads that may be run via set workload functions.</li>\n<li>The simulate package can be used to run a board within a gem5 simulation.</li>\n</ul>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/gem5-stdlib/overview\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/gem5-stdlib/x86-full-system-tutorial\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/gem5-stdlib/overview",
        "title": "No Title Found",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Bobby R. Bruce<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h2 id=\"an-overview-of-the-gem5-standard-library\">An overview of the gem5 standard library</h2>\n<p>Similar to standard libraries in programming languages, the gem5 standard library is designed to provide users of gem5 with commonly used components, features, and functionality with the goal of improving their productivity.\nThe gem5 stdlib was introduced in <a href=\"https://github.com/gem5/gem5/tree/v21.1.0.0\">v21.1</a> in an alpha-release state (then referred to as \u201cgem5 components\u201d), and has been fully released as of <a href=\"https://github.com/gem5/gem5/tree/v21.2.0.0\">v21.2</a>.</p>\n<p>For users new to the gem5 standard library, the following tutorials may be of help in understanding how the gem5 stdlib may be used to improve the creation of gem5 simulations.\nThey include a tutorial on building syscall emulation and full-system simulations, as well as a guide on how to extend the library and contribute.\nThe <a href=\"https://github.com/gem5/gem5/tree/stable/configs/example/gem5_library\"><code class=\"language-plaintext highlighter-rouge\">configs/examples/gem5_library</code></a> directory in the gem5 repository also contains example scripts which use the library.</p>\n<p>The following subsections give a broad overview of the gem5 stdlib packages and what there intended purposes are.</p>\n<p><strong>Note: The documentation/tutorials/etc. related to the standard library have been updated for the v24.1 release.\nPlease ensure you have the correct version of gem5 before proceeding.</strong></p>\n<p>As part of <a href=\"/events/boot-camp-2022\">gem5\u2019s 2022 Bootcamp</a>, the stdlib was taught as a tutorial.\nSlides for this tutorial can be found <a href=\"https://raw.githubusercontent.com/gem5bootcamp/gem5-bootcamp-env/main/assets/slides/using-gem5-02-gem5-stdlib-tutorial.pdf\">here</a>.\nA video recording of this tutorial can be found <a href=\"https://www.youtube.com/watch?v=vbruiMyIFsA\">here</a>.</p>\n<p>The stdlib was also covered during the <a href=\"https://bootcamp.gem5.org/#02-Using-gem5/01-stdlib\">2024 gem5 Bootcamp</a>.</p>\n<!-- Could use a nice picture here showing the main modules of the stdlib and how they relate -->\n<h2 id=\"the-gem5-stdlib-components-package-and-its-design-philosophy\">The gem5 stdlib components package and its design philosophy</h2>\n<p>The gem5 stdlib components package is the central part of the gem5 stdlib.\nWith it users can built complex systems from simple components which connect together using standardized APIs.</p>\n<p>The metaphor that guided the components package development was that of building a computer using off-the-shelf components.\nWhen building a computer, someone may select components, plug them into a board, and assume the interface between the board and the component have been designed in a way in which they will \u201cjust work.\u201d\nFor example, someone can remove a processor from a board and add a different one, compatible with the same socket, without needing to change everything else in their setup.\nWhile there are always limitations to this design philosophy, the components package has a highly modular and extensible design with components of the same type being interchangeable with one another as much as is possible.</p>\n<p>At the core of the components package is the idea of a <em>board</em>.\nThis plays a similar role to the motherboard in a real-world system.\nWhile it may contain embedded caches, controllers, and other complex components, its main purpose is to expose standardized interfaces for other hardware to be added and handle communication between them.\nFor example, a memory device and a processor may be added to a board with the board responsible for communication without the designer of the memory or the processor having to consider this assuming they conform to known APIs.</p>\n<p>Typically, a gem5 components package <em>board</em> requires declaration of these three components:</p>\n<ol>\n<li>The <em>processor</em> : The system processor. A processor component contains at least one <em>core</em> which may be Atomic, O3, Timing, or KVM.</li>\n<li>The <em>memory</em> system: The memory system, for example, a DDR3_1600.</li>\n<li>The <em>cache hierarchies</em>: This component defines any and all components between the processor and main memory, most notably the cache setup. In the simplest of setups this will connect memory directly to the processor.</li>\n</ol>\n<p>The other devices required for full-system simulation, which rarely change between simulations, are handled by the board.</p>\n<p>A typical usage of the components may therefore look like:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>\n<span class=\"n\">cache_hierarchy</span> <span class=\"o\">=</span> <span class=\"n\">MESITwoLevelCacheHierarchy</span><span class=\"p\">(</span>\n    <span class=\"n\">l1d_size</span><span class=\"o\">=</span><span class=\"s\">\"16kB\"</span><span class=\"p\">,</span>\n    <span class=\"n\">l1d_assoc</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">,</span>\n    <span class=\"n\">l1i_size</span><span class=\"o\">=</span><span class=\"s\">\"16kB\"</span><span class=\"p\">,</span>\n    <span class=\"n\">l1i_assoc</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">,</span>\n    <span class=\"n\">l2_size</span><span class=\"o\">=</span><span class=\"s\">\"256kB\"</span><span class=\"p\">,</span>\n    <span class=\"n\">l2_assoc</span><span class=\"o\">=</span><span class=\"mi\">16</span><span class=\"p\">,</span>\n    <span class=\"n\">num_l2_banks</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">memory</span> <span class=\"o\">=</span> <span class=\"n\">SingleChannelDDR3_1600</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"o\">=</span><span class=\"s\">\"3GB\"</span><span class=\"p\">)</span>\n\n<span class=\"n\">processor</span> <span class=\"o\">=</span> <span class=\"n\">SimpleProcessor</span><span class=\"p\">(</span><span class=\"n\">cpu_type</span><span class=\"o\">=</span><span class=\"n\">CPUTypes</span><span class=\"p\">.</span><span class=\"n\">TIMING</span><span class=\"p\">,</span> <span class=\"n\">num_cores</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"n\">board</span> <span class=\"o\">=</span> <span class=\"n\">X86Board</span><span class=\"p\">(</span>\n    <span class=\"n\">clk_freq</span><span class=\"o\">=</span><span class=\"s\">\"3GHz\"</span><span class=\"p\">,</span>\n    <span class=\"n\">processor</span><span class=\"o\">=</span><span class=\"n\">processor</span><span class=\"p\">,</span>\n    <span class=\"n\">memory</span><span class=\"o\">=</span><span class=\"n\">memory</span><span class=\"p\">,</span>\n    <span class=\"n\">cache_hierarchy</span><span class=\"o\">=</span><span class=\"n\">cache_hierarchy</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n</code></pre></div></div>\n<p>The following tutorials go into greater detail on how to use the components package to create gem5 simulations.</p>\n<h2 id=\"the-gem5-resources-package\">The gem5 resources package</h2>\n<p>The gem5 stdlib\u2019s resource package is used to obtain and incorporate resources.\nA resource, in the context of gem5, is something used in a simulation, or by a simulation, but not directly used to construct a system to be simulated.\nTypically these are applications, kernels, disk images, benchmarks, or tests.</p>\n<p>As these resources can be hard to find, or hard to create, we provide pre-built resources as part of <a href=\"/documentation/general_docs/gem5_resources\">gem5-resources</a>.\nFor example, via gem5-resources, a user may download an Ubuntu 18.04 disk image with known compatibility with gem5.\nThey need not setup this themselves.</p>\n<p>A core feature of the gem5 stdlib resource package is that it allows users to <em>automatically obtain</em> prebuilt gem5 resources for their simulation.\nA user may specify in their Python config file that a specific gem5 resource is required and, when run, the package will check if there is a local copy on the host system, and if not, download it.</p>\n<p>The tutorials will demonstrate how to use the resource package in greater detail, but for now, a typical pattern is as follows:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">gem5.resources.resource</span> <span class=\"kn\">import</span> <span class=\"n\">Resource</span>\n\n<span class=\"n\">resource</span> <span class=\"o\">=</span> <span class=\"n\">Resource</span><span class=\"p\">(</span><span class=\"s\">\"riscv-disk-img\"</span><span class=\"p\">)</span>\n\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s\">\"The resources is available at </span><span class=\"si\">{</span><span class=\"n\">resource</span><span class=\"p\">.</span><span class=\"n\">get_local_path</span><span class=\"p\">()</span><span class=\"si\">}</span><span class=\"s\">\"</span><span class=\"p\">)</span>\n</code></pre></div></div>\n<p>This will obtain the <code class=\"language-plaintext highlighter-rouge\">riscv-disk-img</code> resource and store it locally for use in a gem5 simulation.</p>\n<p>The resources package references the resources that are available to view at the <a href=\"https://resources.gem5.org\">gem5 Resources website</a> and the <a href=\"https://github.com/gem5/gem5-resources\">gem5 Resources repository</a>. The website is strongly recommended to get info on what resources are available and where they may be downloaded from.</p>\n<h2 id=\"the-simulate-package\">The Simulate package</h2>\n<p>The simulate package is used to run gem5 simulations.\nWhile there is some boilerplate code this module handles on the users behalf, its primary purpose is to provde default behavior and APIs for what we refer to as <em>Exit Events</em>.\nExit events are when a simulation exits for a particular reason.</p>\n<p>A typical example of an exit event would be a <code class=\"language-plaintext highlighter-rouge\">Workbegin</code> exit event.\nThis is used to specify that a Region-of-Interest (ROI) has been reached.\nUsually this exit would be used to allow a user to begin logging statistics or to switch to a more detailed CPU model.\nPrior to the stdlib, the user would need to specify precisely what the expected behavior was at exit events such as this.\nThe simulation would exit and the configuration script would contain Python code specifying what to do next.\nNow, with the simulate package, there is a default behavior for this kind of event (the stats are reset), and an easy interface to override this behavior with something the user requires.</p>\n<p>More information about exit events can be found in the <a href=\"https://www.gem5.org/documentation/general_docs/m5ops/\">M5ops documentation</a>.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/contributing\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/gem5-stdlib/hello-world-tutorial\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/gem5-stdlib/using-local-resources",
        "title": "No Title Found",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Harshil Patel<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<p>gem5 supports using local data sources in the form of a MongoDB Atlas and JSON datasource. gem5 has a default resources config in <code class=\"language-plaintext highlighter-rouge\">src/python/gem5_default_config.py</code>. This resources config points to the MongoDB Atlas collection of gem5 resources. To utilize data sources other than the main gem5 resources database, you will need to override the gem5-resources-config.</p>\n<p>There are several ways to update the gem5 resources configuration:</p>\n<ol>\n<li>\n<p><strong>Setting GEM5_CONFIG environment variable:</strong> You can set the GEM5_CONFIG environment variable to specify a new configuration file. Doing this will replace the default resources configuration with the one you\u2019ve specified.</p>\n</li>\n<li>\n<p><strong>Using gem5-config.json:</strong> If a file named gem5-config.json exists in the current working directory, it will take precedence over the default resources configuration.</p>\n</li>\n<li>\n<p><strong>Fallback to default resources config:</strong> If neither of the above methods is used, the system will resort to using the default resources configuration.</p>\n</li>\n</ol>\n<p>Additionally, if you wish to utilize or add a local resource JSON file to the currently selected config (as mentioned in the above methods), you have two additional methods available:</p>\n<ul>\n<li>\n<p><strong>GEM5_RESOURCE_JSON environment variable:</strong> This variable can be employed to override the current resources configuration and make use of a specified JSON file.</p>\n</li>\n<li>\n<p><strong>GEM5_RESOURCE_JSON_APPEND environment variable:</strong> Use this variable to add a JSON file to the existing resources configuration without replacing it.</p>\n</li>\n</ul>\n<p>It\u2019s essential to note that overriding or appending doesn\u2019t modify the actual configuration files themselves. These methods allow you to temporarily specify or add resource configurations during runtime without altering the original configuration files.</p>\n<p>MongoDB Atlas Config Format:</p>\n<div class=\"language-json highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"p\">{</span><span class=\"w\">\n    </span><span class=\"nl\">\"sources\"</span><span class=\"p\">:{</span><span class=\"w\">\n        </span><span class=\"nl\">\"example-atlas-config\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\">\n            </span><span class=\"nl\">\"dataSource\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"datasource name\"</span><span class=\"p\">,</span><span class=\"w\">\n            </span><span class=\"nl\">\"database\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"database name\"</span><span class=\"p\">,</span><span class=\"w\">\n            </span><span class=\"nl\">\"collection\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"collection name\"</span><span class=\"p\">,</span><span class=\"w\">\n            </span><span class=\"nl\">\"url\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"Atlas data API URL\"</span><span class=\"p\">,</span><span class=\"w\">\n            </span><span class=\"nl\">\"authUrl\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"Atlas authentication URL\"</span><span class=\"p\">,</span><span class=\"w\">\n            </span><span class=\"nl\">\"apiKey\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"API key for data API for MongoDB Atlas\"</span><span class=\"p\">,</span><span class=\"w\">\n            </span><span class=\"nl\">\"isMongo\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"kc\">true</span><span class=\"w\">\n        </span><span class=\"p\">}</span><span class=\"w\">\n    </span><span class=\"p\">}</span><span class=\"w\">\n</span><span class=\"p\">}</span><span class=\"w\">\n</span></code></pre></div></div>\n<p>JSON Config Format:</p>\n<div class=\"language-json highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"p\">{</span><span class=\"w\">\n    </span><span class=\"nl\">\"sources\"</span><span class=\"p\">:{</span><span class=\"w\">\n        </span><span class=\"nl\">\"example-json-config\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\">\n            </span><span class=\"nl\">\"url\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"local path to JSON file or URL to a JSON file\"</span><span class=\"p\">,</span><span class=\"w\">\n            </span><span class=\"nl\">\"isMongo\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"kc\">false</span><span class=\"w\">\n        </span><span class=\"p\">}</span><span class=\"w\">\n    </span><span class=\"p\">}</span><span class=\"w\">\n</span><span class=\"p\">}</span><span class=\"w\">\n</span></code></pre></div></div>\n<h3 id=\"setting-up-a-mongodb-atlas-database\">Setting up a MongoDB Atlas Database</h3>\n<p>You would need to set up an Atlas cluster, steps on setting up an Atlas cluster can be found here:</p>\n<ul>\n<li>https://www.mongodb.com/basics/mongodb-atlas-tutorial</li>\n</ul>\n<p>You would also need to enable Atlas dataAPI, steps on enabling dataAPI can be found here:</p>\n<ul>\n<li>https://www.mongodb.com/docs/atlas/app-services/data-api/generated-endpoints/</li>\n</ul>\n<h3 id=\"using-multiple-data-sources\">Using Multiple Data Sources</h3>\n<p>gem5 supports the use of more than one data source. The structure of the resource configuration is as follows:</p>\n<div class=\"language-json highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"p\">{</span><span class=\"w\">\n    </span><span class=\"nl\">\"sources\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\">\n         </span><span class=\"nl\">\"gem5-resources\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\">\n            </span><span class=\"nl\">\"dataSource\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"gem5-vision\"</span><span class=\"p\">,</span><span class=\"w\">\n            </span><span class=\"nl\">\"database\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"gem5-vision\"</span><span class=\"p\">,</span><span class=\"w\">\n            </span><span class=\"nl\">\"collection\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"resources\"</span><span class=\"p\">,</span><span class=\"w\">\n            </span><span class=\"nl\">\"url\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"https://data.mongodb-api.com/app/data-ejhjf/endpoint/data/v1\"</span><span class=\"p\">,</span><span class=\"w\">\n            </span><span class=\"nl\">\"authUrl\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"https://realm.mongodb.com/api/client/v2.0/app/data-ejhjf/auth/providers/api-key/login\"</span><span class=\"p\">,</span><span class=\"w\">\n            </span><span class=\"nl\">\"apiKey\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"OIi5bAP7xxIGK782t8ZoiD2BkBGEzMdX3upChf9zdCxHSnMoiTnjI22Yw5kOSgy9\"</span><span class=\"p\">,</span><span class=\"w\">\n            </span><span class=\"nl\">\"isMongo\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"kc\">true</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"p\">},</span><span class=\"w\">\n        </span><span class=\"nl\">\"data-source-json-1\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\">\n            </span><span class=\"nl\">\"url\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"path/to/json\"</span><span class=\"p\">,</span><span class=\"w\">\n            </span><span class=\"nl\">\"isMongo\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"kc\">false</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"p\">},</span><span class=\"w\">\n        </span><span class=\"nl\">\"data-source-json-2\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\">\n            </span><span class=\"nl\">\"url\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"path/to/another/json\"</span><span class=\"p\">,</span><span class=\"w\">\n            </span><span class=\"nl\">\"isMongo\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"kc\">false</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"p\">},</span><span class=\"w\">\n        </span><span class=\"err\">//</span><span class=\"w\"> </span><span class=\"err\">Add</span><span class=\"w\"> </span><span class=\"err\">more</span><span class=\"w\"> </span><span class=\"err\">data</span><span class=\"w\"> </span><span class=\"err\">sources</span><span class=\"w\"> </span><span class=\"err\">as</span><span class=\"w\"> </span><span class=\"err\">needed</span><span class=\"w\">\n    </span><span class=\"p\">}</span><span class=\"w\">\n</span><span class=\"p\">}</span><span class=\"w\">\n</span></code></pre></div></div>\n<p>The above example shows a gem5 resources config with a MongoDB Atlas data source and 2 JSON data sources. By default gem5 will create a union of all the resources present in all the specified data sources. If you ask to obtain a resource where multiple data sources have the same <code class=\"language-plaintext highlighter-rouge\">id</code> and <code class=\"language-plaintext highlighter-rouge\">resource_version</code> of the resource then an error will be thrown. You can also specify a subset of data sources to obtain resources from:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">resource</span> <span class=\"o\">=</span> <span class=\"n\">obtain_resource</span><span class=\"p\">(</span><span class=\"s\">\"id\"</span><span class=\"p\">,</span> <span class=\"n\">clients</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s\">\"data-source-json-1\"</span><span class=\"p\">])</span>\n</code></pre></div></div>\n<h3 id=\"understanding-local-resources\">Understanding Local Resources</h3>\n<p>Local resources, in the context of gem5, pertain to resources that users possess and wish to integrate into gem5 but aren\u2019t pre-existing in the gem5 resources database.</p>\n<p>For users, This offers the flexibility to employ their own resources seamlessly within gem5, bypassing the need to create dedicated resource objects using <code class=\"language-plaintext highlighter-rouge\">BinaryResource(local_path=/path/to/binary)</code>. Instead, they can directly utilize these local resources through <code class=\"language-plaintext highlighter-rouge\">obtain_resource()</code>, streamlining the integration process.</p>\n<h3 id=\"using-custom-resource-configuration-and-local-resources\">Using Custom Resource Configuration and Local Resources</h3>\n<p>In this example, we will walk through how to set up your custom configuration and utilize your own local resources. For this illustration, we\u2019ll employ a JSON file as our resource data source.</p>\n<h4 id=\"creating-a-custom-resource-data-source\">Creating a Custom Resource Data Source</h4>\n<p>Let\u2019s begin by creating a local resource. This is a bare bones resource that will serve as an example. To use local resources with <code class=\"language-plaintext highlighter-rouge\">obtain_resource()</code>, our bare bones resource need to have a binary file. Here we use an empty binary called <code class=\"language-plaintext highlighter-rouge\">fake-binary</code>.</p>\n<p><strong>Note</strong>: Make sure that Gem5 binary and <code class=\"language-plaintext highlighter-rouge\">fake-binary</code> have same ISA target (RISCV here).</p>\n<p>Next, let\u2019s create the JSON data source. I\u2019ll name the file <code class=\"language-plaintext highlighter-rouge\">my-resources.json</code>. The contents should look like this:</p>\n<div class=\"language-json highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"p\">[</span><span class=\"w\">\n    </span><span class=\"p\">{</span><span class=\"w\">\n        </span><span class=\"nl\">\"category\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"binary\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"id\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"test-binary\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"description\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"A test binary\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"architecture\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"RISCV\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"size\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"tags\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">[</span><span class=\"w\">\n            </span><span class=\"s2\">\"test\"</span><span class=\"w\">\n        </span><span class=\"p\">],</span><span class=\"w\">\n        </span><span class=\"nl\">\"is_zipped\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"kc\">false</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"md5sum\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"6d9494d22b90d817e826b0d762fda973\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"source\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"src/simple\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"url\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"file:// path to fake_binary\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"license\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"author\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">[],</span><span class=\"w\">\n        </span><span class=\"nl\">\"source_url\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"https://github.com/gem5/gem5-resources/tree/develop/src/simple\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"resource_version\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"1.0.0\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"gem5_versions\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">[</span><span class=\"w\">\n            </span><span class=\"s2\">\"23.0\"</span><span class=\"w\">\n        </span><span class=\"p\">],</span><span class=\"w\">\n        </span><span class=\"nl\">\"example_usage\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"obtain_resource(resource_id=</span><span class=\"se\">\\\"</span><span class=\"s2\">test-binary</span><span class=\"se\">\\\"</span><span class=\"s2\">)\"</span><span class=\"w\">\n    </span><span class=\"p\">}</span><span class=\"w\">\n</span><span class=\"p\">]</span><span class=\"w\">\n</span></code></pre></div></div>\n<p>The JSON file of a resource should adhere to the <a href=\"https://resources.gem5.org/gem5-resources-schema.json\">gem5 resources schema</a>.</p>\n<p><strong>Note</strong>: While the <code class=\"language-plaintext highlighter-rouge\">url</code> field can be a link, in this case, I\u2019m using a local file.</p>\n<h4 id=\"creating-your-custom-resource-configuration\">Creating Your Custom Resource Configuration</h4>\n<p>Create a file named <code class=\"language-plaintext highlighter-rouge\">gem5-config.json</code> with the following content:</p>\n<div class=\"language-json highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"p\">{</span><span class=\"w\">\n    </span><span class=\"nl\">\"sources\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\">\n        </span><span class=\"nl\">\"my-json-data-source\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\">\n            </span><span class=\"nl\">\"url\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"path/to/my-resources.json\"</span><span class=\"p\">,</span><span class=\"w\">\n            </span><span class=\"nl\">\"isMongo\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"kc\">false</span><span class=\"w\">\n        </span><span class=\"p\">}</span><span class=\"w\">\n    </span><span class=\"p\">}</span><span class=\"w\">\n</span><span class=\"p\">}</span><span class=\"w\">\n</span></code></pre></div></div>\n<p><strong>Note</strong>: It is implied that isMongo = false means that the data source is a JSON data source as gem5 currently only supports 2 types of data sources.</p>\n<h4 id=\"running-gem5-with-a-local-data-source\">Running gem5 with a Local Data Source</h4>\n<p>First, build gem5 with the ALL build, which contains RISCV:</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>scons build/ALL/gem5.opt <span class=\"nt\">-j</span><span class=\"sb\">`</span><span class=\"nb\">nproc</span><span class=\"sb\">`</span>\n</code></pre></div></div>\n<p>Next, run the <code class=\"language-plaintext highlighter-rouge\">local-resource-example.py</code> file using our local <code class=\"language-plaintext highlighter-rouge\">test-binary</code> resource:</p>\n<p>Using environment variable</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">GEM5_RESOURCE_JSON_APPEND</span><span class=\"o\">=</span>path/to/my-resources.json ./build/ALL/gem5.opt configs/example/gem5_library/local-resource-example.py <span class=\"nt\">--resource</span> test-binary\n</code></pre></div></div>\n<p>or you can overwrite the <code class=\"language-plaintext highlighter-rouge\">gem5_default_config</code> with our own custom config:</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">GEM5_CONFIG</span><span class=\"o\">=</span>path/to/gem5-config.json ./build/ALL/gem5.opt configs/example/gem5_library/local-resource-example.py <span class=\"nt\">--resource</span> test-binary\n</code></pre></div></div>\n<p>This command will execute the <code class=\"language-plaintext highlighter-rouge\">local-resource-example.py</code> script using our locally downloaded resource. This script just calls the obtain_resource function and prints the local path of the resource. This script indicates that local resources function similarly as resources on the gem5 resources database.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/gem5-stdlib/suites\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/gem5art/introduction\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/gem5-stdlib/x86-full-system-tutorial",
        "title": "No Title Found",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Bobby R. Bruce<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h2 id=\"building-an-x86-full-system-simulation-with-the-gem5-standard-library\">Building an x86 full-system simulation with the gem5 standard library</h2>\n<p>One of the key ideas behind the gem5 standard library is to allow users to simulate, big, complex systems, with minimal effort.\nThis is done by making sensible assumptions about the nature of the system to simulate and connecting components in a manner which \u201cmakes sense.\u201d\nWhile this takes away some flexibility, it massively simplifies simulating typical hardware setups in gem5.\nThe overarching philosophy is to make the <em>common case</em> simple.</p>\n<p>In this tutorial we will build an X86 simulation, capable of running a full-system simulation, booting an Ubuntu operating system, and running a benchmark.\nThis system will utilize gem5\u2019s ability to switch cores, allowing booting of the operating system in KVM fast-forward mode and switching to a detailed CPU model to run the benchmark, and use a MESI Two Level Ruby cache hierarchy in a dual-core setup.\nWithout using the gem5 library this would take several hundred lines of Python, forcing the user to specify details such as every IO component and exactly how the cache hierarchy is setup.\nHere, we will demonstrate how simple this task can be with using the gem5 standard library.</p>\n<p>First, we build the ALL binary. This will allow us to run simulations for any ISA, including X86:</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>scons build/ALL/gem5.opt <span class=\"nt\">-j</span> &lt;number of threads&gt;\n</code></pre></div></div>\n<p>If you are using a prebuilt gem5 binary, this step is not necessary.</p>\n<p>To start, create a new Python file.\nWe will refer to this as <code class=\"language-plaintext highlighter-rouge\">x86-ubuntu-run.py</code>.</p>\n<p>To begin we add our import statements:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">gem5.coherence_protocol</span> <span class=\"kn\">import</span> <span class=\"n\">CoherenceProtocol</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.boards.x86_board</span> <span class=\"kn\">import</span> <span class=\"n\">X86Board</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.cachehierarchies.ruby.mesi_two_level_cache_hierarchy</span> <span class=\"kn\">import</span> <span class=\"p\">(</span>\n    <span class=\"n\">MESITwoLevelCacheHierarchy</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.memory.single_channel</span> <span class=\"kn\">import</span> <span class=\"n\">SingleChannelDDR3_1600</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.processors.cpu_types</span> <span class=\"kn\">import</span> <span class=\"n\">CPUTypes</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.processors.simple_switchable_processor</span> <span class=\"kn\">import</span> <span class=\"p\">(</span>\n    <span class=\"n\">SimpleSwitchableProcessor</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.isas</span> <span class=\"kn\">import</span> <span class=\"n\">ISA</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.resources.resource</span> <span class=\"kn\">import</span> <span class=\"n\">obtain_resource</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.simulate.exit_event</span> <span class=\"kn\">import</span> <span class=\"n\">ExitEvent</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.simulate.simulator</span> <span class=\"kn\">import</span> <span class=\"n\">Simulator</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.utils.requires</span> <span class=\"kn\">import</span> <span class=\"n\">requires</span>\n</code></pre></div></div>\n<p>As in other Python scripts, these are simply classes/functions needed in our script.\nThey are all included as part of the gem5 binary and therefore do not need to obtained elsewhere.</p>\n<p>A good start is to use the <code class=\"language-plaintext highlighter-rouge\">requires</code> function to specify what kind of gem5 binary/setup is required to run the script:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">requires</span><span class=\"p\">(</span>\n    <span class=\"n\">isa_required</span><span class=\"o\">=</span><span class=\"n\">ISA</span><span class=\"p\">.</span><span class=\"n\">X86</span><span class=\"p\">,</span>\n    <span class=\"n\">coherence_protocol_required</span><span class=\"o\">=</span><span class=\"n\">CoherenceProtocol</span><span class=\"p\">.</span><span class=\"n\">MESI_TWO_LEVEL</span><span class=\"p\">,</span>\n    <span class=\"n\">kvm_required</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n</code></pre></div></div>\n<p>Here we state that we need gem5 compiled to run the X86 ISA and support the MESI Two Level protocol.\nWe also require the host system to have KVM.\n<strong>NOTE: Please ensure your host system supports KVM. If your system does not please remove the <code class=\"language-plaintext highlighter-rouge\">kvm_required</code> check here</strong>.\nKVM will only work if the host platform and the simulated ISA are the same (e.g., X86 host and X86 simulation). You can learn more about using KVM with gem5 <a href=\"https://www.gem5.org/documentation/general_docs/using_kvm/\">here</a>.</p>\n<p>This <code class=\"language-plaintext highlighter-rouge\">requires</code> call is not required but provides a good safety net to those running the script.\nErrors that occur due to incompatible gem5 binaries may not make much sense otherwise.</p>\n<p>Next we start specifying the components in our system.\nWe start with the <em>cache hierarchy</em>:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">cache_hierarchy</span> <span class=\"o\">=</span> <span class=\"n\">MESITwoLevelCacheHierarchy</span><span class=\"p\">(</span>\n    <span class=\"n\">l1d_size</span><span class=\"o\">=</span><span class=\"s\">\"32KiB\"</span><span class=\"p\">,</span>\n    <span class=\"n\">l1d_assoc</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">,</span>\n    <span class=\"n\">l1i_size</span><span class=\"o\">=</span><span class=\"s\">\"32KiB\"</span><span class=\"p\">,</span>\n    <span class=\"n\">l1i_assoc</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">,</span>\n    <span class=\"n\">l2_size</span><span class=\"o\">=</span><span class=\"s\">\"256KiB\"</span><span class=\"p\">,</span>\n    <span class=\"n\">l2_assoc</span><span class=\"o\">=</span><span class=\"mi\">16</span><span class=\"p\">,</span>\n    <span class=\"n\">num_l2_banks</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n</code></pre></div></div>\n<p>Here we setup a MESI Two Level (ruby) cache hierarchy.\nVia the constructor we set the L1 data cache and L1 instruction cache to 32 KiB, and the L2 cache to 256 KiB.</p>\n<p>Next we setup the <em>memory system</em>:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">memory</span> <span class=\"o\">=</span> <span class=\"n\">SingleChannelDDR3_1600</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"o\">=</span><span class=\"s\">\"2GiB\"</span><span class=\"p\">)</span>\n</code></pre></div></div>\n<p>This is quite simple and should be intuitive: A single channel DDR3 1600 setup of size 2GiB.\n<strong>Note:</strong> by default the <code class=\"language-plaintext highlighter-rouge\">SingleChannelDDR3_1600</code> component has a size of 8GiB.\nHowever, due to <a href=\"https://gem5.atlassian.net/browse/GEM5-1142\">a known limitation with the X86Board</a>, we cannot use a memory system greater than 3GiB.\nWe therefore must set the size.</p>\n<p>Next we setup the <em>processor</em>:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">processor</span> <span class=\"o\">=</span> <span class=\"n\">SimpleSwitchableProcessor</span><span class=\"p\">(</span>\n    <span class=\"n\">starting_core_type</span><span class=\"o\">=</span><span class=\"n\">CPUTypes</span><span class=\"p\">.</span><span class=\"n\">KVM</span><span class=\"p\">,</span>\n    <span class=\"n\">switch_core_type</span><span class=\"o\">=</span><span class=\"n\">CPUTypes</span><span class=\"p\">.</span><span class=\"n\">TIMING</span><span class=\"p\">,</span>\n    <span class=\"n\">isa</span><span class=\"o\">=</span><span class=\"n\">ISA</span><span class=\"p\">.</span><span class=\"n\">X86</span><span class=\"p\">,</span>\n    <span class=\"n\">num_cores</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n</code></pre></div></div>\n<p>Here we are utilizing the gem5 standard library\u2019s special <code class=\"language-plaintext highlighter-rouge\">SimpleSwitchableProcessor</code>.\nThis processor can be used for simulations in which a user wants to switch out one type of core for another during a simulation.\nThe <code class=\"language-plaintext highlighter-rouge\">starting_core_type</code> parameter specifies which CPU type to start a simulation with.\nIn this case a KVM core.\n<strong>(Note: If your host system does not support KVM, this simulation will not run. You must change this to another CPU type, such as <code class=\"language-plaintext highlighter-rouge\">CPUTypes.ATOMIC</code>)</strong>\nThe <code class=\"language-plaintext highlighter-rouge\">switch_core_type</code> parameter specifies which CPU type to switch to in a simulation.\nIn this case we\u2019ll be switching from KVM cores to TIMING cores.\nThe final parameter, <code class=\"language-plaintext highlighter-rouge\">num_cores</code>, specifies the number of cores within the processor.</p>\n<p>With this processor a user can call <code class=\"language-plaintext highlighter-rouge\">processor.switch()</code> to switch to and from the starting cores and the switch cores, which we will demonstrate later on in this tutorial.</p>\n<p>Next we add these components to the <em>board</em>:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">board</span> <span class=\"o\">=</span> <span class=\"n\">X86Board</span><span class=\"p\">(</span>\n    <span class=\"n\">clk_freq</span><span class=\"o\">=</span><span class=\"s\">\"3GHz\"</span><span class=\"p\">,</span>\n    <span class=\"n\">processor</span><span class=\"o\">=</span><span class=\"n\">processor</span><span class=\"p\">,</span>\n    <span class=\"n\">memory</span><span class=\"o\">=</span><span class=\"n\">memory</span><span class=\"p\">,</span>\n    <span class=\"n\">cache_hierarchy</span><span class=\"o\">=</span><span class=\"n\">cache_hierarchy</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n</code></pre></div></div>\n<p>Here we use the <code class=\"language-plaintext highlighter-rouge\">X86Board</code>.\nThis is a board used to simulate a typical X86 system in full-system mode.\nAs a minimum, the board needs the <code class=\"language-plaintext highlighter-rouge\">clk_freq</code>, <code class=\"language-plaintext highlighter-rouge\">processor</code>, <code class=\"language-plaintext highlighter-rouge\">memory</code>, and <code class=\"language-plaintext highlighter-rouge\">cache_hierarchy</code> parameters specified.\nThis finalizes our system design.</p>\n<p>Now we set the workload to run on the system:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">workload</span> <span class=\"o\">=</span> <span class=\"n\">obtain_resource</span><span class=\"p\">(</span><span class=\"s\">\"x86-ubuntu-24.04-boot-with-systemd\"</span><span class=\"p\">)</span>\n<span class=\"n\">board</span><span class=\"p\">.</span><span class=\"n\">set_workload</span><span class=\"p\">(</span><span class=\"n\">workload</span><span class=\"p\">)</span>\n</code></pre></div></div>\n<p>The <code class=\"language-plaintext highlighter-rouge\">obtain_resource</code> function acquires the X86 Ubuntu 24.04 boot workload.\nThis workload contains a kernel resource, parameters to the kernel, a disk image resource, and a string indicating the underlying function that gem5 uses when <code class=\"language-plaintext highlighter-rouge\">board.set_workload()</code> is called.\nYou can see these details under the <a href=\"https://resources.gem5.org/resources/x86-ubuntu-24.04-boot-with-systemd/raw?database=gem5-resources&amp;version=3.0.0\">Raw</a> tab of of the gem5 Resources website page for this workload.</p>\n<p>You can also use <code class=\"language-plaintext highlighter-rouge\">set_kernel_disk_workload()</code> instead of <code class=\"language-plaintext highlighter-rouge\">set_workload()</code> and set the disk image and kernel resources separately.\nThis can be used when you want to use your own resources, or a combination of resources that is not provided as a workload on <a href=\"resources.gem5.org\">the gem5 resources website</a>.</p>\n<p><strong>Note: If a user wishes to use their own resource (that is, a resource not prebuilt as part of gem5-resources), they may follow the tutorial <a href=\"../general_docs/gem5_resources\">here</a>. A tutorial is also available at the <a href=\"https://bootcamp.gem5.org/#02-Using-gem5/02-gem5-resources\">2024 gem5 bootcamp website</a></strong></p>\n<p>When using the <code class=\"language-plaintext highlighter-rouge\">set_kernel_disk_workload()</code> function, you can also pass an optional <code class=\"language-plaintext highlighter-rouge\">readfile_contents</code> argument.\nThis will be run as a bash script after the system boots up, and can be used to launch a benchmark after the system boots if the disk image has benchmarks installed.\nAn example can be found <a href=\"https://resources.gem5.org/resources/x86-ubuntu-24.04-npb-ua-b/raw?database=gem5-resources&amp;version=2.0.0\">here</a></p>\n<p>Finally, we specify how the simulation is to be run with the following:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">def</span> <span class=\"nf\">exit_event_handler</span><span class=\"p\">():</span>\n    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"First exit: kernel booted\"</span><span class=\"p\">)</span>\n    <span class=\"k\">yield</span> <span class=\"bp\">False</span>  <span class=\"c1\"># gem5 is now executing systemd startup\n</span>    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"Second exit: Started `after_boot.sh` script\"</span><span class=\"p\">)</span>\n    <span class=\"c1\"># The after_boot.sh script is executed after the kernel and systemd have\n</span>    <span class=\"c1\"># booted.\n</span>    <span class=\"c1\"># Here we switch the CPU type to Timing.\n</span>    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"Switching to Timing CPU\"</span><span class=\"p\">)</span>\n    <span class=\"n\">processor</span><span class=\"p\">.</span><span class=\"n\">switch</span><span class=\"p\">()</span>\n    <span class=\"k\">yield</span> <span class=\"bp\">False</span>  <span class=\"c1\"># gem5 is now executing the `after_boot.sh` script\n</span>    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"Third exit: Finished `after_boot.sh` script\"</span><span class=\"p\">)</span>\n    <span class=\"c1\"># The after_boot.sh script will run a script if it is passed via\n</span>    <span class=\"c1\"># readfile_contents. This is the last exit event before the simulation exits.\n</span>    <span class=\"k\">yield</span> <span class=\"bp\">True</span>\n\n\n<span class=\"n\">simulator</span> <span class=\"o\">=</span> <span class=\"n\">Simulator</span><span class=\"p\">(</span>\n    <span class=\"n\">board</span><span class=\"o\">=</span><span class=\"n\">board</span><span class=\"p\">,</span>\n    <span class=\"n\">on_exit_event</span><span class=\"o\">=</span><span class=\"p\">{</span>\n        <span class=\"n\">ExitEvent</span><span class=\"p\">.</span><span class=\"n\">EXIT</span><span class=\"p\">:</span> <span class=\"n\">exit_event_handler</span><span class=\"p\">(),</span>\n    <span class=\"p\">},</span>\n<span class=\"p\">)</span>\n<span class=\"n\">simulator</span><span class=\"p\">.</span><span class=\"n\">run</span><span class=\"p\">()</span>\n</code></pre></div></div>\n<p>The important thing to note here is the <code class=\"language-plaintext highlighter-rouge\">on_exit_event</code> argument.\nHere we can override default behavior.</p>\n<p>The <code class=\"language-plaintext highlighter-rouge\">on_exit_event</code> parameter is a Python dictionary of exit events and <a href=\"https://wiki.python.org/moin/Generators\">Python generators</a>.\nIn this tutorial we use the <code class=\"language-plaintext highlighter-rouge\">exit_event_handler</code> generator to handle exit events of the type <code class=\"language-plaintext highlighter-rouge\">ExitEvent.EXIT</code>.\nThere are three <code class=\"language-plaintext highlighter-rouge\">EXIT</code> exit events in the Ubuntu 24.04 disk image resource used by the workload.\nIf an exit event handler is not defined, the simulation will end after the first exit event, which takes place after the kernel finishes booting.\nYielding <code class=\"language-plaintext highlighter-rouge\">False</code> allows the simulation to continue, while yielding <code class=\"language-plaintext highlighter-rouge\">True</code> ends the simulation.\nAfter the second exit event, we switch the cores from KVM to TIMING, then yield <code class=\"language-plaintext highlighter-rouge\">False</code> to continue the simulation.\nAfter the third exit event, we yield <code class=\"language-plaintext highlighter-rouge\">True</code>, ending the simulation.</p>\n<p>This completes the setup of our script. To execute the script we run:</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>./build/ALL/gem5.opt x86-ubuntu-run.py\n</code></pre></div></div>\n<p>If you are using a pre-built binary, you can execute the simulation with:</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>gem5 hello-world.py\n</code></pre></div></div>\n<p>You can see the output of the simulator in <code class=\"language-plaintext highlighter-rouge\">m5out/system.pc.com_1.device</code>.</p>\n<p>Below is the configuration script in full.\nIt mirrors closely the example script at <code class=\"language-plaintext highlighter-rouge\">configs/example/gem5_library/x86-ubuntu-run-with-kvm.py</code> in the gem5 repository.</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">gem5.coherence_protocol</span> <span class=\"kn\">import</span> <span class=\"n\">CoherenceProtocol</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.boards.x86_board</span> <span class=\"kn\">import</span> <span class=\"n\">X86Board</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.cachehierarchies.ruby.mesi_two_level_cache_hierarchy</span> <span class=\"kn\">import</span> <span class=\"p\">(</span>\n    <span class=\"n\">MESITwoLevelCacheHierarchy</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.memory.single_channel</span> <span class=\"kn\">import</span> <span class=\"n\">SingleChannelDDR3_1600</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.processors.cpu_types</span> <span class=\"kn\">import</span> <span class=\"n\">CPUTypes</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.components.processors.simple_switchable_processor</span> <span class=\"kn\">import</span> <span class=\"p\">(</span>\n    <span class=\"n\">SimpleSwitchableProcessor</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.isas</span> <span class=\"kn\">import</span> <span class=\"n\">ISA</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.resources.resource</span> <span class=\"kn\">import</span> <span class=\"n\">obtain_resource</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.simulate.exit_event</span> <span class=\"kn\">import</span> <span class=\"n\">ExitEvent</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.simulate.simulator</span> <span class=\"kn\">import</span> <span class=\"n\">Simulator</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gem5.utils.requires</span> <span class=\"kn\">import</span> <span class=\"n\">requires</span>\n\n<span class=\"n\">requires</span><span class=\"p\">(</span>\n    <span class=\"n\">isa_required</span><span class=\"o\">=</span><span class=\"n\">ISA</span><span class=\"p\">.</span><span class=\"n\">X86</span><span class=\"p\">,</span>\n    <span class=\"n\">coherence_protocol_required</span><span class=\"o\">=</span><span class=\"n\">CoherenceProtocol</span><span class=\"p\">.</span><span class=\"n\">MESI_TWO_LEVEL</span><span class=\"p\">,</span>\n    <span class=\"n\">kvm_required</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">cache_hierarchy</span> <span class=\"o\">=</span> <span class=\"n\">MESITwoLevelCacheHierarchy</span><span class=\"p\">(</span>\n    <span class=\"n\">l1d_size</span><span class=\"o\">=</span><span class=\"s\">\"32KiB\"</span><span class=\"p\">,</span>\n    <span class=\"n\">l1d_assoc</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">,</span>\n    <span class=\"n\">l1i_size</span><span class=\"o\">=</span><span class=\"s\">\"32KiB\"</span><span class=\"p\">,</span>\n    <span class=\"n\">l1i_assoc</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">,</span>\n    <span class=\"n\">l2_size</span><span class=\"o\">=</span><span class=\"s\">\"256KiB\"</span><span class=\"p\">,</span>\n    <span class=\"n\">l2_assoc</span><span class=\"o\">=</span><span class=\"mi\">16</span><span class=\"p\">,</span>\n    <span class=\"n\">num_l2_banks</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">memory</span> <span class=\"o\">=</span> <span class=\"n\">SingleChannelDDR3_1600</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"o\">=</span><span class=\"s\">\"2GiB\"</span><span class=\"p\">)</span>\n\n<span class=\"n\">processor</span> <span class=\"o\">=</span> <span class=\"n\">SimpleSwitchableProcessor</span><span class=\"p\">(</span>\n    <span class=\"n\">starting_core_type</span><span class=\"o\">=</span><span class=\"n\">CPUTypes</span><span class=\"p\">.</span><span class=\"n\">KVM</span><span class=\"p\">,</span>\n    <span class=\"n\">switch_core_type</span><span class=\"o\">=</span><span class=\"n\">CPUTypes</span><span class=\"p\">.</span><span class=\"n\">TIMING</span><span class=\"p\">,</span>\n    <span class=\"n\">isa</span><span class=\"o\">=</span><span class=\"n\">ISA</span><span class=\"p\">.</span><span class=\"n\">X86</span><span class=\"p\">,</span>\n    <span class=\"n\">num_cores</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">board</span> <span class=\"o\">=</span> <span class=\"n\">X86Board</span><span class=\"p\">(</span>\n    <span class=\"n\">clk_freq</span><span class=\"o\">=</span><span class=\"s\">\"3GHz\"</span><span class=\"p\">,</span>\n    <span class=\"n\">processor</span><span class=\"o\">=</span><span class=\"n\">processor</span><span class=\"p\">,</span>\n    <span class=\"n\">memory</span><span class=\"o\">=</span><span class=\"n\">memory</span><span class=\"p\">,</span>\n    <span class=\"n\">cache_hierarchy</span><span class=\"o\">=</span><span class=\"n\">cache_hierarchy</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">workload</span> <span class=\"o\">=</span> <span class=\"n\">obtain_resource</span><span class=\"p\">(</span><span class=\"s\">\"x86-ubuntu-24.04-boot-with-systemd\"</span><span class=\"p\">)</span>\n<span class=\"n\">board</span><span class=\"p\">.</span><span class=\"n\">set_workload</span><span class=\"p\">(</span><span class=\"n\">workload</span><span class=\"p\">)</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">exit_event_handler</span><span class=\"p\">():</span>\n    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"First exit: kernel booted\"</span><span class=\"p\">)</span>\n    <span class=\"k\">yield</span> <span class=\"bp\">False</span>  <span class=\"c1\"># gem5 is now executing systemd startup\n</span>    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"Second exit: Started `after_boot.sh` script\"</span><span class=\"p\">)</span>\n    <span class=\"c1\"># The after_boot.sh script is executed after the kernel and systemd have\n</span>    <span class=\"c1\"># booted.\n</span>    <span class=\"c1\"># Here we switch the CPU type to Timing.\n</span>    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"Switching to Timing CPU\"</span><span class=\"p\">)</span>\n    <span class=\"n\">processor</span><span class=\"p\">.</span><span class=\"n\">switch</span><span class=\"p\">()</span>\n    <span class=\"k\">yield</span> <span class=\"bp\">False</span>  <span class=\"c1\"># gem5 is now executing the `after_boot.sh` script\n</span>    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"Third exit: Finished `after_boot.sh` script\"</span><span class=\"p\">)</span>\n    <span class=\"c1\"># The after_boot.sh script will run a script if it is passed via\n</span>    <span class=\"c1\"># readfile_contents. This is the last exit event before the simulation exits.\n</span>    <span class=\"k\">yield</span> <span class=\"bp\">True</span>\n\n\n<span class=\"n\">simulator</span> <span class=\"o\">=</span> <span class=\"n\">Simulator</span><span class=\"p\">(</span>\n    <span class=\"n\">board</span><span class=\"o\">=</span><span class=\"n\">board</span><span class=\"p\">,</span>\n    <span class=\"n\">on_exit_event</span><span class=\"o\">=</span><span class=\"p\">{</span>\n        <span class=\"n\">ExitEvent</span><span class=\"p\">.</span><span class=\"n\">EXIT</span><span class=\"p\">:</span> <span class=\"n\">exit_event_handler</span><span class=\"p\">(),</span>\n    <span class=\"p\">},</span>\n<span class=\"p\">)</span>\n<span class=\"n\">simulator</span><span class=\"p\">.</span><span class=\"n\">run</span><span class=\"p\">()</span>\n\n</code></pre></div></div>\n<p>To recap what we learned in this tutorial:</p>\n<ul>\n<li>The <code class=\"language-plaintext highlighter-rouge\">requires</code> function can be used to specify the gem5 and host requirements for a script.</li>\n<li>The <code class=\"language-plaintext highlighter-rouge\">SimpleSwitchableProcessor</code> can be used to create a setup in which cores can be switched out for others.</li>\n<li>The <code class=\"language-plaintext highlighter-rouge\">X86Board</code> can be used to set up full-system simulations.</li>\n<li>Its workload can be set via either <code class=\"language-plaintext highlighter-rouge\">set_workload()</code> for workload resources, or via <code class=\"language-plaintext highlighter-rouge\">set_kernel_disk_workload()</code> for separate kernel and disk image resources.</li>\n<li>The <code class=\"language-plaintext highlighter-rouge\">set_kernel_disk_workload()</code> function accepts a <code class=\"language-plaintext highlighter-rouge\">readfile_contents</code> argument.\nThis is processed as a script to be executed after the system boot is complete.</li>\n<li>The <code class=\"language-plaintext highlighter-rouge\">Simulator</code> module allows for the overriding of exit events using Python generators.</li>\n</ul>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/gem5-stdlib/hello-world-tutorial\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/gem5-stdlib/develop-own-components-tutorial\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/architecture_support/",
        "title": "Architecture Support",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"architecture-support\">Architecture Support</h1>\n<p class=\"outdated-notice\">The information and hyperlinks in this page may not be accurate.</p>\n<h2 id=\"alpha\">Alpha</h2>\n<p>Gem5 models a DEC Tsunami based system. \nIn addition to the normal Tsunami system that support 4 cores, we have an extension which supports 64 cores (a custom PALcode and patched Linux kernel is required). \nThe simulated system looks like an Alpha 21264 including the BWX, MVI, FIX, and CIX to user level code. \nFor historical reasons the processor executes EV5 based PALcode.</p>\n<p>It can boot unmodified Linux 2.4/2.6, FreeBSD, or L4Ka::Pistachio as well as applications in syscall emulation mode. \nMany years ago it was possible to boot HP/Compaq\u2019s Tru64 5.1 operating system. \nWe no longer actively maintain that capability, however, and it does not currently work.</p>\n<h2 id=\"arm\">ARM</h2>\n<p>The ARM Architecture models within gem5 support an <a href=\"https://developer.arm.com/docs/den0024/latest/armv8-a-architecture-and-processors/armv8-a\">ARMv8-A</a> profile of the ARM\u00ae architecture with multi-processor extensions. \nThis includes both AArch32 and AArch64 state. \nIn AArch32, this include support for <a href=\"https://www.embedded.com/introduction-to-arm-thumb/\">Thumb\u00ae</a>, Thumb-2, VFPv3 (32 double register variant) and <a href=\"https://developer.arm.com/architectures/instruction-sets/simd-isas/neon\">NEON\u2122</a>, and Large Physical Address Extensions (LPAE). \nOptional features of the architecture that are not currently supported are <a href=\"https://developer.arm.com/ip-products/security-ip/trustzone\">TrustZone\u00ae</a>, ThumbEE, <a href=\"https://en.wikipedia.org/wiki/Jazelle\">Jazelle\u00ae</a>, and <a href=\"https://developer.arm.com/docs/100942/0100/aarch64-virtualization\">Virtualization</a>.</p>\n<p>In full system mode gem5 is able to boot uni- or multi-processor Linux and bare metal applications built with ARM\u2019s compilers. \nNewer Linux versions work out of the box (if used with gem5\u2019s DTBs) we also provide gem5-specific Linux kernels with custom configurations and custom drivers Additionally, statically linked Linux binaries can be run in ARM\u2019s syscall emulation mode.</p>\n<h2 id=\"power\">POWER</h2>\n<p>Support for the POWER ISA within gem5 is currently limited to syscall emulation only and is based on the <a href=\"http://kib.kiev.ua/x86docs/POWER/PowerISA_V2.06B_V2_PUBLIC.pdf\">POWER ISA v2.06 B Book</a>.\nA big-endian, 32-bit processor is modeled. \nMost common instructions are available (enough to run all the SPEC CPU2000 integer benchmarks). \nFloating point instructions are available but support may be patchy. \nIn particular, the Floating-Point Status and Control Register (FPSCR) is generally not updated at all. \nThere is no support for vector instructions.</p>\n<p>Full system support for POWER would require a significant amount of effort and is not currently being developed. \nHowever, if there is interest in pursuing this, a set of patches-in-progress that make a start towards this can be obtained from <a href=\"mailto:timothy.jones@cl.cam.ac.uk\">Tim</a>.</p>\n<h2 id=\"sparc\">SPARC</h2>\n<p>The gem5 simulator models a single core of a UltraSPARC T1 processor (UltraSPARC Architecture 2005).</p>\n<p>It can boot Solaris like the Sun T1 Architecture simulator tools do (building the hypervisor with specific defines and using the HSMID virtual disk driver). \nMultiprocessor support was never completed for full-system SPARC. \nWith syscall emulation gem5 supports running Linux or Solaris binaries. \nNew versions of Solaris no longer support generating statically compiled binaries which gem5 requires.</p>\n<h2 id=\"x86\">x86</h2>\n<p>X86 support within the gem5 simulator includes a generic x86 CPU with 64 bit extensions, more similar to AMD\u2019s version of the architecture than Intel\u2019s but not strictly like either. \nUnmodified versions of the Linux kernel can be booted in UP and SMP configurations, and patches are available for speeding up boot. \nSSE and 3dnow are implemented, but the majority of x87 floating point is not. \nMost effort has been focused on 64 bit mode, but compatibility mode and legacy modes have some support as well. \nReal mode works enough to bootstrap an AP, but hasn\u2019t been extensively tested. \nThe features of the architecture that are exercised by Linux and standard Linux binaries are implemented and should work, but other areas may not. \n64 and 32 bit Linux binaries are supported in syscall emulation mode.</p>\n<h2 id=\"mips\">MIPS</h2>\n<h2 id=\"risc-v\">RISC-V</h2>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/architecture_support/arm_implementation/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/architecture_support/isa_parser/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/architecture_support/arm_implementation/",
        "title": "ARM Implementation",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"arm-implementation\">ARM Implementation</h1>\n<h2 id=\"supported-features-and-modes\">Supported features and modes</h2>\n<p>The ARM Architecture models within gem5 support an <a href=\"https://developer.arm.com/docs/den0024/latest/armv8-a-architecture-and-processors/armv8-a\">ARMv8.0-A</a> profile of the ARM\u00ae architecture with multi-processor extensions.\nThis includes both AArch32 and AArch64 state at all ELs. This basically means supporting:</p>\n<ul>\n<li><a href=\"https://developer.arm.com/docs/100942/0100/aarch64-virtualization\">EL2: Virtualization</a></li>\n<li><a href=\"https://developer.arm.com/ip-products/security-ip/trustzone\">EL3: TrustZone\u00ae</a></li>\n</ul>\n<p>The baseline model is ARMv8.0 compliant, we also support some mandatory/optional ARMv8.x features (with x &gt; 0)</p>\n<h3 id=\"from-gem5-v212\">From gem5 v21.2</h3>\n<p>The best way to get a synced version of Arm architectural features is to have a look at the <a href=\"https://github.com/gem5/gem5/blob/develop/src/arch/arm/ArmSystem.py\">ArmExtension</a> enum\nused by the release object and the available example releases provided within the same file.</p>\n<p>A user can choose one of the following options:</p>\n<ul>\n<li>Use the default release</li>\n<li>Use another example release (e.g. Armv82)</li>\n<li>Generate a custom release from the available ArmExtension enum values</li>\n</ul>\n<h3 id=\"before-gem5-v212\">Before gem5 v21.2</h3>\n<p>The best way to get a synced version of Arm architectural features is to have a look at Arm ID registers and boolean values:</p>\n<ul>\n<li><a href=\"https://github.com/gem5/gem5/blob/v21.1.0.2/src/arch/arm/ArmISA.py\">src/arch/arm/ArmISA.py</a></li>\n<li><a href=\"https://github.com/gem5/gem5/blob/v21.1.0.2/src/arch/arm/ArmSystem.py\">src/arch/arm/ArmSystem.py</a></li>\n</ul>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/gem5-apis/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/architecture_support/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/architecture_support/isa_parser/",
        "title": "ISA Parser",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"isa-parser\">ISA Parser</h1>\n<p>The gem5 ISA description language is a custom language designed specifically for generating the class definitions and decoder function needed by gem5. This section provides a practical, informal overview of the language itself. A formal grammar for the language is embedded in the \u201cyacc\u201d portion of the parser (look for the functions starting with p_ in isa_parser.py). A second major component of the parser processes C-like code specifications to extract instruction characteristics; this aspect is covered in the section <a href=\"#code-parsing\">Code parsing</a>.\nAt the highest level, an ISA description file is divided into two parts: a declarations section and a decode section. The decode section specifies the structure of the decoder and defines the specific instructions returned by the decoder. The declarations section defines the global information (classes, instruction formats, templates, etc.) required to support the decoder. Because the decode section is the focus of the description file, we will begin the discussion there.</p>\n<h2 id=\"the-decode-section\">The decode section</h2>\n<p>The decode section of the description is a set of nested decode blocks. A decode block specifies a field of a machine instruction to decode and the result to be provided for particular values of that field. A decode block is similar to a C switch statement in both syntax and semantics. In fact, each decode block in the description file generates a switch statement in the resulting decode function.\nLet\u2019s begin with a (slightly oversimplified) example:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>decode OPCODE {\n  0: add({{ Rc = Ra + Rb; }});\n  1: sub({{ Rc = Ra - Rb; }});\n}\n</code></pre></div></div>\n<p>A decode block begins with the keyword <code class=\"language-plaintext highlighter-rouge\">decode</code> followed by the name of the instruction field to decode. The latter must be defined in the declarations section of the file using a bitfield definition (see <a href=\"#bitfield-definitions\">Bitfield definitions</a>). The remainder of the decode block is a list of statements enclosed in braces. The most common statement is an integer constant and a colon followed by an instruction definition. This statement corresponds to a \u2018case\u2019 statement in a C switch (but note that the \u2018case\u2019 keyword is omitted for brevity). A comma-separated list of integer constants may be used to allow a single decode statement to apply to any of a set of bitfield values.</p>\n<p>Instruction definitions are similar in syntax to C function calls, with the instruction mnemonic taking the place of the function name. The comma-separated arguments are used when processing the instruction definition. In the example above, the instruction definitions each take a single argument, a \u2018\u2018code literal\u2019\u2019. A code literal is operationally similar to a string constant, but is delimited by double braces (<code class=\"language-plaintext highlighter-rouge\">{{</code> and <code class=\"language-plaintext highlighter-rouge\">}}</code>). Code literals may span multiple lines without escaping the end-of-line characters. No backslash escape processing is performed (e.g., <code class=\"language-plaintext highlighter-rouge\">\\t</code> is taken literally, and does not produce a tab). The delimiters were chosen so that C-like code contained in a code literal would be formatted nicely by emacs C-mode.</p>\n<p>A decode statement may specify a nested decode block in place of an instruction definition. In this case, if the bitfield specified by the outer block matches the given value(s), the bitfield specified by the inner block is examined and an additional switch is performed.</p>\n<p>It is also legal, as in C, to use the keyword <code class=\"language-plaintext highlighter-rouge\">default</code> in place of an integer constant to define a default action. However, it is more common to use the decode-block default syntax discussed in the section <a href=\"#decode-block-defaults\">Decode block defaults</a> below.</p>\n<h3 id=\"specifying-instruction-formats\">Specifying instruction formats</h3>\n<p>When the ISA description file is processed, each instruction definition does in fact invoke a function call to generate the appropriate C++ code for the decode file. The function that is invoked is determined by the instruction format. The instruction format determines the number and type of the arguments given to the instruction definition, and how they are processed to generate the corresponding output. Note that the term \u201cinstruction format\u201d as used in this context refers solely to one of these definition-processing functions, and does not necessarily map one-to-one to the machine instruction formats defined by the ISA.\nThe one oversimplification in the previous example is that no instruction format was specified. As a result, the parser does not know how to process the instruction definitions.</p>\n<p>Instruction formats can be specified in two ways. An explicit format specification can be given before the mnemonic, separated by a double colon (::), as follows:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>decode OPCODE {\n  0: Integer::add({{ Rc = Ra + Rb; }});\n  1: Integer::sub({{ Rc = Ra - Rb; }});\n}\n</code></pre></div></div>\n<p>In this example, both instruction definitions will be processed using the format Integer. A more common approach specifies the format for a set of definitions using a format block, as follows:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>decode OPCODE {\n  format Integer {\n    0: add({{ Rc = Ra + Rb; }});\n    1: sub({{ Rc = Ra - Rb; }});\n  }\n}\n</code></pre></div></div>\n<p>In this example, the format \u201cInteger\u201d applies to all of the instruction definitions within the inner braces. The two examples are thus functionally equivalent. There are few restrictions on the use of format blocks. A format block may include only a subset of the statements in a decode block. Format blocks and explicit format specifications may be mixed freely, with the latter taking precedence. Format and decode blocks can be nested within each other arbitrarily. Note that a closing brace will always bind with the nearest format or decode block, making it syntactically impossible to generate format or decode blocks that do not nest fully inside the enclosing block.</p>\n<p>At any point where an instruction definition occurs without an explicit format specification, the format associated with the innermost enclosing format block will be used. If a definition occurs with no explicit format and no enclosing format block, a runtime error will be raised.</p>\n<h3 id=\"decode-block-defaults\">Decode block defaults</h3>\n<p>Default cases for decode blocks can be specified by <code class=\"language-plaintext highlighter-rouge\">default:</code> labels, as in C switch statements. However, it is common in ISA descriptions that unspecified cases correspond to unknown or illegal instruction encodings. To avoid the requirement of a <code class=\"language-plaintext highlighter-rouge\">default:</code> case in every decode block, the language allows an alternate default syntax that specifies a default case for the current decode block and any nested decode block with no explicit default. This alternate default is specified by giving the <code class=\"language-plaintext highlighter-rouge\">default</code> keyword and an instruction definition after the bitfield specification (prior to the opening brace). Specifying the outermost decode block as follows:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>decode OPCODE default Unknown::unknown() {\n   [...]\n}\n</code></pre></div></div>\n<p>is thus (nearly) equivalent to adding <code class=\"language-plaintext highlighter-rouge\">default: Unknown::unknown();</code> inside every decode block that does not otherwise specify a default case.</p>\n<p><em>Note: The appropriate format definition (see _<a href=\"#format-definitions\">Format definitions</a></em>) is invoked each time an instruction definition is encountered.  Thus there is a semantic difference between having a single block-level default and a default within each nested block, which is that the former will invoke the format definition once, while the latter could result in multiple invocations of the format definition.  If the format definition generates header, decoder, or exec output, then that output will be included multiple times in the corresponding files, which typically leads to multiple definition errors when the C++ gets compiled.  If it is absolutely necessary to invoke the format definition for a single instruction multiple times, the format definition should be written to produce <em>only</em> decode-block output, and all needed header, decoder, and exec output should be produced once using_ <code class=\"language-plaintext highlighter-rouge\">output</code> <em>blocks (see _<a href=\"#output-blocks]\">Output blocks</a></em>)._</p>\n<h3 id=\"preprocessor-directive-handling\">Preprocessor directive handling</h3>\n<p>The decode block may also contain C preprocessor directives. These directives are not processed by the parser; instead, they are passed through to the C++ output to be processed when the C++ decoder is compiled. The parser does not recognize any specific directives; any line with a # in the first column is treated as a preprocessor directive.\nThe directives are copied to all of the output streams (the header, the decoder, and the execute files; see <a href=\"#format-definitions\">Format definitions</a>. The directives maintain their position relative to the code generated by the instruction definitions within the decode block. The net result is that, for example, #ifdef/#endif pairs that surround a set of instruction definitions will enclose both the declarations generated by those definitions and the corresponding case statements within the decode function. Thus #ifdef and similar constructs can be used to delineate instruction definitions that will be conditionally compiled into the simulator based on preprocessor symbols (e.g., FULL_SYSTEM). It should be emphasized that #ifdef does not affect the ISA description parser. In an #ifdef/#else/#endif construct, all of the instruction definitions in both parts of the conditional will be processed. Only during the subsequent C++ compilation of the decoder will one or the other set of definitions be selected.</p>\n<h2 id=\"the-declaration-section\">The declaration section</h2>\n<p>As mentioned above, the decode section of the ISA description (consisting of a single outer decode block) is preceded by the declarations section. The primary purpose of the declarations section is to define the instruction formats and other supporting elements that will be used in the decode block, as well as supporting C++ code that is passed almost verbatim to the generated output.\nThis section describes the components that appear in the declaration section: <a href=\"#format-definitions\">Format definitions</a>, <a href=\"#template-definitions\">Template definitions</a>, <a href=\"#output-blocks\">Output blocks</a>, <a href=\"#let-blocks\">Let blocks</a>, <a href=\"#bitfield-definitions\">Bitfield definitions</a>, <a href=\"#operand-and-operand-type-definitions\">Operand and operand type definitions</a>, and <a href=\"#namespace-declaration\">Namespace declaration</a>.</p>\n<h3 id=\"format-definitions\">Format definitions</h3>\n<p>An instruction format is basically a Python function that takes the arguments supplied by an instruction definition (found inside a decode block) and generates up to four pieces of C++ code. The pieces of C++ code are distinguished by where they appear in the generated output.</p>\n<ol>\n<li>The \u2018\u2018header output\u2019\u2019 goes in the header file (decoder.hh) that is included in all the generated source files (decoder.cc and all the per-CPU-model execute .cc files). The header output typically contains the C++ class declaration(s) (if any) that correspond to the instruction.</li>\n<li>The \u2018\u2018decoder output\u2019\u2019 goes before the decode function in the same source file (decoder.cc). This output typically contains definitions that do not need to be visible to the <code class=\"language-plaintext highlighter-rouge\">execute()</code> methods: inline constructor definitions, non-inline method definitions (e.g., for disassembly), etc.</li>\n<li>The \u2018\u2018exec output\u2019\u2019 contains per-CPU model definitions, i.e., the <code class=\"language-plaintext highlighter-rouge\">execute()</code> methods for the instruction class.</li>\n<li>The \u2018\u2018decode block\u2019\u2019 contains a statement or block of statements that go into the decode function (in the body of the corresponding case statement). These statements take control once the bit pattern specified by the decode block is recognized, and are responsible for returning an appropriate instruction object.</li>\n</ol>\n<p>The syntax for defining an instruction format is as follows:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>def format FormatName(arg1, arg2) {{\n    [code omitted]\n}};\n</code></pre></div></div>\n<p>In this example, the format is named \u201cFormatName\u201d. (By convention, instruction format names begin with a capital letter and use mixed case.) Instruction definitions using this format will be expected to provide two arguments (<code class=\"language-plaintext highlighter-rouge\">arg1</code> and <code class=\"language-plaintext highlighter-rouge\">arg2</code>). The language also supports the Python variable-argument mechanism: if the final parameter begins with an asterisk (e.g., <code class=\"language-plaintext highlighter-rouge\">*rest</code>), it receives a list of all the otherwise unbound arguments from the call site.</p>\n<p>Note that the next-to-last syntactic token in the format definition (prior to the semicolon) is simply a code literal (string constant), as described above. In this case, the text within the code literal is a Python code block. This Python code will be called at each instruction definition that uses the specified format.</p>\n<p>In addition to the explicit arguments, the Python code is supplied with two additional parameters: <code class=\"language-plaintext highlighter-rouge\">name</code>, which is bound to the instruction mnemonic, and <code class=\"language-plaintext highlighter-rouge\">Name</code>, which is the mnemonic with the first letter capitalized (useful for forming C++ class names based on the mnemonic).</p>\n<p>The format code block specifies the generated code by assigning strings to four special variables: <code class=\"language-plaintext highlighter-rouge\">header_output</code>, <code class=\"language-plaintext highlighter-rouge\">decoder_output</code>, <code class=\"language-plaintext highlighter-rouge\">exec_output</code>, and <code class=\"language-plaintext highlighter-rouge\">decode_block</code>. Assignment is optional; for any of these variables that does not receive a value, no code will be generated for the corresponding section. These strings may be generated by whatever method is convenient. In practice, nearly all instruction formats use the support functions provided by the ISA description parser to specialize code templates based on characteristics extracted automatically from C-like code snippets. Discussion of these features is deferred to the <a href=\"#code-parsing\">Code parsing</a> page.</p>\n<p>Although the ISA description is completely independent of any specific simulator CPU model, some C++ code (particularly the exec output) must be specialized slightly for each model. This specialization is handled by automatic substitution of CPU-model-specific symbols. These symbols start with <code class=\"language-plaintext highlighter-rouge\">CPU_</code> and are treated specially by the parser. Currently there is only one model-specific symbol, <code class=\"language-plaintext highlighter-rouge\">CPU_exec_context</code>, which evaluates to the model\u2019s execution context class name. As with templates (see <a href=\"#template-definitions\">Template definitions</a>), references to CPU-specific symbols use Python key-based format strings; a reference to the <code class=\"language-plaintext highlighter-rouge\">CPU_exec_context</code> symbol thus appears in a string as <code class=\"language-plaintext highlighter-rouge\">%(CPU_exec_context)s</code>.</p>\n<p>If a string assigned to <code class=\"language-plaintext highlighter-rouge\">header_output</code>, <code class=\"language-plaintext highlighter-rouge\">decoder_output</code>, or <code class=\"language-plaintext highlighter-rouge\">decode_block</code> contains a CPU-specific symbol reference, the string is replicated once for each CPU model, and each instance has its CPU-specific symbols substituted according to that model. The resulting strings are then concatenated to form the final output. Strings assigned to <code class=\"language-plaintext highlighter-rouge\">exec_output</code> are always replicated and subsituted once for each CPU model, regardless of whether they contain CPU-specific symbol references. The instances are not concatenated, but are tracked separately, and are placed in separate per-CPU-model files (e.g., simple_cpu_exec.cc).</p>\n<h3 id=\"template-definitions\">Template definitions</h3>\n<p>As discussed in section Format definitions above, the purpose of an instruction format is to process the arguments of an instruction definition and generate several pieces of C++ code. These code pieces are usually generated by specializing a code template. The description language provides a simple syntax for defining these templates: the keywords <code class=\"language-plaintext highlighter-rouge\">def template</code>, the template name, the template body (a code literal), and a semicolon. By convention, template names start with a capital letter, use mixed case, and end with \u201cDeclare\u201d (for declaration (header output) templates), \u201cDecode\u201d (for decode-block templates), \u201cConstructor\u201d (for decoder output templates), or \u201cExecute\u201d (for exec output templates).\nFor example, the simplest useful decode template is as follows:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>def template BasicDecode {{\n    return new %(class_name)s(machInst);\n}};\n</code></pre></div></div>\n<p>An instruction format would specialize this template for a particular instruction by substituting the actual class name for <code class=\"language-plaintext highlighter-rouge\">%(class_name)s</code>. (Template specialization relies on the Python string format operator <code class=\"language-plaintext highlighter-rouge\">%</code>. The term <code class=\"language-plaintext highlighter-rouge\">%(class_name)s</code> is an extension of the C <code class=\"language-plaintext highlighter-rouge\">%s</code> format string indicating that the value of the symbol <code class=\"language-plaintext highlighter-rouge\">class_name</code> should be substituted.) The resulting code would then cause the C++ decode function to create a new object of the specified class when the particular instruction was recognized.</p>\n<p>Templates are represented in the parser as Python objects. A template is used to generate a string typically by calling the template object\u2019s <code class=\"language-plaintext highlighter-rouge\">subst()</code> method. This method takes a single argument that specifies the mapping of substitution symbols in the template (e.g., <code class=\"language-plaintext highlighter-rouge\">%(class_name)s</code>) to specific values. If the argument is a dictionary, the dictionary itself specifies the mapping. Otherwise, the argument must be another Python object, and the object\u2019s attributes are used as the mapping. In practice, the argument to <code class=\"language-plaintext highlighter-rouge\">subst()</code> is nearly always an instance of the parser\u2019s InstObjParams class; see the <a href=\"#the-instobjparams-class\">InstObjParams class</a>. A template may also reference other templates (e.g., <code class=\"language-plaintext highlighter-rouge\">%(BasicDecode)s</code>) in addition to symbols specified by the <code class=\"language-plaintext highlighter-rouge\">subst()</code> argument; these will be interpolated into the result by <code class=\"language-plaintext highlighter-rouge\">subst()</code> as well.</p>\n<p>Template references to CPU-model-specific symbols (see <a href=\"#format-definitions\">Format definitions</a>) are not expanded by <code class=\"language-plaintext highlighter-rouge\">subst()</code>, but are passed through intact. This feature allows them to later be expanded appropriately according to whether the result is assigned to <code class=\"language-plaintext highlighter-rouge\">exec_output</code> or another output section. However, when a template containing a CPU-model-specific symbol is referenced by another template, then the former template is replicated and expanded into a single string before interpolation, as with templates assigned to <code class=\"language-plaintext highlighter-rouge\">header_output</code> or <code class=\"language-plaintext highlighter-rouge\">decoder_output</code>. This policy guarantees that only templates directly containing CPU-model-specific symbols will be replicated, never templates that contain such symbols indirectly. This last feature is used to interpolate per-CPU declarations of the <code class=\"language-plaintext highlighter-rouge\">execute()</code> method into the instruction class declaration template (see the <code class=\"language-plaintext highlighter-rouge\">BasicExecDeclare</code> template in the Alpha ISA description).</p>\n<h3 id=\"output-blocks\">Output blocks</h3>\n<p>Output blocks allow the ISA description to include C++ code that is copied nearly verbatim to the output file. These blocks are useful for defining classes and local functions that are shared among multiple instruction objects. An output block has the following format:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>output &lt;destination&gt; {{\n    [code omitted]\n}};\n</code></pre></div></div>\n<p>The <code class=\"language-plaintext highlighter-rouge\">&lt;destination&gt;</code> keyword must be one of <code class=\"language-plaintext highlighter-rouge\">header</code>, <code class=\"language-plaintext highlighter-rouge\">decoder</code>, or <code class=\"language-plaintext highlighter-rouge\">exec</code>. The code within the code literal is treated as if it were assigned to the <code class=\"language-plaintext highlighter-rouge\">header_output</code> <code class=\"language-plaintext highlighter-rouge\">decoder_output</code>, or <code class=\"language-plaintext highlighter-rouge\">exec_output</code> variable within an instruction format, respectively, including the special processing of CPU-model-specific symbols. The only additional processing performed on the code literal is substitution of bitfield operators, as used in instruction definitions (see <a href=\"#bitfield-operators\">Bitfield operators</a>, and interpolation of references to templates.</p>\n<h3 id=\"let-blocks\">Let blocks</h3>\n<p>Let blocks provide for global Python code. These blocks consist simply of the keyword <code class=\"language-plaintext highlighter-rouge\">let</code> followed by a code literal (double-brace delimited string) and a semicolon.\nThe code literal is executed immediately by the Python interpreter. The parser maintains the execution context across let blocks, so that variables and functions defined in one let block will be accessible in subsequent let blocks. This context is also used when executing instruction format definitions. The primary purpose of let blocks is to define shared Python data structures and functions for use in instruction formats. The parser exports a limited set of definitions into this execution context, including the set of defined templates (see <a href=\"#template-definitions\">Template definitions</a>, the <code class=\"language-plaintext highlighter-rouge\">InstObjParams</code> and <code class=\"language-plaintext highlighter-rouge\">CodeBlock</code> classes (see <a href=\"#code-parsing\">Code parsing</a>), and the standard Python <code class=\"language-plaintext highlighter-rouge\">string</code> and <code class=\"language-plaintext highlighter-rouge\">re</code> (regular expression) modules.</p>\n<h3 id=\"bitfield-definitions\">Bitfield definitions</h3>\n<p>A bitfield definition provides a name for a bitfield within a machine instruction. These names are typically used as the bitfield specifications in decode blocks. The names are also used within other C++ code in the decoder file, including instruction class definitions and decode code.\nThe bitfield definition syntax is demonstrated in these examples:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>def bitfield OPCODE &lt;31:26&gt;;\ndef bitfield IMM &lt;12&gt;;\ndef signed bitfield MEMDISP &lt;15:0&gt;;\n</code></pre></div></div>\n<p>The specified bit range is inclusive on both ends, and bit 0 is the least significant bit; thus the OPCODE bitfield in the example extracts the most significant six bits from a 32-bit instruction. A single index value extracts a one-bit field, IMM. The extracted value is zero-extended by default; with the additional signed keyword, as in the MEMDISP example, the extracted value will be sign extended. The implementation of bitfields is based on preprocessor macros and C++ template functions, so the size of the resulting value will depend on the context.</p>\n<p>To fully understand where bitfield definitions can be used, we need to go under the hood a bit. A bitfield definition simply generates a C++ preprocessor macro that extracts the specified bitfield from the implicit variable <code class=\"language-plaintext highlighter-rouge\">machInst</code>. The machine instruction parameter to the decode function is also called <code class=\"language-plaintext highlighter-rouge\">machInst</code>; thus any use of a bitfield name that ends up inside the decode function (such as the argument of a decode block or the decode piece of an instruction format\u2019s output) will implicitly reference the instruction currently being decoded. The binary machine instruction stored in the <code class=\"language-plaintext highlighter-rouge\">StaticInst</code> object is also named <code class=\"language-plaintext highlighter-rouge\">machInst</code>, so any use of a bitfield name in a member function of an instruction object will reference this stored value. This data member is initialized in the <code class=\"language-plaintext highlighter-rouge\">StaticInst</code> constructor, so it is safe to use bitfield names even in the constructors of derived objects.</p>\n<h3 id=\"operand-and-operand-type-definitions\">Operand and operand type definitions</h3>\n<p>These statements specify the operand types that can be used in the code blocks that express the functional operation of instructions. See <a href=\"#operand-type-qualifiers\">Operand type qualifiers</a>  and <a href=\"#instruction-operands\">Instruction parsing</a>.</p>\n<h3 id=\"namespace-declaration\">Namespace declaration</h3>\n<p>The final component of the declaration section is the namespace declaration, consisting of the keyword <code class=\"language-plaintext highlighter-rouge\">namespace</code> followed by an identifier and a semicolon. Exactly one namespace declaration must appear in the declarations section. The resulting C++ decode function, the declarations resulting from the instruction definitions in the decode block, and the contents of any <code class=\"language-plaintext highlighter-rouge\">declare</code> statements occurring after then namespace declaration will be placed in a C++ namespace with the specified name. The contents of <code class=\"language-plaintext highlighter-rouge\">declare</code> statements occurring before the namespace declaration will be outside the namespace.</p>\n<h2 id=\"isa-parser-1\">ISA parser</h2>\n<h3 id=\"formats\">Formats</h3>\n<h3 id=\"operands\">operands</h3>\n<h3 id=\"decode-tree\">decode tree</h3>\n<h3 id=\"let-blocks-1\">let blocks</h3>\n<h3 id=\"microcode-assembler\">microcode assembler</h3>\n<h4 id=\"microops\">microops</h4>\n<h4 id=\"macroops\">macroops</h4>\n<h4 id=\"directives\">directives</h4>\n<h4 id=\"rom-object\">rom object</h4>\n<h3 id=\"lots-more-stuff\">Lots more stuff</h3>\n<h1 id=\"code-parsing\">Code parsing</h1>\n<p>To a large extent, the power and flexibility of the ISA description mechanism stem from the fact that the mapping from a brief instruction definition provided in the decode block to the resulting C++ code is performed in a general-purpose programming language (Python). (This function is performed by the \u201cinstruction format\u201d definition described above in <a href=\"#format-definitions\">Format definitions</a>. Technically, the ISA description language allows any arbitrary Python code to perform this mapping. However, the parser provides a library of Python classes and functions designed to automate the process of deducing an instruction\u2019s characteristics from a brief description of its operation, and generating the strings required to populate declaration and decode templates. This library represents roughly half of the code in isa_parser.py.</p>\n<p>Instruction behaviors are described using C++ with two extensions: bitfield operators and operand type qualifiers. To avoid building a full C++ parser into the ISA description system (or conversely constraining the C++ that could be used for instruction descriptions), these extensions are implemented using regular expression matching and substitution. As a result, there are some syntactic constraints on their usage. The following two sections discuss these extensions in turn. The third section discusses operand parsing, the technique by which the parser automatically infers most instruction characteristics. The final two sections discuss the Python classes through which instruction formats interact with the library: <code class=\"language-plaintext highlighter-rouge\">CodeBlock</code>, which analyzes and encapsulates instruction description code; and the instruction object parameter class, <code class=\"language-plaintext highlighter-rouge\">InstObjParams</code>, which encapsulates the full set of parameters to be substituted into a template.</p>\n<h3 id=\"bitfield-operators\">Bitfield operators</h3>\n<p>Simple bitfield extraction can be performed on rvalues using the <code class=\"language-plaintext highlighter-rouge\">&lt;:&gt;</code> postfix operator. Bit numbering matches that used in global bitfield definitions (see <a href=\"#bitfield-definitions\">Bitfield definitions</a>). For example, <code class=\"language-plaintext highlighter-rouge\">Ra&lt;7:0&gt;</code> extracts the low 8 bits of register <code class=\"language-plaintext highlighter-rouge\">Ra</code>. Single-bit fields can be specified by eliminating the latter operand, e.g. <code class=\"language-plaintext highlighter-rouge\">Rb&lt;31:&gt;</code>. Unlike in global bitfield definitions, the colon cannot be eliminated, as it becomes too difficult to distinguish bitfield operators from template arguments. In addition, the bit index parameters must be either identifiers or integer constants; expressions are not allowed. The bit operator will apply either to the syntactic token on its left, or, if that token is a closing parenthesis, to the parenthesized expression.</p>\n<h3 id=\"operand-type-qualifiers\">Operand type qualifiers</h3>\n<p>The effective type of an instruction operand (e.g., a register) may be specified by appending a period and a type qualifier to the operand name. The list of type qualifiers is architecture-specific; the <code class=\"language-plaintext highlighter-rouge\">def operand_types</code> statement in the ISA description is used to specify it. The specification is in the form of a Python dictionary which maps a type extension to type name. For example, the Alpha ISA definition is as follows:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>def operand_types {{\n    'sb' : 'int8_t',\n    'ub' : 'uint8_t',\n    'sw' : 'int16_t',\n    'uw' : 'uint16_t',\n    'sl' : 'int32_t',\n    'ul' : 'uint32_t',\n    'sq' : 'int64_t',\n    'uq' : 'uint64_t',\n    'sf' : 'float',\n    'df' : 'double'\n}};\n</code></pre></div></div>\n<p>Thus the Alpha 32-bit add instruction addl could be defined as:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Rc.sl = Ra.sl + Rb.sl;\n</code></pre></div></div>\n<p>The operations are performed using the types specified; the result will be converted from the specified type to the appropriate register value (in this case by sign-extending the 32-bit result to 64 bits, since Alpha integer registers are 64 bits in size).</p>\n<p>Type qualifiers are allowed only on recognized instruction operands (see <a href=\"#instruction-operands\">Instruction operands</a>).</p>\n<h3 id=\"instruction-operands\">Instruction operands</h3>\n<p>Most of the automation provided by the parser is based on its recognition of the operands used in the instruction definition code. Most relevant instruction characteristics can be inferred from the operands: floating-point vs. integer instructions can be recognized by the registers used, an instruction that reads from a memory location is a load, etc. In combination with the bitfield operands and type qualifiers described above, most instructions can be described in a single line of code. In addition, most of the differences between simulator CPU models lies in the operand access mechanisms; by generating the code for these accesses automatically, a single description suffices for a variety of situations.</p>\n<p>The ISA description provides a list of recognized instruction operands and their characteristics via the <code class=\"language-plaintext highlighter-rouge\">def operands</code> statement. This statement specifies a Python dictionary that maps operand strings to a five-element tuple.  The elements of the tuple specify the operand as follows:</p>\n<ol>\n<li>the operand class, which must be one of the strings \u201cIntReg\u201d, \u201cFloatReg\u201d, \u201cMem\u201d, \u201cNPC\u201d, or \u201cControlReg\u201d, indicating an integer register, floating-point register, memory location, the next program counter (NPC), or a control register, respectively.</li>\n<li>the default type of the operand (an extension string defined in the <code class=\"language-plaintext highlighter-rouge\">def operand_types</code> block),</li>\n<li>a specifier indicating how specific instances of the operand are decoded (e.g., a bitfield name),</li>\n<li>a string or triple of strings indicating the instruction flags that can be inferred when the operand is used, and</li>\n<li>a sort priority used to control the order of operands in disassembly.</li>\n</ol>\n<p>For example, a simplified subset of the Alpha ISA operand traits map is as follows:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>def operands {{\n    'Ra': ('IntReg', 'uq', 'RA', 'IsInteger', 1),\n    'Rb': ('IntReg', 'uq', 'RB', 'IsInteger', 2),\n    'Rc': ('IntReg', 'uq', 'RC', 'IsInteger', 3),\n    'Fa': ('FloatReg', 'df', 'FA', 'IsFloating', 1),\n    'Fb': ('FloatReg', 'df', 'FB', 'IsFloating', 2),\n    'Fc': ('FloatReg', 'df', 'FC', 'IsFloating', 3),\n    'Mem': ('Mem', 'uq', None, ('IsMemRef', 'IsLoad', 'IsStore'), 4),\n    'NPC': ('NPC', 'uq', None, ( None, None, 'IsControl'), 4)\n}};\n</code></pre></div></div>\n<p>The operand named <code class=\"language-plaintext highlighter-rouge\">Ra</code> is an integer register, default type <code class=\"language-plaintext highlighter-rouge\">uq</code> (unsigned quadword), uses the <code class=\"language-plaintext highlighter-rouge\">RA</code> bitfield from the instruction, implies the <code class=\"language-plaintext highlighter-rouge\">IsInteger</code> instruction flag, and has a sort priority of 1 (placing it first in any list of operands).</p>\n<p>For the instruction flag element, a single string (such as <code class=\"language-plaintext highlighter-rouge\">'IsInteger'</code> implies an unconditionally inferred instruction flag. If the flag operand is a triple, the first element is unconditional, the second is inferred when the operand is a source, and the third when it is a destination. Thus the <code class=\"language-plaintext highlighter-rouge\">('IsMemRef', 'IsLoad', 'IsStore')</code> element for memory references indicates that any instruction with a memory operand is marked as a memory reference. In addition, if the memory operand is a source, the instruction is marked as a load, while if the operand is a destination, the instruction is marked a store. Similarly, the <code class=\"language-plaintext highlighter-rouge\">(None, None, 'IsControl')</code> tuple for the NPC operand indicates that any instruction that writes to the NPC is a control instruction, but instructions which merely reference NPC as a source do not receive any default flags.</p>\n<p>Note that description code parsing uses regular expressions, which limits the ability of the parser to infer the nature of a partciular operand.  In particular, destination operands are distinguished from source operands solely by testing whether the operand appears on the left-hand side of an assignment operator (<code class=\"language-plaintext highlighter-rouge\">=</code>). Destination operands that are assigned to in a different fashion, e.g. by being passed by reference to other functions, must still appear on the left-hand side of an assignment to be properly recognized as destinations.  The parser also does not recognize C compound assignments, e.g., <code class=\"language-plaintext highlighter-rouge\">+=</code>.  If an operand is both a source and a destination, it must appear on both the left- and right-hand sides of <code class=\"language-plaintext highlighter-rouge\">=</code>.</p>\n<p>Another limitation of regular-expression-based code parsing is that control flow in the code block is not recognized.  Combined with the details of how register updates are performed in the CPU models, this means that destinations cannot be updated conditionally.  If a particular register is recognized as a destination register, that register will always be updated at the end of the <code class=\"language-plaintext highlighter-rouge\">execute()</code> method, and thus the code must assign a valid value to that register along each possible code path within the block.</p>\n<h3 id=\"the-codeblock-class\">The CodeBlock class</h3>\n<p>An instruction format requests processing of a string containing instruction description code by passing the string to the CodeBlock constructor. The constructor performs all of the needed analysis and processing, storing the results in the returned object. Among the CodeBlock fields are:</p>\n<ul>\n<li><code class=\"language-plaintext highlighter-rouge\">orig_code</code>: the original code string.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">code</code>: a processed string containing legal C++ code, derived from the original code by substituting in the bitfield operators and munging operand type qualifiers (s/./_/) to make valid C++ identifiers.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">constructor</code>: code for the constructor of an instruction object, initializing various C++ object fields including the number of operands and the register indices of the operands.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">exec_decl</code>: code to declare the C++ variables corresponding to the operands, for use in an execution emulation function.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">*_rd</code>: code to read the actual operand values into the corresponding C++ variables for source operands. The first part of the name indicates the relevant CPU model (currently simple and dtld are supported).</li>\n<li><code class=\"language-plaintext highlighter-rouge\">*_wb</code>: code to write the C++ variable contents back to the appropriate register or memory location. Again, the first part of the name reflects the CPU model.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">*_mem_rd</code>, <code class=\"language-plaintext highlighter-rouge\">*_nonmem_rd</code>, <code class=\"language-plaintext highlighter-rouge\">*_mem_wb</code>, <code class=\"language-plaintext highlighter-rouge\">*_nonmem_wb</code>: as above, but with memory and non-memory operands segregated.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">flags</code>: the set of instruction flags implied by the operands.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">op_class</code>: a basic guess at the instruction\u2019s operation class (see OpClass) based on the operand types alone.</li>\n</ul>\n<h3 id=\"the-instobjparams-class\">The InstObjParams class</h3>\n<p>Instances of the InstObjParams class encapsulate all of the parameters needed to substitute into a code template, to be used as the argument to a template\u2019s <code class=\"language-plaintext highlighter-rouge\">subst()</code> method (see Template definitions).</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">class</span> <span class=\"nc\">InstObjParams</span><span class=\"p\">(</span><span class=\"nb\">object</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">__init___</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">parser</span><span class=\"p\">,</span> \n                  <span class=\"n\">mem</span><span class=\"p\">,</span> <span class=\"n\">class_name</span><span class=\"p\">,</span> <span class=\"n\">base_class</span> <span class=\"o\">=</span> <span class=\"s\">''</span><span class=\"p\">,</span>\n                  <span class=\"n\">snippets</span> <span class=\"o\">=</span> <span class=\"p\">{},</span> <span class=\"n\">opt_args</span> <span class=\"o\">=</span> <span class=\"p\">[]):</span>\n</code></pre></div></div>\n<p>The first three constructor arguments populate the object\u2019s <code class=\"language-plaintext highlighter-rouge\">mnemonic</code>, <code class=\"language-plaintext highlighter-rouge\">class_name</code>, and (optionally) <code class=\"language-plaintext highlighter-rouge\">base_class</code> members. The fourth (optional) argument is a CodeBlock object; all of the members of the provided CodeBlock object are copied to the new object, making them accessible for template substitution. Any remaining arguments are interpreted as either additional instruction flags (appended to the <code class=\"language-plaintext highlighter-rouge\">flags</code> list inherited from the CodeBlock argument, if any), or as an operation class (overriding any <code class=\"language-plaintext highlighter-rouge\">op_class</code> from the CodeBlock).</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/architecture_support/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/architecture_support/x86_microop_isa/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/architecture_support/x86_microop_isa/",
        "title": "Register Ops",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"register-ops\">Register Ops</h1>\n<p>These microops typically take two sources and produce one result. Most have a version that operates on only registers and a version which operates on registers and an immediate value. Some optionally set flags according to their operation. Some of them can be predicated.</p>\n<h3 id=\"add\">Add</h3>\n<p>Addition.</p>\n<h4 id=\"add-dest-src1-src2\">add Dest, Src1, Src2</h4>\n<p>Dest # Dest &lt;- Src1 + Src2</p>\n<p>Adds the contents of the Src1 and Src2 registers and puts the result in the Dest register.</p>\n<h4 id=\"addi-dest-src1-imm\">addi Dest, Src1, Imm</h4>\n<p>Dest # Dest &lt;- Src1 + Imm</p>\n<p>Adds the contents of the Src1 register and the immediate Imm and puts the result in the Dest register.</p>\n<h4 id=\"flags\">Flags</h4>\n<p>This microop optionally sets the CF, ECF, ZF, EZF, PF, AF, SF, and OF flags.</p>\n<table>\n<thead>\n<tr>\n<th>Flag</th>\n<th>Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CF and ECF</td>\n<td>The carry out of the most significant bit.</td>\n</tr>\n<tr>\n<td>ZF and EZF</td>\n<td>Whether the result was zero.</td>\n</tr>\n<tr>\n<td>PF</td>\n<td>The parity of the result.</td>\n</tr>\n<tr>\n<td>AF</td>\n<td>The carry from the fourth to fifth bit positions.</td>\n</tr>\n<tr>\n<td>SF</td>\n<td>The sign of the result.</td>\n</tr>\n<tr>\n<td>OF</td>\n<td>Whether there was an overflow.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"adc\">Adc</h3>\n<p>Add with carry.</p>\n<h4 id=\"adc-dest-src1-src2\">adc Dest, Src1, Src2</h4>\n<p>Dest # Dest &lt;- Src1 + Src2 + CF</p>\n<p>Adds the contents of the Src1 and Src2 registers and the carry flag and puts the result in the Dest register.</p>\n<h4 id=\"adci-dest-src1-imm\">adci Dest, Src1, Imm</h4>\n<p>Dest # Dest &lt;- Src1 + Imm + CF</p>\n<p>Adds the contents of the Src1 register, the immediate Imm, and the carry flag and puts the result in the Dest register.</p>\n<h4 id=\"flags-1\">Flags</h4>\n<p>This microop optionally sets the CF, ECF, ZF, EZF, PF, AF, SF, and OF flags.</p>\n<table>\n<thead>\n<tr>\n<th>Flag</th>\n<th>Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CF and ECF</td>\n<td>The carry out of the most significant bit.</td>\n</tr>\n<tr>\n<td>ZF and EZF</td>\n<td>Whether the result was zero.</td>\n</tr>\n<tr>\n<td>PF</td>\n<td>The parity of the result.</td>\n</tr>\n<tr>\n<td>AF</td>\n<td>The carry from the fourth to fifth bit positions.</td>\n</tr>\n<tr>\n<td>SF</td>\n<td>The sign of the result.</td>\n</tr>\n<tr>\n<td>OF</td>\n<td>Whether there was an overflow.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"sub\">Sub</h3>\n<p>Subtraction.</p>\n<h4 id=\"sub-dest-src1-src2\">sub Dest, Src1, Src2</h4>\n<p>Dest # Dest &lt;- Src1 - Src2</p>\n<p>Subtracts the contents of the Src2 register from the Src1 register and puts the result in the Dest register.</p>\n<h4 id=\"subi-dest-src1-imm\">subi Dest, Src1, Imm</h4>\n<p>Dest # Dest &lt;- Src1 - Imm</p>\n<p>Subtracts the contents of the immediate Imm from the Src1 register and puts the result in the Dest register.</p>\n<h4 id=\"flags-2\">Flags</h4>\n<p>This microop optionally sets the CF, ECF, ZF, EZF, PF, AF, SF, and OF flags.</p>\n<table>\n<thead>\n<tr>\n<th>Flag</th>\n<th>Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CF and ECF</td>\n<td>The borrow into of the most significant bit.</td>\n</tr>\n<tr>\n<td>ZF and EZF</td>\n<td>Whether the result was zero.</td>\n</tr>\n<tr>\n<td>PF</td>\n<td>The parity of the result.</td>\n</tr>\n<tr>\n<td>AF</td>\n<td>The borrow from the fourth to fifth bit positions.</td>\n</tr>\n<tr>\n<td>SF</td>\n<td>The sign of the result.</td>\n</tr>\n<tr>\n<td>OF</td>\n<td>Whether there was an overflow.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"sbb\">Sbb</h3>\n<p>Subtract with borrow.</p>\n<h4 id=\"sbb-dest-src1-src2\">sbb Dest, Src1, Src2</h4>\n<p>Dest # Dest &lt;- Src1 - Src2 - CF</p>\n<p>Subtracts the contents of the Src2 register and the carry flag from the Src1 register and puts the result in the Dest register.</p>\n<h4 id=\"sbbi-dest-src1-imm\">sbbi Dest, Src1, Imm</h4>\n<p>Dest # Dest &lt;- Src1 - Imm - CF</p>\n<p>Subtracts the immediate Imm and the carry flag from the Src1 register and puts the result in the Dest register.</p>\n<h4 id=\"flags-3\">Flags</h4>\n<p>This microop optionally sets the CF, ECF, ZF, EZF, PF, AF, SF, and OF flags.</p>\n<table>\n<thead>\n<tr>\n<th>Flag</th>\n<th>Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CF and ECF</td>\n<td>The borrow into of the most significant bit.</td>\n</tr>\n<tr>\n<td>ZF and EZF</td>\n<td>Whether the result was zero.</td>\n</tr>\n<tr>\n<td>PF</td>\n<td>The parity of the result.</td>\n</tr>\n<tr>\n<td>AF</td>\n<td>The borrow from the fourth to fifth bit positions.</td>\n</tr>\n<tr>\n<td>SF</td>\n<td>The sign of the result.</td>\n</tr>\n<tr>\n<td>OF</td>\n<td>Whether there was an overflow.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"mul1s\">Mul1s</h3>\n<p>Signed multiply.</p>\n<h4 id=\"mul1s-src1-src2\">mul1s Src1, Src2</h4>\n<p>ProdHi:ProdLo # Src1 * Src2</p>\n<p>Multiplies the unsigned contents of the Src1 and Src2 registers and puts the high and low portions of the product into the internal registers ProdHi and ProdLo, respectively.</p>\n<h4 id=\"mul1si-src1-imm\">mul1si Src1, Imm</h4>\n<p>ProdHi:ProdLo # Src1 * Imm</p>\n<p>Multiplies the unsigned contents of the Src1 register and the immediate Imm and puts the high and low portions of the product into the internal registers ProdHi and ProdLo, respectively.</p>\n<h4 id=\"flags-4\">Flags</h4>\n<p>This microop does not set any flags.</p>\n<h3 id=\"mul1u\">Mul1u</h3>\n<p>Unsigned multiply.</p>\n<h4 id=\"mul1u-src1-src2\">mul1u Src1, Src2</h4>\n<p>ProdHi:ProdLo # Src1 * Src2</p>\n<p>Multiplies the unsigned contents of the Src1 and Src2 registers and puts the high and low portions of the product into the internal registers ProdHi and ProdLo, respectively.</p>\n<h4 id=\"mul1ui-src1-imm\">mul1ui Src1, Imm</h4>\n<p>ProdHi:ProdLo # Src1 * Imm</p>\n<p>Multiplies the unsigned contents of the Src1 register and the immediate Imm and puts the high and low portions of the product into the internal registers ProdHi and ProdLo, respectively.</p>\n<h4 id=\"flags-5\">Flags</h4>\n<p>This microop does not set any flags.</p>\n<h3 id=\"mulel\">Mulel</h3>\n<p>Unload multiply result low.</p>\n<h4 id=\"mulel-dest\">mulel Dest</h4>\n<p>Dest # Dest &lt;- ProdLo</p>\n<p>Moves the value of the internal ProdLo register into the Dest register.</p>\n<h4 id=\"flags-6\">Flags</h4>\n<p>This microop does not set any flags.</p>\n<h3 id=\"muleh\">Muleh</h3>\n<p>Unload multiply result high.</p>\n<h4 id=\"muleh-dest\">muleh Dest</h4>\n<p>Dest # Dest &lt;- ProdHi</p>\n<p>Moves the value of the internal ProdHi register into the Dest register.</p>\n<h4 id=\"flags-7\">Flags</h4>\n<p>This microop optionally sets the CF, ECF, and OF flags.</p>\n<table>\n<thead>\n<tr>\n<th>Flag</th>\n<th>Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CF and ECF</td>\n<td>Whether ProdHi is non-zero.</td>\n</tr>\n<tr>\n<td>OF</td>\n<td>Whether ProdHi is zero.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"div1\">Div1</h3>\n<p>First stage of division.</p>\n<h4 id=\"div1-src1-src2\">div1 Src1, Src2</h4>\n<p>Quotient * Src2 + Remainder # Src1\nDivisor # Src2</p>\n<p>Begins a division operation where the contents of SrcReg1 is the high part of the dividend and the contents of SrcReg2 is the divisor. The remainder from this partial division is put in the internal register Remainder. The quotient is put in the internal register Quotient. The divisor is put in the internal register Divisor.</p>\n<h4 id=\"div1i-src1-imm\">div1i Src1, Imm:</h4>\n<p>Quotient * Imm + Remainder # Src1\nDivisor # Imm</p>\n<p>Begins a division operation where the contents of SrcReg1 is the high part of the dividend and the immediate Imm is the divisor. The remainder from this partial division is put in the internal register Remainder. The quotient is put in the internal register Quotient. The divisor is put in the internal register Divisor.</p>\n<h4 id=\"flags-8\">Flags</h4>\n<p>This microop does not set any flags.</p>\n<h3 id=\"div2\">Div2</h3>\n<p>Second and later stages of division.</p>\n<h4 id=\"div2-dest-src1-src2\">div2 Dest, Src1, Src2</h4>\n<p>Quotient * Divisor + Remainder # original Remainder with bits shifted in from Src1</p>\n<p>Dest # Dest &lt;- Src2 - number of bits shifted in above</p>\n<p>Performs subsequent steps of division following a div1 instruction. The contents of the register Src1 is the low portion of the dividend. The contents of the register Src2 denote the number of bits in Src1 that have not yet been used before this step in the division. Dest is set to the number of bits in Src1 that have not been used after this step. The internal registers Quotient, Divisor, and Remainder are updated by this instruction.</p>\n<p>If there are no remaining bits in Src1, this instruction does nothing except optionally compute flags.</p>\n<h4 id=\"div2i-dest-src1-imm\">div2i Dest, Src1, Imm</h4>\n<p>Quotient * Divisor + Remainder # original Remainder with bits shifted in from Src1</p>\n<p>Dest # Dest &lt;- Imm - number of bits shifted in above</p>\n<p>Performs subsequent steps of division following a div1 instruction. The contents of the register Src1 is the low portion of the dividend. The immediate Imm denotes the number of bits in Src1 that have not yet been used before this step in the division. Dest is set to the number of bits in Src1 that have not been used after this step. The internal registers Quotient, Divisor, and Remainder are updated by this instruction.</p>\n<p>If there are no remaining bits in Src1, this instruction does nothing except optionally compute flags.</p>\n<h4 id=\"flags-9\">Flags</h4>\n<p>This microop optionally sets the EZF flag.</p>\n<table>\n<thead>\n<tr>\n<th>Flag</th>\n<th>Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>EZF</td>\n<td>Whether there are any remaining bits in Src1 after this step.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"divq\">Divq</h3>\n<p>Unload division quotient.</p>\n<h4 id=\"divq-dest\">divq Dest</h4>\n<p>Dest # Dest &lt;- Quotient</p>\n<p>Moves the value of the internal Quotient register into the Dest register.</p>\n<h4 id=\"flags-10\">Flags</h4>\n<p>This microop does not set any flags.</p>\n<h3 id=\"divr\">Divr</h3>\n<p>Unload division remainder.</p>\n<h4 id=\"divr-dest\">divr Dest</h4>\n<p>Dest # Dest &lt;- Remainder</p>\n<p>Moves the value of the internal Remainder register into the Dest register.</p>\n<h4 id=\"flags-11\">Flags</h4>\n<p>This microop does not set any flags.</p>\n<h3 id=\"or\">Or</h3>\n<p>Logical or.</p>\n<h4 id=\"or-dest-src1-src2\">or Dest, Src1, Src2</h4>\n<p>Dest # Dest &lt;- Src1 | Src2</p>\n<p>Computes the bitwise or of the contents of the Src1 and Src2 registers and puts the result in the Dest register.</p>\n<h4 id=\"ori-dest-src1-imm\">ori Dest, Src1, Imm</h4>\n<p>Dest # Dest &lt;- Src1 | Imm</p>\n<p>Computes the bitwise or of the contents of the Src1 register and the immediate Imm and puts the result in the Dest register.</p>\n<h4 id=\"flags-12\">Flags</h4>\n<p>This microop optionally sets the CF, ECF, ZF, EZF, PF, AF, SF, and OF flags.\nThere is nothing that prevents computing a value for the AF flag, but it\u2019s value will be meaningless.</p>\n<table>\n<thead>\n<tr>\n<th>Flag</th>\n<th>Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CF and ECF</td>\n<td>Cleared.</td>\n</tr>\n<tr>\n<td>ZF and EZF</td>\n<td>Whether the result was zero.</td>\n</tr>\n<tr>\n<td>PF</td>\n<td>The parity of the result.</td>\n</tr>\n<tr>\n<td>AF</td>\n<td>Undefined.</td>\n</tr>\n<tr>\n<td>SF</td>\n<td>The sign of the result.</td>\n</tr>\n<tr>\n<td>OF</td>\n<td>Cleared.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"and\">And</h3>\n<p>Logical And</p>\n<h4 id=\"and-dest-src1-src2\">and Dest, Src1, Src2</h4>\n<p>Dest # Dest &lt;- Src1 &amp; Src2</p>\n<p>Computes the bitwise and of the contents of the Src1 and Src2 registers and puts the result in the Dest register.</p>\n<h4 id=\"andi-dest-src1-imm\">andi Dest, Src1, Imm</h4>\n<p>Dest # Dest &lt;- Src1 &amp; Imm</p>\n<p>Computes the bitwise and of the contents of the Src1 register and the immediate Imm and puts the result in the Dest register.</p>\n<h4 id=\"flags-13\">Flags</h4>\n<p>This microop optionally sets the CF, ECF, ZF, EZF, PF, AF, SF, and OF flags.\nThere is nothing that prevents computing a value for the AF flag, but it\u2019s value will be meaningless.</p>\n<table>\n<thead>\n<tr>\n<th>Flag</th>\n<th>Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CF and ECF</td>\n<td>Cleared.</td>\n</tr>\n<tr>\n<td>ZF and EZF</td>\n<td>Whether the result was zero.</td>\n</tr>\n<tr>\n<td>PF</td>\n<td>The parity of the result.</td>\n</tr>\n<tr>\n<td>AF</td>\n<td>Undefined.</td>\n</tr>\n<tr>\n<td>SF</td>\n<td>The sign of the result.</td>\n</tr>\n<tr>\n<td>OF</td>\n<td>Cleared.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"xor\">Xor</h3>\n<p>Logical exclusive or.</p>\n<h4 id=\"xor-dest-src1-src2\">xor Dest, Src1, Src2</h4>\n<p>Dest # Dest &lt;- Src1 | Src2</p>\n<p>Computes the bitwise xor of the contents of the Src1 and Src2 registers and puts the result in the Dest register.</p>\n<h4 id=\"xori-dest-src1-imm\">xori Dest, Src1, Imm</h4>\n<p>Dest # Dest &lt;- Src1 | Imm</p>\n<p>Computes the bitwise xor of the contents of the Src1 register and the immediate Imm and puts the result in the Dest register.</p>\n<h4 id=\"flags-14\">Flags</h4>\n<p>This microop optionally sets the CF, ECF, ZF, EZF, PF, AF, SF, and OF flags.\nThere is nothing that prevents computing a value for the AF flag, but it\u2019s value will be meaningless.</p>\n<table>\n<thead>\n<tr>\n<th>Flag</th>\n<th>Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CF and ECF</td>\n<td>Cleared.</td>\n</tr>\n<tr>\n<td>ZF and EZF</td>\n<td>Whether the result was zero.</td>\n</tr>\n<tr>\n<td>PF</td>\n<td>The parity of the result.</td>\n</tr>\n<tr>\n<td>AF</td>\n<td>Undefined.</td>\n</tr>\n<tr>\n<td>SF</td>\n<td>The sign of the result.</td>\n</tr>\n<tr>\n<td>OF</td>\n<td>Cleared.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"sll\">Sll</h3>\n<p>Logical left shift.</p>\n<h4 id=\"sll-dest-src1-src2\">sll Dest, Src1, Src2</h4>\n<p>Dest # Dest &lt;- Src1 \u00ab\u00a0Src2</p>\n<p>Shifts the contents of the Src1 register to the left by the value in the Src2 register and writes the result into the Dest register. The shift amount is truncated to either 5 or 6 bits, depending on the operand size.</p>\n<h4 id=\"slli-dest-src1-imm\">slli Dest, Src1, Imm</h4>\n<p>Dest # Dest &lt;- Src1 \u00ab\u00a0Imm</p>\n<p>Shifts the contents of the Src1 register to the left by the value in the immediate Imm and writes the result into the Dest register. The shift amount is truncated to either 5 or 6 bits, depending on the operand size.</p>\n<h4 id=\"flags-15\">Flags</h4>\n<p>This microop optionally sets the CF, ECF, and OF flags. If the shift amount is zero, no flags are modified.</p>\n<table>\n<thead>\n<tr>\n<th>Flag</th>\n<th>Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CF and ECF</td>\n<td>The last bit shifted out of the result.</td>\n</tr>\n<tr>\n<td>OF</td>\n<td>The exclusive OR of what this instruction would set the CF flag to, if requested, and the most significant bit of the result.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"srl\">Srl</h3>\n<p>Logical right shift.</p>\n<h4 id=\"srl-dest-src1-src2\">srl Dest, Src1, Src2</h4>\n<p>Dest # Dest &lt;- Src1\u00a0\u00bb(logical) Src2</p>\n<p>Shifts the contents of the Src1 register to the right by the value in the Src2 register and writes the result into the Dest register. Bits which are shifted in sign extend the result. The shift amount is truncated to either 5 or 6 bits, depending on the operand size.</p>\n<h4 id=\"srli-dest-src1-imm\">srli Dest, Src1, Imm</h4>\n<p>Dest # Dest &lt;- Src1\u00a0\u00bb(logical) Imm</p>\n<p>Shifts the contents of the Src1 register to the right by the value in the immediate Imm and writes the result into the Dest register. Bits which are shifted in sign extend the result. The shift amount is truncated to either 5 or 6 bits, depending on the operand size.</p>\n<h4 id=\"flags-16\">Flags</h4>\n<p>This microop optionally sets the CF, ECF, and OF flags. If the shift amount is zero, no flags are modified.</p>\n<table>\n<thead>\n<tr>\n<th>Flag</th>\n<th>Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CF and ECF</td>\n<td>The last bit shifted out of the result.</td>\n</tr>\n<tr>\n<td>SF</td>\n<td>The most significant bit of the original value to shift.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"sra\">Sra</h3>\n<p>Arithmetic right shift.</p>\n<h4 id=\"sra-dest-src1-src2\">sra Dest, Src1, Src2</h4>\n<p>Dest # Dest &lt;- Src1\u00a0\u00bb(arithmetic) Src2</p>\n<p>Shifts the contents of the Src1 register to the right by the value in the Src2 register and writes the result into the Dest register. Bits which are shifted in zero extend the result. The shift amount is truncated to either 5 or 6 bits, depending on the operand size.</p>\n<h4 id=\"srai-dest-src1-imm\">srai Dest, Src1, Imm</h4>\n<p>Dest # Dest &lt;- Src1\u00a0\u00bb(arithmetic) Imm</p>\n<p>Shifts the contents of the Src1 register to the right by the value in the immediate Imm and writes the result into the Dest register. Bits which are shifted in zero extend the result. The shift amount is truncated to either 5 or 6 bits, depending on the operand size.</p>\n<h4 id=\"flags-17\">Flags</h4>\n<p>This microop optionally sets the CF, ECF, and OF flags. If the shift amount is zero, no flags are modified.</p>\n<table>\n<thead>\n<tr>\n<th>Flag</th>\n<th>Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CF and ECF</td>\n<td>The last bit shifted out of the result.</td>\n</tr>\n<tr>\n<td>OF</td>\n<td>Cleared.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"ror\">Ror</h3>\n<p>Rotate right.</p>\n<h4 id=\"ror-dest-src1-src2\">ror Dest, Src1, Src2</h4>\n<p>Rotates the contents of the Src1 register to the right by the value in the Src2 register and writes the result into the Dest register. The rotate amount is truncated to either 5 or 6 bits, depending on the operand size.</p>\n<h4 id=\"rori-dest-src1-imm\">rori Dest, Src1, Imm</h4>\n<p>Rotates the contents of the Src1 register to the right by the value in the immediate Imm and writes the result into the Dest register. The rotate amount is truncated to either 5 or 6 bits, depending on the operand size.</p>\n<h4 id=\"flags-18\">Flags</h4>\n<p>This microop optionally sets the CF, ECF, and OF flags. If the rotate amount is zero, no flags are modified.</p>\n<table>\n<thead>\n<tr>\n<th>Flag</th>\n<th>Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CF and ECF</td>\n<td>The most significant bit of the result.</td>\n</tr>\n<tr>\n<td>OF</td>\n<td>The exclusive OR of the most two significant bits of the original value.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"rcr\">Rcr</h3>\n<p>Rotate right through carry.</p>\n<h4 id=\"rcr-dest-src1-src2\">rcr Dest, Src1, Src2</h4>\n<p>Rotates the contents of the Src1 register through the carry flag and to the right by the value in the Src2 register and writes the result into the Dest register. The rotate amount is truncated to either 5 or 6 bits, depending on the operand size.</p>\n<h4 id=\"rcri-dest-src1-imm\">rcri Dest, Src1, Imm</h4>\n<p>Rotates the contents of the Src1 register through the carry flag and to the right by the value in the immediate Imm and writes the result into the Dest register. The rotate amount is truncated to either 5 or 6 bits, depending on the operand size.</p>\n<h4 id=\"flags-19\">Flags</h4>\n<p>This microop optionally sets the CF, ECF, and OF flags. If the rotate amount is zero, no flags are modified.</p>\n<table>\n<thead>\n<tr>\n<th>Flag</th>\n<th>Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CF and ECF</td>\n<td>The last bit shifted out of the result.</td>\n</tr>\n<tr>\n<td>OF</td>\n<td>The exclusive OR of the CF flag before the rotate and the most significant bit of the original value.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"rol\">Rol</h3>\n<p>Rotate left.</p>\n<h4 id=\"rol-dest-src1-src2\">rol Dest, Src1, Src2</h4>\n<p>Rotates the contents of the Src1 register to the left by the value in the Src2 register and writes the result into the Dest register. The rotate amount is truncated to either 5 or 6 bits, depending on the operand size.</p>\n<h4 id=\"roli-dest-src1-imm\">roli Dest, Src1, Imm</h4>\n<p>Rotates the contents of the Src1 register to the left by the value in the immediate Imm and writes the result into the Dest register. The rotate amount is truncated to either 5 or 6 bits, depending on the operand size.</p>\n<h4 id=\"flags-20\">Flags</h4>\n<p>This microop optionally sets the CF, ECF, and OF flags. If the rotate amount is zero, no flags are modified.</p>\n<table>\n<thead>\n<tr>\n<th>Flag</th>\n<th>Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CF and ECF</td>\n<td>The least significant bit of the result.</td>\n</tr>\n<tr>\n<td>OF</td>\n<td>The exclusive OR of the most and least significant bits of the result.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"rcl\">Rcl</h3>\n<p>Rotate left through carry.</p>\n<h4 id=\"rcl-dest-src1-src2\">rcl Dest, Src1, Src2</h4>\n<p>Rotates the contents of the Src1 register through the carry flag and to the left by the value in the Src2 register and writes the result into the Dest register. The rotate amount is truncated to either 5 or 6 bits, depending on the operand size.</p>\n<h4 id=\"rcli-dest-src1-imm\">rcli Dest, Src1, Imm</h4>\n<p>Rotates the contents of the Src1 register through the carry flag and to the left by the value in the immediate Imm and writes the result into the Dest register. The rotate amount is truncated to either 5 or 6 bits, depending on the operand size.</p>\n<h4 id=\"flags-21\">Flags</h4>\n<p>This microop optionally sets the CF, ECF, and OF flags. If the rotate amount is zero, no flags are modified.</p>\n<table>\n<thead>\n<tr>\n<th>Flag</th>\n<th>Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CF and ECF</td>\n<td>The last bit rotated out of the result.</td>\n</tr>\n<tr>\n<td>OF</td>\n<td>The exclusive OR of CF before the rotate and the most significant bit of the result.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"mov\">Mov</h3>\n<p>Move.</p>\n<h4 id=\"mov-dest-src1-src2\">mov Dest, Src1, Src2</h4>\n<p>Dest # Src1 &lt;- Src2</p>\n<p>Merge the contents of the Src2 register into the contents of Src1 and put the result into the Dest register.</p>\n<h4 id=\"movi-dest-src1-imm\">movi Dest, Src1, Imm</h4>\n<p>Dest # Src1 &lt;- Imm</p>\n<p>Merge the contents of the immediate Imm into the contents of Src1 and put the results into the Dest register.</p>\n<h4 id=\"flags-22\">Flags</h4>\n<p>This microop does not set any flags. It is optionally predicated.</p>\n<h3 id=\"sext\">Sext</h3>\n<p>Sign extend.</p>\n<h4 id=\"sext-dest-src1-imm\">sext Dest, Src1, Imm</h4>\n<p>Dest # Dest &lt;- sign_extend(Src1, Imm)</p>\n<p>Sign extend the value in the Src1 register starting at the bit position in the immediate Imm, and put the result in the Dest register.</p>\n<h4 id=\"flags-23\">Flags</h4>\n<p>This microop does not set any flags.</p>\n<h3 id=\"zext\">Zext</h3>\n<p>Zero extend.</p>\n<h4 id=\"zext-dest-src1-imm\">zext Dest, Src1, Imm</h4>\n<p>Dest # Dest &lt;- zero_extend(Src1, Imm)</p>\n<p>Zero extend the value in the Src1 register starting at the bit position in the immediate Imm, and put the result in the Dest register.</p>\n<h4 id=\"flags-24\">Flags</h4>\n<p>This microop does not set any flags.</p>\n<h3 id=\"ruflag\">Ruflag</h3>\n<p>Read user flag.</p>\n<h4 id=\"ruflag-dest-imm\">ruflag Dest, Imm</h4>\n<p>Reads the user level flag stored in the bit position specified by the immediate Imm and stores it in the register Dest.</p>\n<p>The mapping between values of Imm and user level flags is show in the following table.</p>\n<table>\n<thead>\n<tr>\n<th>Imm</th>\n<th>Flag</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>0</td>\n<td>CF (carry flag)</td>\n</tr>\n<tr>\n<td>2</td>\n<td>PF (parity flag)</td>\n</tr>\n<tr>\n<td>3</td>\n<td>ECF (emulation carry flag)</td>\n</tr>\n<tr>\n<td>4</td>\n<td>AF (auxiliary flag)</td>\n</tr>\n<tr>\n<td>5</td>\n<td>EZF (emulation zero flag)</td>\n</tr>\n<tr>\n<td>6</td>\n<td>ZF (zero flag)</td>\n</tr>\n<tr>\n<td>7</td>\n<td>CF (sign flag)</td>\n</tr>\n<tr>\n<td>10</td>\n<td>CF (direction flag)</td>\n</tr>\n<tr>\n<td>11</td>\n<td>CF (overflow flag)</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"flags-25\">Flags</h4>\n<p>The EZF flag is always set. In the future this may become optional.</p>\n<h3 id=\"ruflags\">Ruflags</h3>\n<p>Read all user flags.</p>\n<h4 id=\"ruflags-dest\">ruflags Dest</h4>\n<p>Dest # user flags</p>\n<p>Store the user level flags into the Dest register.</p>\n<h4 id=\"flags-26\">Flags</h4>\n<p>This microop does not set any flags.</p>\n<h3 id=\"wruflags\">Wruflags</h3>\n<p>Write all user flags.</p>\n<h4 id=\"wruflags-src1-src2\">wruflags Src1, Src2</h4>\n<p>user flags # Src1 ^ Src2</p>\n<p>Set the user level flags to the exclusive or of the Src1 and Src2 registers.</p>\n<h4 id=\"wruflagsi-src1-imm\">wruflagsi Src1, Imm</h4>\n<p>user flags # Src1 ^ Imm</p>\n<p>Set the user level flags to the exclusive or of the Src1 register and the immediate Imm.</p>\n<h4 id=\"flags-27\">Flags</h4>\n<p>See above.</p>\n<h3 id=\"rdip\">Rdip</h3>\n<p>Read the instruction pointer.</p>\n<h4 id=\"rdip-dest\">rdip Dest</h4>\n<p>Dest # rIP</p>\n<p>Set the Dest register to the current value of rIP.</p>\n<h4 id=\"flags-28\">Flags</h4>\n<p>This microop does not set any flags.</p>\n<h3 id=\"wrip\">Wrip</h3>\n<p>Write the instruction pointer.</p>\n<h4 id=\"wrip-src1-src2\">wrip Src1, Src2</h4>\n<p>rIP # Src1 + Src2</p>\n<p>Set the rIP to the sum of the Src1 and Src2 registers. This causes a macroop branch at the end of the current macroop.</p>\n<h4 id=\"wripi-src1-imm\">wripi Src1, Imm</h4>\n<p>micropc # Src1 + Imm</p>\n<p>Set the rIP to the sum of the Src1 register and immediate Imm. This causes a macroop branch at the end of the current macroop.</p>\n<h4 id=\"flags-29\">Flags</h4>\n<p>This microop does not set any flags. It is optionally predicated.</p>\n<h3 id=\"chks\">Chks</h3>\n<p>Check selector.</p>\n<p>Not yet implemented.</p>\n<h1 id=\"loadstore-ops\">Load/Store Ops</h1>\n<h3 id=\"ld\">Ld</h3>\n<p>Load.</p>\n<h4 id=\"ld-data-seg-sib-disp\">ld Data, Seg, Sib, Disp</h4>\n<p>Loads the integer register Data from memory.</p>\n<h3 id=\"ldf\">Ldf</h3>\n<p>Load floating point.</p>\n<h4 id=\"ldf-data-seg-sib-disp\">ldf Data, Seg, Sib, Disp</h4>\n<p>Loads the floating point register Data from memory.</p>\n<h3 id=\"ldm\">Ldm</h3>\n<p>Load multimedia.</p>\n<h4 id=\"ldm-data-seg-sib-disp\">ldm Data, Seg, Sib, Disp</h4>\n<p>Load the multimedia register Data from memory.\nThis is not implemented and may never be.</p>\n<h3 id=\"ldst\">Ldst</h3>\n<p>Load with store check.</p>\n<h4 id=\"ldst-data-seg-sib-disp\">Ldst Data, Seg, Sib, Disp</h4>\n<p>Load the integer register Data from memory while also checking if a store to that location would succeed.\nThis is not implemented currently.</p>\n<h3 id=\"ldstl\">Ldstl</h3>\n<p>Load with store check, locked.</p>\n<h4 id=\"ldst-data-seg-sib-disp-1\">Ldst Data, Seg, Sib, Disp</h4>\n<p>Load the integer register Data from memory while also checking if a store to that location would succeed, and also provide the semantics of the \u201cLOCK\u201d instruction prefix.\nThis is not implemented currently.</p>\n<h3 id=\"st\">St</h3>\n<p>Store.</p>\n<h4 id=\"st-data-seg-sib-disp\">st Data, Seg, Sib, Disp</h4>\n<p>Stores the integer register Data to memory.</p>\n<h3 id=\"stf\">Stf</h3>\n<p>Store floating point.</p>\n<h4 id=\"stf-data-seg-sib-disp\">stf Data, Seg, Sib, Disp</h4>\n<p>Stores the floating point register Data to memory.</p>\n<h3 id=\"stm\">Stm</h3>\n<p>Store multimedia.</p>\n<h4 id=\"stm-data-seg-sib-disp\">stm Data, Seg, Sib, Disp</h4>\n<p>Store the multimedia register Data to memory.\nThis is not implemented and may never be.</p>\n<h3 id=\"stupd\">Stupd</h3>\n<p>Store with base update.</p>\n<h4 id=\"stupd-data-seg-sib-disp\">Stupd Data, Seg, Sib, Disp</h4>\n<p>Store the integer register Data to memory and update the base register.</p>\n<h3 id=\"lea\">Lea</h3>\n<p>Load effective address.</p>\n<h4 id=\"lea-data-seg-sib-disp\">lea Data, Seg, Sib, Disp</h4>\n<p>Calculates the address for this combination of parameters and stores it in Data.</p>\n<h3 id=\"cda\">Cda</h3>\n<p>Check data address.</p>\n<h4 id=\"cda-seg-sib-disp\">cda Seg, Sib, Disp</h4>\n<p>Check whether the data address is valid.\nThis is not implemented currently.</p>\n<h3 id=\"cdaf\">Cdaf</h3>\n<p>CDA with cache line flush.</p>\n<h4 id=\"cdaf-seg-sib-disp\">cdaf Seg, Sib, Disp</h4>\n<p>Check whether the data address is valid, and flush cache lines\nThis is not implemented currently.</p>\n<h3 id=\"cia\">Cia</h3>\n<p>Check instruction address.</p>\n<h4 id=\"cia-seg-sib-disp\">cia Seg, Sib, Disp</h4>\n<p>Check whether the instruction address is valid.\nThis is not implemented currently.</p>\n<h3 id=\"tia\">Tia</h3>\n<p>TLB invalidate address</p>\n<h4 id=\"tia-seg-sib-disp\">tia Seg, Sib, Disp</h4>\n<p>Invalidate the tlb entry which corresponds to this address.\nThis is not implemented currently.</p>\n<h1 id=\"load-immediate-op\">Load immediate Op</h1>\n<h3 id=\"limm\">Limm</h3>\n<h4 id=\"limm-dest-imm\">limm Dest, Imm</h4>\n<p>Stores the 64 bit immediate Imm into the integer register Dest.</p>\n<h1 id=\"floating-point-ops\">Floating Point Ops</h1>\n<h3 id=\"movfp\">Movfp</h3>\n<h4 id=\"movfp-dest-src\">movfp Dest, Src</h4>\n<p>Dest # Src</p>\n<p>Move the contents of the floating point register Src into the floating point register Dest.</p>\n<p>This instruction is predicated.</p>\n<h3 id=\"xorfp\">Xorfp</h3>\n<h4 id=\"xorfp-dest-src1-src2\">xorfp Dest, Src1, Src2</h4>\n<p>Dest # Src1 ^ Src2</p>\n<p>Compute the bitwise exclusive or of the floating point registers Src1 and Src2 and put the result in the floating point register Dest.</p>\n<h3 id=\"sqrtfp\">Sqrtfp</h3>\n<h4 id=\"sqrtfp-dest-src\">sqrtfp Dest, Src</h4>\n<p>Dest # sqrt(Src)</p>\n<p>Compute the square root of the floating point register Src and put the result in floating point register Dest.</p>\n<h3 id=\"addfp\">Addfp</h3>\n<h4 id=\"addfp-dest-src1-src2\">addfp Dest, Src1, Src2</h4>\n<p>Dest # Src1 + Src2</p>\n<p>Compute the sum of the floating point registers Src1 and Src2 and put the result in the floating point register Dest.</p>\n<h3 id=\"subfp\">Subfp</h3>\n<h4 id=\"subfp-dest-src1-src2\">subfp Dest, Src1, Src2</h4>\n<p>Dest # Src1 - Src2</p>\n<p>Compute the difference of the floating point registers Src1 and Src2 and put the result in the floating point register Dest.</p>\n<h3 id=\"mulfp\">Mulfp</h3>\n<h4 id=\"mulfp-dest-src1-src2\">mulfp Dest, Src1, Src2</h4>\n<p>Dest # Src1 * Src2</p>\n<p>Compute the product of the floating point registers Src1 and Src2 and put the result in the floating point register Dest.</p>\n<h3 id=\"divfp\">Divfp</h3>\n<h4 id=\"divfp-dest-src1-src2\">divfp Dest, Src1, Src2</h4>\n<p>Dest # Src1 / Src2</p>\n<p>Divide Src1 by Src2 and put the result in the floating point register Dest.</p>\n<h3 id=\"compfp\">Compfp</h3>\n<h4 id=\"compfp-src1-src2\">compfp Src1, Src2</h4>\n<p>Compare floating point registers Src1 and Src2.</p>\n<h3 id=\"cvtf_i2d\">Cvtf_i2d</h3>\n<h4 id=\"cvtf_i2d-dest-src\">cvtf_i2d Dest, Src</h4>\n<p>Convert integer register Src into a double floating point value and store the result in the lower part of Dest.</p>\n<h3 id=\"cvtf_i2d_hi\">Cvtf_i2d_hi</h3>\n<h4 id=\"cvtf_i2d_hi-dest-src\">cvtf_i2d_hi Dest, Src</h4>\n<p>Convert integer register Src into a double floating point value and store the result in the upper part of Dest.</p>\n<h3 id=\"cvtf_d2i\">Cvtf_d2i</h3>\n<h4 id=\"cvtf_d2i-dest-src\">cvtf_d2i Dest, Src</h4>\n<p>Convert floating point register Src into an integer value and store the result in the integer register Dest.</p>\n<h1 id=\"special-ops\">Special Ops</h1>\n<h3 id=\"fault\">Fault</h3>\n<p>Generate a fault.</p>\n<h4 id=\"fault-fault_code\">fault fault_code</h4>\n<p>Uses the C++ code fault_code to allocate a Fault object to return.</p>\n<h3 id=\"lddha\">Lddha</h3>\n<p>Set the default handler for a fault.\nThis is not implemented currently.</p>\n<h3 id=\"ldaha\">Ldaha</h3>\n<p>Set the alternate handler for a fault\nThis is not implemented currently.</p>\n<h1 id=\"sequencing-ops\">Sequencing Ops</h1>\n<p>These microops are used for control flow withing microcode</p>\n<h3 id=\"br\">Br</h3>\n<p>Microcode branch. This is never considered the last microop of a sequence. If it appears at the end of a macroop, it is assumed that it branches to microcode in the ROM.</p>\n<h4 id=\"br-target\">br target</h4>\n<p>micropc # target</p>\n<p>Set the micropc to the 16 bit immediate target.</p>\n<h4 id=\"flags-30\">Flags</h4>\n<p>This microop does not set any flags. It is optionally predicated.</p>\n<h3 id=\"eret\">Eret</h3>\n<p>Return from emulation. This instruction is always considered the last microop in a sequence. When executing from the ROM, it is the only way to return to normal instruction decoding.</p>\n<h4 id=\"eret-1\">eret</h4>\n<p>Return from emulation.</p>\n<h4 id=\"flags-31\">Flags</h4>\n<p>This microop does not set any flags. It is optionally predicated.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/architecture_support/isa_parser/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/building/EXTRAS\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/building",
        "title": "Building gem5",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"building-gem5\">Building gem5</h1>\n<h2 id=\"supported-operating-systems-and-environments\">Supported operating systems and environments</h2>\n<p>gem5 has been designed with a Linux environment in mind. We test regularly\non <strong>Ubuntu 22.04</strong> and <strong>Ubuntu 24.04</strong> to ensure gem5 functions well in\nthese environments. Though <strong>any Linux based OS should function if the correct\ndependencies are installed</strong>. We ensure that gem5 is compilable with both gcc\nand clang (see <a href=\"#dependencies\">Dependencies</a>  below for compiler version\ninformation).</p>\n<p>As of gem5 21.0, <strong>we support building and running gem5 with Python 3.6+\nonly</strong>. gem5 20.0 was our last version of gem5 to provide support for Python\n2.</p>\n<p>If running gem5 in a suitable OS/environment is not possible, we have provided\npre-prepared <a href=\"https://www.docker.com/\">Docker</a> images which may be used to\ncompile and run gem5. Please see our <a href=\"#docker\">Docker</a> section below for more\ninformation on this.</p>\n<h2 id=\"dependencies\">Dependencies</h2>\n<ul>\n<li><strong>git</strong> : gem5 uses git for version control.</li>\n<li><strong>gcc</strong>: gcc is used to compiled gem5. <strong>Version &gt;=10 must be used</strong>. We\nsupport up to gcc Version 13.</li>\n<li><strong>Clang</strong>: Clang can also be used. At present, we support Clang 7 to\nClang 16 (inclusive).</li>\n<li><strong>SCons</strong> : gem5 uses SCons as its build environment. SCons 3.0 or greater\nmust be used.</li>\n<li><strong>Python 3.6+</strong> : gem5 relies on Python development libraries. gem5 can be\ncompiled and run in environments using Python 3.6+.</li>\n<li><strong>protobuf 2.1+</strong> (Optional): The protobuf library is used for trace\ngeneration and playback.</li>\n<li><strong>Boost</strong> (Optional): The Boost library is a set of general purpose C++\nlibraries. It is a necessary dependency if you wish to use the SystemC\nimplementation.</li>\n</ul>\n<h3 id=\"setup-on-ubuntu-2404-gem5--v240\">Setup on Ubuntu 24.04 (gem5 &gt;= v24.0)</h3>\n<p>If compiling gem5 on Ubuntu 24.04, or related Linux distributions, you may\ninstall all these dependencies using APT:</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">sudo </span>apt <span class=\"nb\">install </span>build-essential scons python3-dev git pre-commit zlib1g zlib1g-dev <span class=\"se\">\\</span>\n    libprotobuf-dev protobuf-compiler libprotoc-dev libgoogle-perftools-dev <span class=\"se\">\\</span>\n    libboost-all-dev  libhdf5-serial-dev python3-pydot python3-venv python3-tk mypy <span class=\"se\">\\</span>\n    m4 libcapstone-dev libpng-dev libelf-dev pkg-config wget cmake doxygen clang-format\n</code></pre></div></div>\n<h3 id=\"setup-on-ubuntu-2204-gem5--v211\">Setup on Ubuntu 22.04 (gem5 &gt;= v21.1)</h3>\n<p>If compiling gem5 on Ubuntu 22.04, or related Linux distributions, you may\ninstall all these dependencies using APT:</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">sudo </span>apt <span class=\"nb\">install </span>build-essential git m4 scons zlib1g zlib1g-dev <span class=\"se\">\\</span>\n    libprotobuf-dev protobuf-compiler libprotoc-dev libgoogle-perftools-dev <span class=\"se\">\\</span>\n    python3-dev libboost-all-dev pkg-config python3-tk clang-format-15\n</code></pre></div></div>\n<p>You may need to configure <code class=\"language-plaintext highlighter-rouge\">clang-format-15</code> as the default\n<code class=\"language-plaintext highlighter-rouge\">clang-format</code> for your system.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\"># Configure clang-format-15 and git-clang-format-15 as the system defaults.</span>\n<span class=\"nb\">sudo </span>update-alternatives <span class=\"nt\">--install</span> /usr/bin/clang-format clang-format /usr/bin/clang-format-15 150 <span class=\"se\">\\</span>\n        <span class=\"nt\">--slave</span> /usr/bin/clang-format-diff clang-format-diff /usr/bin/clang-format-diff-15 <span class=\"se\">\\</span>\n        <span class=\"nt\">--slave</span> /usr/bin/git-clang-format git-clang-format /usr/bin/git-clang-format-15\n\n<span class=\"c\"># [Optional] Add other alternative versions, and select version 15 as the default version.</span>\n<span class=\"nb\">sudo </span>update-alternatives <span class=\"nt\">--config</span> clang-format\n</code></pre></div></div>\n<h3 id=\"setup-on-ubuntu-2004-gem5--v210\">Setup on Ubuntu 20.04 (gem5 &gt;= v21.0)</h3>\n<p>If compiling gem5 on Ubuntu 20.04, or related Linux distributions, you may\ninstall all these dependencies using APT:</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">sudo </span>apt <span class=\"nb\">install </span>build-essential git m4 scons zlib1g zlib1g-dev <span class=\"se\">\\</span>\n    libprotobuf-dev protobuf-compiler libprotoc-dev libgoogle-perftools-dev <span class=\"se\">\\</span>\n    python3-dev python-is-python3 libboost-all-dev pkg-config gcc-10 g++-10 <span class=\"se\">\\</span>\n    python3-tk clang-format-18\n</code></pre></div></div>\n<p>You may need to configure <code class=\"language-plaintext highlighter-rouge\">clang-format-18</code> as the default\n<code class=\"language-plaintext highlighter-rouge\">clang-format</code> for your system.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\"># Configure clang-format-18 and git-clang-format-18 as the system defaults.</span>\n<span class=\"nb\">sudo </span>update-alternatives <span class=\"nt\">--install</span> /usr/bin/clang-format clang-format /usr/bin/clang-format-18 180 <span class=\"se\">\\</span>\n        <span class=\"nt\">--slave</span> /usr/bin/clang-format-diff clang-format-diff /usr/bin/clang-format-diff-18 <span class=\"se\">\\</span>\n        <span class=\"nt\">--slave</span> /usr/bin/git-clang-format git-clang-format /usr/bin/git-clang-format-18\n\n<span class=\"c\"># [Optional] Add other alternative versions, and select version 18 as the default version.</span>\n<span class=\"nb\">sudo </span>update-alternatives <span class=\"nt\">--config</span> clang-format\n</code></pre></div></div>\n<h3 id=\"docker\">Docker</h3>\n<p>For users struggling to setup an environment to build and run gem5, we provide\nthe following Docker Images:</p>\n<p>Ubuntu 24.04 with all optional dependencies:\n<a href=\"https://ghcr.io/gem5/ubuntu-24.04_all-dependencies:v24-0\">ghcr.io/gem5/ubuntu-24.04_all-dependencies:v24-0</a>\n(<a href=\"https://github.com/gem5/gem5/blob/v24.0.0.0/util/dockerfiles/ubuntu-24.04_all-dependencies/Dockerfile\">source Dockerfile</a>).</p>\n<p>Ubuntu 24.04 with minimum dependencies:\n<a href=\"https://ghcr.io/gem5/ubuntu-24.04_min-dependencies:v24-0\">ghcr.io/gem5/ubuntu-24.04_min-dependencies:v24-0</a>\n(<a href=\"https://github.com/gem5/gem5/blob/v24.0.0.0/util/dockerfiles/ubuntu-24.04_min-dependencies/Dockerfile\">source Dockerfile</a>).</p>\n<p>Ubuntu 22.04 with all optional dependencies:\n<a href=\"https://ghcr.io/gem5/ubuntu-22.04_all-dependencies:v23-0\">ghcr.io/gem5/ubuntu-22.04_all-dependencies:v23-0</a> (<a href=\"https://github.com/gem5/gem5/blob/v23.0.1.0/util/dockerfiles/ubuntu-22.04_all-dependencies/Dockerfile\">source Dockerfile</a>).</p>\n<p>Ubuntu 20.04 with all optional dependencies:\n<a href=\"https://ghcr.io/gem5/ubuntu-20.04_all-dependencies:v23-0\">ghcr.io/gem5/ubuntu-20.04_all-dependencies:v23-0</a> (<a href=\"https://github.com/gem5/gem5/blob/v23.0.1.0/util/dockerfiles/ubuntu-20.04_all-dependencies/Dockerfile\">source Dockerfile</a>).</p>\n<p>Ubuntu 18.04 with all optional dependencies:\n<a href=\"https://ghcr.io/gem5/ubuntu-18.04_all-dependencies:v23-0\">ghcr.io/gem5/ubuntu-18.04_all-dependencies:v23-0</a> (<a href=\"https://github.com/gem5/gem5/blob/v23.0.1.0/util/dockerfiles/ubuntu-18.04_all-dependencies/Dockerfile\">source Dockerfile</a>).</p>\n<p>To obtain a docker image:</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>docker pull &lt;image&gt;\n</code></pre></div></div>\n<p>E.g., for Ubuntu 20.04 with all optional dependencies:</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>docker pull ghcr.io/gem5/ubuntu-20.04_all-dependencies:v23-0\n</code></pre></div></div>\n<p>Then, to work within this environment, we suggest using the following:</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>docker run <span class=\"nt\">-u</span> <span class=\"nv\">$UID</span>:<span class=\"nv\">$GID</span> <span class=\"nt\">--volume</span> &lt;gem5 directory&gt;:/gem5 <span class=\"nt\">--rm</span> <span class=\"nt\">-it</span> &lt;image&gt;\n</code></pre></div></div>\n<p>Where <code class=\"language-plaintext highlighter-rouge\">&lt;gem5 directory&gt;</code> is the full path of the gem5 in your file system, and\n<code class=\"language-plaintext highlighter-rouge\">&lt;image&gt;</code> is the image pulled (e.g.,\nghcr.io/gem5/ubuntu-22.04_all-dependencies:v23-0`).</p>\n<p>From this environment, you will be able to build and run gem5 from the <code class=\"language-plaintext highlighter-rouge\">/gem5</code>\ndirectory.</p>\n<h2 id=\"getting-the-code\">Getting the code</h2>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>git clone https://github.com/gem5/gem5\n</code></pre></div></div>\n<h2 id=\"building-with-scons\">Building with SCons</h2>\n<p>gem5\u2019s build system is based on SCons, an open source build system implemented\nin Python. You can find more information about scons at <a href=\"http://www.scons.org\">http://www.scons.org</a>.\nThe main scons file is called SConstruct and is found in the root of the source\ntree. Additional scons files are named SConscript and are found throughout the\ntree, usually near the files they\u2019re associated with.</p>\n<p>Within the root of the gem5 directory, gem5 can be built with SCons using:</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>scons build/<span class=\"o\">{</span>ISA<span class=\"o\">}</span>/gem5.<span class=\"o\">{</span>variant<span class=\"o\">}</span> <span class=\"nt\">-j</span> <span class=\"o\">{</span>cpus<span class=\"o\">}</span>\n</code></pre></div></div>\n<p>where <code class=\"language-plaintext highlighter-rouge\">{ISA}</code> is the target (guest) Instruction Set Architecture, and\n<code class=\"language-plaintext highlighter-rouge\">{variant}</code> specifies the compilation settings. For most intents and purposes\n<code class=\"language-plaintext highlighter-rouge\">opt</code> is a good target for compilation. The <code class=\"language-plaintext highlighter-rouge\">-j</code> flag is optional and allows\nfor parallelization of compilation with <code class=\"language-plaintext highlighter-rouge\">{cpus}</code> specifying the number of\nthreads. A single-threaded compilation from scratch can take up to 2 hours on\nsome systems. We therefore strongly advise allocating more threads if possible.\nHowever, compilation of gem5 is compute and memory intensive and increasing the\nnumber of threads also increases memory usage. If using a machine with less\nmemory, it is recommended to use fewer threads (e.g. <code class=\"language-plaintext highlighter-rouge\">-j 1</code> or <code class=\"language-plaintext highlighter-rouge\">-j 2</code>).</p>\n<p>The valid ISAs are:</p>\n<ul>\n<li>ALL - recommended, as it has all ISAs and all Ruby protocols as of gem5 v24.1</li>\n<li>ARM</li>\n<li>NULL</li>\n<li>MIPS</li>\n<li>POWER</li>\n<li>RISCV</li>\n<li>SPARC</li>\n<li>X86</li>\n</ul>\n<p>The valid build variants are:</p>\n<ul>\n<li><strong>debug</strong> has optimizations turned off. This ensures that variables won\u2019t be\noptimized out, functions won\u2019t be unexpectedly inlined, and control flow will\nnot behave in surprising ways. That makes this version easier to work with in\ntools like gdb, but without optimizations this version is significantly slower\nthan the others. You should choose it when using tools like gdb and valgrind\nand don\u2019t want any details obscured, but other wise more optimized versions are\nrecommended.</li>\n<li><strong>opt</strong> has optimizations turned on and debugging functionality like asserts\nand DPRINTFs left in. This gives a good balance between the speed of the\nsimulation and insight into what\u2019s happening in case something goes wrong. This\nversion is best in most circumstances.</li>\n<li><strong>fast</strong> has optimizations turned on and debugging functionality compiled\nout. This pulls out all the stops performance wise, but does so at the expense\nof run time error checking and the ability to turn on debug output. This\nversion is recommended if you\u2019re very confident everything is working correctly\nand want to get peak performance from the simulator.</li>\n</ul>\n<p>These versions are summarized in the following table.</p>\n<table>\n<thead>\n<tr>\n<th>Build variant</th>\n<th>Optimizations</th>\n<th>Run time debugging support</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>debug</strong></td>\n<td>\u00a0</td>\n<td>X</td>\n</tr>\n<tr>\n<td><strong>opt</strong></td>\n<td>X</td>\n<td>X</td>\n</tr>\n<tr>\n<td><strong>fast</strong></td>\n<td>X</td>\n<td>\u00a0</td>\n</tr>\n</tbody>\n</table>\n<p>For example, to build gem5 on 4 threads with <code class=\"language-plaintext highlighter-rouge\">opt</code> and with all ISAs:</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>scons build/ALL/gem5.opt <span class=\"nt\">-j</span> 4\n</code></pre></div></div>\n<p>In addition, users may make use of the \u201cgprof\u201d and \u201cpperf\u201d build options to\nenable profiling:</p>\n<ul>\n<li><strong>gprof</strong> allows gem5 to be used with the gprof profiling tool. It can be\nenabled by compiling with the <code class=\"language-plaintext highlighter-rouge\">--gprof</code> flag. E.g.,\n<code class=\"language-plaintext highlighter-rouge\">scons build/ALL/gem5.debug --gprof</code>.</li>\n<li><strong>pprof</strong> allows gem5 to be used with the pprof profiling tool. It can be\nenabled by compiling with the <code class=\"language-plaintext highlighter-rouge\">--pprof</code> flag. E.g.,\n<code class=\"language-plaintext highlighter-rouge\">scons build/ALL/gem5.debug --pprof</code>.</li>\n</ul>\n<h2 id=\"build-with-kconfig\">Build with Kconfig</h2>\n<p>Please see <a href=\"https://www.gem5.org/documentation/general_docs/kconfig_build_system/\">here</a></p>\n<h2 id=\"usage\">Usage</h2>\n<p>Once compiled, gem5 can then be run using:</p>\n<div class=\"language-console highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"go\">./build/{ISA}/gem5.{variant} [gem5 options] {simulation script} [script options]\n</span></code></pre></div></div>\n<p>If you are building gem5 from a pre-compiled binary, gem5 can be run with the following command:</p>\n<div class=\"language-console highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"go\">gem5 [gem5 options] {simulation script} [script options]\n</span></code></pre></div></div>\n<p>Running with the <code class=\"language-plaintext highlighter-rouge\">--help</code> flag will display all the available options:</p>\n<pre><code class=\"language-txt\">Usage\n=====\n  gem5.opt [gem5 options] script.py [script options]\n\ngem5 is copyrighted software; use the --copyright option for details.\n\nOptions\n=======\n--help, -h              show this help message and exit\n--build-info, -B        Show build information\n--copyright, -C         Show full copyright information\n--readme, -R            Show the readme\n--outdir=DIR, -d DIR    Set the output directory to DIR [Default: m5out]\n--redirect-stdout, -r   Redirect stdout (&amp; stderr, without -e) to file\n--redirect-stderr, -e   Redirect stderr to file\n--silent-redirect       Suppress printing a message when redirecting stdout or\n                        stderr\n--stdout-file=FILE      Filename for -r redirection [Default: simout.txt]\n--stderr-file=FILE      Filename for -e redirection [Default: simerr.txt]\n--listener-mode={on,off,auto}\n                        Port (e.g., gdb) listener mode (auto: Enable if\n                        running interactively) [Default: auto]\n--allow-remote-connections\n                        Port listeners will accept connections from anywhere\n                        (0.0.0.0). Default is only localhost.\n--interactive, -i       Invoke the interactive interpreter after running the\n                        script\n--pdb                   Invoke the python debugger before running the script\n--path=PATH[:PATH], -p PATH[:PATH]\n                        Prepend PATH to the system path when invoking the\n                        script\n--quiet, -q             Reduce verbosity\n--verbose, -v           Increase verbosity\n-m mod                  run library module as a script (terminates option\n                        list)\n-c cmd                  program passed in as string (terminates option list)\n-P                      Don't prepend the script directory to the system path.\n                        Mimics Python 3's `-P` option.\n-s                      IGNORED, only for compatibility with python. don'tadd\n                        user site directory to sys.path; also PYTHONNOUSERSITE\n\nStatistics Options\n------------------\n--stats-file=FILE       Sets the output file for statistics [Default:\n                        stats.txt]\n--stats-help            Display documentation for available stat visitors\n\nConfiguration Options\n---------------------\n--dump-config=FILE      Dump configuration output file [Default: config.ini]\n--json-config=FILE      Create JSON output of the configuration [Default:\n                        config.json]\n--dot-config=FILE       Create DOT &amp; pdf outputs of the configuration\n                        [Default: config.dot]\n--dot-dvfs-config=FILE  Create DOT &amp; pdf outputs of the DVFS configuration\n                        [Default: none]\n\nDebugging Options\n-----------------\n--debug-break=TICK[,TICK]\n                        Create breakpoint(s) at TICK(s) (kills process if no\n                        debugger attached)\n--debug-help            Print help on debug flags\n--debug-flags=FLAG[,FLAG]\n                        Sets the flags for debug output (-FLAG disables a\n                        flag)\n--debug-start=TICK      Start debug output at TICK\n--debug-end=TICK        End debug output at TICK\n--debug-file=FILE       Sets the output file for debug. Append '.gz' to the\n                        name for it to be compressed automatically [Default:\n                        cout]\n--debug-activate=EXPR[,EXPR]\n                        Activate EXPR sim objects\n--debug-ignore=EXPR     Ignore EXPR sim objects\n--remote-gdb-port=REMOTE_GDB_PORT\n                        Remote gdb base port (set to 0 to disable listening)\n\nHelp Options\n------------\n--list-sim-objects      List all built-in SimObjects, their params and default\n                        values\n</code></pre>\n<h2 id=\"using-extras\">Using EXTRAS</h2>\n<p>The <a href=\"/documentation/general_docs/building/EXTRAS\">EXTRAS</a> scons variable can be\nused to build additional directories of source files into gem5 by setting it to\na colon delimited list of paths to these additional directories. EXTRAS is a\nhandy way to build on top of the gem5 code base without mixing your new source\nwith the upstream source. You can then manage your new body of code however you\nneed to independently from the main code base.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/building/EXTRAS\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/checkpoints/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/building/EXTRAS",
        "title": "Building EXTRAS",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"building-extras\">Building EXTRAS</h1>\n<p>The <code class=\"language-plaintext highlighter-rouge\">EXTRAS</code> SCons option is a way to add functionality in gem5 without adding your files to the gem5 source tree. Specifically, it allows you to identify one or more directories that will get compiled in with gem5 as if they appeared under the \u2018src\u2019 part of the gem5 tree, without requiring the code to be actually located under \u2018src\u2019. It\u2019s present to allow user to compile in additional functionality (typically additional SimObject classes) that isn\u2019t or can\u2019t be distributed with gem5. This is useful for maintaining local code that isn\u2019t suitable for incorporating into the gem5 source tree, or third-party code that can\u2019t be incorporated due to an incompatible license. Because the EXTRAS location is completely independent of the gem5 repository, you can keep the code under a different version control system as well.</p>\n<p>The main drawback of the EXTRAS feature is that, by itself, it only supports adding code to gem5, not modifying any of the base gem5 code.</p>\n<p>One use of the EXTRAS feature is to support EIO traces. The trace reader for EIO is licensed under the SimpleScalar license, and due to the incompatibility of that license with gem5\u2019s BSD license, the code to read these traces is not included in the gem5 distribution. Instead, the EIO code is distributed via a separate \u201cencumbered\u201d <a href=\"https://github.com/gem5/gem5\">repository</a>.</p>\n<p>The following examples show how to compile the EIO code. By adding to or modifying the extras path, any other suitable extra could be compiled in. To compile in code using EXTRAS simply execute the following</p>\n<div class=\"language-js highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code> <span class=\"nx\">scons</span> <span class=\"nx\">EXTRAS</span><span class=\"o\">=</span><span class=\"sr\">/path/</span><span class=\"nx\">to</span><span class=\"o\">/</span><span class=\"nx\">encumbered</span> <span class=\"nx\">build</span><span class=\"o\">/&lt;</span><span class=\"nx\">ISA</span><span class=\"o\">&gt;</span><span class=\"sr\">/gem5.op</span><span class=\"err\">t\n</span></code></pre></div></div>\n<p>In the root of this directory you should have a SConscript that uses the <code class=\"language-plaintext highlighter-rouge\">Source()</code> and <code class=\"language-plaintext highlighter-rouge\">SimObject()</code> scons functions that are used in the rest of M5 to compile the appropriate sources and add any SimObjects of interest. If you want to add more than one directory, you can set EXTRAS to a colon-separated list of paths.</p>\n<p>Note that EXTRAS is a \u201csticky\u201d parameter, so after a value is provided to scons once, the value will be reused for future scons invocations targeting the same build directory (<code class=\"language-plaintext highlighter-rouge\">build/&lt;ISA&gt;</code> in this case) as long as it is not overridden. Thus you only need to specify EXTRAS the first time you build a particular configuration or if you want to override a previously specified value.\nTo run a regression with EXTRAS use a command line similar to the following:</p>\n<div class=\"language-js highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code> <span class=\"p\">.</span><span class=\"o\">/</span><span class=\"nx\">util</span><span class=\"o\">/</span><span class=\"nx\">regress</span> <span class=\"o\">--</span><span class=\"nx\">scons</span><span class=\"o\">-</span><span class=\"nx\">opts</span> <span class=\"o\">=</span> <span class=\"dl\">\"</span><span class=\"s2\">EXTRAS=/path/to/encumbered</span><span class=\"dl\">\"</span> <span class=\"o\">-</span><span class=\"nx\">j</span> <span class=\"mi\">2</span> <span class=\"nx\">quick</span>\n</code></pre></div></div>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/architecture_support/x86_microop_isa/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/building\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/checkpoints",
        "title": "Checkpoints",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"checkpoints\">Checkpoints</h1>\n<p>Checkpoints are essentially snapshots of a simulation. You would want to use a checkpoint when your simulation takes an extremely long time (which is almost always the case) so you can resume from that checkpoint at a later time with the DerivO3CPU.</p>\n<h2 id=\"creation\">Creation</h2>\n<p>First of all, you need to create a checkpoint. Each checkpoint as saved in a new directory named \u2018cpt.TICKNUMBER\u2019, where TICKNUMBER refers to the tick value at which this checkpoint was created. There are several ways in which a checkpoint can be created:</p>\n<ul>\n<li>After booting the gem5 simulator, execute the command m5 checkpoint. One can execute the command manually using m5term, or include it in a run script to do this automatically after the Linux kernel has booted up.</li>\n<li>There is a pseudo instruction that can be used for creating checkpoints. For example, one may include this pseudo instruction in an application program, so that the checkpoint is created when the application has reached a certain state.</li>\n<li>The option <strong>-</strong><strong>-take-checkpoints</strong> can be provided to the python scripts (fs.py, ruby_fs.py) so that checkpoints are dumped periodically. The option <strong>-</strong><strong>-checkpoint-at-end</strong> can be used for creating the checkpoint at the end of the simulation. Take a look at the file <strong>configs/common/Options.py</strong> for these options.</li>\n</ul>\n<p>While creating checkpoints with Ruby memory model, it is necessary to use the MOESI hammer protocol. This is because checkpointing the correct memory state requires that the caches are flushed to the memory. This flushing operation is currently supported only with the MOESI hammer protocol.</p>\n<h2 id=\"restoring\">Restoring</h2>\n<p>Restoring from a checkpoint can usually be easily done from the command line, e.g.:</p>\n<div class=\"language-console highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"go\">  build/ALL/gem5.debug configs/example/fs.py -r N\n  OR\n  build/ALL/gem5.debug configs/example/fs.py --checkpoint-restore=N\n</span></code></pre></div></div>\n<p>The number N is integer that represents checkpoint number which usually starts from 1 then increases incrementally to 2,3,4\u2026</p>\n<p>By default, gem5 assumes that the checkpoint is to be restored using Atomic CPUs. This may not work if the checkpoint was recorded using Timing / Detailed / Inorder CPU. One can mention the option <br> <strong>-</strong><strong>-restore-with-cpu &lt;CPU Type&gt;</strong> on the command line. The cpu type supplied with this option is then used for restoring from the checkpoint.</br></p>\n<h2 id=\"detailed-example-parsec\">Detailed example: Parsec</h2>\n<p>In the following section we would describe how checkpoints are created for workloads PARSEC benchmark suite. However similar procedure can be followed to create checkpoint for other workloads beyond PARSEC suite. Following are the high level steps of creating checkpoint:</p>\n<ol>\n<li>Annotate each workload with start and end of Region of Interest and with start and end of work units in the program.</li>\n<li>Take a checkpoint at the start of the Region of Interest.</li>\n<li>Simulate the whole program in the Region of Interest and periodically take checkpoints.</li>\n<li>Analyse the statistics corresponding to periodic checkpoints and select the most interesting section of the program execution.</li>\n<li>Take warm up cache trace for Ruby before reaching most interesting portion of the program and take the final checkpoint.\nIn each of the following sections we explain each of the above steps in more details.</li>\n</ol>\n<h3 id=\"annotating-workloads\">Annotating workloads</h3>\n<p>Annotation is required for two purposes: for defining region of program beyond the initialization section of a program and for defining logical units of work in each of the workloads.</p>\n<p>Workloads in PARSEC benchmark suite, already has annotating demarcating start and end of portion of program without program initialization section and program finalization section. We just use gem5 specific annotation for start of Region of Interest. The start of the Region of Interest (ROI) is marked by <strong>m5_roi_begin()</strong> and the end of ROI is demarcated by <strong>m5_roi_end()</strong>.</p>\n<p>Due to large simulation time its not always possible to simulate whole program. Moreover, unlike single threaded programs, simulating for a given number instructions in multi-threaded workloads is not a correct way to simulate portion of a program due to possible presence of instructions spinning on synchronization variable. Thus it is important define semantically meaningful logical units of work in each workload. Simulating for a given number of workuints in a multi-threaded workloads gives a reasonable way of simulating portion of workloads as the problem of instructions spinning on synchronization variables.</p>\n<h1 id=\"switchoverfastforwarding\">Switchover/Fastforwarding</h1>\n<h2 id=\"sampling\">Sampling</h2>\n<p>Sampling (switching between functional and detailed models) can be implemented via your Python script. In your script you can direct the simulator to switch between two sets of CPUs. To do this, in your script setup a list of tuples of (oldCPU, newCPU). If there are multiple CPUs you wish to switch simultaneously, they can all be added to that list. For example:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">run_cpu1</span> <span class=\"o\">=</span> <span class=\"n\">SimpleCPU</span><span class=\"p\">()</span>\n<span class=\"n\">switch_cpu1</span> <span class=\"o\">=</span> <span class=\"n\">DetailedCPU</span><span class=\"p\">(</span><span class=\"n\">switched_out</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n<span class=\"n\">run_cpu2</span> <span class=\"o\">=</span> <span class=\"n\">SimpleCPU</span><span class=\"p\">()</span>\n<span class=\"n\">switch_cpu2</span> <span class=\"o\">=</span> <span class=\"n\">FooCPU</span><span class=\"p\">(</span><span class=\"n\">switched_out</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n<span class=\"n\">switch_cpu_list</span> <span class=\"o\">=</span> <span class=\"p\">[(</span><span class=\"n\">run_cpu1</span><span class=\"p\">,</span><span class=\"n\">switch_cpu1</span><span class=\"p\">),(</span><span class=\"n\">run_cpu2</span><span class=\"p\">,</span><span class=\"n\">switch_cpu2</span><span class=\"p\">)]</span>\n</code></pre></div></div>\n<p>Note that the CPU that does not immediately run should have the parameter \u201cswitched_out=True\u201d. This keeps those CPUs from adding themselves to the list of CPUs to run; they will instead get added when you switch them in.</p>\n<p>In order for gem5 to instantiate all of your CPUs, you must make the CPUs that will be switched in a child of something that is in the configuration hierarchy. Unfortunately at the moment some configuration limitations force the switch CPU to be placed outside of the System object. The Root object is the next most convenient place to place the CPU, as shown below:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">m5</span><span class=\"p\">.</span><span class=\"n\">simulate</span><span class=\"p\">(</span><span class=\"mi\">500</span><span class=\"p\">)</span>  <span class=\"c1\"># simulate for 500 cycles\n</span><span class=\"n\">m5</span><span class=\"p\">.</span><span class=\"n\">switchCpus</span><span class=\"p\">(</span><span class=\"n\">switch_cpu_list</span><span class=\"p\">)</span>\n<span class=\"n\">m5</span><span class=\"p\">.</span><span class=\"n\">simulate</span><span class=\"p\">(</span><span class=\"mi\">500</span><span class=\"p\">)</span>  <span class=\"c1\"># simulate another 500 cycles after switching\n</span></code></pre></div></div>\n<p>Note that gem5 may have to simulate for a few cycles prior to switching CPUs due to any outstanding state that may be present in the CPUs being switched out.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/building\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/common-errors/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/compiling_workloads/",
        "title": "Compiling Workloads",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Hoa Nguyen<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"compiling-workloads\">Compiling Workloads</h1>\n<h2 id=\"cross-compilers\">Cross Compilers</h2>\n<p>A cross compiler is a compiler set up to run on one ISA but generate binaries which run on another. \nYou may need one if you intend to simulate a system which uses a particular ISA, Alpha for instance, but don\u2019t have access to actual Alpha hardware.</p>\n<p>There are various sources for cross compilers. The following are some of them.</p>\n<ol>\n<li><a href=\"https://packages.debian.org/stretch/gcc-arm-linux-gnueabihf\">ARM</a>.</li>\n<li><a href=\"https://github.com/riscv/riscv-gnu-toolchain\">RISC-V</a>.</li>\n</ol>\n<h2 id=\"qemu\">QEMU</h2>\n<p>Alternatively, you can use QEMU and a disk image to run the desired ISA in emulation. \nTo create more recent disk images, see <a href=\"/documentation/general_docs/fullsystem/disk\">this page</a>. \nThe following is a youtube video of working with image files using qemu on Ubuntu 12.04 64bit.</p>\n<iframe allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\" frameborder=\"0\" height=\"315\" src=\"https://www.youtube.com/embed/Oh3NK12fnbg\" width=\"560\"></iframe>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/common-errors/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/cpu_models/execution_basics\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/cpu_models/",
        "title": "No Title Found",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h2 id=\"gem5-bootcamp-2022-module-on-using-cpu-models\">gem5 bootcamp 2022 module on using CPU models</h2>\n<p>gem5 bootcamp (2022) had a session on learning the use of different gem5 CPU models.\nThe slides presented in the session can be found <a href=\"https://ucdavis365-my.sharepoint.com/:p:/g/personal/jlowepower_ucdavis_edu/EYRn68yb9nZJk9Puf7dV40YBm25hQ91WCXnEwyjqniqeVQ?e=7Xo0\">here</a>.</p>\n<p>The youtube video of the recorded bootcamp module on gem5 CPU models is available <a href=\"https://youtu.be/cDv-g-c0XCY\">here</a>.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/cpu_models/execution_basics\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/cpu_models/minor_cpu\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/cpu_models/O3CPU",
        "title": "O3CPU",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"o3cpu\"><strong>O3CPU</strong></h1>\n<p>Table of Contents</p>\n<ol>\n<li><a href=\"##Pipeline-stages\">Pipeline stages</a></li>\n<li><a href=\"##Execute-in-execute-model\">Execute-in-execute model</a></li>\n<li><a href=\"##Template-Policies\">Template Policies</a></li>\n<li><a href=\"##ISA-independence\">ISA independence</a></li>\n<li><a href=\"##Interaction-with-ThreadContext**\">Interaction with ThreadContext</a></li>\n</ol>\n<p>The O3CPU is our new detailed model for the v2.0 release. It is an out of order CPU model loosely based on the Alpha 21264. This page will give you a general overview of the O3CPU model, the pipeline stages and the pipeline resources. We have made efforts to keep the code well documented, so please browse the code for exact details on how each part of the O3CPU works.</p>\n<h2 id=\"pipeline-stages\"><strong>Pipeline stages</strong></h2>\n<ul>\n<li>\n<p>Fetch</p>\n<p>Fetches instructions each cycle, selecting which thread to fetch from based on the policy selected. This stage is where the DynInst is first created. Also handles branch prediction.</p>\n</li>\n<li>\n<p>Decode</p>\n<p>Decodes instructions each cycle. Also handles early resolution of PC-relative unconditional branches.</p>\n</li>\n<li>\n<p>Rename</p>\n<p>Renames instructions using a physical register file with a free list. Will stall if there are not enough registers to rename to, or if back-end resources have filled up. Also handles any serializing instructions at this point by stalling them in rename until the back-end drains.</p>\n</li>\n<li>\n<p>Issue/Execute/Writeback</p>\n<p>Our simulator model handles both execute and writeback when the execute() function is called on an instruction, so we have combined these three stages into one stage. This stage (IEW) handles dispatching instructions to the instruction queue, telling the instruction queue to issue instruction, and executing and writing back instructions.</p>\n</li>\n<li>\n<p>Commit</p>\n<p>Commits instructions each cycle, handling any faults that the instructions may have caused. Also handles redirecting the front-end in the case of a branch misprediction.</p>\n</li>\n</ul>\n<h2 id=\"execute-in-execute-model\"><strong>Execute-in-execute model</strong></h2>\n<p>For the O3CPU, we\u2019ve made efforts to make it highly timing accurate. In order to do this, we use a model that actually executes instructions at the execute stage of the pipeline. Most simulator models will execute instructions either at the beginning or end of the pipeline; SimpleScalar and our old detailed CPU model both execute instructions at the beginning of the pipeline and then pass it to a timing backend. This presents two potential problems: first, there is the potential for error in the timing backend that would not show up in program results. Second, by executing at the beginning of the pipeline, the instructions are all executed in order and out-of-order load interaction is lost. Our model is able to avoid these deficiencies and provide an accurate timing model.</p>\n<h2 id=\"template-policies\"><strong>Template Policies</strong></h2>\n<p>The O3CPU makes heavy use of template policies to obtain a level of polymorphism without having to use virtual functions. It uses template policies to pass in an \u201cImpl\u201d to almost all of the classes used within the O3CPU. This Impl has defined within it all of the important classes for the pipeline, such as the specific Fetch class, Decode class, specific DynInst types, the CPU class, etc. It allows any class that uses it as a template parameter to be able to obtain full type information of any of the classes defined within the Impl. By obtaining full type information, there is no need for the traditional virtual functions/base classes which are normally used to provide polymorphism. The main drawback is that the CPU must be entirely defined at compile time, and that the templated classes require manual instantiation. See <code class=\"language-plaintext highlighter-rouge\">src/cpu/o3/impl.hh </code> and <code class=\"language-plaintext highlighter-rouge\">src/cpu/o3/cpu_policy.hh</code> for example Impl classes.</p>\n<h2 id=\"isa-independence\"><strong>ISA independence</strong></h2>\n<p>The O3CPU has been designed to try to separate code that is ISA dependent and code that is ISA independent. The pipeline stages and resources are all mainly ISA independent, as well as the lower level CPU code. The ISA dependent code implements ISA-specific functions. For example, the AlphaO3CPU implements Alpha-specific functions, such as hardware return from error interrupt (hwrei()) or reading the interrupt flags. The lower level CPU, the FullO3CPU, handles orchestrating all of the pipeline stages and handling other ISA-independent actions. We hope this separation makes it easier to implement future ISAs, as hopefully only the high level classes will have to be redefined.</p>\n<h2 id=\"interaction-with-threadcontext\"><strong>Interaction with ThreadContext</strong></h2>\n<p>The <a href=\"/documentation/general_docs/cpu_models/execution_basics\">ThreadContext</a> provides interface for external objects to access thread state within the CPU. However, this is slightly complicated by the fact that the O3CPU is an out-of-order CPU. While it is well defined what the architectural state is at any given cycle, it is not well defined what happens if that architectural state is changed. Thus it is feasible to do reads to the ThreadContext without much effort, but doing writes to the ThreadContext and altering register state requires the CPU to flush the entire pipeline. This is because there may be in flight instructions that depend on the register that has been changed, and it is unclear if they should or should not view the register update. Thus accesses to the ThreadContext have the potential to cause slowdown in the CPU simulation.</p>\n<h2 id=\"backend-pipeline\"><strong>Backend Pipeline</strong></h2>\n<h3 id=\"compute-instructions\">Compute Instructions</h3>\n<p>Compute instructions are simpler as they do not access memory and\ndo not interact with the LSQ. Included below is a high-level calling chain\n(only important functions) with a description about the functionality of each.</p>\n<div class=\"language-cpp highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">Rename</span><span class=\"o\">::</span><span class=\"n\">tick</span><span class=\"p\">()</span><span class=\"o\">-&gt;</span><span class=\"n\">Rename</span><span class=\"o\">::</span><span class=\"n\">RenameInsts</span><span class=\"p\">()</span>\n<span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">tick</span><span class=\"p\">()</span><span class=\"o\">-&gt;</span><span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">dispatchInsts</span><span class=\"p\">()</span>\n<span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">tick</span><span class=\"p\">()</span><span class=\"o\">-&gt;</span><span class=\"n\">InstructionQueue</span><span class=\"o\">::</span><span class=\"n\">scheduleReadyInsts</span><span class=\"p\">()</span>\n<span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">tick</span><span class=\"p\">()</span><span class=\"o\">-&gt;</span><span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">executeInsts</span><span class=\"p\">()</span>\n<span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">tick</span><span class=\"p\">()</span><span class=\"o\">-&gt;</span><span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">writebackInsts</span><span class=\"p\">()</span>\n<span class=\"n\">Commit</span><span class=\"o\">::</span><span class=\"n\">tick</span><span class=\"p\">()</span><span class=\"o\">-&gt;</span><span class=\"n\">Commit</span><span class=\"o\">::</span><span class=\"n\">commitInsts</span><span class=\"p\">()</span><span class=\"o\">-&gt;</span><span class=\"n\">Commit</span><span class=\"o\">::</span><span class=\"n\">commitHead</span><span class=\"p\">()</span>\n</code></pre></div></div>\n<ul>\n<li>Rename (<code class=\"language-plaintext highlighter-rouge\">Rename::renameInsts()</code>).\nAs suggested by the name, registers are renamed and the instruction\nis pushed to the IEW stage. It checks that the IQ/LSQ can hold the new\ninstruction.</li>\n<li>Dispatch (<code class=\"language-plaintext highlighter-rouge\">IEW::dispatchInsts()</code>).\nThis function inserts the renamed instruction into the IQ and LSQ.</li>\n<li>Schedule (<code class=\"language-plaintext highlighter-rouge\">InstructionQueue::scheduleReadyInsts()</code>)\nThe IQ manages the ready instructions (operands ready) in a ready list,\nand schedules them to an available FU. The latency of the FU is set here,\nand instructions are sent to execution when the FU done.</li>\n<li>Execute (<code class=\"language-plaintext highlighter-rouge\">IEW::executeInsts()</code>).\nHere <code class=\"language-plaintext highlighter-rouge\">execute()</code> function of the compute instruction is invoked and\nsent to commit. Please note <code class=\"language-plaintext highlighter-rouge\">execute()</code> will write results to the destiniation\nregister.</li>\n<li>Writeback (<code class=\"language-plaintext highlighter-rouge\">IEW::writebackInsts()</code>).\nHere <code class=\"language-plaintext highlighter-rouge\">InstructionQueue::wakeDependents()</code> is invoked. Dependent\ninstructions will be added to the ready list for scheduling.</li>\n<li>Commit (<code class=\"language-plaintext highlighter-rouge\">Commit::commitInsts()</code>).\nOnce the instruction reaches the head of ROB, it will be committed and\nreleased from ROB.</li>\n</ul>\n<h3 id=\"load-instruction\">Load Instruction</h3>\n<p>Load instructions share the same path as compute instructions until\nexecution.</p>\n<div class=\"language-cpp highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">tick</span><span class=\"p\">()</span><span class=\"o\">-&gt;</span><span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">executeInsts</span><span class=\"p\">()</span>\n  <span class=\"o\">-&gt;</span><span class=\"n\">LSQUnit</span><span class=\"o\">::</span><span class=\"n\">executeLoad</span><span class=\"p\">()</span>\n    <span class=\"o\">-&gt;</span><span class=\"n\">StaticInst</span><span class=\"o\">::</span><span class=\"n\">initiateAcc</span><span class=\"p\">()</span>\n      <span class=\"o\">-&gt;</span><span class=\"n\">LSQ</span><span class=\"o\">::</span><span class=\"n\">pushRequest</span><span class=\"p\">()</span>\n        <span class=\"o\">-&gt;</span><span class=\"n\">LSQUnit</span><span class=\"o\">::</span><span class=\"n\">read</span><span class=\"p\">()</span>\n          <span class=\"o\">-&gt;</span><span class=\"n\">LSQRequest</span><span class=\"o\">::</span><span class=\"n\">buildPackets</span><span class=\"p\">()</span>\n          <span class=\"o\">-&gt;</span><span class=\"n\">LSQRequest</span><span class=\"o\">::</span><span class=\"n\">sendPacketToCache</span><span class=\"p\">()</span>\n    <span class=\"o\">-&gt;</span><span class=\"n\">LSQUnit</span><span class=\"o\">::</span><span class=\"n\">checkViolation</span><span class=\"p\">()</span>\n<span class=\"n\">DcachePort</span><span class=\"o\">::</span><span class=\"n\">recvTimingResp</span><span class=\"p\">()</span><span class=\"o\">-&gt;</span><span class=\"n\">LSQRequest</span><span class=\"o\">::</span><span class=\"n\">recvTimingResp</span><span class=\"p\">()</span>\n  <span class=\"o\">-&gt;</span><span class=\"n\">LSQUnit</span><span class=\"o\">::</span><span class=\"n\">completeDataAccess</span><span class=\"p\">()</span>\n    <span class=\"o\">-&gt;</span><span class=\"n\">LSQUnit</span><span class=\"o\">::</span><span class=\"n\">writeback</span><span class=\"p\">()</span>\n      <span class=\"o\">-&gt;</span><span class=\"n\">StaticInst</span><span class=\"o\">::</span><span class=\"n\">completeAcc</span><span class=\"p\">()</span>\n      <span class=\"o\">-&gt;</span><span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">instToCommit</span><span class=\"p\">()</span>\n<span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">tick</span><span class=\"p\">()</span><span class=\"o\">-&gt;</span><span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">writebackInsts</span><span class=\"p\">()</span>\n</code></pre></div></div>\n<ul>\n<li><code class=\"language-plaintext highlighter-rouge\">LSQUnit::executeLoad()</code> will initiate the access by invoking the\ninstruction\u2019s <code class=\"language-plaintext highlighter-rouge\">initiateAcc()</code> function. Through the execution context interface,\n<code class=\"language-plaintext highlighter-rouge\">initiateAcc()</code> will call <code class=\"language-plaintext highlighter-rouge\">initiateMemRead()</code> and eventually be directed\nto <code class=\"language-plaintext highlighter-rouge\">LSQ::pushRequest()</code>.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">LSQ::pushRequest()</code> will allocate a <code class=\"language-plaintext highlighter-rouge\">LSQRequest</code> to track all states, and\nstart translation. When the translation completes, it will\nrecord the virtual address and invoke <code class=\"language-plaintext highlighter-rouge\">LSQUnit::read()</code>.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">LSQUnit::read()</code> will check if the load is aliased with any previous\nstore.\n    <ul>\n<li>If can it can forward, then it will schedule <code class=\"language-plaintext highlighter-rouge\">WritebackEvent</code> for the next\ncycle.</li>\n<li>If it is aliased but cannot forward, it calls\n<code class=\"language-plaintext highlighter-rouge\">InstructionQueue::rescheduleMemInst()</code> and <code class=\"language-plaintext highlighter-rouge\">LSQReuqest::discard()</code>.</li>\n<li>Otherwise, it send packets to the cache.</li>\n</ul>\n</li>\n<li><code class=\"language-plaintext highlighter-rouge\">LSQUnit::writeback()</code> will invoke <code class=\"language-plaintext highlighter-rouge\">StaticInst::completeAcc()</code>, which\nwill write a loaded value to the destination register. The\ninstruction is then pushed to the commit queue. <code class=\"language-plaintext highlighter-rouge\">IEW::writebackInsts()</code>\nwill then mark it done and wake up its dependents. Starting from here it\nshares same path as compute instructions.</li>\n</ul>\n<h3 id=\"store-instruction\">Store Instruction</h3>\n<p>Store instructions are similar to load instructions, but only writeback\nto cache after committed.</p>\n<div class=\"language-cpp highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">tick</span><span class=\"p\">()</span><span class=\"o\">-&gt;</span><span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">executeInsts</span><span class=\"p\">()</span>\n  <span class=\"o\">-&gt;</span><span class=\"n\">LSQUnit</span><span class=\"o\">::</span><span class=\"n\">executeStore</span><span class=\"p\">()</span>\n    <span class=\"o\">-&gt;</span><span class=\"n\">StaticInst</span><span class=\"o\">::</span><span class=\"n\">initiateAcc</span><span class=\"p\">()</span>\n      <span class=\"o\">-&gt;</span><span class=\"n\">LSQ</span><span class=\"o\">::</span><span class=\"n\">pushRequest</span><span class=\"p\">()</span>\n        <span class=\"o\">-&gt;</span><span class=\"n\">LSQUnit</span><span class=\"o\">::</span><span class=\"n\">write</span><span class=\"p\">()</span>\n    <span class=\"o\">-&gt;</span><span class=\"n\">LSQUnit</span><span class=\"o\">::</span><span class=\"n\">checkViolation</span><span class=\"p\">()</span>\n<span class=\"n\">Commit</span><span class=\"o\">::</span><span class=\"n\">tick</span><span class=\"p\">()</span><span class=\"o\">-&gt;</span><span class=\"n\">Commit</span><span class=\"o\">::</span><span class=\"n\">commitInsts</span><span class=\"p\">()</span><span class=\"o\">-&gt;</span><span class=\"n\">Commit</span><span class=\"o\">::</span><span class=\"n\">commitHead</span><span class=\"p\">()</span>\n<span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">tick</span><span class=\"p\">()</span><span class=\"o\">-&gt;</span><span class=\"n\">LSQUnit</span><span class=\"o\">::</span><span class=\"n\">commitStores</span><span class=\"p\">()</span>\n<span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">tick</span><span class=\"p\">()</span><span class=\"o\">-&gt;</span><span class=\"n\">LSQUnit</span><span class=\"o\">::</span><span class=\"n\">writebackStores</span><span class=\"p\">()</span>\n  <span class=\"o\">-&gt;</span><span class=\"n\">LSQRequest</span><span class=\"o\">::</span><span class=\"n\">buildPackets</span><span class=\"p\">()</span>\n  <span class=\"o\">-&gt;</span><span class=\"n\">LSQRequest</span><span class=\"o\">::</span><span class=\"n\">sendPacketToCache</span><span class=\"p\">()</span>\n  <span class=\"o\">-&gt;</span><span class=\"n\">LSQUnit</span><span class=\"o\">::</span><span class=\"n\">storePostSend</span><span class=\"p\">()</span>\n<span class=\"n\">DcachePort</span><span class=\"o\">::</span><span class=\"n\">recvTimingResp</span><span class=\"p\">()</span><span class=\"o\">-&gt;</span><span class=\"n\">LSQRequest</span><span class=\"o\">::</span><span class=\"n\">recvTimingResp</span><span class=\"p\">()</span>\n  <span class=\"o\">-&gt;</span><span class=\"n\">LSQUnit</span><span class=\"o\">::</span><span class=\"n\">completeDataAccess</span><span class=\"p\">()</span>\n    <span class=\"o\">-&gt;</span><span class=\"n\">LSQUnit</span><span class=\"o\">::</span><span class=\"n\">completeStore</span><span class=\"p\">()</span>\n</code></pre></div></div>\n<ul>\n<li>Unlike <code class=\"language-plaintext highlighter-rouge\">LSQUnit::read()</code>, <code class=\"language-plaintext highlighter-rouge\">LSQUnit::write()</code> will only copy the store\ndata, but not send the packet to cache, as the store is not committed yet.</li>\n<li>After the store is committed, <code class=\"language-plaintext highlighter-rouge\">LSQUnit::commitStores()</code> will mark the SQ\nentry as <code class=\"language-plaintext highlighter-rouge\">canWB</code> so that <code class=\"language-plaintext highlighter-rouge\">LSQUnit::writebackStores()</code> will send\nthe store request to cache.</li>\n<li>Finally, when the response comes back, <code class=\"language-plaintext highlighter-rouge\">LSQUnit::completeStore()</code> will\nrelease the SQ entries.</li>\n</ul>\n<h3 id=\"branch-misspeculation\">Branch Misspeculation</h3>\n<p>Branch misspeculation is handled in <code class=\"language-plaintext highlighter-rouge\">IEW::executeInsts()</code>. It will\nnotify the commit stage to start squashing all instructions in the ROB\non the misspeculated branch.</p>\n<div class=\"language-cpp highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">tick</span><span class=\"p\">()</span><span class=\"o\">-&gt;</span><span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">executeInsts</span><span class=\"p\">()</span><span class=\"o\">-&gt;</span><span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">squashDueToBranch</span><span class=\"p\">()</span>\n</code></pre></div></div>\n<h3 id=\"memory-order-misspeculation\">Memory Order Misspeculation</h3>\n<p>The <code class=\"language-plaintext highlighter-rouge\">InstructionQueue</code> has a <code class=\"language-plaintext highlighter-rouge\">MemDepUnit</code> to track memory order dependence.\nThe IQ will not schedule an instruction if MemDepUnit states there is\ndependency.</p>\n<p>In <code class=\"language-plaintext highlighter-rouge\">LSQUnit::read()</code>, the LSQ will search for possible aliasing store and\nforward if possible. Otherwise, the load is blocked and rescheduled for when\nthe blocking store completes by notifying the MemDepUnit.</p>\n<p>Both <code class=\"language-plaintext highlighter-rouge\">LSQUnit::executeLoad/Store()</code> will call <code class=\"language-plaintext highlighter-rouge\">LSQUnit::checkViolation()</code>\nto search the LQ for possible misspeculation. If found, it will set\n<code class=\"language-plaintext highlighter-rouge\">LSQUnit::memDepViolator</code> and <code class=\"language-plaintext highlighter-rouge\">IEW::executeInsts()</code> will start later to\nsquash the misspeculated instructions.</p>\n<div class=\"language-cpp highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">tick</span><span class=\"p\">()</span><span class=\"o\">-&gt;</span><span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">executeInsts</span><span class=\"p\">()</span>\n  <span class=\"o\">-&gt;</span><span class=\"n\">LSQUnit</span><span class=\"o\">::</span><span class=\"n\">executeLoad</span><span class=\"p\">()</span>\n    <span class=\"o\">-&gt;</span><span class=\"n\">StaticInst</span><span class=\"o\">::</span><span class=\"n\">initiateAcc</span><span class=\"p\">()</span>\n    <span class=\"o\">-&gt;</span><span class=\"n\">LSQUnit</span><span class=\"o\">::</span><span class=\"n\">checkViolation</span><span class=\"p\">()</span>\n  <span class=\"o\">-&gt;</span><span class=\"n\">IEW</span><span class=\"o\">::</span><span class=\"n\">squashDueToMemOrder</span><span class=\"p\">()</span>\n</code></pre></div></div>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/cpu_models/minor_cpu\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/cpu_models/SimpleCPU\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/cpu_models/SimpleCPU",
        "title": "SimpleCPU",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"simplecpu\"><strong>SimpleCPU</strong></h1>\n<p>The SimpleCPU is a purely functional, in-order model that is suited for cases where a detailed model is not necessary. This can include warm-up periods, client systems that are driving a host, or just testing to make sure a program works.</p>\n<p>It has recently been re-written to support the new memory system, and is now broken up into three classes:</p>\n<p><strong>Table of Contents</strong></p>\n<ol>\n<li><a href=\"#basesimplecpu\"><strong>BaseSimpleCPU</strong></a></li>\n<li><a href=\"#atomicsimplecpu\"><strong>AtomicSimpleCPU</strong></a></li>\n<li><a href=\"#timingsimplecpu\"><strong>TimingSimpleCPU</strong></a></li>\n</ol>\n<h2 id=\"basesimplecpu\"><strong>BaseSimpleCPU</strong></h2>\n<p>The BaseSimpleCPU serves several purposes:</p>\n<ul>\n<li>Holds architected state, stats common across the SimpleCPU models.</li>\n<li>Defines functions for checking for interrupts, setting up a fetch request, handling pre-execute setup, handling post-execute actions, and advancing the PC to the next instruction. These functions are also common across the SimpleCPU models.</li>\n<li>Implements the ExecContext interface.</li>\n</ul>\n<p>The BaseSimpleCPU can not be run on its own. You must use one of the classes that inherits from BaseSimpleCPU, either AtomicSimpleCPU or TimingSimpleCPU.</p>\n<h2 id=\"atomicsimplecpu\"><strong>AtomicSimpleCPU</strong></h2>\n<p>The AtomicSimpleCPU is the version of SimpleCPU that uses atomic memory accesses (see <a href=\"../memory_system/index.html#access-types\">Memory systems</a> for details). It uses the latency estimates from the atomic accesses to estimate overall cache access time. The AtomicSimpleCPU is derived from BaseSimpleCPU, and implements functions to read and write memory, and also to tick, which defines what happens every CPU cycle. It defines the port that is used to hook up to memory, and connects the CPU to the cache.</p>\n<p><img alt=\"AtomicSimpleCPU\" src=\"/assets/img/AtomicSimpleCPU.jpg\"/></p>\n<h2 id=\"timingsimplecpu\"><strong>TimingSimpleCPU</strong></h2>\n<p>The TimingSimpleCPU is the version of SimpleCPU that uses timing memory accesses (see <a href=\"../memory_system/index.html#access-types\">Memory systems</a> for details). It stalls on cache accesses and waits for the memory system to respond prior to proceeding. Like the AtomicSimpleCPU, the TimingSimpleCPU is also derived from BaseSimpleCPU, and implements the same set of functions. It defines the port that is used to hook up to memory, and connects the CPU to the cache. It also defines the necessary functions for handling the response from memory to the accesses sent out.</p>\n<p><img alt=\"TimingSimpleCPU\" src=\"/assets/img/TimingSimpleCPU.jpg\"/></p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/cpu_models/O3CPU\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/cpu_models/TraceCPU\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/cpu_models/TraceCPU",
        "title": "TraceCPU",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"tracecpu\"><strong>TraceCPU</strong></h1>\n<p>Table of Contents</p>\n<ol>\n<li>\n<p><a href=\"##Overveiw\">Overview</a></p>\n</li>\n<li><a href=\"##Elastic-Trace-Generation\">Elastic Trace Generation</a>\n<ol>\n<li><a href=\"##Scripts-and-options\">Scripts and options</a></li>\n<li><a href=\"###Trace-file-formats\">Trace file format</a></li>\n</ol>\n</li>\n<li><a href=\"#replay-with-trace-cpu\">Replay with Trace CPU</a>\n<ol>\n<li><a href=\"##Scripts-and-options\">Scripts and options</a></li>\n</ol>\n</li>\n</ol>\n<h2 id=\"overview\"><strong>Overview</strong></h2>\n<p>The Trace CPU model plays back elastic traces, which are dependency and timing annotated traces generated by the Elastic Trace Probe attached to the O3 CPU model. The focus of the Trace CPU model is to achieve memory-system (cache-hierarchy, interconnects and main memory) performance exploration in a fast and reasonably accurate way instead of using the detailed but slow O3 CPU model. The traces have been developed for single-threaded benchmarks simulating in both SE and FS mode. They have been correlated for 15 memory-sensitive SPEC 2006 benchmarks and a handful of HPC proxy apps by interfacing the Trace CPU with classic memory system and varying cache design parameters and DRAM memory type. In general, elastic traces can be ported to other simulation environments.</p>\n<p><strong>Publication</strong>:</p>\n<p><a href=\"https://ieeexplore.ieee.org/document/7818336\">Exploring System Performance using Elastic Traces: Fast, Accurate and Portable\u201d</a> Radhika Jagtap, Stephan Diestelhorst, Andreas Hansson, Matthias Jung and Norbert Wehn SAMOS 2016</p>\n<p><strong>Trace generation and replay methodology</strong></p>\n<p><img alt=\"Methodology block diagram showing elastic trace generation using O3 CPU and replay using Trace CPU\n\" src=\"/assets/img/Etrace_methodology.jpg\"/></p>\n<h2 id=\"elastic-trace-generation\"><strong>Elastic Trace Generation</strong></h2>\n<p>The Elastic Trace Probe Listener listens to Probe Points inserted in O3 CPU pipeline stages. It monitors each instruction and creates a dependency graph by recording data Read-After-Write dependencies and order dependencies between loads and stores. It writes the instruction fetch request trace and the elastic data memory request trace as two separate files as shown below.</p>\n<p><img alt=\"Elastic trace file generation\" src=\"/assets/img/Etraces_output.jpg\"/></p>\n<h3 id=\"trace-file-formats\"><strong>Trace file formats</strong></h3>\n<p>The elastic data memory trace and fetch request trace are both encoded using google protobuf.</p>\n<h5 id=\"elastic-trace-fields-in-protobuf-format\"><strong>Elastic Trace fields in protobuf format</strong></h5>\n<table>\n<thead>\n<tr>\n<th>Fields</th>\n<th>Discritption</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>required uint64 seq_num \u00a0</td>\n<td>Instruction number used as an id for tracking dependencies</td>\n</tr>\n<tr>\n<td>required RecordType type \u00a0</td>\n<td>RecordType enum has values: INVALID, LOAD, STORE, COMP</td>\n</tr>\n<tr>\n<td>optional uint64 p_addr \u00a0</td>\n<td>Physical memory address if instruction is a load/store</td>\n</tr>\n<tr>\n<td>optional uint32 size \u00a0</td>\n<td>Size in bytes of data if instruction is a load/store</td>\n</tr>\n<tr>\n<td>optional uint32 flags \u00a0</td>\n<td>Flags or attributes of the access, ex. Uncacheable</td>\n</tr>\n<tr>\n<td>required uint64 rob_dep \u00a0</td>\n<td>Past instruction number on which there is order (ROB) dependency</td>\n</tr>\n<tr>\n<td>required uint64 comp_delay \u00a0</td>\n<td>Execution delay between the completion of the last dependency and the execution of the instruction \u00a0</td>\n</tr>\n<tr>\n<td>repeated uint64 reg_dep \u00a0</td>\n<td>Past instruction number on which there is RAW data dependency</td>\n</tr>\n<tr>\n<td>optional uint32 weight \u00a0</td>\n<td>To account for committed instructions that were filtered out</td>\n</tr>\n<tr>\n<td>optional uint64 pc \u00a0</td>\n<td>Instruction address, i.e. the program counter</td>\n</tr>\n<tr>\n<td>optional uint64 v_addr \u00a0</td>\n<td>Virtual memory address if instruction is a load/store</td>\n</tr>\n<tr>\n<td>optional uint32 asid \u00a0</td>\n<td>Address Space ID</td>\n</tr>\n</tbody>\n</table>\n<p>A decode script in Python is available at <code class=\"language-plaintext highlighter-rouge\">util/decode_inst_dep_trace.py</code> that outputs the trace in ASCII format.</p>\n<p><strong>Example of a trace in ASCII</strong></p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>1,356521,COMP,8500::\n\n2,35656,1,COMP,0:,1:\n\n3,35660,1,LOAD,1748752,4,74,500:,2:\n\n4,35660,1,COMP,0:,3:\n\n5,35664,1,COMP,3000::,4\n\n6,35666,1,STORE,1748752,4,74,1000:,3:,4,5\n\n7,35666,1,COMP,3000::,4\n\n8,35670,1,STORE,1748748,4,74,0:,6,3:,7\n\n9,35670,1,COMP,500::,7\n</code></pre></div></div>\n<p>Each record in the instruction fetch trace has the following fields.</p>\n<table>\n<thead>\n<tr>\n<th>Fields</th>\n<th>Discritption</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>required uint64 tick \u00a0</td>\n<td>Timestamp of the access</td>\n</tr>\n<tr>\n<td>required uint32 cmd\t\u00a0</td>\n<td>Read or Write (in this case always Read)</td>\n</tr>\n<tr>\n<td>required uint64 addr \u00a0</td>\n<td>Physical memory address</td>\n</tr>\n<tr>\n<td>required uint32 size \u00a0</td>\n<td>Size in bytes of data</td>\n</tr>\n<tr>\n<td>optional uint32 flags \u00a0</td>\n<td>Flags or attributes of the access</td>\n</tr>\n<tr>\n<td>optional uint64 pkt_id \u00a0</td>\n<td>Id of the access</td>\n</tr>\n<tr>\n<td>optional uint64 pc  \u00a0</td>\n<td>Instruction address, i.e. the program counter</td>\n</tr>\n</tbody>\n</table>\n<p>The decode script in Python at <code class=\"language-plaintext highlighter-rouge\">util/decode_packet_trace.py</code> can be used to output the trace in ASCII format.</p>\n<p><strong>Compile dependencies</strong>:</p>\n<p>You need to install google protocol buffer as the traces are recorded using this.</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>\n<span class=\"nb\">sudo </span>apt-get <span class=\"nb\">install </span>protobuf-compiler\n<span class=\"nb\">sudo </span>apt-get <span class=\"nb\">install </span>libprotobuf-dev\n\n</code></pre></div></div>\n<h3 id=\"scripts-and-options\"><strong>Scripts and options</strong></h3>\n<h4 id=\"se-mode\">SE mode</h4>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>build/ARM/gem5.opt configs/example/arm/etrace_se.py \\\n    --inst-trace-file fetchtrace.proto.gz \\\n    --data-trace-file deptrace.proto.gz \\\n    [WORKLOAD]\n</code></pre></div></div>\n<h4 id=\"fs-mode\">FS mode</h4>\n<p>Create a checkpoint for your region of interest and resume from the checkpoint but with O3 CPU model and tracing enabled.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code># Checkpoint generation\n# NOTE: fs.py is deprecated and will be removed. Do not rely too much on it\nbuild/ARM/gem5.opt --outdir=m5out/bbench \\\n    ./configs/deprecated/example/fs.py [fs.py options] \\\n    --benchmark bbench-ics\n</code></pre></div></div>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code># Checkpoint restore\n# NOTE: fs.py is deprecated and will be removed. Do not rely too much on it\nbuild/ARM/gem5.opt --outdir=m5out/bbench/capture_10M \\\n    ./configs/deprecated/example/fs.py [fs.py options] \\\n    --cpu-type=arm_detailed --caches \\\n    --elastic-trace-en --data-trace-file=deptrace.proto.gz --inst-trace-file=fetchtrace.proto.gz \\\n    --mem-type=SimpleMemory \\\n    --checkpoint-dir=m5out/bbench -r 0 --benchmark bbench-ics -I 10000000\n</code></pre></div></div>\n<h2 id=\"replay-with-trace-cpu\"><strong>Replay with Trace CPU</strong></h2>\n<p>The execution trace generated above is then consumed by the Trace CPU as illustrated below.</p>\n<p><img alt=\"Trace_cpu_top_level\" src=\"/assets/img/Trace_cpu_top_level.jpg\"/></p>\n<p>The Trace CPU model inherits from the Base CPU and interfaces with data and instruction L1 caches. A diagram of the Trace CPU explaining the major logic and control blocks is shown below.</p>\n<p><img alt=\"Trace_CPU_details\" src=\"/assets/img/Trace_cpu_detail.jpg\"/></p>\n<h3 id=\"scripts-and-options-1\"><strong>Scripts and options</strong></h3>\n<ul>\n<li>A trace replay script in the examples folder can be used to play back SE and FS generated traces\n    <ul>\n<li><code class=\"language-plaintext highlighter-rouge\">build/ARM/gem5.opt [gem5.opt options] -d bzip_10Minsts_replay configs/example/etrace_replay.py [options] --caches --data-trace-file=bzip_10Minsts/deptrace.proto.gz --inst-trace-file=bzip_10Minsts/fetchtrace.proto.gz --mem-size=4GB</code></li>\n</ul>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Fields</th>\n<th>Discritption</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>required uint64 seq_num</td>\n<td>Timestamp of the access</td>\n</tr>\n<tr>\n<td>required RecordType type</td>\n<td>Read or Write (in this case always Read)</td>\n</tr>\n<tr>\n<td>optional uint64 p_addr</td>\n<td>Physical memory address if instruction is a load/store</td>\n</tr>\n<tr>\n<td>optional uint32 size</td>\n<td>Size in bytes of data if instruction is a load/store</td>\n</tr>\n<tr>\n<td>optional uint32 flags</td>\n<td>Flags or attributes of the access, ex. Uncacheable</td>\n</tr>\n<tr>\n<td>required uint64 rob_dep</td>\n<td>Past instruction number on which there is order (ROB) dependency</td>\n</tr>\n<tr>\n<td>required uint64 comp_delay</td>\n<td>Execution delay between the completion of the last dependency and the execution of the instruction</td>\n</tr>\n<tr>\n<td>repeated uint64 reg_dep</td>\n<td>Past instruction number on which there is RAW data dependency</td>\n</tr>\n<tr>\n<td>optional uint32 weight</td>\n<td>To account for committed instructions that were filtered out</td>\n</tr>\n<tr>\n<td>optional uint64 pc</td>\n<td>Instruction address, i.e. the program counter</td>\n</tr>\n<tr>\n<td>optional uint64 v_addr</td>\n<td>Virtual memory address if instruction is a load/store</td>\n</tr>\n<tr>\n<td>optional uint32 asid</td>\n<td>Address Space ID</td>\n</tr>\n</tbody>\n</table>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/cpu_models/SimpleCPU\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/cpu_models/visualization/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/cpu_models/execution_basics",
        "title": "Execution basic",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"execution-basic\">Execution basic</h1>\n<h2 id=\"gem5-bootcamp-2022-module-on-instruction-execution\">gem5 bootcamp 2022 module on instruction execution</h2>\n<p>gem5 bootcamp (2022) had a session on learning how instructions work in gem5 and how to add new instructions in gem5.\nThe slides presented in the session can be found <a href=\"https://ucdavis365-my.sharepoint.com/:p:/g/personal/jlowepower_ucdavis_edu/EeRIKzkdUJBDlaa9AmzERusBp28hxMfkyIOp-_2H5L9AqQ?e=RoMFUD\">here</a>.</p>\n<p>The youtube video of the recorded bootcamp module on gem5 instructions is available <a href=\"https://youtu.be/Z5B02jkNpck\">here</a>.</p>\n<h1 id=\"staticinsts\">StaticInsts</h1>\n<p>The StaticInst provides all static information and methods for a binary instruction.</p>\n<p>It holds the following information/methods:</p>\n<ul>\n<li>Flags to tell what kind of instruction it is (integer, floating point, branch, memory barrier, etc.)</li>\n<li>The op class of the instruction</li>\n<li>The number of source and destination registers</li>\n<li>The number of integer and FP registers used</li>\n<li>Method to decode a binary instruction into a StaticInst</li>\n<li>Virtual function execute(), which defines how the specific architectural actions taken for an instruction (e.g. read r1, r2, add them and store in r3.)</li>\n<li>Virtual functions to handle starting and completing memory operations</li>\n<li>Virtual functions to execute the address calculation and memory access separately for models that split memory operations into two operations</li>\n<li>Method to disassemble the instruction, printing it out in a human readable format. (e.g. addq r1 r2 r3)</li>\n</ul>\n<p>It does not have dynamic information, such as the PC of the instruction or the values of the source registers or the result. This allows a 1 to 1 mapping of StaticInst to unique binary machine instructions. We take advantage of this fact by caching the mapping of a binary instruction to a StaticInst in a hash_map, allowing us to decode a binary instruction only once, and directly using the StaticInst the rest of the time.</p>\n<p>Each ISA instruction derives from StaticInst and implements its own constructor, the execute() function, and, if it is a memory instruction, the memory access functions. See ISA_description_system for details about how these ISA instructions are specified.</p>\n<h1 id=\"dyninsts\">DynInsts</h1>\n<p>The DynInst is used to hold dynamic information about instructions. This is necessary for more detailed models or out-of-order models, both of which may need extra information beyond the <a href=\"#staticinsts\">StaticInsts</a> in order to correctly execute instructions.\nSome of the dynamic information that it stores includes:</p>\n<ul>\n<li>The PC of the instruction</li>\n<li>The renamed register indices of the source and destination registers</li>\n<li>The predicted next-PC</li>\n<li>The instruction result</li>\n<li>The thread number of the instruction</li>\n<li>The CPU the instruction is executing on</li>\n<li>Whether or not the instruction is squashed</li>\n</ul>\n<p>Additionally the DynInst provides the ExecContext interface. When ISA instructions are executed, the DynInst is passed in as the ExecContext, handling all accesses of the ISA to CPU state.</p>\n<p>Detailed CPU models can derive from DynInst and create their own specific DynInst subclasses that implement any additional state or functions that might be needed. See src/cpu/o3/alpha/dyn_inst.hh for an example of this.</p>\n<h1 id=\"microcode-support\">Microcode support</h1>\n<h1 id=\"execcontext\">ExecContext</h1>\n<p>The ExecContext describes the interface that the ISA uses to access CPU state. Although there is a file <code class=\"language-plaintext highlighter-rouge\">src/cpu/exec_context.hh</code>, it is purely for documentation purposes and classes do not derive from it. Instead, ExecContext is an implicit interface that is assumed by the ISA.</p>\n<p>The ExecContext interface provides methods to:</p>\n<ul>\n<li>Read and write PC information</li>\n<li>Read and write integer, floating point, and control registers</li>\n<li>Read and write memory</li>\n<li>Record and return the address of a memory access, prefetching, and trigger a system call</li>\n<li>Trigger some full-system mode functionality</li>\n</ul>\n<p>Example implementations of the ExecContext interface include:</p>\n<ul>\n<li>SimpleCPU</li>\n<li>DynInst</li>\n</ul>\n<p>See the ISA description page for more details on how an instruction set is implemented.</p>\n<h1 id=\"threadcontext\">ThreadContext</h1>\n<p>ThreadContext is the interface to all state of a thread for anything outside of the CPU. It provides methods to read or write state that might be needed by external objects, such as the PC, next PC, integer and FP registers, and IPRs. It also provides functions to get pointers to important thread-related classes, such as the ITB, DTB, System, kernel statistics, and memory ports. It is an abstract base class; the CPU must create its own ThreadContext by either deriving from it, or using the templated ProxyThreadContext class.</p>\n<h2 id=\"proxythreadcontext\">ProxyThreadContext</h2>\n<p>The ProxyThreadContext class provides a way to implement a ThreadContext without having to derive from it. ThreadContext is an abstract class, so anything that derives from it and uses its interface will pay the overhead of virtual function calls. This class is created to enable a user-defined Thread object to be used wherever ThreadContexts are used, without paying the overhead of virtual function calls when it is used by itself. The user-defined object must simply provide all the same functions as the normal ThreadContext, and the ProxyThreadContext will forward all calls to the user-defined object. See the code of <a href=\"http://gem5.org/SimpleThread\">SimpleThread</a> for an example of using the ProxyThreadContext.</p>\n<h2 id=\"difference-vs-execcontext\">Difference vs. ExecContext</h2>\n<p>The ThreadContext is slightly different than the ExecContext. The ThreadContext provides access to an individual thread\u2019s state; an ExecContext provides ISA access to the CPU (meaning it is implicitly multithreaded on SMT systems). Additionally the ThreadState is an abstract class that exactly defines the interface; the ExecContext is a more implicit interface that must be implemented so that the ISA can access whatever state it needs. The function calls to access state are slightly different between the two. The ThreadContext provides read/write register methods that take in an architectural register index. The ExecContext provides read/write register methdos that take in a StaticInst and an index, where the index refers to the i\u2019th source or destination register of that <a href=\"#staticinsts\">StaticInsts</a>. Additionally the ExecContext provides read and write methods to access memory, while the ThreadContext does not provide any methods to access memory.</p>\n<h1 id=\"threadstate\">ThreadState</h1>\n<p>The ThreadState class is used to hold thread state that is common across CPU models, such as the thread ID, thread status, kernel statistics, memory port pointers, and some statistics of number of instructions completed. Each CPU model can derive from ThreadState and build upon it, adding in thread state that is deemed appropriate. An example of this is <a href=\"http://gem5.org/SimpleThread\">SimpleThread</a>, where all of the thread\u2019s architectural state has been added in. However, it is not necessary (or even feasible in some cases) for all of the thread\u2019s state to be centrally located in a ThreadState derived class. The DetailedCPU keeps register values and rename maps in its own classes outside of ThreadState. ThreadState is only used to provide a more convenient way to centrally locate some state, and provide sharing across CPU models.</p>\n<h1 id=\"faults\">Faults</h1>\n<h1 id=\"registers\">Registers</h1>\n<h2 id=\"register-types---float-int-misc\">Register types - float, int, misc</h2>\n<h2 id=\"indexing---register-spaces-stuff\">Indexing - register spaces stuff</h2>\n<p>See <a href=\"#register-indexing\">Register Indexing</a> for a more thorough treatment.</p>\n<p>A \u201cnickle tour\u201d of flattening and register indexing in the CPU models.</p>\n<p>First, an instruction has identified that it needs register such and such as determined by its encoding (or the fact that it always uses a certain register, or \u2026). For the sake of argument, lets say we\u2019re talking about SPARC, the register is %g1, and the second bank of globals is active. From the instructions point of view, the unflattened register is %g1, which, likely, is just represented by the index 1.</p>\n<p>Next, we need to map from the instruction\u2019s view of the register file(s) down to actual storage locations. Think of this like virtual memory. The instruction is working within an index space which is like a virtual address space, and it needs to be mapped down to the flattened space which is like physical memory. Here, the index 1 is likely mapped to, say, 9, where 0-7 is the first bank of globals and 8-15 is the second.</p>\n<p>This is the point where the CPU gets involved. The index 9 refers to an actual register the instruction expects to access, and it\u2019s the CPU\u2019s job to make that happen. Before this point, all the work was done by the ISA with no insight available to the CPU, and beyond this point all the work is done by the CPU with no insight available to the ISA.</p>\n<p>The CPU is free to provide a register directly like the simple CPU by having an array and just reading and writing the 9th element on behalf of the instruction. The CPU could, alternatively, do something complicated like renaming and mapping the flattened index further into a physical register like O3.</p>\n<p>One important property of all this, which makes sense if you think about the virtual memory analogy, is that the size of the index space before flattening has nothing to do with the size after. The virtual memory space could be very large (presumably with gaps) and map to a smaller physical space, or it could be small and map to a larger physical space where the extra is for, say, other virtual spaces used at other times. You need to make sure you\u2019re using the right size (post flattening) to size your tables because that\u2019s the space of possible options.</p>\n<p>One other tricky part comes from the fact that we add offsets into the indices to distinguish ints from floats from miscs. Those offsets might be one thing in the preflattening world, but then need to be something else in the post flattening world to keep things from landing on top of each other without leaving gaps. It\u2019s easy to make a mistake here, and it\u2019s one of the reasons I don\u2019t like this offset idea as a way to keep the different types separate. I\u2019d rather see a two dimensional index where the second coordinate was a register type. But in the world as it exists today, this is something you have to keep track of.</p>\n<h1 id=\"pcs\">PCs</h1>\n<h1 id=\"register-indexing\">Register Indexing</h1>\n<p>CPU register indexing in gem5 is a complicated by the need to support multiple ISAs with sometimes very different register semantics (register windows, condition codes, mode-based alternate register sets, etc.). In addition, this support has evolved gradually as new ISAs have been added, so older code may not take advantage of newer features or terminology.</p>\n<h1 id=\"types-of-register-indices\">Types of Register Indices</h1>\n<p>There are three types of register indices used internally in the CPU models: relative, unified, and flattened.</p>\n<h2 id=\"relative\">Relative</h2>\n<p>A relative register index is the index that is encoded in a machine instruction. There is a separate index space for each class of register (integer, floating point, etc.), starting at 0. The register class is implied by the opcode. Thus a value of \u201c1\u201d in a source register field may mean integer register 1 (e.g., \u201c%r1\u201d) or floating point register 1 (e.g., \u201c%f1\u201d) depending on the type of the instruction.</p>\n<h2 id=\"unified\">Unified</h2>\n<p>While relative register indices are good for keeping instruction encodings compact, they are ambiguous, and thus not convenient for things like managing dependencies. To avoid this ambiguity, the decoder maps the relative register indices into a unified register space by adding class-specific offsets to relocate each relative index range into a unique position. Integer registers are unmodified, and continue to start at zero. Floating-point register indices are offset by (at least) the number of integer registers, so that the first FP register (e.g., \u201c%f0\u201d) gets a unified index that is greater than that of the last integer register. Similarly, miscellaneous (a.k.a. control) registers are mapped past the end of the FP register index space.</p>\n<h2 id=\"flattened\">Flattened</h2>\n<p>Unified register indices provide an unambiguous description of all the registers that are accessible as instruction operands at a given point in the execution. Unfortunately, due to the complex features of some ISAs, they do not always unambiguously identify the actual state that the instruction is referencing. For example, in ISAs with register windows (notably SPARC), a particular register identifier such as \u201c%o0\u201d will refer to a different register after a \u201csave\u201d or \u201crestore\u201d operation than it did previously. Several ISAs have registers that are hidden in normal operation, but get mapped on top of ordinary registers when an interrupt occurs (e.g., ARM\u2019s mode-specific registers), or under explicit supervisor control (e.g., SPARC\u2019s \u201calternate globals\u201d).</p>\n<p>We solve this problem by maintaining a flattened register space which provides a distinct index for every unique register storage location. For example, the integer portion of the SPARC flattened register space has distinct indices for the globals and the alternate globals, as well as for each of the available register windows. The \u201cflattening\u201d process of translating from a unified or relative register index to a flattened register index varies by ISA. On some ISAs, the mapping is trivial, while others use table lookups to do the translation.</p>\n<p>A key distinction between the generation of unified and flattened register indices is that the former can always be done statically while the latter often depends on dynamic processor state. That is, the translation from relative to unified indices depends only on the context provided by the instruction itself (which is convenient as the translation is done in the decoder). In contrast, the mapping to a flattened register index may depend on processor state such as the interrupt level or the current window pointer on SPARC.</p>\n<h2 id=\"combining-register-index-types\">Combining Register Index Types</h2>\n<p>Although the typical progression for modifying register indices is relative -&gt; unified -&gt; flattened, it turns out that relative vs. unified and flattened vs. unflattened are orthogonal attributes. Relative vs. unified indicates whether the index is relative to the base register for its register class (integer, FP, or misc) or has the base offset for its class added in. Flattened vs. unflattened indicates whether the index has been adjusted to account for runtime context such as register window adjustments or alternate register file modes. Thus a relative flattened register index is one in which the runtime context has been accounted for, but is still expressed relative to the base offset for its class.</p>\n<p>A single set of class-specific offsets is used to generate unified indices from relative indices regardless of whether the indices are flattened or unflattened. Thus the offsets must be large enough to separate the register classes even when flattened addresses are being used. As a result, the unflattened unified register space is often discontiguous.</p>\n<h1 id=\"illustrations\">Illustrations</h1>\n<p>As an illustration, consider a hypothetical architecture with four integer registers (%r0-%r4), three FP registers (%f0-%f2), and two misc/control registers (%msr0-%msr1). In addition, the architecture supports a complete set of alternate integer and FP registers for fast context switching.</p>\n<p>The resulting register file layout, along with the unified flattened register file indices, is shown at right. Although the indices in the picture range from 0 to 15, the actual set of valid indices depends on the type of index and (for relative indices) the register class as well:</p>\n<table>\n<tbody>\n<tr>\n<td>Relative unflattened</td>\n<td>Int: 0-3; FP: 0-2; Misc: 0-1</td>\n</tr>\n<tr>\n<td>Unified unflattened</td>\n<td>0-3, 8-10, 14-15</td>\n</tr>\n<tr>\n<td>Relative flattened</td>\n<td>Int: 0-7; FP: 0-5; Misc: 0-1</td>\n</tr>\n<tr>\n<td>Unified flattened</td>\n<td>0-15</td>\n</tr>\n</tbody>\n</table>\n<p>In this example, register %f1 in the alternate FP register file could be referred to via the relative flattened index 4 as well as the relative unflattened index 1, the unified unflattened index 9, or the unified flattened index 12. Note that the difference between the relative and unified indices is always 8 (regardless of flattening), and the difference between the unflattened and flattened indices is 3 (regardless of relative vs. unified status). <img alt=\"gem5-regs\" src=\"/assets/img/gem5-regs.png\"/></p>\n<h1 id=\"caveats\">Caveats</h1>\n<ul>\n<li>Although the gem5 code is unfortunately not always clear about which type of register index is expected by a particular function, functions whose name incorporates a register class (e.g., readIntReg()) expect a relative register index, and functions that expect a flattened index often have \u201cflat\u201d in the function name.</li>\n<li>Although the general case is complicated, the common case can be deceptively simple. For example, because integer registers start at the beginning of the unified register space, relative and unified register indices are identical for integer registers. Furthermore, in an architecture with no (or rarely-used) alternate integer registers, the unflattened and flattened indices are (almost always) the same as well, meaning that all four types of register indices are interchangeable in this case. While this situation seems to be a simplification, it also tends to hide bugs where the wrong register index type is used.</li>\n<li>The description above is intended to illustrate the typical usage of these index types. There may be exceptions that don\u2019t precisely   follow this description, but I got tired of writing \u201ctypically\u201d in every sentence.</li>\n<li>The terms \u2018relative\u2019 and \u2018unified\u2019 were invented for use in this documentation, so you are unlikely see them in the code until the code starts catching up with this page.</li>\n<li>This discussion pertains only to the architectural registers. An out-of-order CPU model such as O3 adds another layer of complexity by renaming these architectural registers (using the flattened register indices) to an underlying physical register file.</li>\n</ul>\n<h2 id=\"isa-and-cpu-independence\">ISA and CPU Independence</h2>\n<p>gem5 tries to keep CPU models ISA independent to make it easier to use any ISA with different CPU models. gem5 relies on two generic interfaces to make this independence possible: static instructions and execution context (both are discussed above).\nStatic instructions allow CPU to manage instructions and the execution context allow ISA or instructions to interact with the CPU. Following picture provides a high level overview of\nwhat components in gem5 are ISA dependent or independent:</p>\n<p><img alt=\"ISA dependent or independent components of gem5\" src=\"/assets/img/ISAInd.png\"/></p>\n<p><strong>Source of the above figure:</strong> Modular ISA-Independent Full-System Simulation (Ch 5 of Processor and System-on-Chip Simulation), G. Black, N. Binkert, and S. Reinhardt, A. Saidi.\n<a href=\"https://link.springer.com/content/pdf/10.1007/978-1-4419-6175-4.pdf\">Link</a>.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/compiling_workloads/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/cpu_models/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/cpu_models/minor_cpu",
        "title": "No Title Found",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Andrew Bardsley<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<p>Minor CPU Model</p>\n<p>This document contains a description of the structure and function of the\n<a href=\"http://doxygen.gem5.org/release/current/namespaceMinor.html\">Minor</a> gem5 in-order\nprocessor model.</p>\n<p>It is recommended reading for anyone who wants to understand\n<a href=\"http://doxygen.gem5.org/release/current/namespaceMinor.html\">Minor</a>\u2019s internal\norganisation, design decisions, C++ implementation and Python configuration. A\nfamiliarity with gem5 and some of its internal structures is assumed. This\ndocument is meant to be read alongside the\n<a href=\"http://doxygen.gem5.org/release/current/namespaceMinor.html\">Minor</a> source code\nand to explain its general structure without being too slavish about naming\nevery function and data type.</p>\n<h2 id=\"what-is-minor\">What is Minor?</h2>\n<p><a href=\"http://doxygen.gem5.org/release/current/namespaceMinor.html\">Minor</a> is an in-order\nprocessor model with a fixed pipeline but configurable data structures and\nexecute behaviour. It is intended to be used to model processors with strict\nin-order execution behaviour and allows visualisation of an instruction\u2019s\nposition in the pipeline through the MinorTrace/minorview.py format/tool. The\nintention is to provide a framework for micro-architecturally correlating the\nmodel with a particular, chosen processor with similar capabilities.</p>\n<h2 id=\"design-philosophy\">Design Philosophy</h2>\n<h3 id=\"multithreading\">Multithreading</h3>\n<p>The model isn\u2019t currently capable of multithreading but there are THREAD\ncomments in key places where stage data needs to be arrayed to support\nmultithreading.</p>\n<h3 id=\"data-structures\">Data structures</h3>\n<p>Decorating data structures with large amounts of life-cycle information is\navoided. Only instructions\n(<a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1MinorDynInst.html\">MinorDynInst</a>) contain a\nsignificant proportion of their data content whose values are not set at\nconstruction.</p>\n<p>All internal structures have fixed sizes on construction. Data held in queues\nand FIFOs (<a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1MinorBuffer.html\">MinorBuffer</a>,\n<a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1FUPipeline.html\">FUPipeline</a>) should have\na <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1BubbleIF.html\">BubbleIF</a>\ninterface to allow a distinct \u2018bubble\u2019/no data value option for each type.</p>\n<p>Inter-stage \u2018struct\u2019 data is packaged in structures which are passed by value.\nOnly <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1MinorDynInst.html\">MinorDynInst</a>, the line\ndata in <a href=\"http://doxygen.gem5.org/release/current/classMinorCPU.html#a36a7ec6a8c5a6d27fd013d8b0238029d\">ForwardLineData</a>\nand the memory-interfacing objects <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch1_1_1FetchRequest.html\">Fetch1::FetchRequest</a>\nand <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1LSQ_1_1LSQRequest.html\">LSQ::LSQRequest</a> are\n<code class=\"language-plaintext highlighter-rouge\">::new</code> allocated while running the model.</p>\n<h2 id=\"model-structure\">Model structure</h2>\n<p>Objects of class <a href=\"http://doxygen.gem5.org/release/current/classMinorCPU.html\">MinorCPU</a> are provided by the\nmodel to gem5. <a href=\"http://doxygen.gem5.org/release/current/classMinorCPU.html\">MinorCPU</a> implements the\ninterfaces of (cpu.hh) and can provide data and instruction interfaces for\nconnection to a cache system. The model is configured in a similar way to other\ngem5 models through Python. That configuration is passed on to\n<a href=\"http://doxygen.gem5.org/release/current/classMinorCPU.html#a36a7ec6a8c5a6d27fd013d8b0238029d\">MinorCPU::pipeline</a>\n(of class <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Pipeline.html\">Pipeline</a>) which\nactually implements the processor pipeline.</p>\n<p>The hierarchy of major unit ownership from <a href=\"http://doxygen.gem5.org/release/current/classMinorCPU.html\">MinorCPU</a> down looks like this:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>MinorCPU\n--- Pipeline - container for the pipeline, owns the cyclic 'tick' event mechanism and the idling (cycle skipping) mechanism.\n--- --- Fetch1 - instruction fetch unit responsible for fetching cache lines (or parts of lines from the I-cache interface).\n--- --- --- Fetch1::IcachePort - interface to the I-cache from Fetch1.\n--- --- Fetch2 - line to instruction decomposition.\n--- --- Decode - instruction to micro-op decomposition.\n--- --- Execute - instruction execution and data memory interface.\n--- --- --- LSQ - load store queue for memory ref. instructions.\n--- --- --- LSQ::DcachePort - interface to the D-ache from Execute.\n</code></pre></div></div>\n<h2 id=\"key-data-structures\">Key data structures</h2>\n<h3 id=\"instruction-and-line-identity-instld-dyn_insthh\">Instruction and line identity: Instld (<code class=\"language-plaintext highlighter-rouge\">dyn_inst.hh</code>)</h3>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>- T/S.P/L - for fetched cache lines\n- T/S.P/L/F - for instructions before Decode\n- T/S.P/L/F.E - for instructions from Decode onwards\n</code></pre></div></div>\n<p>for example:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>- 0/10.12/5/6.7\n</code></pre></div></div>\n<p><a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1InstId.html\">InstId</a> fields\nare:</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left\">Field</th>\n<th style=\"text-align: left\">Symbol</th>\n<th style=\"text-align: left\">Generated by</th>\n<th style=\"text-align: left\">Checked by</th>\n<th style=\"text-align: left\">Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left\">InstId::threadId</td>\n<td style=\"text-align: left\">T</td>\n<td style=\"text-align: left\"><a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch1.html\">Fetch1</a></td>\n<td style=\"text-align: left\">Everywhere the thread number is needed</td>\n<td style=\"text-align: left\">Thread number (currently always 0).</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">InstId::streamSeqNum</td>\n<td style=\"text-align: left\">S</td>\n<td style=\"text-align: left\"><a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Execute.html\">Execute</a></td>\n<td style=\"text-align: left\">Fetch1, Fetch2, Execute (to discard lines/insts)</td>\n<td style=\"text-align: left\">Stream sequence number as chosen by Execute. Stream sequence numbers change after changes of PC (branches, exceptions) in Execue and are used to separate pre and post brnach instrucion streams.</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">InstId::predictionSeqNum</td>\n<td style=\"text-align: left\"><a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch2.html\">Fetch2</a></td>\n<td style=\"text-align: left\">Fetch2 (while discarding lines after prediction)</td>\n<td style=\"text-align: left\">Prediction sequence numbers represent branch prediction decisions. This is used by Fetch2 to mark lines/instructions/ according to the last followed branch prediction made by Fetch2. Fetch2 can signal to Fetch1 that it should change its fetch address and mark lines with a new prediction sequence number (which it will only do if the stream sequence number Fetch1 expects matches that of the request).</td>\n<td style=\"text-align: left\">\u00a0</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">InstId::lineSeqNum</td>\n<td style=\"text-align: left\"><a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch1.html\">Fetch1</a></td>\n<td style=\"text-align: left\">(just for debugging)</td>\n<td style=\"text-align: left\">Line fetch sequence number of this cache line or the line this instruction was extracted from.</td>\n<td style=\"text-align: left\">\u00a0</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">InstId::fetchSeqNum</td>\n<td style=\"text-align: left\"><a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch2.html\">Fetch2</a></td>\n<td style=\"text-align: left\">Fetch2 (as the inst. sequence number for branches)</td>\n<td style=\"text-align: left\">Instruction fetch order assigned by Fetch2 when lines are decomposed into instructions.</td>\n<td style=\"text-align: left\">\u00a0</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">InstId::execSeqNum</td>\n<td style=\"text-align: left\"><a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Decode.html\">Decode</a></td>\n<td style=\"text-align: left\">Execute (to check instruction identify in queues/FUs/LSQ</td>\n<td style=\"text-align: left\">Instruction order after micro-op decomposition</td>\n<td style=\"text-align: left\">\u00a0</td>\n</tr>\n</tbody>\n</table>\n<p>The sequence number fields are all independent of each other and although, for\ninstance, <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1InstId.html#a064b0e4480268559e68510311be2a9b0\">InstId::execSeqNum</a>\nfor an instruction will always be &gt;= <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1InstId.html#a06677e68051a2a52f384e55e9368e33d\">InstId::fetchSeqNum</a>,\nthe comparison is not useful.</p>\n<p>The originating stage of each sequence number field keeps a counter for that\nfield which can be incremented in order to generate new, unique numbers.</p>\n<h3 id=\"instructi-ns-minordyninst-dyn_insthh\">Instructi ns: MinorDynInst (<code class=\"language-plaintext highlighter-rouge\">dyn_inst.hh</code>)</h3>\n<p><a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1MinorDynInst.html\">MinorDynInst</a> represents\nan instruction\u2019s progression through the pipeline. An instruction can be three\nthings:</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left\">Things</th>\n<th style=\"text-align: left\">Predicate</th>\n<th style=\"text-align: left\">Explanation</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left\">A bubble</td>\n<td style=\"text-align: left\"><a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1MinorDynInst.html#a24e835fa495026ca63ffec43ee9cc07e\">MinorDynInst::isBubble()</a></td>\n<td style=\"text-align: left\">no instruction at all, just a space-filler</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">A fault</td>\n<td style=\"text-align: left\"><a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1MinorDynInst.html#a24029f3cd1835928d572737a548a824e\">MinorDynInst::isFault()</a></td>\n<td style=\"text-align: left\">a fault to pass down the pipeline in an insturction\u2019s clothing</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">A decoded instruction</td>\n<td style=\"text-align: left\"><a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1MinorDynInst.html#adc55cdcf9f7c6588bb27eddb4c7fe38e\">MinorDynInst::isInst()</a></td>\n<td style=\"text-align: left\">instructions are actually passed to the gem5 decoder in Fetch2 and so are created fully decoded. MinorDynInst::staticInst is the decoded instruction form.</td>\n</tr>\n</tbody>\n</table>\n<p>Instructions are reference counted using the gem5 <a href=\"http://doxygen.gem5.org/release/current/classRefCountingPtr.html\">RefCountingPtr</a> \n(<a href=\"http://doxygen.gem5.org/release/current/refcnt_8hh.html\">base/refcnt.hh</a>)\nwrapper. They therefore usually appear as MinorDynInstPtr in code. Note that as\n<a href=\"http://doxygen.gem5.org/release/current/classRefCountingPtr.html\">RefCountingPtr</a>\ninitialises as nullptr rather than an object that supports\n<a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1BubbleIF.html#a7ce121301dba2e89b94235d96bf339ae\">BubbleIF::isBubble</a>\npassing raw MinorDynInstPtrs to <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Queue.html\">Queues</a> and other similar\nstructures from stage.hh without boxing is dangerous.</p>\n<h3 id=\"forwardlinedata-pipe_datahh\">ForwardLineData (<code class=\"language-plaintext highlighter-rouge\">pipe_data.hh</code>)</h3>\n<p>ForwardLineData is used to pass cache lines from Fetch1 to Fetch2. Like\nMinorDynInsts, they can be bubbles (<a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1ForwardLineData.html#a46789690719acf167be0a57c9d7d4f8f\">ForwardLineData::isBubble()</a>),\nfault-carrying or can contain a line (partial line) fetched by Fetch1. The data\ncarried by ForwardLineData is owned by a Packet object returned from memory and\nis explicitly memory managed and do must be deleted once processed (by Fetch2\ndeleting the Packet).</p>\n<h3 id=\"forwardinstdata-pipe_datahh\">ForwardInstData (<code class=\"language-plaintext highlighter-rouge\">pipe_data.hh</code>)</h3>\n<p>ForwardInstData can contain up to <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1ForwardInstData.html#ad5db21f655f2f1dfff69e6f6d5cc606e\">ForwardInstData::width()</a>\ninstructions in its <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1ForwardInstData.html#ab54a61c683376aaf5a12ea19ab758340\">ForwardInstData::insts</a>\nvector. This structure is used to carry instructions between Fetch2, Decode and\nExecute and to store input buffer vectors in Decode and Execute.</p>\n<h3 id=\"fetch1fetchrequest-fetch1hh\">Fetch1::FetchRequest (<code class=\"language-plaintext highlighter-rouge\">fetch1.hh</code>)</h3>\n<p>FetchRequests represent I-cache line fetch requests. The are used in the memory\nqueues of Fetch1 and are pushed into/popped from <a href=\"http://doxygen.gem5.org/release/current/classPacket.html#ad1dd4fa4370e508806fe4a8253a0ad12\">Packet::senderState</a>\nwhile traversing the memory system.</p>\n<p>FetchRequests contain a memory system Request (<a href=\"http://doxygen.gem5.org/release/current/request_8hh.html\">mem/request.hh</a>) for that fetch access, a\npacket (Packet, <a href=\"http://doxygen.gem5.org/release/current/packet_8hh.html\">mem/packet.hh</a>), if the request gets to\nmemory, and a fault field that can be populated with a TLB-sourced prefetch\nfault (if any).</p>\n<h3 id=\"lsqlsqrequest-executehh\">LSQ::LSQRequest (<code class=\"language-plaintext highlighter-rouge\">execute.hh</code>)</h3>\n<p>LSQRequests are similar to FetchRequests but for D-cache accesses. They carry\nthe instruction associated with a memory access.</p>\n<h2 id=\"the-pipeline\">The pipeline</h2>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>------------------------------------------------------------------------------\n    Key:\n\n    [] : inter-stage BufferBuffer\n    ,--.\n    |  | : pipeline stage\n    `--'\n    ---&gt; : forward communication\n    &lt;--- : backward communication\n\n    rv : reservation information for input buffers\n\n                ,------.     ,------.     ,------.     ,-------.\n (from  --[]-v-&gt;|Fetch1|-[]-&gt;|Fetch2|-[]-&gt;|Decode|-[]-&gt;|Execute|--&gt; (to Fetch1\n Execute)    |  |      |&lt;-[]-|      |&lt;-rv-|      |&lt;-rv-|       |     &amp; Fetch2)\n             |  `------'&lt;-rv-|      |     |      |     |       |\n             `--------------&gt;|      |     |      |     |       |\n                             `------'     `------'     `-------'\n------------------------------------------------------------------------------\n</code></pre></div></div>\n<p>The four pipeline stages are connected together by <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1MinorBuffer.html\">MinorBuffer</a> FIFO\n(stage.hh, derived ultimately from <a href=\"http://doxygen.gem5.org/release/current/classTimeBuffer.html\">TimeBuffer</a>) structures which\nallow inter-stage delays to be modelled. There is a <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1MinorBuffer.html\">MinorBuffers</a> between\nadjacent stages in the forward direction (for example: passing lines from\nFetch1 to Fetch2) and, between Fetch2 and Fetch1, a buffer in the backwards\ndirection carrying branch predictions.</p>\n<p>Stages Fetch2, Decode and Execute have input buffers which, each cycle, can\naccept input data from the previous stage and can hold that data if the stage\nis not ready to process it. Input buffers store data in the same form as it is\nreceived and so Decode and Execute\u2019s input buffers contain the output\ninstruction vector (<a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1ForwardInstData.html\">ForwardInstData</a>\n(<a href=\"http://doxygen.gem5.org/release/current/pipe__data_8hh.html\">pipe_data.hh</a>)) from\ntheir previous stages with the instructions and bubbles in the same positions\nas a single buffer entry.</p>\n<p>Stage input buffers provide a <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Reservable.html\">Reservable</a> (stage.hh)\ninterface to their previous stages, to allow slots to be reserved in their\ninput buffers, and communicate their input buffer occupancy backwards to allow\nthe previous stage to plan whether it should make an output in a given cycle.</p>\n<h3 id=\"event-handling-minoractivityrecorder-activityhh-pipelinehh\">Event handling: MinorActivityRecorder (<code class=\"language-plaintext highlighter-rouge\">activity.hh</code>, <code class=\"language-plaintext highlighter-rouge\">pipeline.hh</code>)</h3>\n<p>Minor is essentially a cycle-callable model with some ability to skip cycles\nbased on pipeline activity. External events are mostly received by callbacks\n(e.g. <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch1_1_1IcachePort.html#aec62b3d89dfe61e8528cdcdf3729eeab\">Fetch1::IcachePort::recvTimingResp</a>)\nand cause the pipeline to be woken up to service advancing request queues.</p>\n<p><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1Ticked.html\">Ticked</a> (sim/ticked.hh)\nis a base class bringing together an evaluate member function and a provided\n<a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1SimObject.html\">SimObject</a>. It\nprovides a <a href=\"http://doxygen.gem5.org/release/current/classTicked.html#a798d1e248c27161de6eb2bc6fef5e425\">Ticked::start</a>/stop\ninterface to start and pause clock events from being periodically issued.\n<a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Pipeline.html\">Pipeline</a> is\na derived class of Ticked.</p>\n<p>During evaluate calls, stages can signal that they still have work to do in the\nnext cycle by calling either <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1MinorCPU.html#ae3b03c96ee234e2c5c6c68f4567245a7\">MinorCPU::activityRecorder</a>-&gt;activity()\n(for non-callable related activity) or MinorCPU::wakeupOnEvent(<stageid>) (for\nstage callback-related 'wakeup' activity).</stageid></p>\n<p><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Pipeline.html#af07fdce00c8937e9de5b6450a1cd62bf\">Pipeline::evaluate</a>\ncontains calls to evaluate for each unit and a test for pipeline idling which\ncan turns off the clock tick if no unit has signalled that it may become active\nnext cycle.</p>\n<p>Within Pipeline (<a href=\"http://doxygen.gem5.org/release/current/pipeline_8hh.html\">pipeline.hh</a>), the stages are\nevaluated in reverse order (and so will ::evaluate in reverse order) and their\nbackwards data can be read immediately after being written in each cycle\nallowing output decisions to be \u2018perfect\u2019 (allowing synchronous stalling of the\nwhole pipeline). Branch predictions from Fetch2 to Fetch1 can also be\ntransported in 0 cycles making fetch1ToFetch2BackwardDelay the only\nconfigurable delay which can be set as low as 0 cycles.</p>\n<p>The <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1MinorCPU.html#a854596342bfb9dd889437e494c4ddb27\">MinorCPU::activateContext</a>\nand <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1MinorCPU.html#ae6aa9b1bb798d8938f0b35e11d9e68b8\">MinorCPU::suspendContext</a>\ninterface can be called to start and pause threads (threads in the MT sense)\nand to start and pause the pipeline. Executing instructions can call this\ninterface (indirectly through the ThreadContext) to idle the CPU/their threads.</p>\n<h3 id=\"each-pipeline-stage\">Each pipeline stage</h3>\n<p>In general, the behaviour of a stage (each cycle) is:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    evaluate:\n        push input to inputBuffer\n        setup references to input/output data slots\n\n        do 'every cycle' 'step' tasks\n\n        if there is input and there is space in the next stage:\n            process and generate a new output\n            maybe re-activate the stage\n\n        send backwards data\n\n        if the stage generated output to the following FIFO:\n            signal pipe activity\n\n        if the stage has more processable input and space in the next stage:\n            re-activate the stage for the next cycle\n\n        commit the push to the inputBuffer if that data hasn't all been used\n</code></pre></div></div>\n<p>The Execute stage differs from this model as its forward output (branch) data\nis unconditionally sent to Fetch1 and Fetch2. To allow this behaviour, Fetch1\nand Fetch2 must be unconditionally receptive to that data.</p>\n<h3 id=\"fetch1-stage\">Fetch1 stage</h3>\n<p><a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch1.html\">Fetch1</a> is\nresponsible for fetching cache lines or partial cache lines from the I-cache\nand passing them on to <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch2.html\">Fetch2</a> to be decomposed\ninto instructions. It can receive \u2018change of stream\u2019 indications from both\n<a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Execute.html\">Execute</a> and\n<a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch2.html\">Fetch2</a> to\nsignal that it should change its internal fetch address and tag newly fetched\nlines with new stream or prediction sequence numbers. When both Execute and\n<a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch2.html\">Fetch2</a> signal\nchanges of stream at the same time, <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch1.html\">Fetch1</a> takes\n<a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Execute.html\">Execute</a>\u2019s\nchange.</p>\n<p>Every line issued by <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch1.html\">Fetch1</a> will bear a\nunique line sequence number which can be used for debugging stream changes.</p>\n<p>When fetching from the I-cache, <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch1.html\">Fetch1</a>  will ask for\ndata from the current fetch address (Fetch1::pc) up to the end of the \u2018data\nsnap\u2019 size set in the parameter fetch1LineSnapWidth. Subsequent autonomous line\nfetches will fetch whole lines at a snap boundary and of size fetch1LineWidth.</p>\n<p><a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch1.html\">Fetch1</a> will\nonly initiate a memory fetch if it can reserve space in <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch2.html\">Fetch2</a> input buffer.\nThat input buffer serves an the fetch queue/LFL for the system.</p>\n<p><a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch1.html\">Fetch1</a>\ncontains two queues: requests and transfers to handle the stages of translating\nthe address of a line fetch (via the TLB) and accommodating the\nrequest/response of fetches to/from memory.</p>\n<p>Fetch requests from <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch1.html\">Fetch1</a> are pushed into\nthe requests queue as newly allocated FetchRequest objects once they have been\nsent to the ITLB with a call to itb-&gt;translateTiming.</p>\n<p>A response from the TLB moves the request from the requests queue to the\ntransfers queue. If there is more than one entry in each queue, it is possible\nto get a TLB response for request which is not at the head of the requests\nqueue. In that case, the TLB response is marked up as a state change to\nTranslated in the request object, and advancing the request to transfers (and\nthe memory system) is left to calls to <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch1.html#ac143710b93ec9f55bfc3e2882ef2fe4c\">Fetch1::stepQueues</a>\nwhich is called in the cycle following any event is received.</p>\n<p><a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch1.html#a9ace21e8131caf360190ea876cfa2934\">Fetch1::tryToSendToTransfers</a>\n\u2014\nlayout: documentation\ntitle: Execution Basics\ndoc: gem5 documentation\nparent: cpu_models\npermalink: /documentation/general_docs/cpu_models/execution_basics\n\u2014</p>\n<p>is responsible for moving requests between the two queues and issuing requests\nto memory. Failed TLB lookups (prefetch aborts) continue to occupy space in the\nqueues until they are recovered at the head of transfers.</p>\n<p>Responses from memory change the request object state to Complete and\n<a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch1.html#a68a0a88ce6ee3dd170c977318cfb4ca9\">Fetch1::evaluate</a>\ncan pick up response data, package it in the <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1ForwardLineData.html\">ForwardLineData</a> object,\nand forward it to <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch2.html\">Fetch2</a>\u2019s input buffer.</p>\n<p>As space is always reserved in <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch2.html#afdaa27275e2f605d9aaa637e8c39f96d\">Fetch2::inputBuffer</a>,\nsetting the input buffer\u2019s size to 1 results in non-prefetching behaviour.</p>\n<p>When a change of stream occurs, translated requests queue members and completed\ntransfers queue members can be unconditionally discarded to make way for new\ntransfers.</p>\n<h3 id=\"fetch2-stage\">Fetch2 stage</h3>\n<p>Fetch2 receives a line from Fetch1 into its input buffer. The data in the head\nline in that buffer is iterated over and separated into individual instructions\nwhich are packed into a vector of instructions which can be passed to\n<a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Decode.html\">Decode</a>.\nPacking instructions can be aborted early if a fault is found in either the\ninput line as a whole or a decomposed instruction.</p>\n<h4 id=\"branch-prediction\">Branch prediction</h4>\n<p>Fetch2 contains the branch prediction mechanism. This is a wrapper around the branch predictor interface provided by gem5 (cpu/pred/\u2026).</p>\n<p>Branches are predicted for any control instructions found. If prediction is\nattempted for an instruction, the <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1MinorDynInst.html#a905b0516019ae7f47b5795ceda33f5cd\">MinorDynInst::triedToPredict</a>\nflag is set on that instruction.</p>\n<p>When a branch is predicted to take, the <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1MinorDynInst.html#aa57659ef9d30162ddcf10fcb0f3963ac\">MinorDynInst::predictedTaken</a> flag is set and <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1MinorDynInst.html#a5eaf9547bcaefa2c0fd37f32c828691b\">MinorDynInst::predictedTarget</a> is set to the predicted target PC value. The predicted branch instruction is then packed into Fetch2\u2019s output vector, the prediction sequence number is incremented, and the branch is communicated to Fetch1.</p>\n<p>After signalling a prediction, Fetch2 will discard its input buffer contents\nand will reject any new lines which have the same stream sequence number as\nthat branch but have a different prediction sequence number. This allows\nfollowing sequentially fetched lines to be rejected without ignoring new lines\ngenerated by a change of stream indicated from a \u2018real\u2019 branch from Execute\n(which will have a new stream sequence number).</p>\n<p>The program counter value provided to Fetch2 by Fetch1 packets is only updated\nwhen there is a change of stream. Fetch2::havePC indicates whether the PC will\nbe picked up from the next processed input line. Fetch2::havePC is necessary to\nallow line-wrapping instructions to be tracked through decode.</p>\n<p>Branches (and instructions predicted to branch) which are processed by Execute\nwill generate BranchData (<a href=\"http://doxygen.gem5.org/release/current/pipe__data_8hh.html\">pipe_data.hh</a>) data explaining the\noutcome of the branch which is sent forwards to Fetch1 and Fetch2. Fetch1 uses\nthis data to change stream (and update its stream sequence number and address\nfor new lines). Fetch2 uses it to update the branch predictor. Minor does not\ncommunicate branch data to the branch predictor for instructions which are\ndiscarded on the way to commit.</p>\n<p>BranchData::BranchReason (<a href=\"http://doxygen.gem5.org/release/current/pipe__data_8hh.html\">pipe_data.hh</a>) encodes the possible\nbranch scenarios:</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left\">Branch enum val.</th>\n<th style=\"text-align: left\">In Execute</th>\n<th style=\"text-align: left\">Fetch1 reaction</th>\n<th style=\"text-align: left\">Fetch2 reaction</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left\">No Branch</td>\n<td style=\"text-align: left\">(output bubble data)</td>\n<td style=\"text-align: left\">-</td>\n<td style=\"text-align: left\">-</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">CorrectlyPredictedBranch</td>\n<td style=\"text-align: left\">Predicted, taken</td>\n<td style=\"text-align: left\">-</td>\n<td style=\"text-align: left\">Update BP as taken branch</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">UnpredictedBranch</td>\n<td style=\"text-align: left\">Not predicted, taken and was taken</td>\n<td style=\"text-align: left\">New stream</td>\n<td style=\"text-align: left\">Update BP as taken branch</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">BadlyPredictedBranch</td>\n<td style=\"text-align: left\">Predicted, not taken</td>\n<td style=\"text-align: left\">New stream to restore to old Inst. source</td>\n<td style=\"text-align: left\">Update BP as not taken branch</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">BadlyPredictedBranchTarget</td>\n<td style=\"text-align: left\">Predicted, taken, but to a different target than predicted one</td>\n<td style=\"text-align: left\">New stream</td>\n<td style=\"text-align: left\">Update BTB to new target</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">SuspendThread</td>\n<td style=\"text-align: left\">Hint to suspend fetch</td>\n<td style=\"text-align: left\">Suspend fetch for this thread (branch to next inst. as wakeup fetch addr</td>\n<td style=\"text-align: left\">-</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">Interrupt</td>\n<td style=\"text-align: left\">Interrupt detected</td>\n<td style=\"text-align: left\">New stream</td>\n<td style=\"text-align: left\">-</td>\n</tr>\n</tbody>\n</table>\n<hr/>\n<p>layout: documentation\ntitle: Execution Basics\ndoc: gem5 documentation\nparent: cpu_models\npermalink: /documentation/general_docs/cpu_models/execution_basics\n\u2014</p>\n<h3 id=\"decode-stage\">Decode Stage</h3>\n<p><a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Decode.html\">Decode</a> takes a\nvector of instructions from <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch2.html\">Fetch2</a> (via its input\nbuffer) and decomposes those instructions into micro-ops (if necessary) and\npacks them into its output instruction vector.</p>\n<p>The parameter executeInputWidth sets the number of instructions which can be\npacked into the output per cycle. If the parameter decodeCycleInput is true,\n<a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Decode.html\">Decode</a> can try\nto take instructions from more than one entry in its input buffer per cycle.</p>\n<h3 id=\"execute-stage\">Execute Stage</h3>\n<p>Execute provides all the instruction execution and memory access mechanisms. An\ninstructions passage through Execute can take multiple cycles with its precise\ntiming modelled by a functional unit pipeline FIFO.</p>\n<p>A vector of instructions (possibly including fault \u2018instructions\u2019) is provided\nto Execute by Decode and can be queued in the Execute input buffer before being\nissued. Setting the parameter executeCycleInput allows execute to examine more\nthan one input buffer entry (more than one instruction vector). The number of\ninstructions in the input vector can be set with executeInputWidth and the\ndepth of the input buffer can be set with parameter executeInputBufferSize.</p>\n<h4 id=\"functional-units\">Functional units</h4>\n<p>The Execute stage contains pipelines for each functional unit comprising the\ncomputational core of the CPU. Functional units are configured via the\nexecuteFuncUnits parameter. Each functional unit has a number of instruction\nclasses it supports, a stated delay between instruction issues, and a delay\nfrom instruction issue to (possible) commit and an optional timing annotation\ncapable of more complicated timing.</p>\n<p>Each active cycle, <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Execute.html#a2d6ca9a694bf99ef82da7759cba8c3da\">Execute::evaluate</a>\nperforms this action:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    Execute::evaluate:\n        push input to inputBuffer\n        setup references to input/output data slots and branch output slot\n\n        step D-cache interface queues (similar to Fetch1)\n\n        if interrupt posted:\n            take interrupt (signalling branch to Fetch1/Fetch2)\n        else\n            commit instructions\n            issue new instructions\n\n        advance functional unit pipelines\n\n        reactivate Execute if the unit is still active\n\n        commit the push to the inputBuffer if that data hasn't all been used\n</code></pre></div></div>\n<h4 id=\"functional-unit-fifos\">Functional unit FIFOs</h4>\n<p>Functional units are implemented as SelfStallingPipelines (stage.hh). These are\n<a href=\"http://doxygen.gem5.org/release/current/classTimeBuffer.html\">TimeBuffer</a> FIFOs\nwith two distinct \u2018push\u2019 and \u2018pop\u2019 wires. They respond to\n<a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1SelfStallingPipeline.html#ad933640bc6aab559c009302e478c3768\">SelfStallingPipeline::advance</a>\nin the same way as TimeBuffers unless there is data at the far, \u2018pop\u2019, end of\nthe FIFO. A \u2018stalled\u2019 flag is provided for signalling stalling and to allow a\nstall to be cleared. The intention is to provide a pipeline for each functional\nunit which will never advance an instruction out of that pipeline until it has\nbeen processed and the pipeline is explicitly unstalled.</p>\n<p>The actions \u2018issue\u2019, \u2018commit\u2019, and \u2018advance\u2019 act on the functional units.</p>\n<h4 id=\"issue\">Issue</h4>\n<p>Issuing instructions involves iterating over both the input buffer instructions\nand the heads of the functional units to try and issue instructions in order.\nThe number of instructions which can be issued each cycle is limited by the\nparameter executeIssueLimit, how executeCycleInput is set, the availability of\n\u2014\nlayout: documentation\ntitle: Execution Basics\ndoc: gem5 documentation\nparent: cpu_models\npermalink: /documentation/general_docs/cpu_models/execution_basics\n\u2014</p>\n<p>pipeline space and the policy used to choose a pipeline in which the\ninstruction can be issued.</p>\n<p>At present, the only issue policy is strict round-robin visiting of each\npipeline with the given instructions in sequence. For greater flexibility,\nbetter (and more specific policies) will need to be possible.</p>\n<p>Memory operation instructions traverse their functional units to perform their\nEA calculations. On \u2018commit\u2019, the <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1ExecContext.html\">ExecContext</a>::initiateAcc\nexecution phase is performed and any memory access is issued (via.\nExecContext::{read,write}Mem calling <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1LSQ.html#a18594a4baa4eef7bfc3be45c03f4d544\">LSQ::pushRequest</a>)\nto the <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1LSQ.html\">LSQ</a>.</p>\n<p>Note that faults are issued as if they are instructions and can (currently) be\nissued to any functional unit.</p>\n<p>Every issued instruction is also pushed into the Execute::inFlightInsts queue.\nMemory ref. instructions are pushing into Execute::inFUMemInsts queue.</p>\n<h4 id=\"commit\">Commit</h4>\n<p>Instructions are committed by examining the head of the Execute::inFlightInsts\nqueue (which is decorated with the functional unit number to which the\ninstruction was issued). Instructions which can then be found in their\nfunctional units are executed and popped from Execute::inFlightInsts.</p>\n<p>Memory operation instructions are committed into the memory queues (as\ndescribed above) and exit their functional unit pipeline but are not popped\nfrom the Execute::inFlightInsts queue. The Execute::inFUMemInsts queue provides\nordering to memory operations as they pass through the functional units\n(maintaining issue order). On entering the LSQ, instructions are popped from\nExecute::inFUMemInsts.</p>\n<p>If the parameter executeAllowEarlyMemoryIssue is set, memory operations can be\nsent from their FU to the LSQ before reaching the head of\nExecute::inFlightInsts but after their dependencies are met.\n<a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1MinorDynInst.html#ac72a9dcff570bbaf24da9ee74392e6d0\">MinorDynInst::instToWaitFor</a>\nis marked up with the latest dependent instruction execSeqNum required to be\ncommitted for a memory operation to progress to the LSQ.</p>\n<p>Once a memory response is available (by testing the head of\nExecute::inFlightInsts against <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1LSQ.html#a458abe5d220a0f66600bf339bceb2100\">LSQ::findResponse</a>),\ncommit will process that response (ExecContext::completeAcc) and pop the\ninstruction from Execute::inFlightInsts.</p>\n<p>Any branch, fault or interrupt will cause a stream sequence number change and\nsignal a branch to Fetch1/Fetch2. Only instructions with the current stream\nsequence number will be issued and/or committed.</p>\n<h4 id=\"advance\">Advance</h4>\n<p>All non-stalled pipeline are advanced and may, thereafter, become stalled.\nPotential activity in the next cycle is signalled if there are any instructions\nremaining in any pipeline.</p>\n<h4 id=\"scoreboard\">Scoreboard</h4>\n<p>The scoreboard (<a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Scoreboard.html\">Scoreboard</a>) is used to\ncontrol instruction issue. It contains a count of the number of in flight\ninstructions which will write each general purpose CPU integer or float\nregister. Instructions will only be issued where the scoreboard contains a\ncount of 0 instructions which will write to one of the instructions source\nregisters.</p>\n<p>Once an instruction is issued, the scoreboard counts for each destination\nregister for an instruction will be incremented.</p>\n<p>The estimated delivery time of the instruction\u2019s result is marked up in the scoreboard by adding the length of the issued-to FU to the current time. The timings parameter on each FU provides a list of additional rules for calculating the delivery time. These are documented in the parameter comments in MinorCPU.py.</p>\n<p>On commit, (for memory operations, memory response commit) the scoreboard counters for an instruction\u2019s source registers are decremented. will be decremented.</p>\n<h4 id=\"executeinflightinsts\">Execute::inFlightInsts</h4>\n<p>The Execute::inFlightInsts queue will always contain all instructions in flight\nin <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Execute.html\">Execute</a> in\nthe correct issue order. <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Execute.html#af0b90170a273f1a0d41f4164ba3fe456\">Execute::issue</a>\nis the only process which will push an instruction into the queue.\n<a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Execute.html#ac2da0ae4202602ce4ad976f33a004237\">Execute::commit</a>\nis the only process that can pop an instruction.</p>\n<h4 id=\"lsq\">LSQ</h4>\n<p>The <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1LSQ.html\">LSQ</a> can\nsupport multiple outstanding transactions to memory in a number of conservative\ncases.</p>\n<p>There are three queues to contain requests: requests, transfers and the store\nbuffer. The requests and transfers queue operate in a similar manner to the\nqueues in Fetch1. The store buffer is used to decouple the delay of completing\nstore operations from following loads.</p>\n<p>Requests are issued to the DTLB as their instructions leave their functional\nunit. At the head of requests, cacheable load requests can be sent to memory\nand on to the transfers queue. Cacheable stores will be passed to transfers\nunprocessed and progress that queue maintaining order with other transactions.</p>\n<p>The conditions in <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1LSQ.html#a7d7b8ddc7c69fd9eb3b8594fe261d8e8\">LSQ::tryToSendToTransfers</a>\ndictate when requests can be sent to memory.</p>\n<p>All uncacheable transactions, split transactions and locked transactions are\nprocessed in order at the head of requests. Additionally, store results\nresiding in the store buffer can have their data forwarded to cacheable loads\n(removing the need to perform a read from memory) but no cacheable load can be\nissue to the transfers queue until that queue\u2019s stores have drained into the\nstore buffer.</p>\n<p>At the end of transfers, requests which are <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1LSQ_1_1LSQRequest.html#a429d50f5dd6be4217d5dba93f8c289d3a81b9dbf6670e396d0266949d59b57428\">LSQ::LSQRequest::Complete</a>\n(are faulting, are cacheable stores, or have been sent to memory and received a\nresponse) can be picked off by Execute and either committed\n(ExecContext::completeAcc) and, for stores, be sent to the store buffer.</p>\n<p>Barrier instructions do not prevent cacheable loads from progressing to memory\nbut do cause a stream change which will discard that load. Stores will not be\ncommitted to the store buffer if they are in the shadow of the barrier but\nbefore the new instruction stream has arrived at Execute. As all other memory\ntransactions are delayed at the end of the requests queue until they are at the\nhead of Execute::inFlightInsts, they will be discarded by any barrier stream\nchange.</p>\n<p>After commit, <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1LSQ_1_1BarrierDataRequest.html\">LSQ::BarrierDataRequest</a>\nrequests are inserted into the store buffer to track each barrier until all\npreceding memory transactions have drained from the store buffer. No further\nmemory transactions will be issued from the ends of FUs until after the barrier\nhas drained.</p>\n<h4 id=\"draining\">Draining</h4>\n<p>Draining is mostly handled by the <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Execute.html\">Execute</a> stage. When\ninitiated by calling <a href=\"http://doxygen.gem5.org/release/current/classMinorCPU.html#a3191c9247cd80dfc603bfcd154cf09a0\">MinorCPU::drain</a>,\n<a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Pipeline.html#af07fdce00c8937e9de5b6450a1cd62bf\">Pipeline::evaluate</a>\nchecks the draining status of each unit each cycle and keeps the pipeline\nactive until draining is complete. It is Pipeline that signals the completion\nof draining. Execute is triggered by <a href=\"http://doxygen.gem5.org/release/current/classMinorCPU.html#a3191c9247cd80dfc603bfcd154cf09a0\">MinorCPU::drain</a>\nand starts stepping through its <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Execute.html#aeb21dbbbbde40d8cdc68e9b17ddd3d40\">Execute::DrainState</a>\nstate machine, starting from state Execute::NotDraining, in this order:</p>\n<table>\n<tbody>\n<tr>\n<td>State</td>\n<td>Meaning</td>\n</tr>\n<tr>\n<td><a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Execute.html#aeb21dbbbbde40d8cdc68e9b17ddd3d40aeecf47987ef0d4aa0a6a59403d085ec9\">Execute::NotDraining</a></td>\n<td>Not trying to drain, normal execution</td>\n</tr>\n<tr>\n<td><a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Execute.html#aeb21dbbbbde40d8cdc68e9b17ddd3d40aec53785380b6256e2baa889739311570\">Execute::DrainCurrentInst</a></td>\n<td>Draining micro-ops to complete inst.</td>\n</tr>\n<tr>\n<td><a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Execute.html#aeb21dbbbbde40d8cdc68e9b17ddd3d40a516d421a79c458d376bedeb067fc207f\">Execute::DrainHaltFetch</a></td>\n<td>Halt fetching instructions</td>\n</tr>\n<tr>\n<td><a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Execute.html#aeb21dbbbbde40d8cdc68e9b17ddd3d40ade3ca2567fed8d893896d71bb95f13ca\">Execute::DrainAllInsts</a></td>\n<td>Discarding all instructions presented</td>\n</tr>\n</tbody>\n</table>\n<p>When complete, a drained Execute unit will be in the <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Execute.html#aeb21dbbbbde40d8cdc68e9b17ddd3d40ade3ca2567fed8d893896d71bb95f13ca\">Execute::DrainAllInsts</a>\nstate where it will continue to discard instructions but has no knowledge of\nthe drained state of the rest of the model.</p>\n<h2 id=\"debug-options\">Debug options</h2>\n<p>The model provides a number of debug flags which can be passed to gem5 with the\n<code class=\"language-plaintext highlighter-rouge\">\u2013debug-flags</code> option.</p>\n<p>The available flags are:</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left\">Debug flag</th>\n<th style=\"text-align: left\">Unit which will generate debugging output</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left\">Activity</td>\n<td style=\"text-align: left\"><a href=\"http://doxygen.gem5.org/release/current/namespaceDebug.html\">Debug</a> ActivityMonitor actions</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">Branch</td>\n<td style=\"text-align: left\"><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Fetch2.html\">Fetch2</a> and <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Execute.html\">Execute</a> branch prediction decisions</td>\n</tr>\n<tr>\n<td style=\"text-align: left\"><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1MinorCPU.html\">MinorCPU</a></td>\n<td style=\"text-align: left\">CPU global actions such as wakeup/thread suspension</td>\n</tr>\n<tr>\n<td style=\"text-align: left\"><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Decode.html\">Decode</a></td>\n<td style=\"text-align: left\"><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Decode.html\">Decode</a></td>\n</tr>\n<tr>\n<td style=\"text-align: left\">MinorExec</td>\n<td style=\"text-align: left\"><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Execute.html\">Execute</a> behaviour</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">Fetch</td>\n<td style=\"text-align: left\"><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Fetch1.html\">Fetch1</a> and <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Fetch2.html\">Fetch2</a></td>\n</tr>\n<tr>\n<td style=\"text-align: left\">MinorInterrupt</td>\n<td style=\"text-align: left\"><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Execute.html\">Execute</a> interrupt handling</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">MinorMem</td>\n<td style=\"text-align: left\"><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Execute.html\">Execute</a> memory interactions</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">MinorScoreboard</td>\n<td style=\"text-align: left\"><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Execute.html\">Execute</a> scoreboard activity</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">MinorTrace</td>\n<td style=\"text-align: left\">Generate MinorTrace cyclic state trace output (see below)</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">MinorTiming</td>\n<td style=\"text-align: left\">MinorTiming instruction timing modification operations</td>\n</tr>\n</tbody>\n</table>\n<p>The group flag <a href=\"http://doxygen.gem5.org/release/current/namespaceminor.html\">Minor</a>\nenables all the flags beginning with <a href=\"http://doxygen.gem5.org/release/current/namespaceMinor.html\">Minor</a>.</p>\n<h2 id=\"minortrace-and-minorviewpy\">MinorTrace and minorview.py</h2>\n<p>The debug flag MinorTrace causes cycle-by-cycle state data to be printed which\ncan then be processed and viewed by the minorview.py tool. This output is very\nverbose and so it is recommended it only be used for small examples.</p>\n<h3 id=\"minortrace-format\">MinorTrace format</h3>\n<p>There are three types of line outputted by MinorTrace:</p>\n<h4 id=\"minortrace---ticked-unit-cycle-state\">MinorTrace - Ticked unit cycle state</h4>\n<p>For example:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code> 110000: system.cpu.dcachePort: MinorTrace: state=MemoryRunning in_tlb_mem=0/0\n</code></pre></div></div>\n<p>For each time step, the MinorTrace flag will cause one MinorTrace line to be\nprinted for every named element in the model.</p>\n<h4 id=\"minorinst---summaries-of-instructions-issued-by-decode\">MinorInst - summaries of instructions issued by Decode</h4>\n<p><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Decode.html\">Decode</a></p>\n<p>For example:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code> 140000: system.cpu.execute: MinorInst: id=0/1.1/1/1.1 addr=0x5c \\\n                             inst=\"  mov r0, #0\" class=IntAlu\n</code></pre></div></div>\n<p>MinorInst lines are currently only generated for instructions which are committed.</p>\n<h4 id=\"minorline---summaries-of-line-fetches-issued-by-fetch1\">MinorLine - summaries of line fetches issued by Fetch1</h4>\n<p><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Fetch1.html\">Fetch1</a></p>\n<p>For example:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  92000: system.cpu.icachePort: MinorLine: id=0/1.1/1 size=36 \\\n                                vaddr=0x5c paddr=0x5c\n</code></pre></div></div>\n<h3 id=\"minorviewpy\">minorview.py</h3>\n<p>Minorview (util/minorview.py) can be used to visualise the data created by\nMinorTrace.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>usage: minorview.py [-h] [--picture picture-file] [--prefix name]\n                   [--start-time time] [--end-time time] [--mini-views]\n                   event-file\n\nMinor visualiser\n\npositional arguments:\n  event-file\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --picture picture-file\n                        markup file containing blob information (default:\n                        &lt;minorview-path&gt;/minor.pic)\n  --prefix name         name prefix in trace for CPU to be visualised\n                        (default: system.cpu)\n  --start-time time     time of first event to load from file\n  --end-time time       time of last event to load from file\n  --mini-views          show tiny views of the next 10 time steps\n</code></pre></div></div>\n<p>Raw debugging output can be passed to minorview.py as the event-file. It will\npick out the MinorTrace lines and use other lines where units in the simulation\nare named (such as system.cpu.dcachePort in the above example) will appear as\n\u2018comments\u2019 when units are clicked on the visualiser.</p>\n<p>Clicking on a unit which contains instructions or lines will bring up a speech\nbubble giving extra information derived from the MinorInst/MinorLine lines.</p>\n<p><code class=\"language-plaintext highlighter-rouge\">\u2013start-time</code> and <code class=\"language-plaintext highlighter-rouge\">\u2013end-time</code> allow only sections of debug files to be loaded.</p>\n<p><code class=\"language-plaintext highlighter-rouge\">\u2013prefix</code> allows the name prefix of the CPU to be inspected to be supplied.\nThis defaults to <code class=\"language-plaintext highlighter-rouge\">system.cpu</code>.</p>\n<p>In the visualiser, The buttons Start, End, Back, Forward, Play and Stop can be\nused to control the displayed simulation time.</p>\n<p>The diagonally striped coloured blocks are showing the <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1InstId.html\">InstId</a> of the\ninstruction or line they represent. Note that lines in <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch1.html\">Fetch1</a> and f1ToF2.F\nonly show the id fields of a line and that instructions in <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1Fetch2.html\">Fetch2</a>, f2ToD, and\ndecode.inputBuffer do not yet have execute sequence numbers. The T/S.P/L/F.E\nbuttons can be used to toggle parts of <a href=\"http://doxygen.gem5.org/release/current/classMinor_1_1InstId.html\">InstId</a> on and off to\nmake it easier to understand the display. Useful combinations are:</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left\">Combination</th>\n<th style=\"text-align: left\">Reason</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left\">E</td>\n<td style=\"text-align: left\">just show the final execute sequence number</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">F/E</td>\n<td style=\"text-align: left\">show the instruction-related numbers</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">S/P</td>\n<td style=\"text-align: left\">show just the stream-related numbers (watch the stream sequence change with branches and not change with predicted branches)</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">S/E</td>\n<td style=\"text-align: left\">show instructions and their stream</td>\n</tr>\n</tbody>\n</table>\n<p>The key to the right shows all the displayable colours (some of the colour\nchoices are quite bad!):</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left\">Symbol</th>\n<th style=\"text-align: left\">Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left\">U</td>\n<td style=\"text-align: left\">Uknown data</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">B</td>\n<td style=\"text-align: left\">Blocked stage</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">-</td>\n<td style=\"text-align: left\">Bubble</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">E</td>\n<td style=\"text-align: left\">Empty queue slot</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">R</td>\n<td style=\"text-align: left\">Reserved queue slot</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">F</td>\n<td style=\"text-align: left\">Fault</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">r</td>\n<td style=\"text-align: left\">Read (used as the leftmost stripe on data in the dcachePort)</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">w</td>\n<td style=\"text-align: left\">Write \u201c \u201c</td>\n</tr>\n<tr>\n<td style=\"text-align: left\">0 to 9</td>\n<td style=\"text-align: left\">last decimal digit of the corresponding data</td>\n</tr>\n</tbody>\n</table>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    ,---------------.         .--------------.  *U\n    | |=|-&gt;|=|-&gt;|=| |         ||=|||-&gt;||-&gt;|| |  *-  &lt;- Fetch queues/LSQ\n    `---------------'         `--------------'  *R\n    === ======                                  *w  &lt;- Activity/Stage activity\n                              ,--------------.  *1\n    ,--.      ,.      ,.      | ============ |  *3  &lt;- Scoreboard\n    |  |-\\[]-\\||-\\[]-\\||-\\[]-\\| ============ |  *5  &lt;- Execute::inFlightInsts\n    |  | :[] :||-/[]-/||-/[]-/| -. --------  |  *7\n    |  |-/[]-/||  ^   ||      |  | --------- |  *9\n    |  |      ||  |   ||      |  | ------    |\n[]-&gt;|  |    -&gt;||  |   ||      |  | ----      |\n    |  |&lt;-[]&lt;-||&lt;-+-&lt;-||&lt;-[]&lt;-|  | ------    |-&gt;[] &lt;- Execute to Fetch1,\n    '--`      `'  ^   `'      | -' ------    |        Fetch2 branch data\n             ---. |  ---.     `--------------'\n             ---' |  ---'       ^       ^\n                  |   ^         |       `------------ Execute\n  MinorBuffer ----' input       `-------------------- Execute input buffer\n                    buffer\n</code></pre></div></div>\n<p>Stages show the colours of the instructions currently being\ngenerated/processed.</p>\n<p>Forward FIFOs between stages show the data being pushed into them at the\ncurrent tick (to the left), the data in transit, and the data available at\ntheir outputs (to the right).</p>\n<p>The backwards FIFO between <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Fetch2.html\">Fetch2</a> and <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Fetch1.html\">Fetch1</a> shows branch\nprediction data.</p>\n<p>In general, all displayed data is correct at the end of a cycle\u2019s activity at\nthe time indicated but before the inter-stage FIFOs are ticked. Each FIFO has,\ntherefore an extra slot to show the asserted new input data, and all the data\ncurrently within the FIFO.</p>\n<p>Input buffers for each stage are shown below the corresponding stage and show\nthe contents of those buffers as horizontal strips. Strips marked as reserved\n(cyan by default) are reserved to be filled by the previous stage. An input\nbuffer with all reserved or occupied slots will, therefore, block the previous\nstage from generating output.</p>\n<p>Fetch queues and <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1LSQ.html\">LSQ</a> show the\nlines/instructions in the queues of each interface and show the number of\nlines/instructions in TLB and memory in the two striped colours of the top of\ntheir frames.</p>\n<p>Inside <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Execute.html\">Execute</a>, the horizontal\nbars represent the individual FU pipelines. The vertical bar to the left is the\ninput buffer and the bar to the right, the instructions committed this cycle.\nThe background of <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Execute.html\">Execute</a> shows\ninstructions which are being committed this cycle in their original FU pipeline\npositions.</p>\n<p>The strip at the top of the <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Execute.html\">Execute</a> block shows the\ncurrent streamSeqNum that <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Execute.html\">Execute</a> is committing.\nA similar stripe at the top of <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Fetch1.html\">Fetch1</a> shows that\nstage\u2019s expected streamSeqNum and the stripe at the top of <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Fetch2.html\">Fetch2</a> shows its\nissuing predictionSeqNum.</p>\n<p>The scoreboard shows the number of instructions in flight which will commit a\nresult to the register in the position shown. The scoreboard contains slots for\neach integer and floating point register.</p>\n<p>The Execute::inFlightInsts queue shows all the instructions in flight in\n<a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1minor_1_1Execute.html\">Execute</a> with\nthe oldest instruction (the next instruction to be committed) to the right.</p>\n<p><code class=\"language-plaintext highlighter-rouge\">Stage activity</code> shows the signalled activity (as E/1) for each stage (with CPU\nmiscellaneous activity to the left)</p>\n<p><code class=\"language-plaintext highlighter-rouge\">Activity</code> show a count of stage and pipe activity.</p>\n<h3 id=\"minorpic-format\">minor.pic format</h3>\n<p>The minor.pic file (src/minor/minor.pic) describes the layout of the models\nblocks on the visualiser. Its format is described in the supplied minor.pic\nfile.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/cpu_models/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/cpu_models/O3CPU\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/cpu_models/visualization",
        "title": "Visualization",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"visualization\">Visualization</h1>\n<p>This page contains information about different types of information visualization that is integrated or can be used with gem5.</p>\n<h2 id=\"o3-pipeline-viewer\">O3 Pipeline Viewer</h2>\n<p>The o3 pipeline viewer is a text based viewer of the out-of-order CPU pipeline. It shows when instructions are fetched (f), decoded (d), renamed (n), dispatched (p), issued (i), completed (c), and retired (r). It is very useful for understanding where the pipeline is stalling or squashing in a reasonable small sequence of code. Next to the colorized viewer that wraps around is the tick the current instruction retired, the pc of that instruction, it\u2019s disassembly, and the o3 sequence number for that instruction.</p>\n<p><img alt=\"o3pipeviewer\" src=\"/assets/img/O3pipeview.png\"/></p>\n<p>To generate output line you see above you first need to run an experiment with the o3 cpu:</p>\n<p><code class=\"language-plaintext highlighter-rouge\">./build/ARM/gem5.opt --debug-flags=O3PipeView --debug-start=&lt;first tick of interest&gt; --debug-file=trace.out configs/example/se.py --cpu-type=detailed --caches -c &lt;path to binary&gt; -m &lt;last cycle of interest&gt;</code></p>\n<p>Then you can run the script to generate a trace similar to the above (500 is the number of ticks per clock (2GHz) in this case):</p>\n<p><code class=\"language-plaintext highlighter-rouge\">./util/o3-pipeview.py -c 500 -o pipeview.out --color m5out/trace.out</code></p>\n<p>You can view the output in color by piping the file through less:</p>\n<p><code class=\"language-plaintext highlighter-rouge\">less -r pipeview.out</code></p>\n<p>When CYCLE_TIME (-c) is wrong, Right square brackets in output may not aligned to the same column. Default value of CYCLE_TIME is 1000. Be careful.</p>\n<p>The script has some additional integrated help: (type \u2018./util/o3-pipeview.py \u2013help\u2019 for help).</p>\n<h2 id=\"minor-viewer\">Minor Viewer</h2>\n<p>The <a href=\"minor_view\">new page</a> on minor viewer is yet to be made, refer to <a href=\"http://pages.cs.wisc.edu/~swilson/gem5-docs/minor.html#trace\">old page</a> for documentation.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/cpu_models/TraceCPU\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/debugging_and_testing/debugging/debugger_based_debugging\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/development/coding_style/",
        "title": "C/C++ Coding Style",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"cc-coding-style\">C/C++ Coding Style</h1>\n<p>We strive to maintain a consistent coding style in the gem5 C/C++ source code to make the source more readable and maintainable. This necessarily involves compromise among the multiple developers who work on this code. We feel that we have been successful in finding such a compromise, as each of the primary M5 developers is annoyed by at least one of the rules below. We ask that you abide by these guidelines as well if you develop code that you would like to contribute back to M5. An Emacs c++-mode style embodying the indentation rules is available in the source tree at util/emacs/m5-c-style.el.</p>\n<h2 id=\"indentation-and-line-breaks\">Indentation and Line Breaks</h2>\n<p>Indentation will be 4 spaces per level, though namespaces should not increase the indentation.</p>\n<ul>\n<li>Exception: labels followed by colons (case and goto labels and public/private/protected modifiers) are indented two spaces from the enclosing context.</li>\n</ul>\n<p>Indentation should use spaces only (no tabs), as tab widths are not always set consistently, and tabs make output harder to read when used with tools such as diff.</p>\n<p>Lines must be a maximum of 79 characters long.</p>\n<h2 id=\"braces\">Braces</h2>\n<p>For control blocks (if, while, etc.), opening braces must be on the same line as the control keyword with a space between the closing parenthesis and the opening brace.</p>\n<ul>\n<li>Exception: for multi-line expressions, the opening brace may be placed on a separate line to distinguish the control block from the statements inside the block.</li>\n</ul>\n<div class=\"language-c++ highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">if</span> <span class=\"p\">(...)</span> <span class=\"p\">{</span>\n    <span class=\"p\">...</span>\n<span class=\"p\">}</span>\n\n<span class=\"c1\">// exception case</span>\n<span class=\"k\">for</span> <span class=\"p\">(...;</span>\n     <span class=\"p\">...;</span>\n     <span class=\"p\">...)</span> <span class=\"c1\">// brace could be up here</span>\n<span class=\"p\">{</span> <span class=\"c1\">// but this is optionally OK *only* when the 'for' spans multiple lines</span>\n    <span class=\"p\">...</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n<p>\u2018Else\u2019 keywords should follow the closing \u2018if\u2019 brace on the same line, as follows:</p>\n<div class=\"language-c++ highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">if</span> <span class=\"p\">(...)</span> <span class=\"p\">{</span>\n    <span class=\"p\">...</span>\n<span class=\"p\">}</span> <span class=\"k\">else</span> <span class=\"k\">if</span> <span class=\"p\">(...)</span> <span class=\"p\">{</span>\n    <span class=\"p\">...</span>\n<span class=\"p\">}</span> <span class=\"k\">else</span> <span class=\"p\">{</span>\n    <span class=\"p\">...</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n<p>Blocks that consist of a single statement that fits on a single line may optionally omit the braces. Braces are still required if the single statement spans multiple lines, or if the block is part of an else/if chain where other blocks have braces.</p>\n<div class=\"language-c++ highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// This is OK with or without braces</span>\n<span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"o\">&gt;</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n    <span class=\"o\">--</span><span class=\"n\">a</span><span class=\"p\">;</span>\n\n<span class=\"c1\">// In the following cases, braces are still required</span>\n<span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"o\">&gt;</span> <span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"n\">obnoxiously_named_function_with_lots_of_args</span><span class=\"p\">(</span><span class=\"n\">verbose_arg1</span><span class=\"p\">,</span>\n                                                 <span class=\"n\">verbose_arg2</span><span class=\"p\">,</span>\n                                                 <span class=\"n\">verbose_arg3</span><span class=\"p\">);</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"o\">&gt;</span> <span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"o\">--</span><span class=\"n\">a</span><span class=\"p\">;</span>\n<span class=\"p\">}</span> <span class=\"k\">else</span> <span class=\"p\">{</span>\n    <span class=\"n\">underflow</span> <span class=\"o\">=</span> <span class=\"nb\">true</span><span class=\"p\">;</span>\n    <span class=\"n\">warn</span><span class=\"p\">(</span><span class=\"s\">\"underflow on a\"</span><span class=\"p\">);</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n<p>For function definitions or class declarations, the opening brace must be in the first column of the following line.</p>\n<p>In function definitions, the return type should be on one line, followed by the function name, left-justified, on the next line. As mentioned above, the opening brace should also be on a separate line following the function name.</p>\n<p>See examples below:</p>\n<div class=\"language-c++ highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kt\">int</span>\n<span class=\"nf\">exampleFunc</span><span class=\"p\">(...)</span>\n<span class=\"p\">{</span>\n    <span class=\"p\">...</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">ExampleClass</span>\n<span class=\"p\">{</span>\n  <span class=\"nl\">public:</span>\n    <span class=\"p\">...</span>\n<span class=\"p\">};</span>\n</code></pre></div></div>\n<p>Functions should be preceded by a block comment describing the function.</p>\n<p>Inline function declarations longer than one line should not be placed inside class declarations. Most functions longer than one line should not be inline anyway.</p>\n<h2 id=\"spacing\">Spacing</h2>\n<p>There should be:</p>\n<ul>\n<li>one space between keywords (if, for, while, etc.) and opening parentheses</li>\n<li>one space around binary operators (+, -, &lt;, &gt;, etc.) including assignment operators (=, +=, etc.)</li>\n<li>no space around \u2018=\u2019 when used in parameter/argument lists, either to bind default parameter values (in Python or C++) or to bind keyword arguments (in Python)</li>\n<li>no space between function names and opening parentheses for arguments</li>\n<li>no space immediately inside parentheses, except for very complex expressions. Complex expressions are preferentially broken into multiple simpler expressions using temporary variables.</li>\n</ul>\n<p>For pointer and reference argument declarations, either of the following are acceptable:</p>\n<div class=\"language-c++ highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">FooType</span> <span class=\"o\">*</span><span class=\"n\">fooPtr</span><span class=\"p\">;</span>\n<span class=\"n\">FooType</span> <span class=\"o\">&amp;</span><span class=\"n\">fooRef</span><span class=\"p\">;</span>\n</code></pre></div></div>\n<p>or</p>\n<div class=\"language-c++ highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">FooType</span><span class=\"o\">*</span> <span class=\"n\">fooPtr</span><span class=\"p\">;</span>\n<span class=\"n\">FooType</span><span class=\"o\">&amp;</span> <span class=\"n\">fooRef</span><span class=\"p\">;</span>\n</code></pre></div></div>\n<p>However, style should be kept consistent within a file. If you are editing an existing file, please keep consistent with the existing code. If you are writing new code in a new file, feel free to choose the style of your preference.</p>\n<h2 id=\"naming\">Naming</h2>\n<p>Class and type names are mixed case, start with an uppercase letter, and do not contain underscores (e.g., ClassName). Exception: names that are acronyms should be all upper case (e.g., CPU). Class member names (method and variables, including const variables) are mixed case, start with a lowercase letter, and do not contain underscores (e.g., aMemberVariable). Class members that have accessor methods should have a leading underscore to indicate that the user should be using an accessor. The accessor functions themselves should have the same name as the variable without the leading underscore.</p>\n<p>Local variables are lower case, with underscores separating words (e.g., local_variable). Function parameters should use underscores and be lower case.</p>\n<p>C preprocessor symbols (constants and macros) should be all caps with underscores. However, these are deprecated, and should be replaced with const variables and inline functions, respectively, wherever possible.</p>\n<div class=\"language-c++ highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">class</span> <span class=\"nc\">FooBarCPU</span>\n<span class=\"p\">{</span>\n  <span class=\"nl\">private:</span>\n    <span class=\"k\">static</span> <span class=\"k\">const</span> <span class=\"kt\">int</span> <span class=\"n\">minLegalFoo</span> <span class=\"o\">=</span> <span class=\"mi\">100</span><span class=\"p\">;</span>  <span class=\"c1\">// consts are formatted just like other vars</span>\n    <span class=\"kt\">int</span> <span class=\"n\">_fooVariable</span><span class=\"p\">;</span>   <span class=\"c1\">// starts with '_' because it has public accessor functions</span>\n    <span class=\"kt\">int</span> <span class=\"n\">barVariable</span><span class=\"p\">;</span>    <span class=\"c1\">// no '_' since it's internal use only</span>\n\n  <span class=\"nl\">public:</span>\n    <span class=\"c1\">// short inline methods can go all on one line</span>\n    <span class=\"kt\">int</span> <span class=\"n\">fooVariable</span><span class=\"p\">()</span> <span class=\"k\">const</span> <span class=\"p\">{</span> <span class=\"k\">return</span> <span class=\"n\">_fooVariable</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n\n    <span class=\"c1\">// longer inline methods should be formatted like regular functions,</span>\n    <span class=\"c1\">// but indented</span>\n    <span class=\"kt\">void</span>\n    <span class=\"n\">fooVariable</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">new_value</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"n\">assert</span><span class=\"p\">(</span><span class=\"n\">new_value</span> <span class=\"o\">&gt;=</span> <span class=\"n\">minLegalFoo</span><span class=\"p\">);</span>\n        <span class=\"n\">_fooVariable</span> <span class=\"o\">=</span> <span class=\"n\">new_value</span><span class=\"p\">;</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">};</span>\n</code></pre></div></div>\n<h2 id=\"includes\">#includes</h2>\n<p>Whenever possible favor C++ includes over C include. E.g. choose cstdio, not stdio.h.</p>\n<p>The block of #includes at the top of the file should be organized. We keep several sorted groups. This makes it easy to find #include and to avoid duplicate #includes.</p>\n<p>Always include Python.h first if you need that header. This is mandated by the integration guide. The next header file should be your main header file (e.g., for foo.cc you\u2019d include foo.hh first). Having this header first ensures that it is independent and can be included in other places without missing dependencies.</p>\n<div class=\"language-c++ highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// Include Python.h first if you need it.</span>\n<span class=\"cp\">#include</span> <span class=\"cpf\">&lt;Python.h&gt;</span><span class=\"cp\">\n</span>\n<span class=\"c1\">// Include your main header file before any other non-Python headers (i.e., the one with the same name as your cc source file)</span>\n<span class=\"cp\">#include</span> <span class=\"cpf\">\"main_header.hh\"</span><span class=\"cp\">\n</span>\n<span class=\"c1\">// C includes in sorted order</span>\n<span class=\"cp\">#include</span> <span class=\"cpf\">&lt;fcntl.h&gt;</span><span class=\"cp\">\n#include</span> <span class=\"cpf\">&lt;sys/time.h&gt;</span><span class=\"cp\">\n</span>\n<span class=\"c1\">// C++ includes</span>\n<span class=\"cp\">#include</span> <span class=\"cpf\">&lt;cerrno&gt;</span><span class=\"cp\">\n#include</span> <span class=\"cpf\">&lt;cstdio&gt;</span><span class=\"cp\">\n#include</span> <span class=\"cpf\">&lt;string&gt;</span><span class=\"cp\">\n#include</span> <span class=\"cpf\">&lt;vector&gt;</span><span class=\"cp\">\n</span>\n<span class=\"c1\">// Shared headers living in include/. These are used both in the simulator and utilities such as the m5 tool.</span>\n<span class=\"cp\">#include</span> <span class=\"cpf\">&lt;gem5/asm/generic/m5ops.h&gt;</span><span class=\"cp\">\n</span>\n<span class=\"c1\">// M5 includes</span>\n<span class=\"cp\">#include</span> <span class=\"cpf\">\"base/misc.hh\"</span><span class=\"cp\">\n#include</span> <span class=\"cpf\">\"cpu/base.hh\"</span><span class=\"cp\">\n#include</span> <span class=\"cpf\">\"params/BaseCPU.hh\"</span><span class=\"cp\">\n#include</span> <span class=\"cpf\">\"sim/system.hh\"</span><span class=\"cp\">\n</span></code></pre></div></div>\n<h2 id=\"file-structure-and-modularity\">File structure and modularity</h2>\n<p>Source files (.cc files) should never contain extern declarations; instead, include the header file associated with the .cc file in which the object is defined. This header file should contain extern declarations for all objects exported from that .cc file. This header should also be included in the defining .cc file. The key here is that we have a single external declaration in the .hh file that the compiler will automatically check for consistency with the .cc file. (This isn\u2019t as important in C++ as it was in C, since linker name mangling will now catch these errors, but it\u2019s still a good idea.)</p>\n<p>When sufficient (i.e., when declaring only pointers or references to a class), header files should use forward class declarations instead of including full header files.</p>\n<p>Header files should never contain using namespace declarations at the top level. This forces all the names in that namespace into the global namespace of any source file including that header file, which basically completely defeats the point of using namespaces. It is OK to use using namespace declarations at the top level of a source (.cc) file since the effect is entirely local to that .cc file. It\u2019s also OK to use them in _impl.hh files, since for practical purposes these are source (not header) files despite their extension.</p>\n<h2 id=\"documenting-the-code\">Documenting the code</h2>\n<p>Each file/class/member should be documented using doxygen style comments.Doxygen allows users to quickly create documentation for our code by extracting the relavent information from the code and comments. It is able to document all the code structures including classes, namespaces, files, members, defines, etc. Most of these are quite simple to document, you only need to place a special documentation block before the declaration. The Doxygen documentation within gem5 is processed every night and the following web pages are generated: <a href=\"http://doxygen.gem5.org/release/current/index.html\">Doxygen</a></p>\n<h3 id=\"using-doxygen\">Using Doxygen</h3>\n<p>The special documentation blocks take the form of a javadoc style comment. A javadoc comment is a C style comment with 2 *\u2019s at the start, like this:</p>\n<div class=\"language-c++ highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"cm\">/**\n * ...documentation...\n */</span>\n</code></pre></div></div>\n<p>The intermediate asterisks are optional, but please use them to clearly delineate the documentation comments.</p>\n<p>The documentation within these blocks is made up of at least a brief description of the documented structure, that can be followed by a more detailed description and other documentation. The brief description is the first sentence of the comment. It ends with a period followed by white space or a new line. For example:</p>\n<div class=\"language-c++ highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"cm\">/**\n * This is the brief description. This is the start of the detailed\n * description. Detailed Description continued.\n */</span>\n</code></pre></div></div>\n<p>If you need to have a period in the brief description, follow it with a backslash followed by a space.</p>\n<div class=\"language-c++ highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"cm\">/**\n * e.g.\\ This is a brief description with an internal period.\n */</span>\n</code></pre></div></div>\n<p>Blank lines within these comments are interpreted as paragraph breaks to help you make the documentation more readble.</p>\n<h3 id=\"special-commands\">Special commands</h3>\n<p>Placing these comments before the declaration works in most cases. For files however, you need to specify that you are documenting the file. To do this you use the @file special command. To document the file that you are currently in you just need to use the command followed by your comments. To comment a separate file (we shouldn\u2019t have to do this) you can supply the name directly after the file command. There are some other special commands we will be using quite often. To document functions we will use @param and @return or @retval to document the parameters and the return value. @param takes the name of the paramter and its description. @return just describes the return value, while @retval adds a name to it. To specify pre and post conditions you can use @pre and @post.</p>\n<p>Some other useful commands are @todo and @sa. @todo allows you to place reminders of things to fix/implement and associate them with a specific class or member/function. @sa lets you place references to another piece of documentation (class, member, etc.). This can be useful to provide links to code that would be helpful in understanding the code being documented.</p>\n<h3 id=\"example-of-simple-documentation\">Example of Simple Documentation</h3>\n<p>Here is a simple header file with doxygen comments added.</p>\n<div class=\"language-c++ highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"cm\">/**\n * @file\n * Contains an example of documentation style.\n */</span>\n\n<span class=\"cp\">#include</span> <span class=\"cpf\">&lt;vector&gt;</span><span class=\"cp\">\n</span>\n<span class=\"cm\">/**\n * Adds two numbers together.\n */</span>\n<span class=\"cp\">#define DUMMY(a,b) (a+b)\n</span>\n<span class=\"cm\">/**\n * A simple class description. This class does really great things in detail.\n *\n * @todo Update to new statistics model.\n */</span>\n<span class=\"k\">class</span> <span class=\"nc\">foo</span>\n<span class=\"p\">{</span>\n  <span class=\"cm\">/** This variable stores blah, which does foo and has invariants x,y,z\n         @warning never set this to 0\n         @invariant foo\n    */</span>\n   <span class=\"kt\">int</span> <span class=\"n\">myVar</span><span class=\"p\">;</span>\n\n <span class=\"cm\">/**\n  * This function does something.\n  * @param a The number of times to do it.\n  * @param b The thing to do it to.\n  * @return The number of times it was done.\n  *\n  * @sa DUMMY\n  */</span>\n <span class=\"kt\">int</span> <span class=\"n\">bar</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"kt\">long</span> <span class=\"n\">b</span><span class=\"p\">);</span>\n\n\n <span class=\"cm\">/**\n  * A function that does bar.\n  * @retval true if there is a problem, false otherwise.\n  */</span>\n <span class=\"kt\">bool</span> <span class=\"n\">manchu</span><span class=\"p\">();</span>\n\n<span class=\"p\">};</span>\n</code></pre></div></div>\n<h3 id=\"grouping\">Grouping</h3>\n<p>Doxygen also allows for groups of classes and member (or other groups) to be declared. We can use these to create a listing of all statistics/global variables. Or just to comment about the memory hierarchy as a whole. You define a group using @defgroup and then add to it using @ingroup or @addgroup. For example:</p>\n<div class=\"language-c++ highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"cm\">/**\n * @defgroup statistics Statistics group\n */</span>\n\n<span class=\"cm\">/**\n  * @defgroup substat1 Statistitics subgroup\n  * @ingroup statistics\n  */</span>\n\n<span class=\"cm\">/**\n *  A simple class.\n */</span>\n<span class=\"k\">class</span> <span class=\"nc\">foo</span>\n<span class=\"p\">{</span>\n  <span class=\"cm\">/**\n   * Collects data about blah.\n   * @ingroup statistics\n   */</span>\n  <span class=\"n\">Stat</span> <span class=\"n\">stat1</span><span class=\"p\">;</span>\n\n  <span class=\"cm\">/**\n   * Collects data about the rate of blah.\n   * @ingroup statistics\n   */</span>\n  <span class=\"n\">Stat</span> <span class=\"n\">stat2</span><span class=\"p\">;</span>\n\n  <span class=\"cm\">/**\n   * Collects data about flotsam.\n   * @ingroup statistics\n   */</span>\n  <span class=\"n\">Stat</span> <span class=\"n\">stat3</span><span class=\"p\">;</span>\n\n  <span class=\"cm\">/**\n   * Collects data about jetsam.\n   * @ingroup substat1\n   */</span>\n  <span class=\"n\">Stat</span> <span class=\"n\">stat4</span><span class=\"p\">;</span>\n\n<span class=\"p\">};</span>\n</code></pre></div></div>\n<p>This places stat1-3 in the statistics group and stat4 in the subgroup. There is a shorthand method to place objects in groups. You can use @{ and @} to mark the start and end of group inclusion. The example above can be rewritten as:</p>\n<div class=\"language-c++ highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"cm\">/**\n * @defgroup statistics Statistics group\n */</span>\n\n<span class=\"cm\">/**\n  * @defgroup substat1 Statistitics subgroup\n  * @ingroup statistics\n  */</span>\n\n<span class=\"cm\">/**\n *  A simple class.\n */</span>\n<span class=\"k\">class</span> <span class=\"nc\">foo</span>\n<span class=\"p\">{</span>\n  <span class=\"cm\">/**\n   * @ingroup statistics\n   * @{\n   */</span>\n\n  <span class=\"cm\">/** Collects data about blah.*/</span>\n  <span class=\"n\">Stat</span> <span class=\"n\">stat1</span><span class=\"p\">;</span>\n  <span class=\"cm\">/** Collects data about the rate of blah. */</span>\n  <span class=\"n\">Stat</span> <span class=\"n\">stat2</span><span class=\"p\">;</span>\n  <span class=\"cm\">/** Collects data about flotsam.*/</span>\n  <span class=\"n\">Stat</span> <span class=\"n\">stat3</span><span class=\"p\">;</span>\n\n  <span class=\"cm\">/** @} */</span>\n\n  <span class=\"cm\">/**\n   * Collects data about jetsam.\n   * @ingroup substat1\n   */</span>\n  <span class=\"n\">Stat</span> <span class=\"n\">stat4</span><span class=\"p\">;</span>\n\n<span class=\"p\">};</span>\n</code></pre></div></div>\n<p>It remains to be seen what groups we can come up with.</p>\n<h3 id=\"other-features\">Other features</h3>\n<p>Not sure what other doxygen features we want to use.</p>\n<h2 id=\"m5-status-messages\">M5 Status Messages</h2>\n<h3 id=\"fatal-v-panic\">Fatal v. Panic</h3>\n<p>There are two error functions defined in <code class=\"language-plaintext highlighter-rouge\">src/base/logging.hh:</code> <code class=\"language-plaintext highlighter-rouge\">panic()</code> and <code class=\"language-plaintext highlighter-rouge\">fatal()</code>. While these two functions have roughly similar effects (printing an error message and terminating the simulation process), they have distinct purposes and use cases. The distinction is documented in the comments in the header file, but is repeated here for convenience because people often get confused and use the wrong one.</p>\n<ul>\n<li><code class=\"language-plaintext highlighter-rouge\">panic()</code> should be called when something happens that should never ever happen regardless of what the user does (i.e., an actual m5 bug). <code class=\"language-plaintext highlighter-rouge\">panic()</code> calls <code class=\"language-plaintext highlighter-rouge\">abort()</code> which can dump core or enter the debugger.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">fatal()</code> should be called when the simulation cannot continue due to some condition that is the user\u2019s fault (bad configuration, invalid arguments, etc.) and not a simulator bug. <code class=\"language-plaintext highlighter-rouge\">fatal()</code> calls <code class=\"language-plaintext highlighter-rouge\">exit(1)</code>, i.e., a \u201cnormal\u201d exit with an error code.</li>\n</ul>\n<p>The reasoning behind these definitions is that there\u2019s no need to panic if it\u2019s just a silly user error; we only panic if m5 itself is broken. On the other hand, it\u2019s not hard for users to make errors that are fatal, that is, errors that are serious enough that the m5 process cannot continue.</p>\n<h3 id=\"inform-warn-and-hack\">Inform, Warn and Hack</h3>\n<p>The file <code class=\"language-plaintext highlighter-rouge\">src/base/logging.hh</code> also houses 3 functions that alert the user to various conditions happening within the simulation: <code class=\"language-plaintext highlighter-rouge\">inform()</code>, <code class=\"language-plaintext highlighter-rouge\">warn()</code> and <code class=\"language-plaintext highlighter-rouge\">hack()</code>. The purpose of these functions is strictly to provide simulation status to the user so none of these functions will stop the simulator from running.</p>\n<ul>\n<li>\n<p><code class=\"language-plaintext highlighter-rouge\">inform()</code> and <code class=\"language-plaintext highlighter-rouge\">inform_once()</code> should be called for informative messages that users should know, but not worry about. <code class=\"language-plaintext highlighter-rouge\">inform_once()</code> will only display the status message generated by the <code class=\"language-plaintext highlighter-rouge\">inform_once()</code> function the first time it is called.</p>\n</li>\n<li>\n<p><code class=\"language-plaintext highlighter-rouge\">warn()</code> and <code class=\"language-plaintext highlighter-rouge\">warn_once()</code> should be called when some functionality isn\u2019t necessarily implemented correctly, but it might work well enough. The idea behind a <code class=\"language-plaintext highlighter-rouge\">warn()</code> is to inform the user that if they see some strange behavior shortly after a <code class=\"language-plaintext highlighter-rouge\">warn()</code> the description might be a good place to go looking for an error.</p>\n</li>\n<li><code class=\"language-plaintext highlighter-rouge\">hack()</code> should be called when some functionality isn\u2019t implemented nearly as well as it could or should be but for expediency or history sake hasn\u2019t been fixed.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">inform()</code> Provides status messages and normal operating messages to the console for the user to see, without any connotations of incorrect behavior.</li>\n</ul>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/debugging_and_testing/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/development/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/development/release_procedures/",
        "title": "No Title Found",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<p>Information on when releases are carried out, how the community is notified, versioning information, and how to contribute to a release can be found in our <a href=\"https://github.com/gem5/gem5/blob/stable/CONTRIBUTING.md#releases\">CONTRIBUTING.md document</a>.\nThe purpose of this document is to outline specific procedures carried out during a release.</p>\n<h2 id=\"gem5-repository\">gem5 repository</h2>\n<p>The <a href=\"https://github.com/gem5/gem5\">gem5 git repository</a> has two branches, <a href=\"https://github.com/gem5/gem5/tree/stable\">stable</a> and <a href=\"https://github.com/gem5/gem5/tree/develop\">develop</a>.\nThe HEAD of the stable branch is the latest official release of gem5 and will be tagged as such.\nUsers are not permitted to submit patches to the stable branch, and instead submit patches to the develop branch.\nAt least two weeks prior to a release a staging branch is created from the develop branch.\nThis staging branch is rigorously tested and only bug fixes or inconsequential changes (format fixes, typo fixes, etc.) are permitted to be be submitted to this branch.</p>\n<p>The staging branch is updated with the following changes:</p>\n<ul>\n<li>The <code class=\"language-plaintext highlighter-rouge\">-werror</code> is removed.\nThis ensures that gem5 compiles on newer compilers as new/stricter compiler warnings are incorporated.\nFor example: <a href=\"https://gem5-review.googlesource.com/c/public/gem5/+/43425\">https://gem5-review.googlesource.com/c/public/gem5/+/43425</a>.</li>\n<li>The <a href=\"https://github.com/gem5/gem5/blob/v21.0.1.0/src/Doxyfile#34\">Doxygen \u201cProject Number\u201d field</a> is updated to the version ID.\nFor example: <a href=\"https://gem5-review.googlesource.com/c/public/gem5/+/47079\">https://gem5-review.googlesource.com/c/public/gem5/+/47079</a>.</li>\n<li>The <a href=\"https://github.com/gem5/gem5/blob/stable/src/base/version.cc\"><code class=\"language-plaintext highlighter-rouge\">src/base/version.cc</code></a> file is updated to state the version ID.\nFor example: <a href=\"https://gem5-review.googlesource.com/c/public/gem5/+/47079\">https://gem5-review.googlesource.com/c/public/gem5/+/47079</a>.</li>\n<li>The <a href=\"https://github.com/gem5/gem5/blob/stable/ext/testlib/configuration.py\"><code class=\"language-plaintext highlighter-rouge\">ext/testlib/configuration.py</code></a>  file\u2019s <code class=\"language-plaintext highlighter-rouge\">default.resource_url</code> field is updated to point towards the correct Google Cloud release bucket (see <a href=\"#gem5-resources-google-cloud-bucket\">the Cloud Bucket release procedures</a>).\nFor example: <a href=\"https://gem5-review.googlesource.com/c/public/gem5/+/44725\">https://gem5-review.googlesource.com/c/public/gem5/+/44725</a>.</li>\n<li>The Resource downloader, <code class=\"language-plaintext highlighter-rouge\">src/python/gem5/resources/downloader.py</code>, has a function <code class=\"language-plaintext highlighter-rouge\">def _resources_json_version_required()</code>. This must be updated to the correct version of the <code class=\"language-plaintext highlighter-rouge\">resources.json</code> file to use (see the <a href=\"#gem5-resources-repository\">gem5 resources repository release procedures</a>) for more information on this).</li>\n<li>The <code class=\"language-plaintext highlighter-rouge\">tests/weekly.sh</code>, <code class=\"language-plaintext highlighter-rouge\">tests/nightly.sh</code>, <code class=\"language-plaintext highlighter-rouge\">tests/compiler-tests.sh</code>, and <code class=\"language-plaintext highlighter-rouge\">tests/jenkins/presubmit.sh</code> should be updated ensure they remain stable across different gem5 releases. This is achieved by:\n    <ol>\n<li>Fix the docker pulls images by appending the version (example <a href=\"https://gem5-review.googlesource.com/c/public/gem5/+/54470\">here</a>. This will be done after following the <a href=\"#the-docker-images\">docker image release procedures</a>.</li>\n<li>Ensure the download links are downloading from the correct Google Cloud bucket for the release version.</li>\n</ol>\n</li>\n<li>Hardcode the <code class=\"language-plaintext highlighter-rouge\">rocm_patches/ROCclr.patch</code> download link in <code class=\"language-plaintext highlighter-rouge\">util/dockerfiles/gcn-gpu</code> to the correct Google bucket.</li>\n<li>Update the <code class=\"language-plaintext highlighter-rouge\">ext/sst/README.md</code> file for the current version. This simply means updating the download links.\nSee <a href=\"https://gem5-review.googlesource.com/c/public/gem5/+/54703\">here</a> for an example of how this is done.</li>\n</ul>\n<p>When the staging branch is confirmed to be in a satisfactory state, it will be merged into both develop and stable.\nThere is then two additional actions:</p>\n<ol>\n<li>The above changes to the staging branch are reverted on the develop branch.</li>\n<li>The stable branch is tagged with the latest release version id at its HEAD.\n    <ul>\n<li>For example, <code class=\"language-plaintext highlighter-rouge\">git tag -a v21.1.0.0 -m \"gem5 version 21.1.0.0\" &amp;&amp; git push --tags</code></li>\n</ul>\n</li>\n</ol>\n<p>The <a href=\"https://github.com/gem5/gem5/blob/stable/RELEASE-NOTES.md\">RELEASE-NOTES.md</a> should be updated to notify the community of the major changes in this release.\nThis can be done on the develop branch prior to the creation of the staging branch, or on the staging branch.\nIt has been customary to create a blog post on <a href=\"http://www.gem5.org\">http://www.gem5.org</a> outlining the release.\nWhile appreciated, it is not mandatory.</p>\n<p><strong>Important notes:</strong></p>\n<ul>\n<li>You must a member of the \u201cProject Owners\u201d or \u201cgoogle/gem5-admins@googlegroups.com\u201d Gerrit permission groups to push to the stable branch.\nPlease contact Bobby R. Bruce (bbruce@ucdavis.edu) for help pushing to the gem5 stable branch.</li>\n</ul>\n<h2 id=\"gem5-resources-repository\">gem5 resources repository</h2>\n<p>The <a href=\"https://github.com/gem5/gem5-resources\">gem5 resources git repository</a> has two branches, <a href=\"https://github.com/gem5/gem5-resources/tree/stable\">stable</a> and <a href=\"https://github.com/gem5/gem5-resources/tree/develop\">develop</a>.\nThe HEAD of the stable branch contains the source for resources with known compatibility to the most recently release of gem5.\nE.g., if the current release of gem5 is v22.3, the head of gem5 resources repository will contain the source for resources with known compatibility with v22.3.\nThe develop branch contains sources compatible with the develop branch of the gem5 repository.\nUnlike the gem5 repo, changes to the gem5 resources repo may be submitted to the stable branch permitting the changes are compatible with the latest release of gem5.</p>\n<p>As with the gem5 repository, a staging branch is created at least two weeks prior to a release.\nThe purpose of this staging branch is identical to that of the main gem5 repository, and it is merged into both the stable and develop branches upon a gem5 release.\nPrior to this the following changes should be applied to the staging branch:</p>\n<ul>\n<li>A new Google Cloud Bucket directory should be created for that version (see the <a href=\"#gem5-resources-google-cloud-bucket\">the Cloud Bucket release procedures</a>), and all the resources from the staging branch must match that found within that Google Cloud Bucket directory (i.e., the compiled resources within the bucket are built from the sources in the staging branch).</li>\n<li>URL download links in the resources repo should be updated to point towards the correct Google Cloud Bucket directory.</li>\n<li>The <code class=\"language-plaintext highlighter-rouge\">resources.json</code> file, found in the root of the repository, must be updated for the current release.\n<a href=\"https://gem5-review.googlesource.com/c/public/gem5-resources/+/54403\">This patch</a> shows an example of doing this.\nThe <code class=\"language-plaintext highlighter-rouge\">version</code> field must be updated to the version that matches that in the <code class=\"language-plaintext highlighter-rouge\">src/python/gem5/resources/downloader.py</code> file.\nThe <code class=\"language-plaintext highlighter-rouge\">previous-version</code> list must be updated to support all versions prior, inclusive of develop.\nEach previous version must map to a file that may be downloaded.</li>\n<li>The <code class=\"language-plaintext highlighter-rouge\">resources.json</code> <code class=\"language-plaintext highlighter-rouge\">url_base</code> field must be updated to the correct directory from the Google Cloud Bucket.</li>\n</ul>\n<p>When merged into the develop branch, the URL download links should reverted back to <code class=\"language-plaintext highlighter-rouge\">http://dist.gem5.org/dist/develop</code>.</p>\n<p>Immediately prior to merging, the stable branch is tagged with the previous release version ID.\nFor example, if the staging branch is for <code class=\"language-plaintext highlighter-rouge\">v22.2,</code> and the content on the stable branch is for <code class=\"language-plaintext highlighter-rouge\">v22.1</code>, the stable branch will be tagged as <code class=\"language-plaintext highlighter-rouge\">v22.1</code> immediately prior to the merge.\nThis is because we want users to be able to revert the gem5 resources to get sources compatible with previous gem5 releases.\nTherefore, if a user wished to get the resources sources compatible with the the v20.1 release, they\u2019d checkout the revision tagged as <code class=\"language-plaintext highlighter-rouge\">v20.1</code> on the stable branch.</p>\n<h3 id=\"gem5-resources-google-cloud-bucket\">gem5 resources Google Cloud Bucket</h3>\n<p>The built gem5 resources are found within the gem5 Google Cloud Bucket.</p>\n<p>The <a href=\"#gem5-resources-repository\">gem5 resources git repository</a> contains sources of the gem5 resources, these are then compiled and stored in the Google Cloud Bucket.\nThe gem5 resources repo <a href=\"https://github.com/gem5/gem5-resources/blob/stable/README.md\">README.md</a> contains links to download the built resources from the Google Cloud Bucket.</p>\n<p>The Google Cloud Bucket, like the gem5 resources repository, is versioned.\nEach resource is stored under <code class=\"language-plaintext highlighter-rouge\">http://dist.gem5.org/dist/{major version}</code>.\nE.g., the PARSEC Benchmark image, for version 20.1, is stored at <a href=\"http://dist.gem5.org/dist/v20-1/images/x86/ubuntu-18-04/parsec.img.gz\">http://dist.gem5.org/dist/v20-1/images/x86/ubuntu-18-04/parsec.img.gz</a>, while the image for version 21.0 is stored at <a href=\"http://dist.gem5.org/dist/v21-0/images/x86/ubuntu-18-04/parsec.img.gz\">http://dist.gem5.org/dist/v21-0/images/x86/ubuntu-18-04/parsec.img.gz</a> (note the <code class=\"language-plaintext highlighter-rouge\">.</code> substitution with <code class=\"language-plaintext highlighter-rouge\">-</code> for the version in the URL).\nThe build for the develop branch is found under <a href=\"http://dist.gem5.org/dist/develop\">http://dist.gem5.org/dist/develop</a>.</p>\n<p>As the gem5 resources staging branch is from develop, the easiest way to create a copy of the develop bucket directory:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>gsutil -m cp -r gs://dist.gem5.org/dist/develop gsutil -m cp -r gs://dist.gem5.org/dist/{major version}\n</code></pre></div></div>\n<p>The develop bucket <em>should</em> be in-sync with the changes on develop.\nThough this is worth checking.\nNaturally, any changes on the staging branch must be reflected in the Cloud Bucket accordingly.</p>\n<p><strong>Important notes:</strong></p>\n<ul>\n<li>Due to legacy reason <a href=\"http://dist.gem5.org/dist/current\">http://dist.gem5.org/dist/current</a> is used to store legacy resources related to v19 of gem5.</li>\n<li>Special permissions are needed to push to the Google Cloud Bucket.\nPlease contact Bobby R. Bruce (bbruce@ucdavis.edu) for help pushing resources to the bucket.</li>\n</ul>\n<h2 id=\"the-docker-images\">The docker images</h2>\n<p>Currently hosted in <a href=\"https://github.com/gem5/gem5/tree/stable/util/dockerfiles/\"><code class=\"language-plaintext highlighter-rouge\">util/dockerfiles</code></a> in the gem5 repository, we have a series of Dockerfiles which can be built to produce environments in which gem5 can be built and run.\nThese images are mostly used for testing purposes.\nThe <a href=\"https://github.com/gem5/gem5/tree/stable/util/dockerfiles/ubuntu-20.04_all-dependencies/\"><code class=\"language-plaintext highlighter-rouge\">ubuntu-20.04_all-dependencies</code></a> Dockerfile is the one most suitable for users who wish to build and execute gem5 in a supported environment.</p>\n<p>We provide pre-built Docker images hosted at <ghcr.io> under \"gem5\".\nAll the Dockerfiles found in `util/dockerfiles` have been built and stored there.\nFor instance, `ubuntu-20.04_all-dependencies` can be found at &lt;ghcr.io/gem5/ubuntu-20.04_all-dependencies&gt; (and can thereby be obtained with `docker pull ghcr.io/gem5/ubuntu-20.04_all-dependencies`).</ghcr.io></p>\n<p>The Docker images are continually built from the Dockerfiles found on the develop branch.\nTherefore the docker image with the <code class=\"language-plaintext highlighter-rouge\">latest</code> tag is that in-sync with the Dockerfiles found on the gem5 repo\u2019s develop branch.\nUpon a release of the latest version of gem5, when the staging branches are merged into develop, the built images hosted at <ghcr.io> will be tagged with the gem5 version number.\nSo, upon the release of `v23.2`, the images will be tagged with `v23-2`\nThe purpose of this is so users of an older versions of gem5, may obtain images compatible with their release.\nI.e., a user of gem5 `v21.0` may obtain the `v21.0` version of the `ubuntu-20.04_all-dependencies` with `docker pull ghcr.io/gem5/ubuntu-20.04_all-dependencies:v21-0`.</ghcr.io></p>\n<p><strong>Important notes:</strong></p>\n<ul>\n<li>If changes to the Dockerfile are done on the staging branch, then these changes will need to be pushed to <ghcr.io> manually.</ghcr.io></li>\n<li>Special permissions are needed to push to the <ghcr.io>.\nPlease contact Bobby R. Bruce (bbruce@ucdavis.edu) for help pushing images.</ghcr.io></li>\n<li>It is a future goal of ours to move <a href=\"https://gem5.atlassian.net/browse/GEM5-1044\">the Dockerfiles from <code class=\"language-plaintext highlighter-rouge\">util/dockerfiles</code> to gem5-resources</a>.</li>\n</ul>\n<h2 id=\"gem5-website-repository\">gem5 website repository</h2>\n<p>The <a href=\"https://github.com/gem5/website/\">gem5 website git repository</a> has two branches, <a href=\"https://github.com/gem5/website/tree/stable\">stable</a> and <a href=\"https://github.com/gem5/website/tree/develop\">develop</a>.\nThe stable branch is what is built and viewable at <a href=\"http://www.gem5.org\">http://www.gem5.org</a>, and is up-to-date with the current gem5 release.\nE.g., if the current release of gem5, on its stable branch, is <code class=\"language-plaintext highlighter-rouge\">v20.1</code>, the documentation on the stable branch will related to <code class=\"language-plaintext highlighter-rouge\">v20.1</code>.\nThe develop branch contains the state of the website for the upcoming gem5 release.\nE.g., it contains the changes needed to apply to the website when the new version of gem5 is released.</p>\n<p>As the stable branch may be updated at any time (as long as those updates relate to the current release), stable is merged periodically into develop.\nAs with the gem5 resources, and the main gem5 repository, a staging branch is created from the develop branch at least two weeks prior to a gem5 release.</p>\n<p>The staging branch needs updated so that the documentation is up-to-date with the upcoming release.\nOf particular note, references to gem5 resources, hosted on the Google Cloud bucket should be updated.\nFor example, links to, say <a href=\"http://dist.gem5.org/dist/v21-0/images/x86/ubuntu-18-04/parsec.img.gz\">http://dist.gem5.org/dist/v21-0/images/x86/ubuntu-18-04/parsec.img.gz</a>, would need to be updated to <a href=\"http://dist.gem5.org/dist/v21-1/images/x86/ubuntu-18-04/parsec.img.gz\">http://dist.gem5.org/dist/v21-1/images/x86/ubuntu-18-04/parsec.img.gz</a> when transitioning from <code class=\"language-plaintext highlighter-rouge\">v21-0</code> to <code class=\"language-plaintext highlighter-rouge\">v21-1</code>.</p>\n<p>Upon a new major gem5 release, the develop branch is merged into stable.\nThe website repo is tagged with the preceding version prior to merging the staging branch into stable.\nThis is identical to the gem5 resources repository.\nFor example, if the current release is v21.1.0.4 and the next release is v21.2.0.0, immediately prior to the release of v21.2.0.0 the stable branch will be tagged as v21.1.0.4 then the develop branch merged into stable.\nThis ensures that a user may revert the website back to its state as of a previous release, if needed.</p>\n<h2 id=\"gem5-doxygen\">gem5 Doxygen</h2>\n<p>The <a href=\"http://doxygen.gem5.org\">gem5 Doxygen website</a> is created by the <a href=\"https://www.doxygen.nl/index.html\">Doxygen documentation generator</a>.\nIt can be created in gem5 repo as follows:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>cd src\ndoxygen\n</code></pre></div></div>\n<p>The html will be output to <code class=\"language-plaintext highlighter-rouge\">src/doxygen/html</code>.</p>\n<p>The gem5 Doxygen website is hosted as a static webpage in a Google Cloud Bucket.\nThe directory structure is as follows:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>doxygen.gem5.org/\n    - develop/              # Contains the Doxygen for the gem5 develop branch.\n        - index.html\n        ...\n    - release/              # An archive of the Doxygen for every gem5 release.\n        - current/          # Doxygen for the current gem5 release.\n            - index.html\n            ...\n        - v21-0-1-0/\n            - index.html\n            ...\n        - v21-0-0-0/\n            - index.html\n            ...\n        - v20-1-0-5/\n            - index.html\n            ...\n        ...\n    - index.html           # Redirects to release/current/index.html.\n</code></pre></div></div>\n<p>Therefore, the Doxygen for the latest release can be obtained at <a href=\"http://doxygen.gem5.org/\">http://doxygen.gem5.org/</a>, for the develop branch at <a href=\"http://doxygen.gem5.org/develop\">http://doxygen.gem5.org/develop</a>, and for past releases at <a href=\"http://doxygen.gem5.org/release/{version}\">http://doxygen.gem5.org/release/{version}</a> (e.g., <a href=\"http://doxygen.gem5.org/release/v20-1-0-5\">http://doxygen.gem5.org/release/v20-1-0-5</a>).</p>\n<p>After a gem5 release the following code is run on the gem5 repository stable branch</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>cd src\ndoxygen\n\ngsutil -m rm gs://doxygen.gem5.org/release/current/*\ngsutil -m cp -r doxygen/html/* gs://doxygen.gem5.org/release/current/\ngsutil -m cp -r gs://doxygen.gem5.org/release/current gs://doxygen.gem5.org/release/{version id}\n</code></pre></div></div>\n<p>The final step is to add a link to this gem5 Doxygen version on the website, via the <a href=\"https://github.com/gem5/website/blob/stable/_data/documentation.yml\"><code class=\"language-plaintext highlighter-rouge\">_data/documentation.yml</code> file</a>.\nFor example: <a href=\"https://gem5-review.googlesource.com/c/public/gem5-website/+/43385\">https://gem5-review.googlesource.com/c/public/gem5-website/+/43385</a>.</p>\n<p><strong>Important Notes:</strong></p>\n<ul>\n<li>The gem5 develop branch Doxygen website is updated daily via an automated build process.\nThe footer on the Doxygen website will state when the page was generated.</li>\n<li>Special permissions are needed to push to the Google Cloud Bucket.\nPlease contact Bobby R. Bruce (bbruce@ucdavis.edu) for help pushing to the Google Cloud Bucket.</li>\n</ul>\n<h2 id=\"minor-and-hotfix-releases\">Minor and Hotfix releases</h2>\n<p>The previous sections have focus on major gem5 releases.\nMinor and hotfix releases of gem5 should never change any API or features in a major way.\nAs such, for minor and hotfix releases of gem5 we only carry out the release procedures for the <a href=\"#gem5-repository\">gem5 code repository</a> and the <a href=\"#gem5-doxygen\">gem5 Doxygen website</a>.\nThe latter may be unnecessary depending on the change/changes, but this is a low cost endeavor.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/development/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/fullsystem/building_android_m\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/fullsystem/building_android_m",
        "title": "Building Android Marshmallow",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"building-android-marshmallow\">Building Android Marshmallow</h1>\n<p>This guide gives detailed step-by-step instructions on building an Android Marshmallow image along with a working kernel and .dtb file that work with gem5.</p>\n<h2 id=\"overview\">Overview</h2>\n<p>To successfully run Android in gem5, an image, a compatible kernel and a device tree blob.dtb file configured for the simulator are necessary. This guide shows how to build Android Marshmallow 32bit version using a 3.14 kernel with Mali support. An extra section will be added in the future on how to build the 4.4 kernel with Mali.</p>\n<h2 id=\"pre-requisites\">Pre-requisites</h2>\n<p>This guide assumes a 64-bit system running 14.04 LTS Ubuntu. Before starting it is important first to set up our system correctly. To do this the following packages need to be installed through shell.</p>\n<p><strong>Tip: Always check for the up-to-date prerequisites at the Android build page.</strong></p>\n<p>Update and install all the dependencies. This can be done with the following commands:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>sudo apt-get update\n\nsudo apt-get install openjdk-7-jdk git-core gnupg flex bison gperf build-essential zip curl zlib1g-dev gcc-multilib g++-multilib libc6-dev-i386 lib32ncurses5-dev x11proto-core-dev libx11-dev lib32z-dev ccache libgl1-mesa-dev libxml2-utils xsltproc unzip\n</code></pre></div></div>\n<p>Also, make sure to have repo correctly installed <a href=\"https://source.android.com/source/downloading.html#installing-repo\">(instructions here)</a>.</p>\n<p>Ensure that the default JDK is OpenJDK 1.7:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>javac -version\n</code></pre></div></div>\n<p>To cross-compile the kernel (32bit) and for the device tree we will need the following packages to be installed:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>sudo apt-get install gcc-arm-linux-gnueabihf device-tree-compiler\n</code></pre></div></div>\n<p>Before getting started, as a final step make sure to have the gem5 binaries and busybox for 32-bit ARM.</p>\n<p>For the gem5 binaries just do the following starting from your gem5 directory:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>cd util/m5\nmake -f Makefile.arm\ncd ../term\nmake\ncd ../../system/arm/simple_bootloader/\nmake\n</code></pre></div></div>\n<p>For busybox you can find the guide <a href=\"http://wiki.beyondlogic.org/index.php?title=Cross_Compiling_BusyBox_for_ARM\">here</a>.</p>\n<h2 id=\"building-android\">Building Android</h2>\n<p>We build Android Marshmallow using an AOSP running build based on the release for the Pixel C. The AOSP provides <a href=\"https://source.android.com/source/build-numbers.html#source-code-tags-and-builds\">other builds</a>, which are untested with this guide.</p>\n<p><strong>Tip: Synching with repo will take a long time. Use the -jN flag to speed up the make process, where N is the number of parallel jobs to run.</strong></p>\n<p>Make a directory and pull the Android repository:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>mkdir android\ncd android\nrepo init --depth=1 -u https://android.googlesource.com/platform/manifest -b android-6.0.1_r63\nrepo sync -c -jN\n</code></pre></div></div>\n<p>Before you start the AOSP build, you will need to make one change to the build system to enable building libion.so, which is used by the Mali driver. Edit the file <code class=\"language-plaintext highlighter-rouge\">aosp/system/core/libion/Android.mk</code> to change <code class=\"language-plaintext highlighter-rouge\">LOCAL_MODULE_TAGS</code> for libion from \u2018optional\u2019 to \u2018debug\u2019. Here is the output of <code class=\"language-plaintext highlighter-rouge\">repo diff</code>:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  --- a/system/core/libion/Android.mk\n  +++ b/system/core/libion/Android.mk\n  @@ -3,7 +3,7 @@ LOCAL_PATH := $(call my-dir)\n  include $(CLEAR_VARS)\n  LOCAL_SRC_FILES := ion.c\n  LOCAL_MODULE := libion\n  -LOCAL_MODULE_TAGS := optional\n  +LOCAL_MODULE_TAGS := debug\n  LOCAL_SHARED_LIBRARIES := liblog\n  LOCAL_C_INCLUDES := $(LOCAL_PATH)/include $(LOCAL_PATH)/kernel-headers\n  LOCAL_EXPORT_C_INCLUDE_DIRS := $(LOCAL_PATH)/include\n  $(LOCAL_PATH)/kernel-headers\n</code></pre></div></div>\n<p>Source the environment setup and build Android:</p>\n<p><strong>Tip: For root access and \u201cdebuggability\u201d [sic] we choose userdebug. Build can be done in different modes as seen</strong> <a href=\"https://source.android.com/source/building.html#choose-a-target\">here</a>.\n<strong>Tip: Making Android will take a long time. Use the -jN flag to speed up the make process, where N is the number of parallel jobs to run.</strong></p>\n<p><strong><em>Make sure to do this in a bash shell.</em></strong></p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>source build/envsetup.sh\nlunch aosp_arm-userdebug\nmake -jN\n</code></pre></div></div>\n<h2 id=\"creating-an-android-image\">Creating an Android image</h2>\n<p>After a successful build, we create an image of Android and add the init files and binaries that configure the system for gem5. The following example creates a 3GB image.</p>\n<p><strong>Tip: If you want to add applications or data, make the image large enough to fit the build and anything else that is meant to be written into it.</strong></p>\n<p>Create an empty image to flash the Android build and attach the image to a loopback device:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>dd if=/dev/zero of=myimage.img bs=1M count=2560\nsudo losetup /dev/loop0 myimage.img\n</code></pre></div></div>\n<p>We now need to create three partitions: AndroidRoot (1.5GB), AndroidData (1GB), and AndroidCache (512MB).</p>\n<p>First, partition the device:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>sudo fdisk /dev/loop0\n</code></pre></div></div>\n<p>Update the partition table:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>sudo partprobe /dev/loop0\n</code></pre></div></div>\n<p>Name the partitions / Define filesystem as ext4:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>sudo mkfs.ext4 -L AndroidRoot /dev/loop0p1\nsudo mkfs.ext4 -L AndroidData /dev/loop0p\nsudo mkfs.ext4 -L AndroidCache /dev/loop0p3\n</code></pre></div></div>\n<p>Mount the Root partition to a directory:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>sudo mkdir -p /mnt/androidRoot\nsudo mount /dev/loop0p1 /mnt/androidRoot\n</code></pre></div></div>\n<p>Load the build to the partition:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>cd /mnt/androidRoot\nsudo zcat &lt;path/to/build/android&gt;/out/target/product/generic/ramdisk.img | sudo cpio -i\nsudo mkdir cache\nsudo mkdir /mnt/tmp\nsudo mount -oro,loop &lt;path/to/build/android&gt;/out/target/product/generic/system.img /mnt/tmp\nsudo cp -a /mnt/tmp/* system/\nsudo umount /mnt/tmp\n</code></pre></div></div>\n<p>Download and unpack the <a href=\"http://dist.gem5.org/dist/current/arm/kitkat-overlay.tar.bz2\">overlays</a> that are necessary from the <a href=\"http://old.gem5.org/Android_KitKat.html\" title=\"wikilink\">gem5 Android KitKat page</a> and make the following changes to the <code class=\"language-plaintext highlighter-rouge\">init.gem5.rc</code> file. Here is the output of <code class=\"language-plaintext highlighter-rouge\">repo diff</code>:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  --- /kitkat_overlay/init.gem5.rc\n  +++ /m_overlay/init.gem5.rc\n  @@ -1,21 +1,13 @@\n  +\n   on early-init\n       mount debugfs debugfs /sys/kernel/debug\n  \n   on init\n  -    export LD_LIBRARY_PATH ${LD_LIBRARY_PATH}:/vendor/lib/egl\n  -\n  -    # See storage config details at http://source.android.com/tech/storage/\n  -    mkdir /mnt/media_rw/sdcard 0700 media_rw media_rw\n  -    mkdir /storage/sdcard 0700 root root\n  +    # Support legacy paths\n  +    symlink /sdcard /mnt/sdcard\n       chmod 0666 /dev/mali0\n       chmod 0666 /dev/ion\n  -\n  -    export EXTERNAL_STORAGE /storage/sdcard\n  -\n  -    # Support legacy paths\n  -    symlink /storage/sdcard /sdcard\n  -    symlink /storage/sdcard /mnt/sdcard\n  \n   on fs\n       mount_all /fstab.gem5\n  @@ -60,7 +52,6 @@\n       group root\n       oneshot\n  \n  -# fusewrapped external sdcard daemon running as media_rw (1023)\n  -service fuse_sdcard /system/bin/sdcard -u 1023 -g 1023 -d\n  /mnt/media_rw/sdcard /storage/sdcard\n  +service fingerprintd /system/bin/fingerprintd\n       class late_start\n  -    disabled\n  +    user system\n</code></pre></div></div>\n<p>Add the Android overlays and configure their permissions:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>sudo cp -r &lt;path/to/android/overlays&gt;/* /mnt/androidRoot/\nsudo chmod ug+x /mnt/androidRoot/init.gem5.rc\n/mnt/androidRoot/gem5/postboot.sh\n</code></pre></div></div>\n<p>Add the m5 and busybox binaries under the sbin directory and make them executable:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>sudo cp &lt;path/to/gem5&gt;/util/m5/m5 /mnt/androidRoot/sbin\nsudo cp &lt;path/to/busybox&gt;/busybox /mnt/androidRoot/sbin\nsudo chmod a+x /mnt/androidRoot/sbin/busybox /mnt/androidRoot/sbin/m5\n</code></pre></div></div>\n<p>Make the directories readable and searchable:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>sudo chmod a+rx /mnt/androidRoot/sbin/ /mnt/androidRoot/gem5/\n</code></pre></div></div>\n<p>Remove the boot animation:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>sudo rm /mnt/androidRoot/system/bin/bootanimation\n</code></pre></div></div>\n<p>Download and unpack the Mali drivers, for gem5 Android 4.4, from <a href=\"https://developer.arm.com/downloads/-/mali-drivers/midgard-kernel\">here</a>. Then, make the directories for the drivers and copy them:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>sudo mkdir -p /mnt/androidRoot/system/vendor/lib/egl\nsudo mkdir -p /mnt/androidRoot/system/vendor/lib/hw\nsudo cp &lt;path/to/userspace/Mali/drivers&gt;/lib/egl/libGLES_mali.so /mnt/androidRoot/system/vendor/lib/egl\nsudo cp &lt;path/to/userspace/Mali/drivers&gt;/lib/hw/gralloc.default.so /mnt/androidRoot/system/vendor/lib/hw\n</code></pre></div></div>\n<p>Change the permissions</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>sudo chmod 0755 /mnt/androidRoot/system/vendor/lib/hw\nsudo chmod 0755 /mnt/androidRoot/system/vendor/lib/egl\nsudo chmod 0644 /mnt/androidRoot/system/vendor/lib/egl/libGLES_mali.so\nsudo chmod 0644 /mnt/androidRoot/system/vendor/lib/hw/gralloc.default.so\n</code></pre></div></div>\n<p>Unmount and remove loopback device:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>cd /..\nsudo umount /mnt/androidRoot\nsudo losetup -d /dev/loop0\n</code></pre></div></div>\n<h2 id=\"building-the-kernel-314\">Building the Kernel (3.14)</h2>\n<p>After successfully setting up the image, a compatible kernel needs to be built and a .dtb file generated.</p>\n<p>Clone the repository containing the gem5 specific kernel:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>git clone -b ll_20140416.0-gem5 https://github.com/gem5/linux-arm-gem5.git\n</code></pre></div></div>\n<p>Make the following changes to the kernel gem5 config file at <code class=\"language-plaintext highlighter-rouge\">&lt;path/to/kernel/repo&gt;/arch/arm/configs/vexpress_gem5_defconfig</code>. Here is the output of <code class=\"language-plaintext highlighter-rouge\">repo diff</code>:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  --- a/arch/arm/configs/vexpress_gem5_defconfig\n  +++ b/arch/arm/configs/vexpress_gem5_defconfig\n  @@ -200,4 +200,15 @@ CONFIG_EARLY_PRINTK=y\n  CONFIG_DEBUG_PREEMPT=n\n  # CONFIG_CRYPTO_ANSI_CPRNG is not set\n  # CONFIG_CRYPTO_HW is not set\n  +CONFIG_MALI_MIDGARD=y\n  +CONFIG_MALI_MIDGARD_DEBUG_SYS=y\n  +CONFIG_ION=y\n  +CONFIG_ION_DUMMY=y\n  CONFIG_BINARY_PRINTF=y\n  +CONFIG_NET_9P=y\n  +CONFIG_NET_9P_VIRTIO=y\n  +CONFIG_9P_FS=y\n  +CONFIG_9P_FS_POSIX_ACL=y\n  +CONFIG_9P_FS_SECURITY=y\n  +CONFIG_VIRTIO_BLK=y\n  +CONFIG_VMSPLIT_3G=y\n  +CONFIG_DNOTIFY=y\n  +CONFIG_FUSE_FS=y\n</code></pre></div></div>\n<p>For the device tree, add the Mali GPU device and increase the memory to 1.8GB. Do this with the following changes at <code class=\"language-plaintext highlighter-rouge\">&lt;path/to/kernel/repo&gt;/arch/arm/boot/dts/vexpress-v2p-ca15-tc1-gem5.dts.</code> Here is the output of <code class=\"language-plaintext highlighter-rouge\">repo diff</code>:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  --- a/arch/arm/boot/dts/vexpress-v2p-ca15-tc1-gem5.dts\n  +++ b/arch/arm/boot/dts/vexpress-v2p-ca15-tc1-gem5.dts\n  @@ -45,7 +45,7 @@\n  \n           memory@80000000 {\n                   device_type = \"memory\";\n  -                reg = &lt;0 0x80000000 0 0x40000000&gt;;\n  +                reg = &lt;0 0x80000000 0 0x74000000&gt;;\n           };\n  \n          hdlcd@2b000000 {\n  @@ -59,6 +59,14 @@\n  //                mode = \"3840x2160MR-16@60\"; // UHD4K mode string\n                    framebuffer = &lt;0 0x8f000000 0 0x01000000&gt;;\n            };\n  +\n  +    gpu@0x2d000000 {\n  +        compatible = \"arm,mali-midgard\";\n  +        reg = &lt;0 0x2b400000 0 0x4000&gt;;\n  +        interrupts = &lt;0 86 4&gt;, &lt;0 87 4&gt;, &lt;0 88 4&gt;;\n  +        interrupt-names = \"JOB\", \"MMU\", \"GPU\";\n  +    };\n  +\n  /*\n          memory-controller@2b0a0000 {\n                    compatible = \"arm,pl341\", \"arm,primecell\";\n</code></pre></div></div>\n<p>Download and unpack the userspace matching Mali kernel drivers for gem5 from [http://malideveloper.arm.com/resources/drivers/open-source-mali-midgard-gpu-kernel-drivers/ here]. Copy them to the gpu driver directory:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>cp -r &lt;path/to/kernelspace/Mali/drivers&gt;/driver/product/kernel/drivers/gpu/arm/ drivers/gpu\n</code></pre></div></div>\n<p>Change the following in <code class=\"language-plaintext highlighter-rouge\">&lt;path/to/kernelspace/Mali/drivers&gt;/drivers/video/Kconfig</code> and <code class=\"language-plaintext highlighter-rouge\">&lt;path/to/kernelspace/Mali/drivers&gt;/drivers/gpu/Makefile</code> based on the following diffs:</p>\n<p>Here is the output of the Kconfig <code class=\"language-plaintext highlighter-rouge\">repo diff</code>:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  --- a/drivers/video/Kconfig\n  +++ b/drivers/video/Kconfig\n  @@ -23,6 +23,8 @@ source \"drivers/gpu/host1x/Kconfig\"\n  \n  source \"drivers/gpu/drm/Kconfig\"\n  \n  +source \"drivers/gpu/arm/Kconfig\"\n  +\n   config VGASTATE\n          tristate\n          default n\n</code></pre></div></div>\n<p>Here is the output of the drivers/gpu/Makefile <code class=\"language-plaintext highlighter-rouge\">repo diff</code>:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  --- a/drivers/gpu/Makefile\n  +++ b/drivers/gpu/Makefile\n  @@ -1,2 +1,2 @@\n  -obj-y                += drm/ vga/\n  +obj-y                += drm/ vga/ arm/\n</code></pre></div></div>\n<p>Finally, build the kernel and the .dtb file.</p>\n<p><strong>Tip: Use the -jN flag to speed up the make process, where N is the number of parallel jobs to run.</strong></p>\n<p>Build the kernel:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>make CROSS_COMPILE=arm-linux-gnueabihf- ARCH=arm vexpress_gem5_defconfig\nmake CROSS_COMPILE=arm-linux-gnueabihf- ARCH=arm vmlinux -jN\n</code></pre></div></div>\n<p>Create the .dtb file:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>dtc -I dts -O dtb arch/arm/boot/dts/vexpress-v2p-ca15-tc1-gem5.dts &gt; vexpress-v2p-ca15-tc1-gem5.dtb\n</code></pre></div></div>\n<h2 id=\"testing-the-build\">Testing the build</h2>\n<p>Make the following changes to example/fs.py. Here is the output <code class=\"language-plaintext highlighter-rouge\">repo diff</code>:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  --- a/configs/example/fs.py Thu Jun 02 20:34:39 2016 +0100\n  +++ b/configs/example/fs.py Fri Jun 10 15:37:29 2016 -0700\n  @@ -144,6 +144,13 @@\n       if is_kvm_cpu(TestCPUClass) or is_kvm_cpu(FutureClass):\n           test_sys.vm = KvmVM()\n  \n  +    test_sys.gpu = NoMaliGpu(\n  +        gpu_type=\"T760\",\n  +        ver_maj=0, ver_min=0, ver_status=1,\n  +        int_job=118, int_mmu=119, int_gpu=120,\n  +        pio_addr=0x2b400000,\n  +        pio=test_sys.membus.master)\n  +\n      if options.ruby:\n          # Check for timing mode because ruby does not support atomic accesses\n          if not (options.cpu_type == \"detailed\" or options.cpu_type == \"timing\"):\n</code></pre></div></div>\n<p>And the changes to FS config to either enable or disable software rendering.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  --- a/configs/common/FSConfig.py Thu Jun 02 20:34:39 2016 +0100\n  +++ b/configs/common/FSConfig.py Thu Jun 16 10:23:44 2016 -0700\n  @@ -345,7 +345,7 @@\n  \n             # release-specific tweaks\n             if 'kitkat' in mdesc.os_type():\n  -                cmdline += \" androidboot.hardware=gem5 qemu=1 qemu.gles=0 \" + \\\n  +                cmdline += \" androidboot.hardware=gem5 qemu=1 qemu.gles=1 \" + \\\n                            \"android.bootanim=0\"\n  \n         self.boot_osflags = fillInCmdline(mdesc, cmdline\n</code></pre></div></div>\n<p>Set the following M5_PATH:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>M5_PATH=. build/ARM/gem5.opt configs/example/fs.py --cpu-type=atomic --mem-type=SimpleMemory --os-type=android-kitkat --disk-image=myimage.img --machine-type=VExpress_EMM --dtb-filename=vexpress-v2p-ca15-tc1-gem5.dtb -n 1 --mem-size=1800MB\n</code></pre></div></div>\n<h2 id=\"building-older-versions-of-android\">Building older versions of Android</h2>\n<p>gem5 has support for running even older versions of Android like KitKat. The documentation to do so, as well as the necessary drivers and files required, can be found on the old wiki <a href=\"http://old.gem5.org/Android_KitKat.html\">here</a>.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/development/release_procedures/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/fullsystem/building_arm_kernel\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/fullsystem/building_arm_kernel",
        "title": "Building ARM Kernel",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"building-arm-kernel\">Building ARM Kernel</h1>\n<p>This page contains instructions for building up-to-date kernels for gem5 running on ARM.</p>\n<p>If you don\u2019t want to build the Kernel (or a disk image) on your own you could still <a href=\"./guest_binaries\">download a\nprebuilt version</a>.</p>\n<h2 id=\"prerequisites\">Prerequisites</h2>\n<p>These instructions are for running headless systems. That is a more \u201cserver\u201d style system where there is no frame-buffer. The description has been created using the latest known-working tag in the repositories linked below, however the tables in each section list previous tags that are known to work. To built the kernels on an x86 host you\u2019ll need ARM cross compilers and the device tree compiler. If you\u2019re running a reasonably new version of Ubuntu or Debian you can get required software through apt:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>apt-get install  gcc-arm-linux-gnueabihf gcc-aarch64-linux-gnu device-tree-compiler\n</code></pre></div></div>\n<p>If you can\u2019t use these pre-made compilers the next easiest way to obtain the\nrequired compilers from ARM:</p>\n<ul>\n<li><a href=\"https://developer.arm.com/tools-and-software/open-source-software/developer-tools/gnu-toolchain/gnu-a/downloads\">Cortex A cross-compilers</a></li>\n<li><a href=\"https://developer.arm.com/tools-and-software/open-source-software/developer-tools/gnu-toolchain/gnu-rm/downloads\">Cortex RM cross-compilers</a></li>\n</ul>\n<p>Download (one of) these and make sure the binaries are on your <code class=\"language-plaintext highlighter-rouge\">PATH</code>.</p>\n<p>Depending on the exact source of your cross compilers, the compiler names used below will required small changes.</p>\n<p>To actually run the kernel, you\u2019ll need to download or compile gem5\u2019s\nbootloader. See the <a href=\"#bootloaders\">bootloaders</a> section in this documents for\ndetails.</p>\n<h2 id=\"linux-4x\">Linux 4.x</h2>\n<p>Newer gem5 kernels for ARM (v4.x and later) are based on the vanilla Linux kernel and typically have a small number of patches to make them work better with gem5. The patches are optional and you should be able to use a vanilla kernel as well. However, this requires you to configure the kernel yourself. Newer kernels all use the VExpress_GEM5_V1 gem5 platform for both AArch32 and AArch64.</p>\n<h1 id=\"kernel-checkout\">Kernel Checkout</h1>\n<p>To checkout the kernel, execute the following command:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>git clone https://gem5.googlesource.com/arm/linux\n</code></pre></div></div>\n<p>The repository contains a tag per gem5 kernel releases and working branches for major Linux revisions. Check the <a href=\"https://gem5-review.googlesource.com/#/admin/projects/arm/linux\">project page</a> for a list of tags and branches. The clone command will, by default, check out the latest release branch. To checkout the v4.14 branch, execute the following in the repository:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>git checkout -b gem5/v4.14\n</code></pre></div></div>\n<h1 id=\"kernel-build\">Kernel build</h1>\n<p>To compile the kernel, execute the following commands in the repository:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>make ARCH=arm64 CROSS_COMPILE=aarch64-linux-gnu- gem5_defconfig\nmake ARCH=arm64 CROSS_COMPILE=aarch64-linux-gnu- -j `nproc`\n</code></pre></div></div>\n<p>Testing the just built kernel:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>./build/ARM/gem5.opt configs/example/arm/starter_fs.py --kernel=/tmp/linux-arm-gem5/vmlinux \\\n    --disk-image=ubuntu-18.04-arm64-docker.img\n</code></pre></div></div>\n<h1 id=\"bootloaders\">Bootloaders</h1>\n<p>There are two different bootloaders for gem5. One of 32-bit kernels and one for 64-bit kernels. They can be compiled using the following command:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>make -C system/arm/bootloader/arm\nmake -C system/arm/bootloader/arm64\n</code></pre></div></div>\n<h1 id=\"device-tree-blobs\">Device Tree Blobs</h1>\n<p>The required DTB files to describe the hardware to the OS ship with gem5. To build them, execute this command:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>make -C system/arm/dt\n</code></pre></div></div>\n<p>We recommend to use these device tree files only if you are planning to amend them. If not, we recommend you to rely on DTB autogeneration: by running a FS script without the \u2013dtb option, gem5 will automatically generate the DTB on the fly depending on the instantiated platform.</p>\n<p>Once you have compiled the binaries, put them in the binaries directory in your\n<code class=\"language-plaintext highlighter-rouge\">M5_PATH</code>.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/fullsystem/building_android_m\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/fullsystem/devices\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/fullsystem/devices",
        "title": "Devices in full system mode",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"devices-in-full-system-mode\">Devices in full system mode</h1>\n<h2 id=\"io-device-base-classes\">I/O Device Base Classes</h2>\n<p>The base classes in src/dev/*_device.* allow devices to be created with reasonable ease.\nThe classes and virtual functions that must be implemented are listed below.\nBefore reading the following it will help to be familiar with the <a href=\"../memory_system\">Memory_System</a>.</p>\n<h3 id=\"pioport\">PioPort</h3>\n<p>The PioPort class is a programmed I/O port that all devices that are sensitive to an address range use.\nThe port takes all the memory access types and roles them into one <code class=\"language-plaintext highlighter-rouge\">read()</code> and <code class=\"language-plaintext highlighter-rouge\">write()</code> call that the device must respond to.\nThe device must also provide the <code class=\"language-plaintext highlighter-rouge\">addressRanges()</code> function with which it returns the address ranges it is interested in.\nIf desired a device could have more than one PIO port.\nHowever in the normal case it would only have one port and return multiple ranges when the <code class=\"language-plaintext highlighter-rouge\">addressRange()</code> function is called. The only time multiple PIO ports would be desirable is if your device wanted to have separate connection to two memory objects.</p>\n<h3 id=\"piodevice\">PioDevice</h3>\n<p>This is the base class which all devices senstive to an address range inherit from.\nThere are three pure virtual functions which all devices must implement <code class=\"language-plaintext highlighter-rouge\">addressRanges()</code>, <code class=\"language-plaintext highlighter-rouge\">read()</code>, and <code class=\"language-plaintext highlighter-rouge\">write()</code>.\nThe magic to choose which mode we are in, etc is handled by the PioPort so the device doesn\u2019t have to bother.</p>\n<p>Parameters for each device should be in a Params struct derived from <code class=\"language-plaintext highlighter-rouge\">PioDevice::Params</code>.</p>\n<h3 id=\"basicpiodevice\">BasicPioDevice</h3>\n<p>Since most PioDevices only respond to one address range <code class=\"language-plaintext highlighter-rouge\">BasicPioDevice</code> provides an <code class=\"language-plaintext highlighter-rouge\">addressRanges()</code> and parameters for the normal pio delay and the address to which the device responds to.\nSince the size of the device normally isn\u2019t configurable a parameter is not used for this and anything that inherits from this class is expected to write it\u2019s size into pioSize in its constructor.</p>\n<h3 id=\"dmaport\">DmaPort</h3>\n<p>The DmaPort (in dma_device.hh) is used only for device mastered accesses.\nThe <code class=\"language-plaintext highlighter-rouge\">recvTimingResp()</code> method must be available to responses (nacked or not) to requests it makes.\nThe port has two public methods <code class=\"language-plaintext highlighter-rouge\">dmaPending()</code> which returns if the dma port is busy (e.g. It is still trying to send out all the pieces of the last request).\nAll the code to break requests up into suitably sized chunks, collect the potentially multiple responses and respond to the device is accessed through <code class=\"language-plaintext highlighter-rouge\">dmaAction()</code>.\nA command, start address, size, completion event, and possibly data is handed to the function which will then execute the completion events <code class=\"language-plaintext highlighter-rouge\">process()</code> method when the request has been completed.\nInternally the code uses <code class=\"language-plaintext highlighter-rouge\">DmaReqState</code> to manage what blocks it has received and to know when to execute the completion event.</p>\n<h3 id=\"dmadevice\">DmaDevice</h3>\n<p>This is the base class from which a DMA non-pci device would inherit from, however none of those exist currently within M5. The class does have some methods <code class=\"language-plaintext highlighter-rouge\">dmaWrite()</code>, <code class=\"language-plaintext highlighter-rouge\">dmaRead()</code> that select the appropriate command from a DMA read or write operation.</p>\n<h3 id=\"nic-devices\">NIC Devices</h3>\n<p>The gem5 simulator has two different Network Interface Cards (NICs) devices that can be used to connect together two simulation instances over a simulated ethernet link.</p>\n<h4 id=\"getting-a-list-of-packets-on-the-ethernet-link\">Getting a list of packets on the ethernet link</h4>\n<p>You can get a list of the packet on the ethernet link by creating a Etherdump object, setting it\u2019s file parameter, and setting the dump parameter on the EtherLink to it.\nThis is easily accomplished with our fs.py example configuration by adding the command line option --etherdump=&lt;filename&gt;. The resulting file will be named &lt;file&gt; and be in a standard pcap format.\nThis file can be read with <a href=\"https://www.wireshark.org/\">wireshark</a> or anything else that understands the pcap format.</p>\n<h3 id=\"pci-devices\">PCI devices</h3>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>To do: Explanation of platforms and systems, how they\u2019re related, and what they\u2019re each for\n</code></pre></div></div>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/fullsystem/building_arm_kernel\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/fullsystem/disks\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/fullsystem/disks",
        "title": "Creating disk images for full system mode",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"creating-disk-images-for-full-system-mode\">Creating disk images for full system mode</h1>\n<p>In full-system mode, gem5 relies on a disk image with an installed operating system to run simulations.\nA disk device in gem5 gets its initial contents from disk image.\nThe disk image file stores all the bytes present on the disk just as you would find them on an actual device.\nSome other systems also use disk images which are in more complicated formats and which provide compression, encryption, etc. gem5 currently only supports raw images, so if you have an image in one of those other formats, you\u2019ll have to convert it into a raw image before you can use it in a simulation.\nThere are often tools available which can convert between the different formats.</p>\n<p>There are multiple ways of creating a disk image which can be used with gem5.\nFollowing are four different methods to build disk images:</p>\n<ul>\n<li>Using gem5 utils to create a disk image</li>\n<li>Using gem5 utils and chroot to create a disk image</li>\n<li>Using QEMU to create a disk image</li>\n<li>Using Packer to create a disk image</li>\n</ul>\n<p>All of these methods are independent of each other.\nNext, we will discuss each of these methods one by one.</p>\n<h2 id=\"1-using-gem5-utils-to-create-a-disk-image\">1) Using gem5 utils to create a disk image</h2>\n<div class=\"language-md highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Disclaimer: This is from the old website and some of the stuff in this method can be out-dated.\n\n</code></pre></div></div>\n<p>Because a disk image represents all the bytes on the disk itself, it contains more than just a file system.\nFor hard drives on most systems, the image starts with a partition table.\nEach of the partitions in the table (frequently only one) is also in the image.\nIf you want to manipulate the entire disk you\u2019ll use the entire image, but if you want to work with just one partition and/or the file system on it, you\u2019ll need to specifically select that part of the image.\nThe losetup command (discussed below) has a -o option which lets you specify where to start in an image.</p>\n<iframe allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\" frameborder=\"0\" height=\"315\" src=\"https://www.youtube.com/embed/Oh3NK12fnbg\" width=\"560\"></iframe>\n<div class=\"thumbcaption\">A youtube video of working with image files using qemu on Ubuntu 12.04 64bit. Video resolution can be set to 1080</div>\n<h3 id=\"creating-an-empty-image\">Creating an empty image</h3>\n<p>You can use the ./util/gem5img.py script provided with gem5 to build the disk image.\nIt\u2019s a good idea to understand how to build an image in case something goes wrong or you need to do something in an unusual way.\nHowever, in this mehtod, we are using gem5img.py script to go through the process of building and formatting an image.\nIf you want to understand the guts of what it\u2019s doing see below.\nRunning gem5img.py may require you to enter the sudo password.\n<em>You should never run commands as the root user that you don\u2019t understand! You should look at the file util/gem5img.py and ensure that it isn\u2019t going to do anything malicious to your computer!</em></p>\n<p>You can use the \u201cinit\u201d option with gem5img.py to create an empty image, \u201cnew\u201d, \u201cpartition\u201d, or \u201cformat\u201d to perform those parts of init independently, and \u201cmount\u201d or \u201cumount\u201d to mount or unmount an existing image.</p>\n<h3 id=\"mounting-an-image\">Mounting an image</h3>\n<p>To mount a file system on your image file, first find a loopback device and attach it to your image with an appropriate offset as will be described further in the <a href=\"#formatting\">Formatting</a> section.</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>mount <span class=\"nt\">-o</span> loop,offset<span class=\"o\">=</span>32256 foo.img\n</code></pre></div></div>\n<iframe allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\" frameborder=\"0\" height=\"315\" src=\"https://www.youtube.com/embed/OXH1oxQbuHA\" width=\"560\"></iframe>\n<div class=\"thumbcaption\">A youtube video of add file using mount on Ubuntu 12.04 64bit. Video resolution can be set to 1080</div>\n<h3 id=\"unmounting\">Unmounting</h3>\n<p>To unmount an image, use the umount command like you normally would.</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>umount\n</code></pre></div></div>\n<h3 id=\"image-contents\">Image Contents</h3>\n<p>Now that you can create an image file and mount it\u2019s file system, you\u2019ll want to actually put some files in it.\nYou\u2019re free to use whatever files you want, but the gem5 developers have found that Gentoo stage3 tarballs are a great starting point.\nThey\u2019re essentially an almost bootable and fairly minimal Linux installation and are available for a number of architectures.</p>\n<p>If you choose to use a Gentoo tarball, first extract it into your mounted image.\nThe /etc/fstab file will have placeholder entries for the root, boot, and swap devices.\nYou\u2019ll want to update this file as apporpriate, deleting any entries you aren\u2019t going to use (the boot partition, for instance).\nNext, you\u2019ll want to modify the inittab file so that it uses the m5 utility program (described elsewhere) to read in the init script provided by the host machine and to run that.\nIf you allow the normal init scripts to run, the workload you\u2019re interested in may take much longer to get started, you\u2019ll have no way to inject your own init script to dynamically control what benchmarks are started, for instance, and you\u2019ll have to interact with the simulation through a simulated terminal which introduces non-determinism.</p>\n<h4 id=\"modifications\">Modifications</h4>\n<p>By default gem5 does not store modifications to the disk back to the underlying image file.\nAny changes you make will be stored in an intermediate COW layer and thrown away at the end of the simulation.\nYou can turn off the COW layer if you want to modify the underlying disk.</p>\n<h4 id=\"kernel-and-bootloader\">Kernel and bootloader</h4>\n<p>Also, generally speaking, gem5 skips over the bootloader portion of boot and loads the kernel into simulated memory itself. This means that there\u2019s no need to install a bootloader like grub to your disk image, and that you don\u2019t have to put the kernel you\u2019re going to boot from on the image either.\nThe kernel is provided separately and can be changed out easily without having to modify the disk image.</p>\n<h3 id=\"manipulating-images-with-loopback-devices\">Manipulating images with loopback devices</h3>\n<h4 id=\"loopback-devices\">Loopback devices</h4>\n<p>Linux supports loopback devices which are devices backed by files.\nBy attaching one of these to your disk image, you can use standard Linux commands on it which normally run on real disk devices.\nYou can use the mount command with the \u201cloop\u201d option to set up a loopback device and mount it somewhere.\nUnfortunately you can\u2019t specify an offset into the image, so that would only be useful for a file system image, not a disk image which is what you need.\nYou can, however, use the lower level losetup command to set up a loopback device yourself and supply the proper offset.\nOnce you\u2019ve done that, you can use the mount command on it like you would on a disk partition, format it, etc.\nIf you don\u2019t supply an offset the loopback device will refer to the whole image, and you can use your favorite program to set up the partitions on it.</p>\n<h3 id=\"working-with-image-files\">Working with image files</h3>\n<p>To create an empty image from scratch, you\u2019ll need to create the file itself, partition it, and format (one of) the partition(s) with a file system.</p>\n<h4 id=\"create-the-actual-file\">Create the actual file</h4>\n<p>First, decide how large you want your image to be.\nIt\u2019s a good idea to make it large enough to hold everything you know you\u2019ll need on it, plus some breathing room.\nIf you find out later it\u2019s too small, you\u2019ll have to create a new larger image and move everything over.\nIf you make it too big, you\u2019ll take up actual disk space unnecessarily and make the image harder to work with.\nOnce you\u2019ve decided on a size you\u2019ll want to actually create the file.\nBasically, all you need to do is create a file of a certain size that\u2019s full of zeros.\nOne approach is to use the dd command to copy the right number of bytes from /dev/zero into the new file.\nAlternatively you could create the file, seek in it to the last byte, and write one zero byte.\nAll of the space you skipped over will become part of the file and is defined to read as zeroes, but because you didn\u2019t explicitly write any data there, most file systems are smart enough to not actually store that to disk.\nYou can create a large image that way but take up very little space on your physical disk.\nOnce you start writing to the file later that will change, and also if you\u2019re not careful, copying the file may expand it to its full size.</p>\n<h4 id=\"partitioning\">Partitioning</h4>\n<p>First, find an available loopback device using the losetup command with the -f option.</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>losetup <span class=\"nt\">-f</span>\n</code></pre></div></div>\n<p>Next, use losetup to attach that device to your image.\nIf the available device was /dev/loop0 and your image is foo.img, you would use a command like this.</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>losetup /dev/loop0 foo.img\n</code></pre></div></div>\n<p>/dev/loop0 (or whatever other device you\u2019re using) will now refer to your entire image file.\nUse whatever partitioning program you like on it to set up one (or more) paritions.\nFor simplicity it\u2019s probably a good idea to create only one parition that takes up the entire image.\nWe say it takes up the entire image, but really it takes up all the space except for the partition table itself at the beginning of the file, and possibly some wasted space after that for DOS/bootloader compatibility.</p>\n<p>From now on we\u2019ll want to work with the new partition we created and not the whole disk, so we\u2019ll free up the loopback device using losetup\u2019s -d option</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>losetup <span class=\"nt\">-d</span> /dev/loop0\n</code></pre></div></div>\n<h4 id=\"formatting\">Formatting</h4>\n<p>First, find an available loopback device like we did in the partitioning step above using losetup\u2019s -f option.</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>losetup <span class=\"nt\">-f</span>\n</code></pre></div></div>\n<p>We\u2019ll attach our image to that device again, but this time we only want to refer to the partition we\u2019re going to put a file system on.\nFor PC and Alpha systems, that partition will typically be one track in, where one track is 63 sectors and each sector is 512 bytes, or 63 * 512 = 32256 bytes.\nThe correct value for you may be different, depending on the geometry and layout of your image.\nIn any case, you should set up the loopback device with the -o option so that it represents the partition you\u2019re interested in.</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>losetup <span class=\"nt\">-o</span> 32256 /dev/loop0 foo.img\n</code></pre></div></div>\n<p>Next, use an appropriate formating command, often mke2fs, to put a file system on the partition.</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>mke2fs /dev/loop0\n</code></pre></div></div>\n<p>You\u2019ve now successfully created an empty image file.\nYou can leave the loopback device attached to it if you intend to keep working with it (likely since it\u2019s still empty) or clean it up using losetup -d.</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>losetup <span class=\"nt\">-d</span> /dev/loop0\n</code></pre></div></div>\n<p>Don\u2019t forget to clean up the loopback device attached to your image with the losetup -d command.</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>losetup <span class=\"nt\">-d</span> /dev/loop0\n</code></pre></div></div>\n<h2 id=\"2-using-gem5-utils-and-chroot-to-create-a-disk-image\">2) Using gem5 utils and chroot to create a disk image</h2>\n<p>The discussion in this section assumes that you have already checked out a version of gem5 and can build and run gem5 in full-system mode.\nWe will use the x86 ISA for gem5 in this discussion, and this is mostly applicable to other ISAs as well.</p>\n<h3 id=\"creating-a-blank-disk-image\">Creating a blank disk image</h3>\n<p>The first step is to create a blank disk image (usually a .img file).\nThis is similar to what we did in the first metod.\nWe can use the gem5img.py script provided by gem5 developers.\nTo create a blank disk image, which is formatted with ext2 by default, simply run the following.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>&gt; util/gem5img.py init ubuntu-14.04.img 4096\n</code></pre></div></div>\n<p>This command creates a new image, called \u201cubuntu-14.04.img\u201d that is 4096 MB.\nThis command may require you to enter the sudo password, if you don\u2019t have permission to create loopback devices.\n<em>You should never run commands as the root user that you don\u2019t understand! You should look at the file util/gem5img.py and ensure that it isn\u2019t going to do anything malicious to your computer!</em></p>\n<p>We will be using util/gem5img.py heavily throughout this section, so you may want to understand it better.\nIf you just run <code class=\"language-plaintext highlighter-rouge\">util/gem5img.py</code>, it displays all of the possible commands.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Usage: %s [command] &lt;command arguments&gt;\nwhere [command] is one of\n    init: Create an image with an empty file system.\n    mount: Mount the first partition in the disk image.\n    umount: Unmount the first partition in the disk image.\n    new: File creation part of \"init\".\n    partition: Partition part of \"init\".\n    format: Formatting part of \"init\".\nWatch for orphaned loopback devices and delete them with\nlosetup -d. Mounted images will belong to root, so you may need\nto use sudo to modify their contents\n</code></pre></div></div>\n<h3 id=\"copying-root-files-to-the-disk\">Copying root files to the disk</h3>\n<p>Now that we have created a blank disk, we need to populate it with all of the OS files.\nUbuntu distributes a set of files explicitly for this purpose.\nYou can find the <a href=\"https://wiki.ubuntu.com/Core\">Ubuntu core</a> distribution for 14.04 at <a href=\"http://cdimage.ubuntu.com/releases/14.04/release/\">http://cdimage.ubuntu.com/releases/14.04/release/</a>. Since we are simulating an x86 machine, we will use <code class=\"language-plaintext highlighter-rouge\">ubuntu-core-14.04-core-amd64.tar.gz</code>.\nDownload whatever image is appropriate for the system you are simulating.</p>\n<p>Next, we need to mount the blank disk and copy all of the files onto the disk.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>mkdir mnt\n../../util/gem5img.py mount ubuntu-14.04.img mnt\nwget http://cdimage.ubuntu.com/ubuntu-core/releases/14.04/release/ubuntu-core-14.04-core-amd64.tar.gz\nsudo tar xzvf ubuntu-core-14.04-core-amd64.tar.gz -C mnt\n</code></pre></div></div>\n<p>The next step is to copy a few required files from your working system onto the disk so we can chroot into the new disk. We need to copy <code class=\"language-plaintext highlighter-rouge\">/etc/resolv.conf</code> onto the new disk.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>sudo cp /etc/resolv.conf mnt/etc/\n</code></pre></div></div>\n<h3 id=\"setting-up-gem5-specific-files\">Setting up gem5-specific files</h3>\n<h4 id=\"create-a-serial-terminal\">Create a serial terminal</h4>\n<p>By default, gem5 uses the serial port to allow communication from the host system to the simulated system. To use this, we need to create a serial tty.\nSince Ubuntu uses upstart to control the init process, we need to add a file to /etc/init which will initialize our terminal.\nAlso, in this file, we will add some code to detect if there was a script passed to the simulated system.\nIf there is a script, we will execute the script instead of creating a terminal.</p>\n<p>Put the following code into a file called /etc/init/tty-gem5.conf</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code># ttyS0 - getty\n#\n# This service maintains a getty on ttyS0 from the point the system is\n# started until it is shut down again, unless there is a script passed to gem5.\n# If there is a script, the script is executed then simulation is stopped.\n\nstart on stopped rc RUNLEVEL=[12345]\nstop on runlevel [!12345]\n\nconsole owner\nrespawn\nscript\n   # Create the serial tty if it doesn't already exist\n   if [ ! -c /dev/ttyS0 ]\n   then\n      mknod /dev/ttyS0 -m 660 /dev/ttyS0 c 4 64\n   fi\n\n   # Try to read in the script from the host system\n   /sbin/m5 readfile &gt; /tmp/script\n   chmod 755 /tmp/script\n   if [ -s /tmp/script ]\n   then\n      # If there is a script, execute the script and then exit the simulation\n      exec su root -c '/tmp/script' # gives script full privileges as root user in multi-user mode\n      /sbin/m5 exit\n   else\n      # If there is no script, login the root user and drop to a console\n      # Use m5term to connect to this console\n      exec /sbin/getty --autologin root -8 38400 ttyS0\n   fi\nend script\n</code></pre></div></div>\n<h4 id=\"setup-localhost\">Setup localhost</h4>\n<p>We also need to set up the localhost loopback device if we are going to use any applications that use it.\nTo do this, we need to add the following to the <code class=\"language-plaintext highlighter-rouge\">/etc/hosts</code> file.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>127.0.0.1 localhost\n::1 localhost ip6-localhost ip6-loopback\nfe00::0 ip6-localnet\nff00::0 ip6-mcastprefix\nff02::1 ip6-allnodes\nff02::2 ip6-allrouters\nff02::3 ip6-allhosts\n</code></pre></div></div>\n<h4 id=\"update-fstab\">Update fstab</h4>\n<p>Next, we need to create an entry in <code class=\"language-plaintext highlighter-rouge\">/etc/fstab</code> for each partition we want to be able to access from the simulated system. Only one partition is absolutely required (<code class=\"language-plaintext highlighter-rouge\">/</code>); however, you may want to add additional partitions, like a swap partition.</p>\n<p>The following should appear in the file <code class=\"language-plaintext highlighter-rouge\">/etc/fstab</code>.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code># /etc/fstab: static file system information.\n#\n# Use 'blkid' to print the universally unique identifier for a\n# device; this may be used with UUID= as a more robust way to name devices\n# that works even if disks are added and removed. See fstab(5).\n#\n# &lt;file system&gt;    &lt;mount point&gt;   &lt;type&gt;  &lt;options&gt;   &lt;dump&gt;  &lt;pass&gt;\n/dev/hda1      /       ext3        noatime     0 1\n</code></pre></div></div>\n<h4 id=\"copy-the-m5-binary-to-the-disk\">Copy the <code class=\"language-plaintext highlighter-rouge\">m5</code> binary to the disk</h4>\n<p>gem5 comes with an extra binary application that executes pseudo-instructions to allow the simulated system to interact with the host system.\nTo build this binary, run <code class=\"language-plaintext highlighter-rouge\">make -f Makefile.&lt;isa&gt;</code> in the <code class=\"language-plaintext highlighter-rouge\">gem5/m5</code> directory, where <code class=\"language-plaintext highlighter-rouge\">&lt;isa&gt;</code> is the ISA that you are simulating (e.g., x86). After this, you should have an <code class=\"language-plaintext highlighter-rouge\">m5</code> binary file.\nCopy this file to /sbin on your newly created disk.</p>\n<p>After updating the disk with all of the gem5-specific files, unless you are going on to add more applications or copying additional files, unmount the disk image.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>&gt; util/gem5img.py umount mnt\n</code></pre></div></div>\n<h3 id=\"install-new-applications\">Install new applications</h3>\n<p>The easiest way to install new applications on to your disk, is to use <code class=\"language-plaintext highlighter-rouge\">chroot</code>.\nThis program logically changes the root directory (\u201c/\u201d) to a different directory, mnt in this case.\nBefore you can change the root, you first have to set up the special directories in your new root. To do\nthis, we use <code class=\"language-plaintext highlighter-rouge\">mount -o bind</code>.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>&gt; sudo /bin/mount -o bind /sys mnt/sys\n&gt; sudo /bin/mount -o bind /dev mnt/dev\n&gt; sudo /bin/mount -o bind /proc mnt/proc\n</code></pre></div></div>\n<p>After binding those directories, you can now <code class=\"language-plaintext highlighter-rouge\">chroot</code>:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>&gt; sudo /usr/sbin/chroot mnt /bin/bash\n</code></pre></div></div>\n<p>At this point you will see a root prompt and you will be in the <code class=\"language-plaintext highlighter-rouge\">/</code>\ndirectory of your new disk.</p>\n<p>You should update your repository information.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>&gt; apt-get update\n</code></pre></div></div>\n<p>You may want to add the universe repositories to your list with the\nfollowing commands.\nNote: The first command is require in 14.04.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>&gt; apt-get install software-properties-common\n&gt; add-apt-repository universe\n&gt; apt-get update\n</code></pre></div></div>\n<p>Now, you are able to install any applications you could install on a\nnative Ubuntu machine via <code class=\"language-plaintext highlighter-rouge\">apt-get</code>.</p>\n<p>Remember, after you exit you need to unmount all of the directories we\nused bind on.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>&gt; sudo /bin/umount mnt/sys\n&gt; sudo /bin/umount mnt/proc\n&gt; sudo /bin/umount mnt/dev\n</code></pre></div></div>\n<h2 id=\"3-using-qemu-to-create-a-disk-image\">3) Using QEMU to create a disk image</h2>\n<p>This method is a follow-up on the previous method to create a disk image.\nWe will see how to create, edit and set up a disk image using qemu instead of relying on gem5 tools.\nThis section assumes that you have installed qemu on your system.\nIn Ubuntu, this can be done with</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>sudo apt-get install qemu-kvm libvirt-bin ubuntu-vm-builder bridge-utils\n</code></pre></div></div>\n<h3 id=\"step-1-create-an-empty-disk\">Step 1: Create an empty disk</h3>\n<p>Using the qemu disk tools, create a blank raw disk image.\nIn this case, I chose to create a disk named \u201cubuntu-test.img\u201d that is 8GB.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>qemu-img create ubuntu-test.img 8G\n</code></pre></div></div>\n<h3 id=\"step-2-install-ubuntu-with-qemu\">Step 2: Install ubuntu with qemu</h3>\n<p>Now that we have a blank disk, we are going to use qemu to install Ubuntu on the disk.\nIt is encouraged that you use the server version of Ubuntu since gem5 does not have great support for displays.\nThus, the desktop environment isn\u2019t very useful.</p>\n<p>First, you need to download the installation CD image from the <a href=\"https://www.ubuntu.com/download/server\">Ubuntu website</a>.</p>\n<p>Next, use qemu to boot off of the CD image, and set the disk in the system to be the blank disk you created above.\nUbuntu needs at least 1GB of memory to install correctly, so be sure to configure qemu to use at least 1GB memory.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>qemu-system-x86_64 -hda ../gem5-fs-testing/ubuntu-test.img -cdrom ubuntu-16.04.1-server-amd64.iso -m 1024 -enable-kvm -boot d\n</code></pre></div></div>\n<p>With this, you can simply follow the on-screen directions to install Ubuntu to the disk image.\nThe only gotcha in the installation is that gem5\u2019s IDE drivers don\u2019t seem to play nicely with logical paritions.\nThus, during the Ubuntu install, be sure to manually partition the disk and remove any logical partitions.\nYou don\u2019t need any swap space on the disk anyway, unless you\u2019re doing something specifically with swap space.</p>\n<h3 id=\"step-3-boot-up-and-install-needed-software\">Step 3: Boot up and install needed software</h3>\n<p>Once you have installed Ubuntu on the disk, quit qemu and remove the <code class=\"language-plaintext highlighter-rouge\">-boot d</code> option so that you are not booting off of the CD anymore.\nNow, you can again boot off of the main disk image you have installed Ubuntu on.</p>\n<p>Since we\u2019re using qemu, you should have a network connection (although <a href=\"http://wiki.qemu.org/Documentation/Networking#User_Networking_.28SLIRP.29\">ping won\u2019t\nwork</a>).\nWhen booting in qemu, you can just use <code class=\"language-plaintext highlighter-rouge\">sudo apt-get install</code> and\ninstall any software you need on your disk.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>qemu-system-x86_64 -hda ../gem5-fs-testing/ubuntu-test.img -cdrom ubuntu-16.04.1-server-amd64.iso -m 1024 -enable-kvm\n</code></pre></div></div>\n<h3 id=\"step-4-update-init-script\">Step 4: Update init script</h3>\n<p>By default, gem5 expects a modified init script which loads a script off of the host to execute in the guest.\nTo use this feature, you need to follow the steps below.</p>\n<p>Alternatively, you can install the precompiled binaries for x86 found on this <a href=\"http://cs.wisc.edu/~powerjg/files/gem5-guest-tools-x86.tgz\">website</a>.\nFrom qemu, you can run the following, which completes the above steps for you.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>wget http://cs.wisc.edu/~powerjg/files/gem5-guest-tools-x86.tgz\ntar xzvf gem5-guest-tools-x86.tgz\ncd gem5-guest-tools/\nsudo ./install\n</code></pre></div></div>\n<p>Now, you can use the <code class=\"language-plaintext highlighter-rouge\">system.readfile</code> parameter in your Python config scripts. This file will automatically be loaded (by the <code class=\"language-plaintext highlighter-rouge\">gem5init</code> script) and executed.</p>\n<h3 id=\"manually-installing-the-gem5-init-script\">Manually installing the gem5 init script</h3>\n<p>First, build the m5 binary on the host.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>cd util/m5\nmake -f Makefile.x86\n</code></pre></div></div>\n<p>Then, copy this binary to the guest and put it in <code class=\"language-plaintext highlighter-rouge\">/sbin</code>. Also, create a link from <code class=\"language-plaintext highlighter-rouge\">/sbin/gem5</code>.</p>\n<p>Then, to get the init script to execute when gem5 boots, create file /lib/systemd/system/gem5.service with the following:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>[Unit]\nDescription=gem5 init script\nDocumentation=http://gem5.org\nAfter=getty.target\n\n[Service]\nType=idle\nExecStart=/sbin/gem5init\nStandardOutput=tty\nStandardInput=tty-force\nStandardError=tty\n\n[Install]\nWantedBy=default.target\n</code></pre></div></div>\n<p>Enable the gem5 service and <strong>disable the ttyS0 service</strong>.\nIf your disk boots up to a login prompt, it might be caused by not disabling the ttyS0 service.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>systemctl enable gem5.service\n</code></pre></div></div>\n<p>Finally, create the init script that is executed by the service. In\n<code class=\"language-plaintext highlighter-rouge\">/sbin/gem5init</code>:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>#!/bin/bash -\n\nCPU=`cat /proc/cpuinfo | grep vendor_id | head -n 1 | cut -d ' ' -f2-`\necho \"Got CPU type: $CPU\"\n\nif [ \"$CPU\" != \"M5 Simulator\" ];\nthen\n    echo \"Not in gem5. Not loading script\"\n    exit 0\nfi\n\n# Try to read in the script from the host system\n/sbin/m5 readfile &gt; /tmp/script\nchmod 755 /tmp/script\nif [ -s /tmp/script ]\nthen\n    # If there is a script, execute the script and then exit the simulation\n    su root -c '/tmp/script' # gives script full privileges as root user in multi-user mode\n    sync\n    sleep 10\n    /sbin/m5 exit\nfi\necho \"No script found\"\n</code></pre></div></div>\n<h3 id=\"problems-and-some-solutions\">Problems and (some) solutions</h3>\n<p>You might run into some problems while following this method.\nSome of the issues and solutions are discussed on this <a href=\"http://www.lowepower.com/jason/setting-up-gem5-full-system.html\">page</a>.</p>\n<h2 id=\"4-using-packer-to-create-a-disk-image\">4) Using Packer to create a disk image</h2>\n<p>This section discusses an automated way of creating gem5-compatible disk images with Ubuntu server installed. We make use of packer to do this which makes use of a .json template file to build and configure a disk image. The template file could be configured to build a disk image with specific benchmarks installed. The mentioned template file can be found <a href=\"/assets/files/packer_template.json\">here</a>.</p>\n<h3 id=\"building-a-simple-disk-image-with-packer\">Building a Simple Disk Image with Packer</h3>\n<h4 id=\"a-how-it-works-briefly\">a. How It Works, Briefly</h4>\n<p>We use <a href=\"https://www.packer.io/\">Packer</a> and <a href=\"https://www.qemu.org/\">QEMU</a> to automate the process of disk creation.\nEssentially, QEMU is responsible for setting up a virtual machine and all interactions with the disk image during the building process.\nThe interactions include installing Ubuntu Server to the disk image, copying files from your machine to the disk image, and running scripts on the disk image after Ubuntu is installed.\nHowever, we will not use QEMU directly.\nPacker provides a simpler way to interact with QEMU using a JSON script, which is more expressive than using QEMU from command line.</p>\n<h4 id=\"b-install-required-softwaredependencies\">b. Install Required Software/Dependencies</h4>\n<p>If not already installed, QEMU can be installed using:</p>\n<div class=\"language-shell highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">sudo </span>apt-get <span class=\"nb\">install </span>qemu\n</code></pre></div></div>\n<p>Download the Packer binary from <a href=\"https://www.packer.io/downloads.html\">the official website</a>.</p>\n<h4 id=\"c-customize-the-packer-script\">c. Customize the Packer Script</h4>\n<p>The default packer script <code class=\"language-plaintext highlighter-rouge\">template.json</code> should be modified and adapted according to the required disk image and the avaiable resources for the build proces. We will rename the default template to <code class=\"language-plaintext highlighter-rouge\">[disk-name].json</code>. The variables that should be modified appear at the end of <code class=\"language-plaintext highlighter-rouge\">[disk-name].json</code> file, in <code class=\"language-plaintext highlighter-rouge\">variables</code> section.\nThe configuration files that are used to build the disk image, and the directory structure is shown below:</p>\n<div class=\"language-shell highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>disk-image/\n    <span class=\"o\">[</span>disk-name].json: packer script\n    Any experiment-specific post installation script\n    post-installation.sh: generic shell script that is executed after Ubuntu is installed\n    preseed.cfg: preseeded configuration to <span class=\"nb\">install </span>Ubuntu\n</code></pre></div></div>\n<h5 id=\"i-customizing-the-vm-virtual-machine\">i. Customizing the VM (Virtual Machine)</h5>\n<p>In <code class=\"language-plaintext highlighter-rouge\">[disk-name].json</code>, following variables are available to customize the VM:</p>\n<table>\n<thead>\n<tr>\n<th>Variable</th>\n<th>Purpose</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><a href=\"https://www.packer.io/docs/builders/qemu.html#cpus\">vm_cpus</a> <strong>(should be modified)</strong></td>\n<td>number of host CPUs used by VM</td>\n<td>\u201c2\u201d: 2 CPUs are used by the VM</td>\n</tr>\n<tr>\n<td><a href=\"https://www.packer.io/docs/builders/qemu.html#memory\">vm_memory</a> <strong>(should be modified)</strong></td>\n<td>amount of VM memory, in MB</td>\n<td>\u201c2048\u201d: 2 GB of RAM are used by the VM</td>\n</tr>\n<tr>\n<td><a href=\"https://www.packer.io/docs/builders/qemu.html#accelerator\">vm_accelerator</a> <strong>(should be modified)</strong></td>\n<td>accelerator used by the VM e.g. Kvm</td>\n<td>\u201ckvm\u201d: kvm will be used</td>\n</tr>\n</tbody>\n</table>\n<p><br/></p>\n<h5 id=\"ii-customizing-the-disk-image\">ii. Customizing the Disk Image</h5>\n<p>In <code class=\"language-plaintext highlighter-rouge\">[disk-name].json</code>, disk image size can be customized using following variable:</p>\n<table>\n<thead>\n<tr>\n<th>Variable</th>\n<th>Purpose</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><a href=\"https://www.packer.io/docs/builders/qemu.html#disk_size\">image_size</a> <strong>(should be modified)</strong></td>\n<td>size of the disk image, in megabytes</td>\n<td>\u201c8192\u201d: the image has the size of 8 GB</td>\n</tr>\n<tr>\n<td>[image_name]</td>\n<td>name of the built disk image</td>\n<td>\u201cboot-exit\u201d</td>\n</tr>\n</tbody>\n</table>\n<p><br/></p>\n<h5 id=\"iii-file-transfer\">iii. File Transfer</h5>\n<p>While building a disk image, users would need to move their files (benchmarks, data sets etc.) to\nthe disk image. In order to do this file transfer, in <code class=\"language-plaintext highlighter-rouge\">[disk-name].json</code> under <code class=\"language-plaintext highlighter-rouge\">provisioners</code>, you could add the following:</p>\n<div class=\"language-shell highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">{</span>\n    <span class=\"s2\">\"type\"</span>: <span class=\"s2\">\"file\"</span>,\n    <span class=\"s2\">\"source\"</span>: <span class=\"s2\">\"post_installation.sh\"</span>,\n    <span class=\"s2\">\"destination\"</span>: <span class=\"s2\">\"/home/gem5/\"</span>,\n    <span class=\"s2\">\"direction\"</span>: <span class=\"s2\">\"upload\"</span>\n<span class=\"o\">}</span>\n</code></pre></div></div>\n<p>The above example copies the file <code class=\"language-plaintext highlighter-rouge\">post_installation.sh</code> from the host to <code class=\"language-plaintext highlighter-rouge\">/home/gem5/</code> in the disk image.\nThis method is also capable of copying a folder from host to the disk image and vice versa.\nIt is important to note that the trailing slash affects the copying process <a href=\"https://www.packer.io/docs/provisioners/file.html#directory-uploads\">(more details)</a>.\nThe following are some notable examples of the effect of using slash at the end of the paths.</p>\n<table>\n<thead>\n<tr>\n<th><code class=\"language-plaintext highlighter-rouge\">source</code></th>\n<th><code class=\"language-plaintext highlighter-rouge\">destination</code></th>\n<th><code class=\"language-plaintext highlighter-rouge\">direction</code></th>\n<th><code class=\"language-plaintext highlighter-rouge\">Effect</code></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">foo.txt</code></td>\n<td><code class=\"language-plaintext highlighter-rouge\">/home/gem5/bar.txt</code></td>\n<td><code class=\"language-plaintext highlighter-rouge\">upload</code></td>\n<td>copy file (host) to file (image)</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">foo.txt</code></td>\n<td><code class=\"language-plaintext highlighter-rouge\">bar/</code></td>\n<td><code class=\"language-plaintext highlighter-rouge\">upload</code></td>\n<td>copy file (host) to folder (image)</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">/foo</code></td>\n<td><code class=\"language-plaintext highlighter-rouge\">/tmp</code></td>\n<td><code class=\"language-plaintext highlighter-rouge\">upload</code></td>\n<td><code class=\"language-plaintext highlighter-rouge\">mkdir /tmp/foo</code> (image);  <code class=\"language-plaintext highlighter-rouge\">cp -r /foo/* (host) /tmp/foo/ (image)</code>;</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">/foo/</code></td>\n<td><code class=\"language-plaintext highlighter-rouge\">/tmp</code></td>\n<td><code class=\"language-plaintext highlighter-rouge\">upload</code></td>\n<td><code class=\"language-plaintext highlighter-rouge\">cp -r /foo/* (host) /tmp/ (image)</code></td>\n</tr>\n</tbody>\n</table>\n<p>If <code class=\"language-plaintext highlighter-rouge\">direction</code> is <code class=\"language-plaintext highlighter-rouge\">download</code>, the files will be copied from the image to the host.</p>\n<p><strong>Note</strong>: <a href=\"#customizingscripts3\">This is a way to run script once after installing Ubuntu without copying to the disk image</a>.</p>\n<h5 id=\"iv-install-benchmark-dependencies\">iv. Install Benchmark Dependencies</h5>\n<p>To install the dependencies, you can use a bash script <code class=\"language-plaintext highlighter-rouge\">post_installation.sh</code>, which will be run after the Ubuntu installation and file copying is done.\nFor example, if we want to install <code class=\"language-plaintext highlighter-rouge\">gfortran</code>, add the following in <code class=\"language-plaintext highlighter-rouge\">post_installation.sh</code>:</p>\n<div class=\"language-shell highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">echo</span> <span class=\"s1\">'12345'</span> | <span class=\"nb\">sudo </span>apt-get <span class=\"nb\">install </span>gfortran<span class=\"p\">;</span>\n</code></pre></div></div>\n<p>In the above example, we assume that the user password is <code class=\"language-plaintext highlighter-rouge\">12345</code>.\nThis is essentially a bash script that is executed on the VM after the file copying is done, you could modify the script as a bash script to fit any purpose.</p>\n<h5 id=\"v-running-other-scripts-on-disk-image\">v. Running Other Scripts on Disk Image</h5>\n<p>In <code class=\"language-plaintext highlighter-rouge\">[disk-name].json</code>, we could add more scripts to <code class=\"language-plaintext highlighter-rouge\">provisioners</code>.\nNote that the files are on the host, but the effects are on the disk image.\nFor example, the following example runs <code class=\"language-plaintext highlighter-rouge\">post_installation.sh</code> after Ubuntu is installed,</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">{</span>\n    <span class=\"s2\">\"type\"</span>: <span class=\"s2\">\"shell\"</span>,\n    <span class=\"s2\">\"execute_command\"</span>: <span class=\"s2\">\"echo '{{ user </span><span class=\"sb\">`</span>ssh_password<span class=\"sb\">`</span><span class=\"s2\"> }}' | {{.Vars}} sudo -E -S bash '{{.Path}}'\"</span>,\n    <span class=\"s2\">\"scripts\"</span>:\n    <span class=\"o\">[</span>\n        <span class=\"s2\">\"post-installation.sh\"</span>\n    <span class=\"o\">]</span>\n<span class=\"o\">}</span>\n</code></pre></div></div>\n<h4 id=\"d-build-the-disk-image\">d. Build the Disk Image</h4>\n<h5 id=\"i-build\">i. Build</h5>\n<p>In order to build a disk image, the template file is first validated using:</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>./packer validate <span class=\"o\">[</span>disk-name].json\n</code></pre></div></div>\n<p>Then, the template file can be used to build the disk image:</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>./packer build <span class=\"o\">[</span>disk-name].json\n</code></pre></div></div>\n<p>On a fairly recent machine, the building process should not take more than 15 minutes to complete.\nThe disk image with the user-defined name (image_name) will be produced in a folder called [image_name]-image.\n<a href=\"#inspect\">We recommend to use a VNC viewer in order to inspect the building process</a>.</p>\n<h5 id=\"ii-inspect-the-building-process\">ii. Inspect the Building Process</h5>\n<p>While the building of disk image takes place, Packer will run a VNC (Virtual Network Computing) server and you will be able to see the building process by connecting to the VNC server from a VNC client. There are a plenty of choices for VNC client. When you run the Packer script, it will tell you which port is used by the VNC server. For example, if it says <code class=\"language-plaintext highlighter-rouge\">qemu: Connecting to VM via VNC (127.0.0.1:5932)</code>, the VNC port is 5932.\nTo connect to VNC server from the VNC client, use the address <code class=\"language-plaintext highlighter-rouge\">127.0.0.1:5932</code> for a port number 5932.\nIf you need port forwarding to forward the VNC port from a remote machine to your local machine, use SSH tunneling</p>\n<div class=\"language-shell highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>ssh <span class=\"nt\">-L</span> 5932:127.0.0.1:5932 &lt;username&gt;@&lt;host&gt;\n</code></pre></div></div>\n<p>This command will forward port 5932 from the host machine to your machine, and then you will be able to connect to the VNC server using the address <code class=\"language-plaintext highlighter-rouge\">127.0.0.1:5932</code> from your VNC viewer.</p>\n<p><strong>Note</strong>: While Packer is installing Ubuntu, the terminal screen will display \u201cwaiting for SSH\u201d without any update for a long time.\nThis is not an indicator of whether the Ubuntu installation produces any errors.\nTherefore, we strongly recommend using VNC viewer at least once to inspect the image building process.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/fullsystem/devices\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/fullsystem/guest_binaries\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/fullsystem/m5term",
        "title": "m5 term",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"m5-term\">m5 term</h1>\n<p>The m5term program allows the user to connect to the simulated console interface that full-system gem5 provides. Simply change into the util/term directory and build m5term:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>% cd gem5/util/term\n% make\ngcc  -o m5term term.c\n% make install\nsudo install -o root -m 555 m5term /usr/local/bin\n</code></pre></div></div>\n<p>The usage of m5term is:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>./m5term &lt;host&gt; &lt;port&gt;\n</code></pre></div></div>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>&lt;host&gt; is the host that is running gem5\n\n&lt;port&gt; is the console port to connect to. gem5 defaults to\nusing port 3456, but if the port is used, it will try the next\nhigher port until it finds one available.\n\nIf there are multiple systems running within one simulation,\nthere will be a console for each one.  (The first system's\nconsole will be on 3456 and the second on 3457 for example)\n\nm5term uses '~' as an escape character.  If you enter\nthe escape character followed by a '.', the m5term program\nwill exit.\n</code></pre></div></div>\n<p>m5term can be used to interactively work with the simulator, though users must often set various terminal settings to get things to work</p>\n<p>A slightly shortened example of m5term in action:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>% m5term localhost 3456\n==== m5 slave console: Console 0 ====\nM5 console\nGot Configuration 127\nmemsize 8000000 pages 4000\nFirst free page after ROM 0xFFFFFC0000018000\nHWRPB 0xFFFFFC0000018000 l1pt 0xFFFFFC0000040000 l2pt 0xFFFFFC0000042000 l3pt_rpb 0xFFFFFC0000044000 l3pt_kernel 0xFFFFFC0000048000 l2reserv 0xFFFFFC0000046000\nCPU Clock at 2000 MHz IntrClockFrequency=1024\nBooting with 1 processor(s)\n...\n...\nVFS: Mounted root (ext2 filesystem) readonly.\nFreeing unused kernel memory: 480k freed\ninit started:  BusyBox v1.00-rc2 (2004.11.18-16:22+0000) multi-call binary\n\nPTXdist-0.7.0 (2004-11-18T11:23:40-0500)\n\nmounting filesystems...\nEXT2-fs warning: checktime reached, running e2fsck is recommended\nloading script...\nScript from M5 readfile is empty, starting bash shell...\n# ls\nbenchmarks  etc         lib         mnt         sbin        usr\nbin         floppy      lost+found  modules     sys         var\ndev         home        man         proc        tmp         z\n#\n</code></pre></div></div>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/fullsystem/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/gem5_resources/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/gem5-apis",
        "title": "The gem5 API",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<p>For complete documentation of all methods and variables tagged as APIs, please\nsee our <a href=\"http://doxygen.gem5.org/release/v20-1-0-0/modules.html\">Doxygen Module page</a>.</p>\n<h1 id=\"the-gem5-api\">The gem5 API</h1>\n<p>In efforts to improve product stability, the gem5 development team is gradually\ntagging methods and variables within gem5 as APIs which developers will need to\nundergo specific procedures to change. Our goal with the gem5 API is to provide\na stable interface for users to build gem5 models, and extend the gem5\ncode-base, with guarantees these APIs will not change in a dramatic sudden\nmanner between gem5 releases.</p>\n<h2 id=\"how-is-the-gem5-api-documented\">How is the gem5 API documented?</h2>\n<p>We document the gem5 APIs using the <a href=\"https://www.doxygen.nl/index.html\">Doxygen documentation generation tool</a>. This means you may see the API tagged\nat the level of source-code and via our <a href=\"http://doxygen.gem5.org\">web-based documentation</a>. We use Doxygen\u2019s <code class=\"language-plaintext highlighter-rouge\">@ingroup</code> tag, to specify a\nmethod/variables as part of the gem5 API. We break the API down into\nsub-domains such as <code class=\"language-plaintext highlighter-rouge\">api_simobject</code> or <code class=\"language-plaintext highlighter-rouge\">api_ports</code>, though all the gem5 APIs\nare tagged with the prefix <code class=\"language-plaintext highlighter-rouge\">api_</code>. For example, we tag SimObject\u2019s <code class=\"language-plaintext highlighter-rouge\">params()</code>\nfunction as follows:</p>\n<div class=\"language-cpp highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"cm\">/**\n* @return This function returns the cached copy of the object parameters.\n*\n* @ingroup api_simobject\n*/</span>\n<span class=\"k\">const</span> <span class=\"n\">Params</span> <span class=\"o\">*</span><span class=\"n\">params</span><span class=\"p\">()</span> <span class=\"k\">const</span> <span class=\"p\">{</span> <span class=\"k\">return</span> <span class=\"n\">_params</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n</code></pre></div></div>\n<p>Via Doxygen automatic generation, the list of gem5 APIs can be found on the\n<a href=\"http://doxygen.gem5.org/release/current/modules.html\">Doxygen module page</a>.\nIn this example, the entire list of SimObject APIs are noted in the\n<a href=\"http://doxygen.gem5.org/release/current/group__api__simobject.html\">SimObject API page</a>. The\ndefinitions of different API groups can be found in\n<a href=\"https://github.com/gem5/gem5/blob/stable/src/doxygen/group_definitions.hh\"><code class=\"language-plaintext highlighter-rouge\">src/doxygen/group_definitions.hh</code></a>.</p>\n<h3 id=\"notes-for-developers\">Notes for developers</h3>\n<p>If a developer wishes to tag a new method/variable as part of the gem5 API,\nthe gem5 community should be consulted. APIs are intended to stay unaltered for\nsome time. To avoid the gem5 project becoming encumbered with \u201ctoo many APIs\u201d,\nwe strongly advise those wishing to extend the API to communicate to the\ngem5 development team as to why the API will be of value. The\n<a href=\"https://github.com/orgs/gem5/discussions/categories/gem5-dev\">gem5 Discussion page</a>\nis a good communication channel for this.</p>\n<h2 id=\"how-can-the-api-change\">How can the API change?</h2>\n<p>We do not guarantee the gem5 API will never change over time. gem5 is a\nproduct under continual development which must adapt to the needs of the\ncomputer architecture research community. However, we guarantee that API\nchanges will follow strict guidelines outlined below.</p>\n<ol>\n<li>\n<p>When an API method or variable is altered, it will be done so in a way in\nwhich the new API will exist alongside the old, with the old API tagged as\ndeprecated and still functional.</p>\n</li>\n<li>\n<p>The old, deprecated API will exist for two gem5 major cycles before being\nremoved entirely from code-base, though gem5 developers may choose to keep a\ndeprecated API in the code-base for longer. For example, if an API is tagged as\ndeprecated in gem5 21.0, it will also still exist (still tagged as deprecated)\nin gem5 21.1. It may be removed entirely in gem5 21.2, though this will be left\nto the discretion of the gem5 developers.</p>\n</li>\n<li>\n<p>The gem5 deprecated C++ APIs will be tagged with the C++ deprecated\nattribute (<code class=\"language-plaintext highlighter-rouge\">[[deprecated(&lt;msg&gt;)]]</code>). When utilizing a deprecated C++ API, a\nwarning will be given at compilation time specifying which API to transition\nto. The gem5 deprecated Python parameter APIs are wrapped with our <a href=\"https://github.com/gem5/gem5/blob/bd13e8e206e6c86581cf9afa904ef1060351a4b0/src/python/m5/params.py#L2166\">bespoke\n<code class=\"language-plaintext highlighter-rouge\">DeprecatedParam</code> class</a>.\nPython parameters wrapped in this class will throw an warning when used and\nspecify which API to transition to.</p>\n</li>\n</ol>\n<h3 id=\"notes-for-developers-1\">Notes for Developers</h3>\n<p>Prior to making any changes to the gem5 API the <a href=\"/ask-a-question/\">gem5-dev mailing list</a> should be consulted. Changing the API, for whatever reason,\n<strong>will</strong> be subject to higher scrutiny than other changes. Developers should\nbe prepared to provide compelling arguments as to why the API needs changed. We\nstrongly recommend API changes are discussed or they may be rejected during the\ncode review.</p>\n<p>When creating a new API the old API must be tagged as deprecated and the new\nAPI created to exist alongside the old. <strong>It is of upmost importance that the\nold, deprecated API is maintained and not deleted</strong>.</p>\n<p>As an example, take the following code:</p>\n<div class=\"language-cpp highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"cm\">/**\n * @ingroup api_bitfield\n */</span>\n<span class=\"kr\">inline</span> <span class=\"kt\">uint64_t</span>\n<span class=\"nf\">mask</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">first</span><span class=\"p\">,</span> <span class=\"kt\">int</span> <span class=\"n\">last</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"k\">return</span> <span class=\"n\">mbits</span><span class=\"p\">((</span><span class=\"kt\">uint64_t</span><span class=\"p\">)</span><span class=\"o\">-</span><span class=\"mi\">1LL</span><span class=\"p\">,</span> <span class=\"n\">first</span><span class=\"p\">,</span> <span class=\"n\">last</span><span class=\"p\">);</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n<p>This function is part of the gem5 bitfield API. It is a basic mask function\nthat takes the MSB (first) and the LSB (last) for the generation of a 64-bit.\nLet us assume there is a good argument that this function should be replaced\nwith one that takes the MSB (first), and the length of the mask instead.</p>\n<p>To start, the old API needs maintained (i.e., not changed) and tagged with the\n<code class=\"language-plaintext highlighter-rouge\">[[deprecated(&lt;msg&gt;)]]</code> tag. The message (<code class=\"language-plaintext highlighter-rouge\">&lt;msg&gt;</code>) Should state the new API\nto use, and the API tagging should be removed. The new API should then be\ncreated and tagged. So, using our example:</p>\n<div class=\"language-cpp highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"p\">[[</span><span class=\"n\">deprecated</span><span class=\"p\">(</span><span class=\"s\">\"Use mask_length instead.\"</span><span class=\"p\">)]]</span>\n<span class=\"kr\">inline</span> <span class=\"kt\">uint64_t</span>\n<span class=\"nf\">mask</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">first</span><span class=\"p\">,</span> <span class=\"kt\">int</span> <span class=\"n\">last</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"k\">return</span> <span class=\"n\">mbits</span><span class=\"p\">((</span><span class=\"kt\">uint64_t</span><span class=\"p\">)</span><span class=\"o\">-</span><span class=\"mi\">1LL</span><span class=\"p\">,</span> <span class=\"n\">first</span><span class=\"p\">,</span> <span class=\"n\">last</span><span class=\"p\">);</span>\n<span class=\"p\">}</span>\n\n<span class=\"cm\">/**\n * @ingroup api_bitfield\n */</span>\n<span class=\"kr\">inline</span> <span class=\"kt\">uint64_t</span>\n<span class=\"n\">mask_length</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">first</span><span class=\"p\">,</span> <span class=\"kt\">int</span> <span class=\"n\">length</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"k\">return</span> <span class=\"n\">mbits</span><span class=\"p\">((</span><span class=\"kt\">uint64_t</span><span class=\"p\">)</span><span class=\"o\">-</span><span class=\"mi\">1LL</span><span class=\"p\">,</span> <span class=\"n\">first</span><span class=\"p\">,</span> <span class=\"n\">first</span> <span class=\"o\">+</span> <span class=\"n\">length</span><span class=\"p\">);</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n<p>Here a new function, <code class=\"language-plaintext highlighter-rouge\">mask_length</code>, has been created. It has been tagged\ncorrectly via Doxygen. The old API, <code class=\"language-plaintext highlighter-rouge\">mask</code> exists but has the\n<code class=\"language-plaintext highlighter-rouge\">[[deprecated]]</code> annotation added. The message provided states which API\nreplaces it.</p>\n<p>The developer then needs to replace all usage of <code class=\"language-plaintext highlighter-rouge\">mask</code> in the code-base with\n<code class=\"language-plaintext highlighter-rouge\">mask_length</code>. A warning will be given at compile time if <code class=\"language-plaintext highlighter-rouge\">mask</code> is used,\nstating that it is deprecated and to \u201cUse mask_length instead.\u201d.</p>\n<p>Occasionally there may be need to change the python API interface, which\nrelates to tagged APIs. For example, let\u2019s take the below code:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">class</span> <span class=\"nc\">TLBCoalescer</span><span class=\"p\">(</span><span class=\"n\">ClockedObject</span><span class=\"p\">):</span>\n    <span class=\"nb\">type</span> <span class=\"o\">=</span> <span class=\"s\">'TLBCoalescer'</span>\n    <span class=\"n\">cxx_class</span> <span class=\"o\">=</span> <span class=\"s\">'TLBCoalescer'</span>\n    <span class=\"n\">cxx_header</span> <span class=\"o\">=</span> <span class=\"s\">'gpu-compute/tlb_coalescer.hh'</span>\n\n    <span class=\"p\">...</span>\n\n    <span class=\"n\">slave</span>    <span class=\"o\">=</span> <span class=\"n\">VectorResponsePort</span><span class=\"p\">(</span><span class=\"s\">\"Port on side closer to CPU/CU\"</span><span class=\"p\">)</span>\n    <span class=\"n\">master</span>   <span class=\"o\">=</span> <span class=\"n\">VectorRequestPort</span><span class=\"p\">(</span><span class=\"s\">\"Port on side closer to memory\"</span><span class=\"p\">)</span>\n\n   <span class=\"p\">...</span>\n</code></pre></div></div>\n<p><a href=\"https://github.com/gem5/gem5/tree/392c1ced53827198652f5eda58e1874246b024f4\">In recent revisions</a>\nthe terms <code class=\"language-plaintext highlighter-rouge\">master</code> and <code class=\"language-plaintext highlighter-rouge\">slave</code> have been replaced. Though, the <code class=\"language-plaintext highlighter-rouge\">slave</code> and\n<code class=\"language-plaintext highlighter-rouge\">master</code> terminology are widely used, so much so we consider them part of the\nold API. We therefore wish to deprecate this API is a safe manner while\nchanging <code class=\"language-plaintext highlighter-rouge\">master</code> and <code class=\"language-plaintext highlighter-rouge\">slave</code> with <code class=\"language-plaintext highlighter-rouge\">cpu_side_ports</code> and <code class=\"language-plaintext highlighter-rouge\">mem_side_ports</code>. To\ndo so we would maintain the <code class=\"language-plaintext highlighter-rouge\">master</code> and <code class=\"language-plaintext highlighter-rouge\">slave</code> variables but utilize our\n<a href=\"https://github.com/gem5/gem5/blob/bd13e8e206e6c86581cf9afa904ef1060351a4b0/src/python/m5/params.py#L2166\"><code class=\"language-plaintext highlighter-rouge\">DeprecatedParam</code> Class</a>\nto produce warnings when and if these deprecated variables are used. Working on\nour example, we would produce the following:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">class</span> <span class=\"nc\">TLBCoalescer</span><span class=\"p\">(</span><span class=\"n\">ClockedObject</span><span class=\"p\">):</span>\n    <span class=\"nb\">type</span> <span class=\"o\">=</span> <span class=\"s\">'TLBCoalescer'</span>\n    <span class=\"n\">cxx_class</span> <span class=\"o\">=</span> <span class=\"s\">'TLBCoalescer'</span>\n    <span class=\"n\">cxx_header</span> <span class=\"o\">=</span> <span class=\"s\">'gpu-compute/tlb_coalescer.hh'</span>\n\n    <span class=\"p\">...</span>\n\n    <span class=\"n\">cpu_side_ports</span> <span class=\"o\">=</span> <span class=\"n\">VectorResponsePort</span><span class=\"p\">(</span><span class=\"s\">\"Port on side closer to CPU/CU\"</span><span class=\"p\">)</span>\n    <span class=\"n\">slave</span>    <span class=\"o\">=</span> <span class=\"n\">DeprecatedParam</span><span class=\"p\">(</span><span class=\"n\">cpu_side_ports</span><span class=\"p\">,</span>\n                        <span class=\"s\">'`slave` is now called `cpu_side_ports`'</span><span class=\"p\">)</span>\n    <span class=\"n\">mem_side_ports</span> <span class=\"o\">=</span> <span class=\"n\">VectorRequestPort</span><span class=\"p\">(</span><span class=\"s\">\"Port on side closer to memory\"</span><span class=\"p\">)</span>\n    <span class=\"n\">master</span>   <span class=\"o\">=</span> <span class=\"n\">DeprecatedParam</span><span class=\"p\">(</span><span class=\"n\">mem_side_ports</span><span class=\"p\">,</span>\n                        <span class=\"s\">'`master` is now called `mem_side_ports`'</span><span class=\"p\">)</span>\n\n   <span class=\"p\">...</span>\n</code></pre></div></div>\n<p>Note the use of <code class=\"language-plaintext highlighter-rouge\">DeprecatedParam</code> that both ensures <code class=\"language-plaintext highlighter-rouge\">master</code> and <code class=\"language-plaintext highlighter-rouge\">slave</code> still\nfunction by redirecting to <code class=\"language-plaintext highlighter-rouge\">mem_side_ports</code> and <code class=\"language-plaintext highlighter-rouge\">cpu_side_ports</code> respectively,\nas well as providing a comment explaining why this API was deprecated. This\nwill be displayed to the user as a warning if <code class=\"language-plaintext highlighter-rouge\">master</code> or <code class=\"language-plaintext highlighter-rouge\">slave</code> are ever\nused.</p>\n<p>As with all changes to the gem5 source, these changes will have to go through\nour Gerrit code review system before being merged into the <code class=\"language-plaintext highlighter-rouge\">develop</code> branch,\nand eventually making its way to our <code class=\"language-plaintext highlighter-rouge\">stable</code> branch as part of a gem5 release.\nIn line with our API policy, these deprecated APIs must exist in a\nmarked-as-deprecated state for two gem5 major release cycles. After this they\nmay be removed though developers are under no requirement to do so.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/gem5art/tutorials/microbench-tutorial\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/architecture_support/arm_implementation/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/gem5_resources",
        "title": "gem5 Resources",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"gem5-resources\">gem5 Resources</h1>\n<p>gem5 Resources is a repository providing sources for artifacts known and\nproven compatible with the gem5 architecture simulator. These resources\nare not necessary for the compilation or running of gem5, but may aid users\nin producing certain simulations.</p>\n<h2 id=\"why-gem5-resources\">Why gem5 Resources?</h2>\n<p>gem5 has been designed with flexibility in mind. Users may simulate a wide\nvariety of hardware, with an equally wide variety of workloads. However,\nrequiring users to find and configure workloads for gem5 (their own disk\nimages, their own OS boots, their own tests, etc.) is a significant\ninvestment, and a hurdle to many.</p>\n<p>The purpose of gem5 Resources is therefore <strong>to provide a stable set of\ncommonly used resources, with proven and documented compatibility with gem5</strong>.\nIn addition to this, gem5 resources also puts emphasis on <strong>reproducibility\nof experiments</strong> by providing citable, stable resources, tied to a particular\nrelease of gem5.</p>\n<h2 id=\"where-can-i-obtain-the-gem5-resources\">Where can I obtain the gem5 Resources?</h2>\n<p>To find a specific resource with the gem5 Resources, we recommend using the <a href=\"https://resources.gem5.org\">gem5 Resources Website</a>. Detailed information on how searching, filtering and sorting works on this website is on this <a href=\"https://resources.gem5.org/help\">help page</a>.</p>\n<p>The gem5 Resources are hosted on our Google Cloud Bucket. Links to the\nresources can be found <a href=\"https://gem5.googlesource.com/public/gem5-resources/+/refs/heads/stable/README.md\">gem5 resources README.md file</a>.\nThe resource metadata is stored in a MongoDB database hosted on MongoDB Atlas.\nTo request updates to gem5 resources, create an issue or mail gem5-dev.</p>\n<h2 id=\"using-a-resource-from-the-gem5-resources-website-in-gem5\">Using a Resource from the gem5 Resources Website in gem5</h2>\n<p>When you find the Resource that you want to use in your simulation, navigate to the \u2018Usage\u2019 tab of that Resource.</p>\n<p>For the purpose of this tutorial, let\u2019s assume that the Resource you are looking for is <code class=\"language-plaintext highlighter-rouge\">riscv-hello</code>, found <a href=\"https://resources.gem5.org/resources/riscv-hello\">here</a>.In the <a href=\"https://resources.gem5.org/resources/riscv-hello/usage\">\u2018Usage\u2019</a> tab of this Resource, you will find the code that can be pasted in a gem5 simulation to use this Resource.</p>\n<p>In this case, the code is <code class=\"language-plaintext highlighter-rouge\">obtain_resource(resource_id=\"riscv-hello\")</code>.</p>\n<p>To use the <code class=\"language-plaintext highlighter-rouge\">obtain_resource</code> function, you require the following import statement:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>from gem5.resources.resource import obtain_resource\n</code></pre></div></div>\n<p>The <code class=\"language-plaintext highlighter-rouge\">obtain_resource</code> function accepts the following parameters:</p>\n<ul>\n<li><code class=\"language-plaintext highlighter-rouge\">resource_id</code>: The ID of the Resource you want to use.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">resource_version</code>: An optional parameter that specifies the version of the Resource you want to use. If not specified, the latest version of the Resource compatible with the version of gem5 being used will be used.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">clients</code>: An optional parameter that specifies the list of clients that gem5 would search for the Resource in. If not specified, gem5 will search for the Resource in all clients specified in the <code class=\"language-plaintext highlighter-rouge\">src/python/gem5_default_config.py</code> file. By default, gem5 will use the public MongoDB metadata database to find resources. This can be overridden to specify your own local resource metadata.</li>\n</ul>\n<h2 id=\"using-a-workload-from-the-gem5-resources-website-in-gem5\">Using a Workload from the gem5 Resources Website in gem5</h2>\n<p>When you find the Workload that you want to use in your simulation, navigate to the \u2018Usage\u2019 tab of that Workload.</p>\n<p>For the purpose of this tutorial, let\u2019s assume that the Workload you are looking for is <code class=\"language-plaintext highlighter-rouge\">riscv-ubuntu-20.04-boot</code>, found <a href=\"https://resources.gem5.org/resources/riscv-ubuntu-20.04-boot\">here</a>. In the <a href=\"https://resources.gem5.org/resources/riscv-ubuntu-20.04-boot/usage\">\u2018Usage\u2019</a> tab of this Workload, you will find the code that can be pasted in a gem5 simulation to use this Workload.</p>\n<p>In this case, the code is <code class=\"language-plaintext highlighter-rouge\">Workload(\"riscv-ubuntu-20.04-boot\")</code>.</p>\n<p>To use the <code class=\"language-plaintext highlighter-rouge\">Workload</code> class, you require the following import statement:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>from gem5.resources.workload import Workload\n</code></pre></div></div>\n<p>The <code class=\"language-plaintext highlighter-rouge\">Workload</code> class accepts the following parameters:</p>\n<ul>\n<li><code class=\"language-plaintext highlighter-rouge\">workload_name</code>: The name of the Workload you want to use.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">resource_directory</code>: An optional parameter that specifies where any resources should be download and accessed from.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">resource_version</code>: An optional parameter that specifies the version of the Resource that should be used. If not specified, the latest version of the Resource compatible with the version of gem5 being used will be used.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">clients</code>: An optional parameter that specifies a list of clients that gem5 would search for the Resource in. If not specified, gem5 will search for the Resource in all clients specified in the <code class=\"language-plaintext highlighter-rouge\">src/python/gem5_default_config.py</code> file.</li>\n</ul>\n<h2 id=\"using-a-custom-resource-in-gem5\">Using a Custom Resource in gem5</h2>\n<p>To use a Custom Resource in gem5, we recommend using one of the supported data sources formats in gem5. Currently, we support MongoDB Atlas, local JSON files and remote JSON files.</p>\n<p>You can use your own config file by overriding the <code class=\"language-plaintext highlighter-rouge\">GEM5_DEFAULT_CONFIG</code> variable while running a file.</p>\n<p>NOTE: Any Custom Resource you add must be compliant with the <a href=\"https://resources.gem5.org/gem5-resources-schema.json\">gem5 Resources Schema</a>.</p>\n<p>There is a utility in <code class=\"language-plaintext highlighter-rouge\">utils/gem5-resources-manager</code> which provides a GUI for updating and creating resources for both the public resources (only modifiable by gem5 admins) and local resource metadata.\nYou can find more information on the gem5 Resources Manager in the README file.</p>\n<h2 id=\"how-do-i-obtain-the-gem5-resource-sources\">How do I obtain the gem5 Resource sources?</h2>\n<p>gem5 resources sources may be obtained from\n<a href=\"https://github.com/gem5/gem5-resources\">https://github.com/gem5/gem5-resources</a>:</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>git clone https://github.com/gem5/gem5-resources\n</code></pre></div></div>\n<p>The HEAD of the <code class=\"language-plaintext highlighter-rouge\">stable</code> branch will point towards a set of resource sources\ncompatible with the latest release of gem5 (which can be obtained via\n<code class=\"language-plaintext highlighter-rouge\">git clone https://github.com/gem5/gem5.git</code>).</p>\n<p>Please consult the <a href=\"https://gem5.googlesource.com/public/gem5-resources/+/refs/heads/stable/README.md\">README.md</a>\nfile for information on compiling individual gem5 resources. Where license\npermits, the <a href=\"https://gem5.googlesource.com/public/gem5-resources/+/refs/heads/stable/README.md\">README.md</a>\nfile will provide a link to download the compiled resource from our\ndist.gem5.org Google Cloud Bucket.</p>\n<h2 id=\"how-is-gem5-resources-repository-constructed\">How is gem5 Resources repository constructed?</h2>\n<p>The structure of this repository is as follows:</p>\n<ul>\n<li><strong>README.md</strong> : This README will outline each resources, their origin,\nhow they have been modified to work with gem5 (if applicable), relevant\nlicensing information, and compilation instructions. This should be the first\nport-of-call for those looking to use a gem5 resource.</li>\n<li><strong>src</strong> : The resource sources. The gem5 resources can be found in this\ndirectory. Each sub-directory outlines a resource. Each resource contains its\nown README.md file documenting relevant information \u2013 compilation\ninstructions, usage notes, etc.</li>\n<li><strong>CHANGELOG.md</strong> : This CHANGELOG will outline the changes in a particular resource across its versions.</li>\n</ul>\n<h3 id=\"versioning\">Versioning</h3>\n<p>Each resource can have multiple versions. A version is in the form of\n<code class=\"language-plaintext highlighter-rouge\">&lt;major&gt;.&lt;minor&gt;.&lt;patch&gt;</code>. The versioning scheme is based on <a href=\"https://semver.org/\">Semantic\nVersioning</a>. Each version of a resource is linked to one\nor more gem5 versions (e.g., v20.0, v20.1, v20.2, etc.).</p>\n<p>By default, gem5 uses the latest version of a resource compatible with the\nversion of gem5 being used. However, users may specify a particular version\nof a resource to use. If a user specifies a version of a resource that is not\ncompatible with the version of gem5 being used, gem5 will throw a warning.\nYou may still use the resource at your own risk.</p>\n<h3 id=\"citing-a-resource\">Citing a Resource</h3>\n<p>We strongly recommend gem5 Resources are cited in publications to aid in\nreplication of experiments, tutorials, etc.</p>\n<p>To cite as a URL, please use the following formats:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code># For the git repository at a particular revision:\nhttps://github.com/gem5/gem5-resources/&lt;revision&gt;/src/&lt;resource&gt;\n\n# For the git repository at a particular tag:\nhttps://github.com/gem5/gem5-resources/tree/&lt;branch&gt;/src/&lt;resource&gt;\n</code></pre></div></div>\n<p>Alternatively, as BibTex:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>@misc{gem5-resources,\n  title = {gem5 Resources. Resource: &lt;resource&gt;},\n  howpublished = {\\url{https://github.com/gem5/gem5-resources/&lt;revision&gt;/src/&lt;resource&gt;}},\n  note = {Git repository at revision '&lt;revision&gt;'}\n}\n\n@misc{gem5-resources,\n  title = {gem5 Resources. Resource: &lt;resource&gt;},\n  howpublished = {\\url{https://github.com/gem5/gem5-resources/tree/&lt;branch&gt;/src/&lt;resource&gt;}},\n  note = {Git repository at tag '&lt;tag&gt;'}\n}\n</code></pre></div></div>\n<h2 id=\"how-to-i-contribute-to-gem5-resources\">How to I contribute to gem5 Resources?</h2>\n<p>Changes to the gem5 Resources repository are made to the develop branch via our\nGerrit code review system. Therefore, to make changes, first clone the\nrepository:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>git clone https://github.com/gem5/gem5-resources.git\n</code></pre></div></div>\n<p>Then make changes and commit. When ready, push to Gerrit with:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>git push origin HEAD:refs/for/stable\n</code></pre></div></div>\n<p>This will add resources to be used in the latest release of gem5.</p>\n<p>To contribute resources to the next release of gem5,</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>git clone https://github.com/gem5/gem5-resources.git\ngit checkout --track origin/develop\n</code></pre></div></div>\n<p>Then make changes, commit, and push with:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>git push origin HEAD:refs/for/develop\n</code></pre></div></div>\n<p>Commit message heads should not exceed 65 characters and start with the tag\n<code class=\"language-plaintext highlighter-rouge\">resources:</code>. The description after the header must not exceed 72 characters.</p>\n<p>E.g.:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>resources: Adding a new resources X\n\nThis is where the description of this commit will occur taking into\nnote the 72 character line limit.\n</code></pre></div></div>\n<p>We strongly advise contributors follow our <a href=\"/documentation/general_docs/development/coding_style/\">Style Guide</a> where\npossible and appropriate.</p>\n<p>Any change will then be reviewed via our <a href=\"https://gem5-review.googlesource.com\">Gerrit code review system</a>. Once fully accepted and merged into\nthe gem5 resources repository, please contact Bobby R. Bruce\n(<a href=\"mailto:bbruce@ucdavis.edu\">bbruce@ucdavis.edu</a>) to have any compiled sources\nuploaded to the gem5 resources bucket.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/fullsystem/m5term\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/gpu_models/gpufs\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/gpu_models/gpufs",
        "title": "Full System AMD GPU model",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"full-system-amd-gpu-model\"><strong>Full System AMD GPU model</strong></h1>\n<p>The Full System AMD GPU model simulates a GPU at the \u201cgfx9\u201d ISA level, as opposed to the intermediate language level. This page will give you a general overview of how to use this model, the software stack the model uses, and provide resources that detail the model and how it is implemented. <strong>It is recommended to use Full System instead of System Emulation as Full System supports the latest versions of the GPU software stack.</strong></p>\n<h2 id=\"requirements\">Requirements</h2>\n<p>The Full System GPU model is primarily designed to simulate discrete GPUs using a native software stack without modification. This means that the CPU portion of simulation is not configured for detailed simulation \u2013 only the GPU is detailed. The <a href=\"https://rocm.docs.amd.com/en/latest/\">ROCm software stack</a> limits usage to officially supported gfx9 devices listed in the <a href=\"https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html\">ROCm documentation</a>. Currently gem5 provides configurations for Vega10 (gfx900), MI210/MI250X (gfx90a), and MI300X (gfx942).</p>\n<p><em>Note:</em> Previously supported \u201cgfx9\u201d devices in older versions of ROCm still work in most cases (gfx900, gfx906). As mentioned in the ROCm documentation, these may result in runtime errors for prebuilt ROCm libraries.</p>\n<p>The CPU portion of code is ideally fast-forwarded using the KVM CPU model. Since the software stack is x86 you will need an x86 Linux host with KVM enabled to run Full System efficiently. The atomic CPU can also be used to run on non-x86 hosts or where KVM is not usable. See the <a href=\"#Running-without-kvm\">Running without KVM</a> section for details.</p>\n<h2 id=\"using-the-model\"><strong>Using the model</strong></h2>\n<p>Several places in this guide assume that gem5 and gem5-resources are located in the same base directory.</p>\n<p>The <a href=\"https://github.com/gem5/gem5\">gem5 repository</a> contains the base code of the GPU model.\nThe <a href=\"https://github.com/gem5/gem5-resources/\">gem5-resources repository</a> contains files needed to create a disk image for Full System and comes with a number of sample applications that can be used to get started with the model. We recommend users start with <a href=\"https://resources.gem5.org/resources/square\">square</a>, as it is a simple, heavily tested application that should run relatively quickly.</p>\n<h4 id=\"building-gem5\">Building gem5</h4>\n<p>The GPU model requires the GPU_VIPER cache coherence protocol which is implemented in Ruby and the Full System software stack is only supported in a simulated X86 environment. The VEGA_X86 build option uses the GPU_VIPER protocol and x86. Therefore, gem5 must be built using the VEGA_X86 build option:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>scons build/VEGA_X86/gem5.opt\n</code></pre></div></div>\n<p>The Full System GPU model is built similarly to a CPU only version of gem5. Refer to the <a href=\"https://www.gem5.org/documentation/general_docs/building\">building gem5</a> documentation for how to build gem5, including number of build threads, linker options, and gem5 binary targets.</p>\n<h4 id=\"building-disk-image-and-kernel\">Building Disk Image and Kernel</h4>\n<p>Just like a CPU only version of gem5, the Full System GPU model requires a disk image and kernel to run. The <a href=\"https://github.com/gem5/gem5-resources/\">gem5-resources repository</a> provides a one-step disk image builder to create a disk image for the GPU model with all of the software requirements installed.</p>\n<p>From your base directory with gem5 and gem5-resources cloned, navigate to <a href=\"https://github.com/gem5/gem5-resources/tree/stable/src/x86-ubuntu-gpu-ml\">gem5-resources/src/x86-ubuntu-gpu-ml</a>. This directory contains a file <code class=\"language-plaintext highlighter-rouge\">./build.sh</code> to create the disk image in one step. Building the disk depends on the <a href=\"https://www.packer.io/\">packer</a> tool which uses <a href=\"https://www.qemu.org/\">QEMU</a> as a backend. See the <a href=\"https://github.com/gem5/gem5-resources/blob/stable/src/x86-ubuntu-gpu-ml/BUILDING.md\">BUILDING.md</a> guide for troubleshooting. Generally, the disk image can be created in one step using the following command:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>./build.sh\n</code></pre></div></div>\n<p>This process takes approximately 15-20 minutes and is mostly bound by download speed as a majority of the time is spent downloading Ubuntu packages.</p>\n<p>Building the disk image will also extract the Linux kernel. The extracted Linux kernel <em>must</em> be used with the disk image. In other words, you cannot input an arbitrary kernel to gem5 otherwise the GPU driver may not load successfully.</p>\n<p>After this process your environment should contain:</p>\n<ul>\n<li>Disk image: <code class=\"language-plaintext highlighter-rouge\">gem5-resources/src/x86-ubuntu-gpu-ml/disk-image/x86-ubuntu-gpu-ml</code></li>\n<li>Kernel: <code class=\"language-plaintext highlighter-rouge\">gem5-resources/src/x86-ubuntu-gpu-ml/vmlinux-gpu-ml</code></li>\n</ul>\n<h4 id=\"building-gpu-applications\">Building GPU applications</h4>\n<p>The GPU model is designed to run unmodified GPU binaries. If you have an application which runs on AMD GPU hardware and that hardware is supported in gem5, you can run the same binary in gem5. Note that as this is simulation, the application will need to be scaled down to a reasonable size to simulate in a realistic amount of time.</p>\n<p>Building applications for the GPU model is similar to <a href=\"https://www.gem5.org/documentation/general_docs/compiling_workloads/\">cross compiling</a> when the simulated ISA does not match the host. Either you must have the development tools installed locally or containerization like Docker can be used. Docker images to build GPU applications are provided with gem5 in <a href=\"https://github.com/gem5/gem5/tree/stable/util/dockerfiles/gpu-fs\">util/dockerfiles/gpu-fs</a>. You may either build this image or use the gem5 provided image at <code class=\"language-plaintext highlighter-rouge\">ghcr.io/gem5/gpu-fs</code>. This docker image provides a specific version of ROCm. The ROCm version in the Dockerfile must match the ROCm version on the disk image being used to simulate gem5. The docker and disk image versions are synced upon gem5 releases. The instructions below show an example using the pre-built gem5 docker on GitHub container registry (ghcr.io).</p>\n<p><a href=\"https://github.com/gem5/gem5-resources/tree/stable/src/gpu/square\">Square</a> is a simple application provided in gem5-resources which can be used to get started with the model. Generally, the <code class=\"language-plaintext highlighter-rouge\">src/gpu</code> directory of gem5-resources contains a <code class=\"language-plaintext highlighter-rouge\">Makefile.default</code> which is used to build a native application and <code class=\"language-plaintext highlighter-rouge\">Makefile.gpufs</code> which contains application annotated with <a href=\"https://www.gem5.org/documentation/general_docs/m5ops/\">m5ops</a> that will only run within gem5.</p>\n<p>To build square using the gem5 provided docker image, navigate to the square directory and use the <code class=\"language-plaintext highlighter-rouge\">Makefile.default</code> Makefile:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>cd gem5-resources/src/gpu/square\ndocker run --rm -u $UID:$GID -v $PWD:$PWD -w $PWD ghcr.io/gem5/gpu-fs make -f Makefile.default\n</code></pre></div></div>\n<p>The square binary should then be located at <code class=\"language-plaintext highlighter-rouge\">gem5-resources/src/gpu/square/bin.default/square.default</code></p>\n<h4 id=\"testing-gpu-application\">Testing GPU application</h4>\n<p>The GPU model provides multiple gfx9 configurations to simulate GPU applications. The configurations specify the ISA (e.g., gfx942, gfx90a) and generally a minimally sized device. <em>They are not intended to be indicative of real hardware measurements</em>. In the gem5 repository, these are:</p>\n<ul>\n<li>MI300X: <code class=\"language-plaintext highlighter-rouge\">configs/example/gpufs/mi300.py</code></li>\n<li>MI210 / MI250: <code class=\"language-plaintext highlighter-rouge\">configs/example/gpufs/mi200.py</code></li>\n</ul>\n<p>The GPU model uses config script based configuration (i.e., not <a href=\"https://www.gem5.org/documentation/gem5-stdlib/overview\">standard library</a>) which uses command line arguments as the primary way to modify simulation parameters. However, most common configuration options are set by the top-level scripts (e.g., <code class=\"language-plaintext highlighter-rouge\">configs/example/gpufs/mi300.py</code>). The main required arguments are disk image, kernel, and application.</p>\n<p>Using the disk image and kernel created above and the square binary built above, square can be run with the following command:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>build/VEGA_X86/gem5.opt configs/example/gpufs/mi300.py --disk-image gem5-resources/src/x86-ubuntu-gpu-ml/disk-image/x86-ubuntu-gpu-ml --kernel gem5-resources/src/x86-ubuntu-gpu-ml/vmlinux-gpu-ml --app gem5-resources/src/gpu/square/bin.default/square.default\n</code></pre></div></div>\n<p>In Full System the output of the simulator and the output of the simulated system are shown in two separate locations. By default, the gem5 output prints to the terminal where gem5 is run. The simulated terminal output is located in the gem5 output directory which is <code class=\"language-plaintext highlighter-rouge\">m5out</code> by default.</p>\n<p>Once gem5 completes (or while running) the output of the Full System simulation can be seen in <code class=\"language-plaintext highlighter-rouge\">m5out/system.pc.com_1.device</code>. For the square example, the application will print \u201cPASSED!\u201d to the simulated terminal output upon successful completion.</p>\n<h4 id=\"using-python-or-shell-scripts\">Using Python or shell scripts</h4>\n<p>Python scripts such as PyTorch, TensorFlow, etc. and shell scripts can be passed directly as the value of the <code class=\"language-plaintext highlighter-rouge\">--app</code> command line. For example, the following minimal PyTorch application can be run directly when saved as <code class=\"language-plaintext highlighter-rouge\">pytorch_test.py</code>:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>#!/usr/bin/env python3\n\nimport torch\n\nx = torch.rand(5, 3).to('cuda')\ny = torch.rand(3, 5).to('cuda')\n\nz = x @ y\n</code></pre></div></div>\n<p>For example:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>build/VEGA_X86/gem5.opt configs/example/gpufs/mi300.py --disk-image gem5-resources/src/x86-ubuntu-gpu-ml/disk-image/x86-ubuntu-gpu-ml --kernel gem5-resources/src/x86-ubuntu-gpu-ml/vmlinux-gpu-ml --app ./pytorch_test.py\n</code></pre></div></div>\n<h4 id=\"input-files\">Input files</h4>\n<p>The GPU model configuration files are designed to copy the file provided to the <code class=\"language-plaintext highlighter-rouge\">--app</code> option into the simulator. <strong>Full System gem5 cannot read files from your host system!</strong> If your application requires input files, they must be copied into the disk image. See instructions for <a href=\"https://github.com/gem5/gem5-resources/blob/stable/src/x86-ubuntu-gpu-ml/BUILDING.md\">extending the disk image</a> for ways to do this.</p>\n<p>If your application requires input files, it is recommended to create a shell script and pass the shell script to the <code class=\"language-plaintext highlighter-rouge\">--app</code> option. The shell script should be written with paths relative to the disk image paths as it will run within gem5. For example, if your application requires <code class=\"language-plaintext highlighter-rouge\">foo.dat</code>, create a shell script such as:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>#!/bin/bash\n\n# We have previously copied foo.dat to /data outside of simulation.\ncd /data\nmy_gpu_app -i foo.dat\n</code></pre></div></div>\n<h2 id=\"advanced-usage\">Advanced Usage</h2>\n<h4 id=\"running-without-kvm\">Running without KVM</h4>\n<p>The AtomicSimpleCPU can also be used in situations where the host is not x86 or KVM is not available. To enable the Atomic CPU, you will need to modify your config (e.g., <code class=\"language-plaintext highlighter-rouge\">configs/example/gpufs/mi300.py</code>) and replace <code class=\"language-plaintext highlighter-rouge\">args.cpu_type = \"X86KvmCPU\"</code> with <code class=\"language-plaintext highlighter-rouge\">args.cpu_type = \"AtomicSimpleCPU\"</code>.</p>\n<p>Note that this will slow down the CPU portion of your simulation potentially by 100x. It is possible to speed this up using <a href=\"https://www.gem5.org/documentation/general_docs/checkpoints/\">checkpoints</a>.</p>\n<h4 id=\"checkpoints\">Checkpoints</h4>\n<p>The config scripts provided allow for checkpointing after Linux boots out of the box. It is recommended to use this when using the atomic CPU. To create a checkpoint after boot, simply add a <code class=\"language-plaintext highlighter-rouge\">--checkpoint-dir</code> to the command line with a directory to place the checkpoint. For example:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>build/VEGA_X86/gem5.opt configs/example/gpufs/mi300.py --disk-image gem5-resources/src/x86-ubuntu-gpu-ml/disk-image/x86-ubuntu-gpu-ml --kernel gem5-resources/src/x86-ubuntu-gpu-ml/vmlinux-gpu-ml --app gem5-resources/src/gpu/square/bin.default/square.default --checkpoint-dir square-cpt\n</code></pre></div></div>\n<p>The checkpoint can then be restored and re-simulating the application will take significantly less time. To restore a checkpoint, replace the <code class=\"language-plaintext highlighter-rouge\">--checkpoint-dir</code> option with <code class=\"language-plaintext highlighter-rouge\">--restore-dir</code>:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>build/VEGA_X86/gem5.opt configs/example/gpufs/mi300.py --disk-image gem5-resources/src/x86-ubuntu-gpu-ml/disk-image/x86-ubuntu-gpu-ml --kernel gem5-resources/src/x86-ubuntu-gpu-ml/vmlinux-gpu-ml --app gem5-resources/src/gpu/square/bin.default/square.default --restore-dir square-cpt\n</code></pre></div></div>\n<p>Checkpoints can also be taken using the <code class=\"language-plaintext highlighter-rouge\">m5_checkpoint(..)</code> <a href=\"\">pseudo instruction</a> or by checkpointing in the python configs after an exit event. For example, kernel exit events can be enabled using <code class=\"language-plaintext highlighter-rouge\">--exit-at-gpu-task=-1</code> and the config can be modified to create a checkpoint at the <em>Nth</em> kernel by checking the current task number in <code class=\"language-plaintext highlighter-rouge\">configs/example/gpufs/runfs.py</code>.</p>\n<p>Note that checkpoints are currently not supported within a GPU kernel. Thus, checkpoints must be taken when no GPU kernels are running.</p>\n<h4 id=\"build-gpu-custom-applications\">Build GPU custom applications</h4>\n<p>If you want to build an application that is not part of gem5-resources, you will want to build the GPU application targeting either <code class=\"language-plaintext highlighter-rouge\">gfx90a</code> (MI210 and MI250), <code class=\"language-plaintext highlighter-rouge\">gfx942</code> (MI300X), or both. For example:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>hipcc my_gpu_app.cpp -o my_gpu_app --offload-arch=gfx90a,gfx942\n</code></pre></div></div>\n<p>You can build without a docker image on an x86 Linux host by installing the rocm-dev package after setting up a package manager following the steps in the <a href=\"https://rocm.docs.amd.com/projects/install-on-linux/en/latest/\">ROCm Linux documentation</a>.</p>\n<h4 id=\"modifying-gpu-configuration\">Modifying GPU configuration</h4>\n<p>The configurations in <code class=\"language-plaintext highlighter-rouge\">configs/example/gpufs/</code> are helper configurations that interface with <code class=\"language-plaintext highlighter-rouge\">configs/example/gpufs/runfs.py</code> and set meaningful default values for a specific device. Some parameters of interest in this file are the number of compute units, the GPU topology, the system memory size, and the CPU type.</p>\n<p>Some of these parameters <em>only</em> modify the value in gem5 and do not change the simulated device. In particular the dgpu_mem_size parameter does not change the amount of memory seen by the device driver and is hardcoded to 16GB in C++. Changing this value will result in a gem5 fatal.</p>\n<p>The supported cpu_types are X86KvmCPU and AtomicSimpleCPU as timing CPUs do not support the disjointed Ruby network required to simulate a discrete GPU.</p>\n<p>Other parameters related to GPU can be found in <code class=\"language-plaintext highlighter-rouge\">configs/example/gpufs/system/amdgpu.py</code> which creates the compute units for the GPU. See the ComputeUnit class in <code class=\"language-plaintext highlighter-rouge\">src/gpu-compute/GPU.py</code> for all available options. Note that not all possible combinations of options can be tested. Options such as queue sizes and latencies are generally safe to modify.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/gem5_resources/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/gpu_models/vega\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/gpu_models/vega",
        "title": "System Emulation AMD VEGA GPU model",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"system-emulation-amd-vega-gpu-model\"><strong>System Emulation AMD VEGA GPU model</strong></h1>\n<p>Table of Contents</p>\n<ol>\n<li><a href=\"#Using-the-model\">Using the model</a></li>\n<li><a href=\"#ROCm\">ROCm</a></li>\n<li><a href=\"#Documentation-and-Tutorials\">Documentation and Tutorials</a></li>\n</ol>\n<p>The AMD VEGA GPU is a model that simulates a GPU at the VEGA ISA level, as opposed to the intermediate language level. This page will give you a general overview of how to use this model, the software stack the model uses, and provide resources that detail the model and how it is implemented.</p>\n<h2 id=\"using-the-model\"><strong>Using the model</strong></h2>\n<p>Currently, the AMD VEGA GPU model in gem5 is supported on the stable and develop branch.</p>\n<p>The <a href=\"https://github.com/gem5/gem5\">gem5 repository</a> comes with a dockerfile located in <code class=\"language-plaintext highlighter-rouge\">util/dockerfiles/gcn-gpu/</code>. This dockerfile contains the drivers and libraries needed to run the GPU model. A pre-built version of the docker image is hosted at <code class=\"language-plaintext highlighter-rouge\">ghcr.io/gem5-test/gcn-gpu:v23-1</code>.\nThe <a href=\"https://github.com/gem5/gem5-resources/\">gem5-resources repository</a> also comes with a number of sample applications that can be used to verify that the model runs correctly.  We recommend users start with <a href=\"https://resources.gem5.org/resources/square\">square</a>, as it is a simple, heavily tested application that should run relatively quickly.</p>\n<h4 id=\"using-the-image\">Using the image</h4>\n<p>The docker image can either be built or pulled from ghcr.io.</p>\n<p>To build the docker image from source:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code># Working directory: gem5/util/dockerfiles/gcn-gpu\ndocker build -t &lt;image_name&gt; .\n</code></pre></div></div>\n<p>To pull the pre-built docker image (Note the <code class=\"language-plaintext highlighter-rouge\">v23-1</code> tag, to get the correct\nimage for this release):</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>docker pull ghcr.io/gem5-test/gcn-gpu:v23-1\n</code></pre></div></div>\n<p>You can also put <code class=\"language-plaintext highlighter-rouge\">ghcr.io/gem5-test/gcn-gpu:v23-1</code> as the image in the docker run command without pulling beforehand and it will be pulled automatically.</p>\n<h4 id=\"building-gem5-using-the-image\">Building gem5 using the image</h4>\n<p>See square in <a href=\"https://github.com/gem5/gem5-resources/tree/stable/src/gpu/square/\">gem5 resources</a> for an example of how to build gem5 in the docker.  Note: these directions assume you are pulling the latest image automatically.</p>\n<h4 id=\"building--running-a-gpu-application-using-the-image\">Building &amp; running a GPU application using the image</h4>\n<p>See <a href=\"https://github.com/gem5/gem5-resources/tree/stable/src/gpu/\">gem5 resources</a> for examples of how to build and run GPU applications in the docker.</p>\n<h2 id=\"rocm\"><strong>ROCm</strong></h2>\n<p>The AMD VEGA GPU model was designed with enough fidelity to not require an emulated runtime. Instead, the model uses the Radeon Open Compute platform (ROCm). ROCm is an open platform from AMD that implements <a href=\"http://www.hsafoundation.com/\">Heterogeneous Systems Architecture (HSA)</a> principles. More information about the HSA standard can be found on the HSA Foundation\u2019s website. More information about ROCm can be found on the <a href=\"https://rocmdocs.amd.com/en/latest/\">ROCm website</a></p>\n<h4 id=\"simulation-support-for-rocm\">Simulation support for ROCm</h4>\n<p>The model currently works with system-call emulation (SE) mode and full-system (FS) mode.</p>\n<p>In SE mode, all kernel level driver functionality is modeled entirely within the SE mode layer of gem5. In particular, the emulated GPU driver supports the necessary <code class=\"language-plaintext highlighter-rouge\">ioctl()</code> commands it receives from the userspace code. The source for the emulated GPU driver can be found in:</p>\n<ul>\n<li>\n<p>The GPU compute driver: <code class=\"language-plaintext highlighter-rouge\">src/gpu-compute/gpu_compute_driver.[hh|cc]</code></p>\n</li>\n<li>\n<p>The HSA device driver: <code class=\"language-plaintext highlighter-rouge\">src/dev/hsa/hsa_driver.[hh|cc]</code></p>\n</li>\n</ul>\n<p>The HSA driver code models the basic functionality for an HSA agent, which is any device that can be targeted by the HSA runtime and accepts Architected Query Language (AQL) packets. AQL packets are a standard format for all HSA agents, and are used primarily to initiate kernel launches on the GPU. The base <code class=\"language-plaintext highlighter-rouge\">HSADriver</code> class holds a pointer to the HSA packet processor for the device, and defines the interface for any HSA device. An HSA agent does not have to be a GPU, it could be a generic accelerator, CPU, NIC, etc.</p>\n<p>The <code class=\"language-plaintext highlighter-rouge\">GPUComputeDriver</code> derives from <code class=\"language-plaintext highlighter-rouge\">HSADriver</code> and is a device-specific implementation of an <code class=\"language-plaintext highlighter-rouge\">HSADriver</code>. It provides the implementation for GPU-specific <code class=\"language-plaintext highlighter-rouge\">ioctl()</code> calls.</p>\n<p>The <code class=\"language-plaintext highlighter-rouge\">src/dev/hsa/kfd_ioctl.h</code> header must match the <code class=\"language-plaintext highlighter-rouge\">kfd_ioctl.h</code> header that comes with ROCt. The emulated driver relies on that file to interpret the <code class=\"language-plaintext highlighter-rouge\">ioctl()</code> codes the thunk uses.</p>\n<p>In FS mode, the real amdgpu Linux driver is used and installed as you would on a real machine. The source for the driver can instead be found in the <a href=\"https://github.com/RadeonOpenCompute/ROCK-Kernel-Driver\">ROCK-Kernel-Driver</a> repository.</p>\n<h4 id=\"rocm-toolchain-and-software-stack\">ROCm toolchain and software stack</h4>\n<p>The AMD VEGA GPU model supports ROCm versions up to 5.4 in FS mode and 4.0 in SE mode.</p>\n<p>The following ROCm components are required in SE mode:</p>\n<ul>\n<li><a href=\"https://github.com/RadeonOpenCompute/hcc\">Heterogeneous Compute Compiler (HCC)</a></li>\n<li><a href=\"https://github.com/RadeonOpenCompute/ROCR-Runtime\">Radeon Open Compute runtime (ROCr)</a></li>\n<li><a href=\"https://github.com/RadeonOpenCompute/ROCT-Thunk-Interface\">Radeon Open Compute thunk (ROCt)</a></li>\n<li><a href=\"https://github.com/ROCm-Developer-Tools/HIP\">HIP</a></li>\n</ul>\n<p>The following additional components are used to build and run machine learning programs:</p>\n<ul>\n<li><a href=\"https://github.com/ROCmSoftwarePlatform/hipBLAS/\">hipBLAS</a></li>\n<li><a href=\"https://github.com/ROCmSoftwarePlatform/rocBLAS/\">rocBLAS</a></li>\n<li><a href=\"https://github.com/ROCmSoftwarePlatform/MIOpen/\">MIOpen</a></li>\n<li><a href=\"https://github.com/RadeonOpenCompute/rocm-cmake/\">rocm-cmake</a></li>\n<li><a href=\"https://pytorch.org/\">PyTorch</a> (FS mode only)</li>\n<li><a href=\"https://www.tensorflow.org/\">Tensorflow</a> - specifically the tensorflow-rocm python package (FS mode only)</li>\n</ul>\n<p>For information about installing these components locally, the commands in the GCN3 dockerfile (<code class=\"language-plaintext highlighter-rouge\">util/dockerfiles/gcn-gpu/</code>) can be followed on an Ubuntu 16 machine.</p>\n<h2 id=\"documentation-and-tutorials\"><strong>Documentation and Tutorials</strong></h2>\n<p>Note that the VEGA ISA is a newer, superset ISA derived from GCN3. Therefore, the contents of the following papers, tutorials, and documentation apply to VEGA as well.</p>\n<h4 id=\"gpu-model\">GPU Model</h4>\n<p>Describes the gem5 GPU model with the GCN3 ISA (at the time of writing). VEGA is a newer, superset ISA derived from GCN3. Therefore the contents of the following papers)</p>\n<ul>\n<li><a href=\"https://ieeexplore.ieee.org/document/8327041\">HPCA 2018</a></li>\n</ul>\n<h4 id=\"gem5-gcn3-isca-tutorial\">gem5 GCN3 ISCA tutorial</h4>\n<p>Covers information about the GPU architecture, GCN3 ISA and HW-SW interfaces in gem5. Also provides an introduction to ROCm.</p>\n<ul>\n<li><a href=\"http://www.gem5.org/events/isca-2018\">gem5 GCN3 ISCA webpage</a></li>\n<li><a href=\"http://old.gem5.org/wiki/images/1/19/AMD_gem5_APU_simulator_isca_2018_gem5_wiki.pdf\">gem5 GCN3 ISCA slides</a></li>\n</ul>\n<h4 id=\"vega-isa\">VEGA ISA</h4>\n<ul>\n<li><a href=\"https://gpuopen.com/documentation/amd-isa-documentation/\">VEGA ISA</a></li>\n</ul>\n<h4 id=\"rocm-documentation\">ROCm Documentation</h4>\n<p>Contains further documentation about the ROCm stack, as well as programming guides for using ROCm.</p>\n<ul>\n<li><a href=\"https://rocmdocs.amd.com/en/latest/\">ROCm webpage</a></li>\n</ul>\n<h4 id=\"amdgpu-llvm-information\">AMDGPU LLVM Information</h4>\n<ul>\n<li><a href=\"https://llvm.org/docs/AMDGPUUsage.html\">LLVM AMDGPU</a></li>\n</ul>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/gpu_models/gpufs\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/kconfig_build_system/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/m5ops",
        "title": "M5ops",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"m5ops\">M5ops</h1>\n<p>This page explains the special opcodes that can be used in M5 to do checkpoints etc. The m5 utility program (on our disk image and in util/m5/*) provides some of this functionality on the command line. In many cases it is best to insert the operation directly in the source code of your application of interest. You should be able to link with the appropriate libm5.a file and the m5ops.h header file has prototypes for all the functions.\nA tutorial on using the M5ops was given as a part of the gem5 2022 Bootcamp. A recording of this event can be found <a href=\"https://youtu.be/TeHKMVOWUAY\">here</a>.</p>\n<h2 id=\"building-m5-and-libm5\">Building M5 and libm5</h2>\n<p>In order to build m5 and libm5.a for your target ISA, run the following command in the util/m5/ directory.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>scons build/<span class=\"o\">{</span>TARGET_ISA<span class=\"o\">}</span>/out/m5\n</code></pre></div></div>\n<p>The list of target ISAs is shown below.</p>\n<ul>\n<li>x86</li>\n<li>arm (arm-linux-gnueabihf-gcc)</li>\n<li>thumb (arm-linux-gnueabihf-gcc)</li>\n<li>sparc (sparc64-linux-gnu-gcc)</li>\n<li>arm64 (aarch64-linux-gnu-gcc)</li>\n<li>riscv (riscv64-unknown-linux-gnu-gcc)</li>\n</ul>\n<p>Note if you are using a x86 system for other ISAs you need to have the cross-compiler installed. The name of the cross-compiler is shown inside the parentheses in the list above.</p>\n<p>See <a href=\"https://github.com/gem5/gem5/blob/stable/util/m5/README.md\">util/m5/README.md</a> for more details.</p>\n<h2 id=\"the-m5-utility-fs-mode\">The m5 Utility (FS mode)</h2>\n<p>The m5 utility (see util/m5/) can be used in FS mode to issue special instructions to trigger simulation specific functionality. It currently offers the following options:</p>\n<ul>\n<li>initparam: Deprecated, present only for old binary compatibility</li>\n<li>exit [delay]: Stop the simulation in delay nanoseconds.</li>\n<li>resetstats [delay [period]]: Reset simulation statistics in delay nanoseconds; repeat this every period nanoseconds.</li>\n<li>dumpstats [delay [period]]: Save simulation statistics to a file in delay nanoseconds; repeat this every period nanoseconds.</li>\n<li>dumpresetstats [delay [period]]: same as dumpstats; resetstats</li>\n<li>checkpoint [delay [period]]: Create a checkpoint in delay nanoseconds; repeat this every period nanoseconds.</li>\n<li>readfile: Print the file specified by the config parameter system.readfile. This is how the the rcS files are copied into the simulation environment.</li>\n<li>debugbreak: Call debug_break() in the simulator (causes simulator to get SIGTRAP signal, useful if debugging with GDB).</li>\n<li>switchcpu: Cause an exit event of type, \u201cswitch cpu,\u201d allowing the Python to switch to a different CPU model if desired.</li>\n<li>workbegin: Cause an exit evet of type, \u201cworkbegin\u201d, that could be used to mark the begining of an ROI.</li>\n<li>workend: Cause an exit event of type, \u201cworkend\u201d, that could be used to mark the termination of an ROI.</li>\n</ul>\n<h2 id=\"other-m5-ops\">Other M5 ops</h2>\n<p>These are other M5 ops that aren\u2019t useful in command line form.</p>\n<ul>\n<li>quiesce: De-schedule the CPUs tick() call until some asynchronous event wakes it (an interrupt)</li>\n<li>quiesceNS: Same as above, but automatically wakes after a number of nanoseconds if it\u2019s not woken up prior</li>\n<li>quiesceCycles: Same as above but with CPU cycles instead of nanoseconds</li>\n<li>quisceTIme: The amount of time the CPU was quiesced for</li>\n<li>addsymbol: Add a symbol to the simulators symbol table. For example when a kernel module is loaded</li>\n</ul>\n<h2 id=\"using-gem5-ops-in-java-code\">Using gem5 ops in Java code</h2>\n<p>These ops can also be used in Java code. These ops allow gem5 ops to be called from within java programs like the following:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">jni.gem5Op</span><span class=\"p\">;</span>\n\n<span class=\"n\">public</span>  <span class=\"k\">class</span> <span class=\"nc\">HelloWorld</span> <span class=\"p\">{</span>\n\n   <span class=\"n\">public</span> <span class=\"n\">static</span> <span class=\"n\">void</span> <span class=\"n\">main</span><span class=\"p\">(</span><span class=\"n\">String</span><span class=\"p\">[]</span> <span class=\"n\">args</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n       <span class=\"n\">gem5Op</span> <span class=\"n\">gem5</span> <span class=\"o\">=</span> <span class=\"n\">new</span> <span class=\"n\">gem5Op</span><span class=\"p\">();</span>\n       <span class=\"n\">System</span><span class=\"p\">.</span><span class=\"n\">out</span><span class=\"p\">.</span><span class=\"n\">println</span><span class=\"p\">(</span><span class=\"s\">\"Rpns0:\"</span> <span class=\"o\">+</span> <span class=\"n\">gem5</span><span class=\"p\">.</span><span class=\"n\">rpns</span><span class=\"p\">());</span>\n       <span class=\"n\">System</span><span class=\"p\">.</span><span class=\"n\">out</span><span class=\"p\">.</span><span class=\"n\">println</span><span class=\"p\">(</span><span class=\"s\">\"Rpns1:\"</span> <span class=\"o\">+</span> <span class=\"n\">gem5</span><span class=\"p\">.</span><span class=\"n\">rpns</span><span class=\"p\">());</span>\n   <span class=\"p\">}</span>\n\n   <span class=\"n\">static</span> <span class=\"p\">{</span>\n       <span class=\"n\">System</span><span class=\"p\">.</span><span class=\"n\">loadLibrary</span><span class=\"p\">(</span><span class=\"s\">\"gem5OpJni\"</span><span class=\"p\">);</span>\n   <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n<p>When building you need to make sure classpath includes gem5OpJni.jar:</p>\n<div class=\"language-javascript highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nx\">javac</span> <span class=\"o\">-</span><span class=\"nx\">classpath</span> <span class=\"nx\">$CLASSPATH</span><span class=\"p\">:</span><span class=\"o\">/</span><span class=\"nx\">path</span><span class=\"o\">/</span><span class=\"nx\">to</span><span class=\"o\">/</span><span class=\"nx\">gem5OpJni</span><span class=\"p\">.</span><span class=\"nx\">jar</span> <span class=\"nx\">HelloWorld</span><span class=\"p\">.</span><span class=\"nx\">java</span>\n</code></pre></div></div>\n<p>and when running you need to make sure both the java and library path are set:</p>\n<div class=\"language-javascript highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nx\">java</span> <span class=\"o\">-</span><span class=\"nx\">classpath</span> <span class=\"nx\">$CLASSPATH</span><span class=\"p\">:</span><span class=\"o\">/</span><span class=\"nx\">path</span><span class=\"o\">/</span><span class=\"nx\">to</span><span class=\"o\">/</span><span class=\"nx\">gem5OpJni</span><span class=\"p\">.</span><span class=\"nx\">jar</span> <span class=\"o\">-</span><span class=\"nx\">Djava</span><span class=\"p\">.</span><span class=\"nx\">library</span><span class=\"p\">.</span><span class=\"nx\">path</span><span class=\"o\">=</span><span class=\"sr\">/path/</span><span class=\"nx\">to</span><span class=\"o\">/</span><span class=\"nx\">libgem5OpJni</span><span class=\"p\">.</span><span class=\"nx\">so</span> <span class=\"nx\">HelloWorld</span>\n</code></pre></div></div>\n<h2 id=\"using-gem5-ops-with-fortran-code\">Using gem5 ops with Fortran code</h2>\n<p>gem5\u2019s special opcodes (psuedo instructions) can be used with Fortran programs. In the Fortran code, one can add calls to C functions that invoke the special opcode. While creating the final binary, compile the object files for the Fortran program and the C program (for opcodes) together. I found the documentation provided <a href=\"https://gcc.gnu.org/wiki/GFortranGettingStarted\">here</a> useful. Read the section <strong>-</strong><strong>- Compiling a mixed C-Fortran program</strong>.</p>\n<p>The idea of using gem5 ops with Fortran code is essentially to compile the m5 ops C code to an object file, and then link the object file against the binary calling the m5 ops.\nThe C function calling convention in Fortran is such that, if the function name in C code is <code class=\"language-plaintext highlighter-rouge\">void foo_bar_(void)</code>, then in Fortran, you can call the function by <code class=\"language-plaintext highlighter-rouge\">call foo_bar</code>.</p>\n<h2 id=\"linking-m5-to-your-cc-code\">Linking M5 to your C/C++ code</h2>\n<p>In order to link m5 to your code, first build <code class=\"language-plaintext highlighter-rouge\">libm5.a</code> as described in the section above.</p>\n<p>Then</p>\n<ul>\n<li>Include <code class=\"language-plaintext highlighter-rouge\">gem5/m5ops.h</code> in your source file(s)</li>\n<li>Add <code class=\"language-plaintext highlighter-rouge\">gem5/include</code> to your compiler\u2019s include search path</li>\n<li>Add <code class=\"language-plaintext highlighter-rouge\">gem5/util/m5/build/{TARGET_ISA}/out</code> to the linker search path</li>\n<li>Link against <code class=\"language-plaintext highlighter-rouge\">libm5.a</code></li>\n</ul>\n<p>For example, this could be achieved by adding the following to your Makefile:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>CFLAGS += -I$(GEM5_PATH)/include\nLDFLAGS += -L$(GEM5_PATH)/util/m5/build/$(TARGET_ISA)/out -lm5\n</code></pre></div></div>\n<p>Here is a simple Makefile example:</p>\n<div class=\"language-make highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">TARGET_ISA</span><span class=\"o\">=</span>x86\n\n<span class=\"nv\">GEM5_HOME</span><span class=\"o\">=</span><span class=\"nf\">$(</span><span class=\"nb\">realpath</span> ./<span class=\"nf\">)</span>\n<span class=\"err\">$(info</span>   <span class=\"err\">GEM5_HOME</span> <span class=\"err\">is</span> <span class=\"err\">$(GEM5_HOME))</span>\n\n<span class=\"nv\">CXX</span><span class=\"o\">=</span>g++\n\n<span class=\"nv\">CFLAGS</span><span class=\"o\">=</span><span class=\"nt\">-I</span><span class=\"nv\">$(GEM5_HOME)</span>/include\n\n<span class=\"nv\">LDFLAGS</span><span class=\"o\">=</span><span class=\"nt\">-L</span><span class=\"nv\">$(GEM5_HOME)</span>/util/m5/build/<span class=\"nv\">$(TARGET_ISA)</span>/out <span class=\"nt\">-lm5</span>\n\n<span class=\"nv\">OBJECTS</span><span class=\"o\">=</span> hello_world\n\n<span class=\"nl\">all</span><span class=\"o\">:</span> <span class=\"nf\">hello_world</span>\n\n<span class=\"nl\">hello_world</span><span class=\"o\">:</span>\n\t<span class=\"nv\">$(CXX)</span> <span class=\"nt\">-o</span> <span class=\"nv\">$(OBJECTS)</span> hello_world.cpp <span class=\"nv\">$(CFLAGS)</span> <span class=\"nv\">$(LDFLAGS)</span>\n\n<span class=\"nl\">clean</span><span class=\"o\">:</span>\n\t<span class=\"nb\">rm</span> <span class=\"nt\">-f</span> <span class=\"nv\">$(OBJECTS)</span>\n</code></pre></div></div>\n<h2 id=\"using-the-_addr-version-of-m5ops\">Using the \u201c_addr\u201d version of M5ops</h2>\n<p>The \u201c_addr\u201d version of m5ops triggers the same simulation specific functionality as the default m5ops, but they use different trigger mechanisms. Below is a quote from the m5 utility README.md explaining the trigger mechanisms.</p>\n<div class=\"language-markdown highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>The bare function name as defined in the header file will use the magic instruction based trigger mechanism, what would have historically been the default.\n\nSome macros at the end of the header file will set up other declarations which mirror all of the other definitions, but with an \u201c_addr\u201d and \u201c_semi\u201d suffix. These other versions will trigger the same gem5 operations, but using the \u201cmagic\u201d address or semihosting trigger mechanisms. While those functions will be unconditionally declared in the header file, a definition will exist in the library only if that trigger mechanism is supported for that ABI.\n</code></pre></div></div>\n<p><em>Note</em>: The macros generating the \u201c_addr\u201d and \u201c_semi\u201d m5ops are called <code class=\"language-plaintext highlighter-rouge\">M5OP</code>, which are defined in <code class=\"language-plaintext highlighter-rouge\">util/m5/abi/*/m5op_addr.S</code> and <code class=\"language-plaintext highlighter-rouge\">util/m5/abi/*/m5op_semi.S</code>.</p>\n<p>In order to use the \u201c_addr\u201d version of m5ops, you need to include the m5_mmap.h header file, pass the \u201cmagic\u201d address (e.g., \u201c0xFFFF0000\u201d for x86, and \u201c0x10010000\u201d for arm64/riscv) to m5op_addr, then call the map_m5_mem() to open /dev/mem. You can insert m5ops by adding \u201c_addr\u201d at the end of the original m5ops functions.</p>\n<p>Here is a simple example using the \u201c_addr\u201d version of the m5ops:</p>\n<div class=\"language-c highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"cp\">#include</span> <span class=\"cpf\">&lt;gem5/m5ops.h&gt;</span><span class=\"cp\">\n#include</span> <span class=\"cpf\">&lt;m5_mmap.h&gt;</span><span class=\"cp\">\n#include</span> <span class=\"cpf\">&lt;stdio.h&gt;</span><span class=\"cp\">\n</span>\n<span class=\"cp\">#define GEM5\n</span>\n<span class=\"kt\">int</span> <span class=\"nf\">main</span><span class=\"p\">(</span><span class=\"kt\">void</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n<span class=\"cp\">#ifdef GEM5\n</span>    <span class=\"n\">m5op_addr</span> <span class=\"o\">=</span> <span class=\"mh\">0xFFFF0000</span><span class=\"p\">;</span>\n    <span class=\"n\">map_m5_mem</span><span class=\"p\">();</span>\n    <span class=\"n\">m5_work_begin_addr</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">);</span>\n<span class=\"cp\">#endif\n</span>\n    <span class=\"n\">printf</span><span class=\"p\">(</span><span class=\"s\">\"hello world!</span><span class=\"se\">\\n</span><span class=\"s\">\"</span><span class=\"p\">);</span>\n\n<span class=\"cp\">#ifdef GEM5\n</span>    <span class=\"n\">m5_work_end_addr</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">);</span>\n    <span class=\"n\">unmap_m5_mem</span><span class=\"p\">();</span>\n<span class=\"cp\">#endif\n</span><span class=\"p\">}</span>\n</code></pre></div></div>\n<p><em>Note</em>: You\u2019ll need to add a new header location for the compiler to find the <code class=\"language-plaintext highlighter-rouge\">m5_mmap.h</code>.\nIf you are following the example Makefile above, you can add the following line below where CFLAGS is defined,</p>\n<div class=\"language-c highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">CFLAGS</span> <span class=\"o\">+=</span> <span class=\"err\">$</span><span class=\"p\">(</span><span class=\"n\">GEM5_PATH</span><span class=\"p\">)</span><span class=\"o\">/</span><span class=\"n\">util</span><span class=\"o\">/</span><span class=\"n\">m5</span><span class=\"o\">/</span><span class=\"n\">src</span><span class=\"o\">/</span>\n</code></pre></div></div>\n<p>When you run the applications with m5ops inserted in FS mode with a KVM CPU, this error might appear.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>```illegal instruction (core dumped)```\n</code></pre></div></div>\n<p>This is because m5ops instructions are not valid instructions to the host. Using the \u201c_addr\u201d version of the m5ops can fix this issue, so it is necessary to use the \u201c_addr\u201d version if you want to integrate m5ops into your applications or use the m5 binary utility when running with KVM CPUs.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/using_kvm/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/memory_system/classic-coherence-protocol/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/memory_system/",
        "title": "Memory system",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Jason Lowe-Power<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"memory-system\">Memory system</h1>\n<p>M5\u2019s new memory system (introduced in the first 2.0 beta release) was\ndesigned with the following goals:</p>\n<ol>\n<li>Unify timing and functional accesses in timing mode. With the old\nmemory system the timing accesses did not have data and just\naccounted for the time it would take to do an operation. Then a\nseparate functional access actually made the operation visible to\nthe system. This method was confusing, it allowed simulated\ncomponents to accidentally cheat, and prevented the memory system\nfrom returning timing-dependent values, which isn\u2019t reasonable for\nan execute-in-execute CPU model.</li>\n<li>Simplify the memory system code \u2013 remove the huge amount of\ntemplating and duplicate code.</li>\n<li>Make changes easier, specifically to allow other memory\ninterconnects besides a shared bus.</li>\n</ol>\n<p>For details on the new coherence protocol, introduced (along with a\nsubstantial cache model rewrite) in 2.0b4, see <a href=\"classic-coherence-protocol\" title=\"wikilink\">Coherence\nProtocol</a>.</p>\n<h3 id=\"memobjects\">MemObjects</h3>\n<p>All objects that connect to the memory system inherit from <code class=\"language-plaintext highlighter-rouge\">MemObject</code>.\nThis class adds the pure virtual functions <code class=\"language-plaintext highlighter-rouge\">getMasterPort(const\nstd::string &amp;name, PortID idx)</code> and <code class=\"language-plaintext highlighter-rouge\">getSlavePort(const std::string\n&amp;name, PortID idx)</code> which returns a port corresponding to the given name\nand index. This interface is used to structurally connect the MemObjects\ntogether.</p>\n<h3 id=\"ports\">Ports</h3>\n<p>The next large part of the memory system is the idea of ports. Ports are\nused to interface memory objects to each other. They will always come in\npairs, with a MasterPort and a SlavePort, and we refer to the other port\nobject as the peer. These are used to make the design more modular. With\nports a specific interface between every type of object doesn\u2019t have to\nbe created. Every memory object has to have at least one port to be\nuseful. A master module, such as a CPU, has one or more MasterPort\ninstances. A slave module, such as a memory controller, has one or more\nSlavePorts. An interconnect component, such as a cache, bridge or bus,\nhas both MasterPort and SlavePort instances.</p>\n<p>There are two groups of functions in the port object. The <code class=\"language-plaintext highlighter-rouge\">send*</code>\nfunctions are called on the port by the object that owns that port. For\nexample to send a packet in the memory system a CPU would call\n<code class=\"language-plaintext highlighter-rouge\">myPort-&gt;sendTimingReq(pkt)</code>. Each send function has a\ncorresponding recv function that is called on the ports peer. So the\nimplementation of the <code class=\"language-plaintext highlighter-rouge\">sendTimingReq()</code> call above would simply be\n<code class=\"language-plaintext highlighter-rouge\">peer-&gt;recvTimingReq(pkt)</code> on the slave port. Using this method we only\nhave one virtual function call penalty but keep generic ports that can\nconnect together any memory system objects.</p>\n<p>Master ports can send requests and receive responses, whereas slave\nports receive requests and send responses. Due to the coherence\nprotocol, a slave port can also send snoop requests and receive snoop\nresponses, with the master port having the mirrored interface.</p>\n<h3 id=\"connections\">Connections</h3>\n<p>In Python, Ports are first-class attributes of simulation objects, much\nlike Params. Two objects can specify that their ports should be\nconnected using the assignment operator. Unlike a normal variable or\nparameter assignment, port connections are symmetric: <code class=\"language-plaintext highlighter-rouge\">A.port1 =\nB.port2</code> has the same meaning as <code class=\"language-plaintext highlighter-rouge\">B.port2 = A.port1</code>. The notion of\nmaster and slave ports exists in the Python objects as well, and a check\nis done when the ports are connected together.</p>\n<p>Objects such as busses that have a potentially unlimited number of ports\nuse \u201cvector ports\u201d. An assignment to a vector port appends the peer to a\nlist of connections rather than overwriting a previous connection.</p>\n<p>In C++, memory ports are connected together by the python code after all\nobjects are instantiated.</p>\n<h3 id=\"request\">Request</h3>\n<p>A request object encapsulates the original request issued by a CPU or\nI/O device. The parameters of this request are persistent throughout the\ntransaction, so a request object\u2019s fields are intended to be written at\nmost once for a given request. There are a handful of constructors and\nupdate methods that allow subsets of the object\u2019s fields to be written\nat different times (or not at all). Read access to all request fields is\nprovided via accessor methods which verify that the data in the field\nbeing read is valid.</p>\n<p>The fields in the request object are typically not available to devices\nin a real system, so they should normally be used only for statistics or\ndebugging and not as architectural values.</p>\n<p>Request object fields include:</p>\n<ul>\n<li>Virtual address. This field may be invalid if the request was issued\ndirectly on a physical address (e.g., by a DMA I/O device).</li>\n<li>Physical address.</li>\n<li>Data size.</li>\n<li>Time the request was created.</li>\n<li>The ID of the CPU/thread that caused this request. May be invalid if\nthe request was not issued by a CPU (e.g., a device access or a\ncache writeback).</li>\n<li>The PC that caused this request. Also may be invalid if the request\nwas not issued by a CPU.</li>\n</ul>\n<h3 id=\"packet\">Packet</h3>\n<p>A Packet is used to encapsulate a transfer between two objects in the\nmemory system (e.g., the L1 and L2 cache). This is in contrast to a\nRequest where a single Request travels all the way from the requester to\nthe ultimate destination and back, possibly being conveyed by several\ndifferent Packets along the way.</p>\n<p>Read access to many packet fields is provided via accessor methods which\nverify that the data in the field being read is valid.</p>\n<p>A packet contains the following all of which are accessed by accessors\nto be certain the data is valid:</p>\n<ul>\n<li>The address. This is the address that will be used to route the\npacket to its target (if the destination is not explicitly set) and\nto process the packet at the target. It is typically derived from\nthe request object\u2019s physical address, but may be derived from the\nvirtual address in some situations (e.g., for accessing a fully\nvirtual cache before address translation has been performed). It may\nnot be identical to the original request address: for example, on a\ncache miss, the packet address may be the address of the block to\nfetch and not the request address.</li>\n<li>The size. Again, this size may not be the same as that of the\noriginal request, as in the cache miss scenario.</li>\n<li>A pointer to the data being manipulated.\n    <ul>\n<li>Set by <code class=\"language-plaintext highlighter-rouge\">dataStatic()</code>, <code class=\"language-plaintext highlighter-rouge\">dataDynamic()</code>, and <code class=\"language-plaintext highlighter-rouge\">dataDynamicArray()</code>\nwhich control if the data associated with the packet is freed\nwhen the packet is, not, with <code class=\"language-plaintext highlighter-rouge\">delete</code>, and with <code class=\"language-plaintext highlighter-rouge\">delete []</code>\nrespectively.</li>\n<li>Allocated if not set by one of the above methods <code class=\"language-plaintext highlighter-rouge\">allocate()</code>\nand the data is freed when the packet is destroyed. (Always safe\nto call).</li>\n<li>A pointer can be retrived by calling <code class=\"language-plaintext highlighter-rouge\">getPtr()</code></li>\n<li><code class=\"language-plaintext highlighter-rouge\">get()</code> and <code class=\"language-plaintext highlighter-rouge\">set()</code> can be used to manipulate the data in the\npacket. The get() method does a guest-to-host endian conversion\nand the set method does a host-to-guest endian conversion.</li>\n</ul>\n</li>\n<li>A status indicating Success, BadAddress, Not Acknowleged, and\nUnknown.</li>\n<li>A list of command attributes associated with the packet\n    <ul>\n<li>Note: There is some overlap in the data in the status field and\nthe command attributes. This is largely so that a packet can be\neasily reinitialized when nacked or easily reused with atomic or\nfunctional accesses.</li>\n</ul>\n</li>\n<li>A <code class=\"language-plaintext highlighter-rouge\">SenderState</code> pointer which is a virtual base opaque structure\nused to hold state associated with the packet but specific to the\nsending device (e.g., an MSHR). A pointer to this state is returned\nin the packet\u2019s response so that the sender can quickly look up the\nstate needed to process it. A specific subclass would be derived\nfrom this to carry state specific to a particular sending device.</li>\n<li>A <code class=\"language-plaintext highlighter-rouge\">CoherenceState</code> pointer which is a virtual base opaque structure\nused to hold coherence-related state. A specific subclass would be\nderived from this to carry state specific to a particular coherence\nprotocol.</li>\n<li>A pointer to the request.</li>\n</ul>\n<h3 id=\"access-types\">Access Types</h3>\n<p>There are three types of accesses supported by the ports.</p>\n<ol>\n<li><strong>Timing</strong> - Timing accesses are the most detailed access. They\nreflect our best effort for realistic timing and include the\nmodeling of queuing delay and resource contention. Once a timing\nrequest is successfully sent at some point in the future the device\nthat sent the request will either get the response or a NACK if the\nrequest could not be completed (more below). Timing and Atomic\naccesses can not coexist in the memory system.</li>\n<li><strong>Atomic</strong> - Atomic accesses are a faster than detailed access. They\nare used for fast forwarding and warming up caches and return an\napproximate time to complete the request without any resource\ncontention or queuing delay. When a atomic access is sent the\nresponse is provided when the function returns. Atomic and timing\naccesses can not coexist in the memory system.</li>\n<li><strong>Functional</strong> - Like atomic accesses functional accesses happen\ninstantaneously, but unlike atomic accesses they can coexist in the\nmemory system with atomic or timing accesses. Functional accesses\nare used for things such as loading binaries, examining/changing\nvariables in the simulated system, and allowing a remote debugger to\nbe attached to the simulator. The important note is when a\nfunctional access is received by a device, if it contains a queue of\npackets all the packets must be searched for requests or responses\nthat the functional access is effecting and they must be updated as\nappropriate. The <code class=\"language-plaintext highlighter-rouge\">Packet::intersect()</code> and <code class=\"language-plaintext highlighter-rouge\">fixPacket()</code> methods can\nhelp with this.</li>\n</ol>\n<h3 id=\"packet-allocation-protocol\">Packet allocation protocol</h3>\n<p>The protocol for allocation and deallocation of Packet objects varies\ndepending on the access type. (We\u2019re talking about low-level C++\n<code class=\"language-plaintext highlighter-rouge\">new</code>/<code class=\"language-plaintext highlighter-rouge\">delete</code> issues here, not anything related to the coherence\nprotocol.)</p>\n<ul>\n<li><em>Atomic</em> and <em>Functional</em> : The Packet object is owned by the\nrequester. The responder must overwrite the request packet with the\nresponse (typically using the <code class=\"language-plaintext highlighter-rouge\">Packet::makeResponse()</code> method).\nThere is no provision for having multiple responders to a single\nrequest. Since the response is always generated before\n<code class=\"language-plaintext highlighter-rouge\">sendAtomic()</code> or <code class=\"language-plaintext highlighter-rouge\">sendFunctional()</code> returns, the requester can\nallocate the Packet object statically or on the stack.</li>\n<li><em>Timing</em> : Timing transactions are composed of two one-way messages,\na request and a response. In both cases, the Packet object must be\ndynamically allocated by the sender. Deallocation is the\nresponsibility of the receiver (or, for broadcast coherence packets,\nthe target device, typically memory). In the case where the receiver\nof a request is generating a response, it <em>may</em> choose to reuse the\nrequest packet for its response to save the overhead of calling\n<code class=\"language-plaintext highlighter-rouge\">delete</code> and then <code class=\"language-plaintext highlighter-rouge\">new</code> (and gain the convenience of using\n<code class=\"language-plaintext highlighter-rouge\">makeResponse()</code>). However, this optimization is optional, and the\nrequester must not rely on receiving the same Packet object back in\nresponse to a request. Note that when the responder is not the\ntarget device (as in a cache-to-cache transfer), then the target\ndevice will still delete the request packet, and thus the responding\ncache must allocate a new Packet object for its response. Also,\nbecause the target device may delete the request packet immediately\non delivery, any other memory device wishing to reference a\nbroadcast packet past the point where the packet is delivered must make\na copy of that packet, as the pointer to the packet that is\ndelivered cannot be relied upon to stay valid.</li>\n</ul>\n<h3 id=\"timing-flow-control\">Timing Flow control</h3>\n<p>Timing requests simulate a real memory system, so unlike functional and\natomic accesses their response is not instantaneous. Because the timing\nrequests are not instantaneous, flow control is needed. When a timing\npacket is sent via <code class=\"language-plaintext highlighter-rouge\">sendTiming()</code> the packet may or may not be accepted,\nwhich is signaled by returning true or false. If false is returned the\nobject should not attempt to sent anymore packets until it receives a\n<code class=\"language-plaintext highlighter-rouge\">recvRetry()</code> call. At this time it should again try to call\n<code class=\"language-plaintext highlighter-rouge\">sendTiming()</code>; however the packet may again be rejected. Note: The\noriginal packet does not need to be resent, a higher priority packet can\nbe sent instead. Once <code class=\"language-plaintext highlighter-rouge\">sendTiming()</code> returns true, the packet may still\nnot be able to make it to its destination. For packets that require a\nresponse (i.e. <code class=\"language-plaintext highlighter-rouge\">pkt-&gt;needsResponse()</code> is true), any memory object can\nrefuse to acknowledge the packet by changing its result to <code class=\"language-plaintext highlighter-rouge\">Nacked</code> and\nsending it back to its source. However, if it is a response packet, this\ncan not be done. The true/false return is intended to be used for local\nflow control, while nacking is for global flow control. In both cases a\nresponse can not be nacked.</p>\n<h3 id=\"response-and-snoop-ranges\">Response and Snoop ranges</h3>\n<p>Ranges in the memory system are handled by having devices that are\nsensitive to an address range provide an implementation for\n<code class=\"language-plaintext highlighter-rouge\">getAddrRanges</code> in their slave port objects. This method returns an\n<code class=\"language-plaintext highlighter-rouge\">AddrRangeList</code> of addresses it responds to. When these ranges change\n(e.g. from PCI configuration taking place) the device should call\n<code class=\"language-plaintext highlighter-rouge\">sendRangeChange()</code> on its slave port so that the new ranges are\npropagated to the entire hierarchy. This is precisely what happens\nduring <code class=\"language-plaintext highlighter-rouge\">init()</code>; all memory objects call <code class=\"language-plaintext highlighter-rouge\">sendRangeChange()</code>, and a\nflurry of range updates occur until everyones ranges have been\npropagated to all busses in the system.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/memory_system/gem5_memory_system/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/memory_system/indexing_policies/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/memory_system/classic-coherence-protocol",
        "title": "Classic Memory System coherence",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Jason Lowe-Power<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"classic-memory-system-coherence\">Classic Memory System coherence</h1>\n<p>M5 2.0b4 introduced a substantially rewritten and streamlined cache\nmodel, including a new coherence protocol. (The old pre-2.0 cache model\nhad been patched up to work with the new <a href=\"/documentation/general_docs/memory_system/\">Memory\nSystem</a> introduced in 2.0beta, but not\nrewritten to take advantage of the new memory system\u2019s features.)</p>\n<p>The key feature of the new coherence protocol is that it is designed to\nwork with more-or-less arbitrary cache hierarchies (multiple caches each\non multiple levels). In contrast, the old protocol restricted sharing to\na single bus.</p>\n<p>In the real world, a system architecture will have limits on the number\nor configuration of caches that the protocol can be designed to\naccommodate. It\u2019s not practical to design a protocol that\u2019s fully\nrealistic and yet efficient for arbitrary configurations. In order to\nenable our protocol to work on (nearly) arbitrary configurations, we\ncurrently sacrifice a little bit of realism and a little bit of\nconfigurability. Our intent is that this protocol is adequate for\nresearchers studying aspects of system behavior other than coherence\nmechanisms. Researchers studying coherence specifically will probably\nwant to replace the default coherence mechanism with implementations of\nthe specific protocols under investigation.</p>\n<p>The protocol is a MOESI snooping protocol. Inclusion is <strong>not</strong>\nenforced; in a CMP configuration where you have several L1s whose total\ncapacity is a significant fraction of the capacity of the common L2 they\nshare, inclusion can be very inefficient.</p>\n<p>Requests from upper-level caches (those closer to the CPUs) propagate\ntoward memory in the expected fashion: an L1 miss is broadcast on the\nlocal L1/L2 bus, where it is snooped by the other L1s on that bus and\n(if none respond) serviced by the L2. If the request misses in the L2,\nthen after some delay (currently set equal to the L2 hit latency), the\nL2 will issue the request on its memory-side bus, where it will possibly\nbe snooped by other L2s and then be issued to an L3 or memory.</p>\n<p>Unfortunately, propagating snoop requests incrementally back up the\nhierarchy in a similar fashion is a source of myriad nearly intractable\nrace conditions. Real systems don\u2019t typically do this anyway; in general\nyou want a single snoop operation at the L2 bus to tell you the state of\nthe block in the whole L1/L2 hierarchy. There are a handful of methods\nfor this:</p>\n<ol>\n<li>just snoop the L2, but enforce inclusion so that the L2 has all the\ninfo you need about the L1s as well\u2014an idea we\u2019ve already rejected\nabove</li>\n<li>keep an extra set of tags for all the L1s at the L2 so those can be\nsnooped at the same time (see the Compaq Piranha)\u2014reasonable, if\nyou\u2019re hierarchy\u2019s not too deep, but now you\u2019ve got to size the tags\nin the lower-level caches based on the number, size, and\nconfiguration of the upper-level caches, which is a configuration\npain</li>\n<li>snoop the L1s in parallel with the L2, something that\u2019s not hard if\nthey\u2019re all on the same die (I believe Intel started doing this with\nthe Pentium Pro; not sure if they still do with the Core2 chips or\nnot, or if AMD does this as well, but I suspect so)\u2014also\nreasonable, but adding explicit paths for these snoops would also\nmake for a very cumbersome configuration process</li>\n</ol>\n<p>We solve this dilemma by introducing \u201cexpress snoops\u201d, which are special\nsnoop requests that get propagated up the hierarchy instantaneously and\natomically (much like the atomic-mode accesses described on the <a href=\"/documentation/general_docs/memory_system\">Memory\nSystem</a> page), even when the system is running\nin timing mode. Functionally this behaves very much like options 2 or 3\nabove, but because the snoops propagate along the regular bus\ninterconnects, there\u2019s no additional configuration overhead. There is\nsome timing inaccuracy introduced, but if we assume that there are\ndedicated paths in the real hardware for these snoops (or for\nmaintaining the additional copies of the upper-level tags at the\nlower-level caches) then the differences are probably minor.</p>\n<p>(More to come: how does a cache know when its request is completed? and\nother fascinating questions\u2026)</p>\n<p>Note: there are still some bugs in this protocol as of 2.0b4,\nparticularly if you have multiple L2s each with multiple L1s behind it,\nbut I believe it works for any configuration that worked in 2.0b3.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/m5ops/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/memory_system/classic_caches/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/memory_system/classic_caches",
        "title": "Classic Caches",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Jason Lowe-Power<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"classic-caches\">Classic Caches</h1>\n<p>The default cache is a non-blocking cache with MSHR (miss status holding\nregister) and WB (Write Buffer) for read and write misses. The Cache can\nalso be enabled with prefetch (typically in the last level of cache).</p>\n<p>There are multiple possible <a href=\"/documentation/general_docs/memory_system/replacement_policies\">replacement policies</a> and <a href=\"/documentation/general_docs/memory_system/indexing_policies\">indexing\npolicies</a> implemented in gem5. These define, respectively, the possible\nblocks that can be used for a block replacement given an address, and\nhow to use the address information to find a block's location. By\ndefault the cache lines are replaced using <a href=\"/documentation/general_docs/memory_system/replacement_policies\">LRU (least recently used)</a>,\nand indexed with the <a href=\"/documentation/general_docs/memory_system/indexing_policies\">Set Associative</a> policy.</p>\n<h1 id=\"interconnects\">Interconnects</h1>\n<h3 id=\"crossbars\">Crossbars</h3>\n<p>The two types of traffic in the crossbar are memory-mapped packets and\nsnooping packets. The memory-mapped requests go down the memory\nhierarchy, and responses go up the memory hierarchy (same route back).\nThe snooping requests go horizontally and up the cache hierarchy,\nsnooping responses go horizontally and down the hierarchy (same route\nback). Normal snoops go horizontally and express snoops go up the cache\nhierarchy.</p>\n<p><img alt=\"Bus Connections\" src=\"/assets/img/Bus.png\"/></p>\n<h3 id=\"bridges\">Bridges</h3>\n<h3 id=\"others\">Others\u2026</h3>\n<h1 id=\"debugging\">Debugging</h1>\n<p>There is a feature in the classic memory system for displaying the coherence state of a particular block from within the debugger (e.g., gdb). This feature is built on the classic memory system\u2019s support for functional accesses. (Note that this feature is currently rarely used and may have bugs.)</p>\n<p>If you inject a functional request with the command set to PrintReq, the packet traverses the memory system (like a regular functional request) but on any object that matches (other queued packet, cache block, etc.) it simply prints out some information about that object.</p>\n<p>There\u2019s a helper method on Port called printAddr() that takes an address and builds an appropriate PrintReq packet and injects it. Since it propagates using the same mechanism as a normal functional request, it needs to be injected from a port where it will propagate through the whole memory system, such as at a CPU. There are helper printAddr() methods on MemTest, AtomicSimpleCPU, and TimingSimpleCPU objects that simply call printAddr() on their respective cache ports. (Caveat: the latter two are untested.)</p>\n<p>Putting it all together, you can do this:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>(gdb) set print object\n(gdb) call SimObject::find(\" system.physmem.cache0.cache0.cpu\")\n$4 = (MemTest *) 0xf1ac60\n(gdb) p (MemTest*)$4\n$5 = (MemTest *) 0xf1ac60\n(gdb) call $5-&gt;printAddr(0x107f40)\n\nsystem.physmem.cache0.cache0\n  MSHRs\n    [107f40:107f7f] Fill   state:\n      Targets:\n        cpu: [107f40:107f40] ReadReq\nsystem.physmem.cache1.cache1\n  blk VEM\nsystem.physmem\n  0xd0\n</code></pre></div></div>\n<p>\u2026 which says that cache0.cache0 has an MSHR allocated for that address to serve a target ReadReq from the CPU, but it\u2019s not in service yet (else it would be marked as such); the block is valid, exclusive, and modified in cache1.cache1, and the byte has a value of 0xd0 in physical memory.</p>\n<p>Obviously it\u2019s not necessarily all the info you\u2019d want, but it\u2019s pretty useful. Feel free to extend. There\u2019s also a verbosity parameter that\u2019s currently not used that could be exploited to have different levels of output.</p>\n<p>Note that the extra \u201cp (MemTest*)$4\u201d is needed since although \u201cset print object\u201d displays the derived type, internally gdb still considers the pointer to be of the base type, so if you try and call printAddr directly on the $4 pointer you get this:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>(gdb) call $4-&gt;printAddr(0x400000)\nCouldn't find method SimObject::printAddr\n</code></pre></div></div>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/memory_system/classic-coherence-protocol/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/memory_system/gem5_memory_system/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/memory_system/gem5_memory_system",
        "title": "The gem5 Memory System",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Djordje Kovacevi<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"the-gem5-memory-system\">The gem5 Memory System</h1>\n<p>The document describes memory subsystem in gem5 with focus on program flow\nduring CPU\u2019s simple memory transactions (read or write).</p>\n<h2 id=\"model-hierarchy\">Model Hierarchy</h2>\n<p>Model that is used in this document consists of two out-of-order (O3) ARM v7\nCPUs with corresponding L1 data caches and Simple Memory. It is created by\nrunning gem5 with the following parameters:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>configs/example/fs.py \u2013-caches \u2013-cpu-type=arm_detailed \u2013-num-cpus=2\n</code></pre></div></div>\n<p>Gem5 uses Simulation Objects derived objects as basic blocks for building\nmemory system. They are connected via ports with established master/slave\nhierarchy. Data flow is initiated on master port while the response messages\nand snoop queries appear on the slave port.</p>\n<p><img alt=\"Simulation Object hierarchy of the model\" src=\"/assets/img/gem5_MS_Fig1.PNG\"/></p>\n<h2 id=\"cpu\">CPU</h2>\n<p>Data <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1cache.html\">Cache</a> object\nimplements a standard cache structure:</p>\n<p><img alt=\"DCache Simulation Objet\" src=\"/assets/img/gem5_MS_Fig2.PNG\"/></p>\n<p>It is not in the scope of this document to describe O3 CPU model in details, so\nhere are only a few relevant notes about the model:</p>\n<p><strong>Read access</strong> is initiated by sending message to the port towards DCache\nobject. If DCache rejects the message (for being blocked or busy) CPU will\nflush the pipeline and the access will be re-attempted later on. The access is\ncompleted upon receiving reply message (ReadRep) from DCache.</p>\n<p><strong>Write access</strong> is initiated by storing the request into store buffer whose\ncontext is emptied and sent to DCache on every tick. DCache may also reject the\nrequest. Write access is completed when write reply (WriteRep) message is\nreceived from DCache.</p>\n<p>Load &amp; store buffers (for read and write access) don\u2019t impose any restriction\non the number of active memory accesses. Therefore, the maximum number of\noutstanding CPU\u2019s memory access requests is not limited by CPU Simulation\nObject but by underlying memory system model.</p>\n<p><strong>Split memory access</strong> is implemented.</p>\n<p>The message that is sent by CPU contains memory type (Normal, Device, Strongly\nOrdered and cachebility) of the accessed region. However, this is not being\nused by the rest of the model that takes more simplified approach towards\nmemory types.</p>\n<h2 id=\"data-cache-object\">Data Cache Object</h2>\n<p>Data <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1Cache.html\">Cache</a> object\nimplements a standard cache structure:</p>\n<p><strong>Cached memory reads</strong> that match particular cache tag (with Valid &amp; Read\nflags) will be completed (by sending ReadResp to CPU) after a configurable\ntime. Otherwise, the request is forwarded to Miss Status and Handling Register\n(<a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1MSHR.html\">MSHR</a>) block.</p>\n<p><strong>Cached memory writes</strong> that match particular cache tag (with Valid, Read &amp;\nWrite flags) will be completed (by sending WriteResp CPU) after the same\nconfigurable time. Otherwise, the request is forwarded to Miss Status and\nHandling Register(MSHR) block.</p>\n<p><strong>Uncached memory reads</strong> are forwarded to <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1MSHR.html\">MSHR</a> block.</p>\n<p><strong>Uncached memory writes</strong> are forwarded to WriteBuffer block.</p>\n<p><strong>Evicted (&amp; dirty) cache lines</strong> are forwarded to WriteBuffer block.</p>\n<p>CPU\u2019s access to Data <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1Cache.html\">Cache</a> is blocked if any of the\nfollowing is true:</p>\n<ul>\n<li><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1MSHR.html\">MSHR</a> block is full.\n(The size of MSHR\u2019s buffer is configurable.)</li>\n<li>Writeback block is full. (The size of the block\u2019s buffer is configurable.)</li>\n<li>The number of outstanding memory accesses against the same memory cache line\nhas reached configurable threshold value \u2013 see <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1MSHR.html\">MSHR</a> and Write Buffer for\ndetails.</li>\n</ul>\n<p>Data <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1Cache.html\">Cache</a> in block\nstate will reject any request from slave port (from CPU) regardless of whether\nit would result in cache hit or miss. Note that incoming messages on master\nport (response messages and snoop requests) are never rejected.</p>\n<p><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1Cache.html\">Cache</a> hit on uncachable\nmemory region (unpredicted behaviour according to ARM ARM) will invalidate\ncache line and fetch data from memory.</p>\n<h3 id=\"tags--data-block\">Tags &amp; Data Block</h3>\n<p><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1Cache.html\">Cache</a> lines (referred as\nblocks in source code) are organised into sets with configurable associativity\nand size. They have the following status flags:</p>\n<ul>\n<li><strong>Valid</strong>. It holds data. Address tag is valid</li>\n<li><strong>Read</strong>. No read request will be accepted without this flag being set. For\nexample, cache line is valid and unreadable when it waits for write flag to\ncomplete write access.</li>\n<li><strong>Write</strong>. It may accept writes. Cache line with Write flags identifies\nUnique state \u2013 no other cache memory holds the copy.</li>\n<li><strong>Dirty</strong>. It needs Writeback when evicted.</li>\n</ul>\n<p>Read access will hit cache line if address tags match and Valid and Read flags\nare set. Write access will hit cache line if address tags match and Valid, Read\nand Write flags are set.</p>\n<h3 id=\"mshr-and-write-buffer-queues\">MSHR and Write Buffer Queues</h3>\n<p>Miss Status and Handling Register (<a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1MSHR.html\">MSHR</a>) queue holds the list of\nCPU\u2019s outstanding memory requests that require read access to lower memory\nlevel. They are:</p>\n<ul>\n<li>Cached Read misses.</li>\n<li>Cached Write misses.</li>\n<li>Uncached reads.</li>\n</ul>\n<p>WriteBuffer queue holds the following memory requests:</p>\n<ul>\n<li>Uncached writes.</li>\n<li>Writeback from evicted (&amp; dirty) cache lines.</li>\n</ul>\n<p><img alt=\"MSHR and Write Buffer Blocks\" src=\"/assets/img/gem5_MS_Fig3.PNG\"/></p>\n<p>Each memory request is assigned to corresponding <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1MSHR.html\">MSHR</a> object (READ or WRITE on\ndiagram above) that represents particular block (cache line) of memory that has\nto be read or written in order to complete the command(s). As shown on gigure\nabove, cached read/writes against the same cache line have a common <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1MSHR.html\">MSHR</a> object and will be\ncompleted with a single memory access.</p>\n<p>The size of the block (and therefore the size of read/write access to lower\nmemory) is:</p>\n<ul>\n<li>The size of cache line for cached access &amp; writeback;</li>\n<li>As specified in CPU instruction for uncached access.</li>\n</ul>\n<p>In general, Data <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1Cache.html\">Cache</a>\nmodel distinguishes between just two memory types:</p>\n<ul>\n<li>Normal Cached memory. It is always treated as write back, read and write\nallocate.</li>\n<li>Normal uncached, Device and Strongly Ordered types are treated equally (as\nuncached memory)</li>\n</ul>\n<h3 id=\"memory-access-ordering\">Memory Access Ordering</h3>\n<p>An unique order number is assigned to each CPU read/write request(as they\nappear on slave port). Order numbers of <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1MSHR.html\">MSHR</a> objects are copied from the\nfirst assigned read/write.</p>\n<p>Memory read/writes from each of these two queues are executed in order\n(according to the assigned order number). When both queues are not empty the\nmodel will execute memory read from <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1MSHR.html\">MSHR</a> block unless WriteBuffer is\nfull. It will, however, always preserve the order of read/writes on the same\n(or overlapping) memory cache line (block).</p>\n<p>In summary:</p>\n<ul>\n<li>Order of accesses to cached memory is not preserved unless they target the\nsame cache line. For example, the accesses #1, #5 &amp; #10 will complete\nsimultaneously in the same tick (still in order). The access #5 will complete\nbefore #3.</li>\n<li>Order of all uncached memory writes is preserved. Write#6 always completes\nbefore Write#13.</li>\n<li>Order to all uncached memory reads is preserved. Read#2 always completes\nbefore Read#8.</li>\n<li>The order of a read and a write uncached access is not necessarily preserved\nunless their access regions overlap. Therefore, Write#6 always completes before\nRead#8 (they target the same memory block). However, Write#13 may complete\nbefore Read#8.</li>\n</ul>\n<h2 id=\"coherent-bus-object\">Coherent Bus Object</h2>\n<p><img alt=\"Coherent Bus Object\" src=\"/assets/img/gem5_MS_Fig4.PNG\"/></p>\n<p>Coherent Bus object provides basic support for snoop protocol:</p>\n<p>All requests on the slave port are forwarded to the appropriate master port.\nRequests for cached memory regions are also forwarded to other slave ports (as\nsnoop requests).</p>\n<p>Master port replies are forwarded to the appropriate slave port.</p>\n<p>Master port snoop requests are forwarded to all slave ports.</p>\n<p>Slave port snoop replies are forwarded to the port that was the source of the\nrequest. (Note that the source of snoop request can be either slave or master\nport.)</p>\n<p>The bus declares itself blocked for a configurable period of time after any of\nthe following events:</p>\n<ul>\n<li>A packet is sent (or failed to be sent) to a slave port.</li>\n<li>A reply message is sent to a master port.</li>\n<li>Snoop response from one slave port is sent to another slave port.</li>\n</ul>\n<p>The bus in blocked state rejects the following incoming messages:</p>\n<ul>\n<li>Slave port requests.</li>\n<li>Master port replies.</li>\n<li>Master port snoop requests.</li>\n</ul>\n<h2 id=\"simple-memory-object\">Simple Memory Object</h2>\n<p>It never blocks the access on slave port.</p>\n<p>Memory read/write takes immediate effect. (Read or write is performed when the\nrequest is received).</p>\n<p>Reply message is sent after a configurable period of time .</p>\n<h2 id=\"message-flow\">Message Flow</h2>\n<h3 id=\"memory-access-ordering-1\">Memory Access Ordering</h3>\n<p>The following diagram shows read access that hits Data Cache line with Valid\nand Read flags:</p>\n<p><img alt=\"Read Hit(Read flag must be set in cache line)\" src=\"/assets/img/gem5_MS_Fig5.PNG\"/></p>\n<p>Cache miss read access will generate the following sequence of messages:</p>\n<p><img alt=\"Read Miss with snoop reply\" src=\"/assets/img/gem5_MS_Fig6.PNG\"/></p>\n<p>Note that bus object never gets response from both DCache2 and Memory object.\nIt sends the very same ReadReq package (message) object to memory and data\ncache. When Data Cache wants to reply on snoop request it marks the message\nwith MEM_INHIBIT flag that tells Memory object not to process the message.</p>\n<h3 id=\"memory-access-ordering-2\">Memory Access Ordering</h3>\n<p>The following diagram shows write access that hits DCache1 cache line with\nValid &amp; Write flags:</p>\n<p><img alt=\"Write Hit (with Write flag set in cache line)\" src=\"/assets/img/gem5_MS_Fig7.PNG\"/></p>\n<p>Next figure shows write access that hits DCache1 cache line with Valid but no\nWrite flags \u2013 which qualifies as write miss. DCache1 issues UpgradeReq to\nobtain write permission. DCache2::snoopTiming will invalidate cache line that\nhas been hit. Note that UpgradeResp message doesn\u2019t carry data.</p>\n<p><img alt=\"Write Miss \u2013 matching tag with no Write flag\" src=\"/assets/img/gem5_MS_Fig8.PNG\"/></p>\n<p>The next diagram shows write miss in DCache. ReadExReq invalidates cache line\nin DCache2. ReadExResp carries the content of memory cache line.</p>\n<p><img alt=\"Miss - no matching tag\" src=\"/assets/img/gem5_MS_Fig9.PNG\"/></p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/memory_system/classic_caches/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/memory_system/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/memory_system/indexing_policies",
        "title": "Indexing Policies",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Jason Lowe-Power<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"indexing-policies\">Indexing Policies</h1>\n<p>Indexing policies determine the locations to which a block is mapped\nbased on its address.</p>\n<p>The most important methods of indexing policies are getPossibleEntries()\nand regenerateAddr():</p>\n<ul>\n<li>getPossibleEntries() determines the list of entries a given address\ncan be mapped to.</li>\n<li>regenerateAddr() uses the address information stored in an entry to\ndetermine its full original address.</li>\n</ul>\n<p>For further information on Cache Indexing Policies, please refer to the\nwikipedia articles on <a href=\"https://en.wikipedia.org/wiki/Cache_Placement_Policies\">Placement Policies</a> and\n<a href=\"https://en.wikipedia.org/wiki/CPU_cache#Associativity%7C\">Associativity</a>.</p>\n<h2 id=\"set_associative\">Set Associative</h2>\n<p>The set associative indexing policy is the standard for table-like\nstructures, and can be further divided into Direct-Mapped (or 1-way\nset-associative), Set-Associative and Full-Associative (N-way\nset-associative, where N is the number of table entries).</p>\n<p>A set associative cache can be seen as a skewed associative cache whose\nskewing function maps to the same value for every way.</p>\n<h2 id=\"skewed_associative\">Skewed Associative</h2>\n<p>The skewed associative indexing policy has a variable mapping based on a\nhash function, so a value x can be mapped to different sets, based on\nthe way being used. Gem5 implements skewed caches as described in\n<a href=\"https://www.researchgate.net/publication/220758754_Skewed-associative_Caches\">\u201cSkewed-Associative\nCaches\u201d, from Seznec et al</a>.</p>\n<p>Note that there are only a limited number of implemented hashing\nfunctions, so if the number of ways is higher than that number then a\nsub-optimal automatically generated hash function is used.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/memory_system/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/memory_system/replacement_policies/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/memory_system/replacement_policies",
        "title": "Replacement Policies",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Jason Lowe-Power<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"replacement-policies\">Replacement Policies</h1>\n<p>Gem5 has multiple implemented replacement policies. Each one uses its\nspecific replacement data to determine a replacement victim on\nevictions.</p>\n<p>All of the replacement policies prioritize victimizing invalid blocks.</p>\n<p>A replacement policy consists of a reset(), touch(), invalidate() and\ngetVictim() methods. Each of which handles the replacement data\ndifferently.</p>\n<ul>\n<li>reset() is used to initialize a replacement data (i.e., validate).\nIt should be called only on entry insertion, and must not be called\nagain until invalidation. The first touch to an entry must always be\na reset().</li>\n<li>touch() is used on accesses to the replacement data, and as such\nshould be called on entry accesses. It updates the replacement data.</li>\n<li>invalidate() is called whenever an entry is invalidated, possibly\ndue to coherence handling. It makes the entry as likely to be\nevicted as possible on the next victim search. An entry does not\nneed to be invalidated before a reset() is done. When the simulation\nstarts all entries are invalid.</li>\n<li>getVictim() is called when there is a miss, and an eviction must be\ndone. It searches among all replacement candidates for an entry with\nthe worst replacement data, generally prioritizing the eviction of\ninvalid entries.</li>\n</ul>\n<p>We briefly describe the replacement policies implemented in Gem5. If\nfurther information is required, the <a href=\"https://en.wikipedia.org/wiki/Cache_replacement_policies\">Cache Replacement Policies\nWikipedia page</a>, or the respective papers can be studied.</p>\n<h2 id=\"random\">Random</h2>\n<p>The simplest replacement policy; it does not need replacement data, as\nit randomly selects a victim among the candidates.</p>\n<h2 id=\"least_recently_used_lru\">Least Recently Used (LRU)</h2>\n<p>Its replacement data consists of a last touch timestamp, and the victim\nis chosen based on it: the oldest it is, the more likely its respective\nentry is to be victimized.</p>\n<h2 id=\"tree_pseudo_least_recently_used_treeplru\">Tree Pseudo Least Recently Used (TreePLRU)</h2>\n<p>A variation of the LRU that uses a binary tree to keep track of the\nrecency of use of the entries through 1-bit pointers.</p>\n<h2 id=\"bimodal_insertion_policy_bip\">Bimodal Insertion Policy (BIP)</h2>\n<p>The <a href=\"https://dl.acm.org/citation.cfm?id=1250709\">Bimodal Insertion Policy</a> is similar to the LRU, however, blocks\nhave a probability of being inserted as the MRU, according to a bimodal\nthrottle parameter (btp). The highest btp is, the highest is the\nlikelihood of a new block being inserted as MRU.</p>\n<h2 id=\"lru_insertion_policy_lip\">LRU Insertion Policy (LIP)</h2>\n<p>The <a href=\"https://dl.acm.org/citation.cfm?id=1250709\">LRU Insertion Policy</a> consists of a LRU\nreplacement policy that instead of inserting blocks with the most recent\nlast touch timestamp, it inserts them as the LRU entry. On subsequent\ntouches to the block, its timestamp is updated to be the MRU, as in LRU.\nIt can also be seen as a BIP where the likelihood of inserting a new\nblock as the most recently used is 0%.</p>\n<h2 id=\"most_recently_used_mru\">Most Recently Used (MRU)</h2>\n<p>The Most Recently Used policy chooses replacement victims by their\nrecency, however, as opposed to LRU, the newer the entry is, the more\nlikely it is to be victimized.</p>\n<h2 id=\"least_frequently_used_lfu\">Least Frequently Used (LFU)</h2>\n<p>The victim is chosen using the reference frequency. The least referenced\nentry is chosen to be evicted, regardless of the amount of times it has\nbeen touched, or how much time has passed since its last touch.</p>\n<h2 id=\"first_in_first_out_fifo\">First-In, First-Out (FIFO)</h2>\n<p>The victim is chosen using the insertion timestamp. If no invalid\nentries exist, the oldest one is victimized, regardless of the amount of\ntimes it has been touched.</p>\n<h2 id=\"second_chance\">Second-Chance</h2>\n<p>The <a href=\"https://apps.dtic.mil/docs/citations/AD0687552\">Second-Chance</a> replacement policy is similar to FIFO, however\nentries are given a second chance before being victimized. If an entry\nwould have been the next to be victimized, but its second chance bit is\nset, this bit is cleared, and the entry is re-inserted at the end of the\nFIFO. Following a miss, an entry is inserted with its second chance bit\ncleared.</p>\n<h2 id=\"not_recently_used_nru\">Not Recently Used (NRU)</h2>\n<p>Not Recently Used (NRU) is an approximation of LRU that uses a single\nbit to determine if a block is going to be re-referenced in the near or\ndistant future. If the bit is 1, it is likely to not be referenced soon,\nso it is chosen as the replacement victim. When a block is victimized,\nall its co-replacement candidates have their re-reference bit\nincremented.</p>\n<h2 id=\"re_reference_interval_prediction_rrip\">Re-Reference Interval Prediction (RRIP)</h2>\n<p><a href=\"https://dl.acm.org/citation.cfm?id=1815971\">Re-Reference Interval Prediction (RRIP)</a> is an extension of NRU that\nuses a re-reference prediction value to determine if blocks are going to\nbe re-used in the near future or not. The higher the value of the RRPV,\nthe more distant the block is from its next access. From the original\npaper, this implementation of RRIP is also called Static RRIP (SRRIP),\nas it always inserts blocks with the same RRPV.</p>\n<h2 id=\"bimodal_re_reference_interval_prediction_brrip\">Bimodal Re-Reference Interval Prediction (BRRIP)</h2>\n<p><a href=\"https://dl.acm.org/citation.cfm?id=1815971\">Bimodal Re-Reference Interval Prediction\n(BRRIP)</a> is an extension of\nRRIP that has a probability of not inserting blocks as the LRU, as in\nthe Bimodal Insertion Policy. This probability is controlled by the\nbimodal throtle parameter (btp).</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/memory_system/indexing_policies/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/moving_to_github/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/ruby",
        "title": "Ruby",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Jason Lowe-Power<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"ruby\">Ruby</h1>\n<p>Ruby implements a detailed simulation model for the memory subsystem. It\nmodels inclusive/exclusive cache hierarchies with various replacement\npolicies, coherence protocol implementations, interconnection networks,\nDMA and memory controllers, various sequencers that initiate memory\nrequests and handle responses. The models are modular, flexible and\nhighly configurable. Three key aspects of these models are:</p>\n<ol>\n<li>Separation of concerns \u2013 for example, the coherence protocol\nspecifications are separate from the replacement policies and cache\nindex mapping, the network topology is specified separately from the\nimplementation.</li>\n<li>Rich configurability \u2013 almost any aspect affecting the memory\nhierarchy functionality and timing can be controlled.</li>\n<li>Rapid prototyping \u2013 a high-level specification language, SLICC, is\nused to specify functionality of various controllers.</li>\n</ol>\n<p>The following picture, taken from the GEMS tutorial in ISCA 2005, shows\na high-level view of the main components in Ruby.\n<img alt=\"ruby_overview.jpg\" src=\"/assets/img/Ruby_overview.jpg\"/></p>\n<p>For a tutorial-based approach to Ruby see <a href=\"/documentation/learning_gem5/part3/\">Part III of Learning gem5</a></p>\n<h3 id=\"slicc--coherence-protocols\">SLICC + Coherence protocols:</h3>\n<p><strong><em><a href=\"slicc\">SLICC</a></em></strong> stands for <em>Specification Language for\nImplementing Cache Coherence</em>. It is a domain specific language that is\nused for specifying cache coherence protocols. In essence, a cache\ncoherence protocol behaves like a state machine. SLICC is used for\nspecifying the behavior of the state machine. Since the aim is to model\nthe hardware as close as possible, SLICC imposes constraints on the\nstate machines that can be specified. For example, SLICC can impose\nrestrictions on the number of transitions that can take place in a\nsingle cycle. Apart from protocol specification, SLICC also combines\ntogether some of the components in the memory model. As can be seen in\nthe following picture, the state machine takes its input from the input\nports of the inter-connection network and queues the output at the\noutput ports of the network, thus tying together the cache / memory\ncontrollers with the inter-connection network itself.</p>\n<p><img alt=\"slicc_overview.jpg\" src=\"/assets/img/Slicc_overview.jpg\"/></p>\n<p>The following cache coherence protocols are supported:</p>\n<ol>\n<li><strong><a href=\"MI_example\">MI_example</a></strong>: example protocol, 1-level\ncache.</li>\n<li><strong><a href=\"MESI_Two_Level\">MESI_Two_Level</a></strong>: single chip,\n2-level caches, strictly-inclusive hierarchy.</li>\n<li><strong><a href=\"MOESI_CMP_directory\">MOESI_CMP_directory</a></strong>:\nmultiple chips, 2-level caches, non-inclusive (neither strictly\ninclusive nor exclusive) hierarchy.</li>\n<li><strong><a href=\"MOESI_CMP_token\">MOESI_CMP_token</a></strong>: 2-level caches.\nTODO.</li>\n<li><strong><a href=\"MOESI_hammer\">MOESI_hammer</a></strong>: single chip, 2-level\nprivate caches, strictly-exclusive hierarchy.</li>\n<li><strong><a href=\"Garnet_standalone\">Garnet_standalone</a></strong>: protocol to\nrun the Garnet network in a standalone manner.</li>\n<li><strong>MESI Three Level</strong>: 3-level caches,\nstrictly-inclusive hierarchy. Based on MESI Two Level with an extra L0 cache.</li>\n<li><strong><a href=\"CHI\">CHI</a></strong>: flexible protocol that implements Arm\u2019s AMBA5 CHI transactions.\nSupports configurable cache hierarchy with both MESI or MOESI coherency.</li>\n</ol>\n<p>Commonly used notations and data structures in the protocols have been\ndescribed in detail <a href=\"cache-coherence-protocols\">here</a>.</p>\n<h3 id=\"protocol-independent-memory-components\">Protocol independent memory components</h3>\n<ol>\n<li><strong>Sequencer</strong></li>\n<li><strong>Cache Memory</strong></li>\n<li><strong>Replacement Policies</strong></li>\n<li><strong>Memory Controller</strong></li>\n</ol>\n<p>In general cache coherence protocol independent components comprises of\nthe Sequencer, Cache Memory structure, Cache Replacement policies and\nthe Memory controller. The Sequencer class is responsible for feeding\nthe memory subsystem (including the caches and the off-chip memory) with\nload/store/atomic memory requests from the processor. Every memory\nrequest when completed by the memory subsystem also send back the\nresponse to the processor via the Sequencer. There is one Sequencer for\neach hardware thread (or core) simulated in the system. The Cache Memory\nmodels a set-associative cache structure with parameterizable size,\nassociativity, replacement policy. L1, L2, L3 caches (if exists)in the\nsystem are instances of Cache Memory. The Cache Replacement policies are\nkept modular from the Cache Memory, so that different instances of Cache\nMemory can use different replacement policies of their choice. Currently\ntwo replacement polices \u2013 LRU and Pseudo-LRU \u2013 are distributed with\nthe release. Memory Controller is responsible for simulating and\nservicing any request that misses on all the on-chip caches of the\nsimulated system. Memory Controller currently simple, but models DRAM\nban contention, DRAM refresh faithfully. It also models close-page\npolicy for DRAM buffer.</p>\n<h3 id=\"interconnection-network\">Interconnection Network</h3>\n<p>The interconnection network connects the various components of the\nmemory hierarchy (cache, memory, dma controllers) together.</p>\n<p><img alt=\"Interconnection_network.jpg\" src=\"/assets/img/Interconnection_network.jpg\" title=\"Interconnection_network.jpg\"/></p>\n<p>The key components of an interconnection network are:</p>\n<ol>\n<li><strong>Topology</strong></li>\n<li><strong>Routing</strong></li>\n<li><strong>Flow Control</strong></li>\n<li><strong>Router Microarchitecture</strong></li>\n</ol>\n<p><strong><em>More details about the network model implementation are described\n<a href=\"Interconnection_Network\">here</a>.</em></strong></p>\n<p>Alternatively, Interconnection network could be replaced with the\nexternal simulator <a href=\"https://github.com/ceunican/tpzsimul\">TOPAZ</a>. This\nsimulator is ready to run within gem5 and adds a significant number of\nfeatures\nover original ruby network simulator. It includes, new advanced router\nmicro-architectures, new topologies, precision-performance adjustable\nrouter models, mechanisms to speed-up network simulation, etc.</p>\n<h2 id=\"life-of-a-memory-request-in-ruby\">Life of a memory request in Ruby</h2>\n<p>In this section we will provide a high level overview of how a memory\nrequest is serviced by Ruby as a whole and what components in Ruby it\ngoes through. For detailed operations within each components though,\nrefer to previous sections describing each component in isolation.</p>\n<ol>\n<li>A memory request from a core or hardware context of gem5 enters the\njurisdiction of Ruby through the <strong><em>RubyPort::recvTiming</em></strong>\ninterface (in src/mem/ruby/system/RubyPort.hh/cc). The number of\nRubyport instantiation in the simulated system is equal to the\nnumber of hardware thread context or cores (in case of\n<em>non-multithreaded</em> cores). A port from the side of each core is\ntied to a corresponding RubyPort.</li>\n<li>The memory request arrives as a gem5 packet and RubyPort is\nresponsible for converting it to a RubyRequest object that is\nunderstood by various components of Ruby. It also finds out if the\nrequest is for some PIO or not and maneuvers the packet to correct\nPIO. Finally once it has generated the corresponding RubyRequest\nobject and ascertained that the request is a <em>normal</em> memory request\n(not PIO access), it passes the request to the\n<strong><em>Sequencer::makeRequest</em></strong> interface of the attached Sequencer\nobject with the port (variable <em>ruby_port</em> holds the pointer to\nit). Observe that Sequencer class itself is a derived class from the\nRubyPort class.</li>\n<li>As mentioned in the section describing Sequencer class of Ruby,\nthere are as many objects of Sequencer in a simulated system as the\nnumber of hardware thread context (which is also equal to the number\nof RubyPort object in the system) and there is an one-to-one mapping\nbetween the Sequencer objects and the hardware thread context. Once\na memory request arrives at the <strong><em>Sequencer::makeRequest</em></strong>, it\ndoes various accounting and resource allocation for the request and\nfinally pushes the request to the Ruby\u2019s coherent cache hierarchy\nfor satisfying the request while accounting for the delay in\nservicing the same. The request is pushed to the Cache hierarchy by\nenqueueing the request to the <em>mandatory queue</em> after accounting for\nL1 cache access latency. The <em>mandatory queue</em> (variable name\n<em>m_mandatory_q_ptr</em>) effectively acts as the interface between\nthe Sequencer and the SLICC generated cache coherence files.</li>\n<li>L1 cache controllers (generated by SLICC according to the coherence\nprotocol specifications) dequeues request from the <em>mandatory queue</em>\nand looks up the cache, makes necessary coherence state transitions\nand/or pushes the request to the next level of cache hierarchy as\nper the requirements. Different controller and components of SLICC\ngenerated Ruby code communicates among themselves through\ninstantiations of <em>MessageBuffer</em> class of Ruby\n(src/mem/ruby/buffers/MessageBuffer.cc/hh) , which can act as\nordered or unordered buffer or queues. Also the delays in servicing\ndifferent steps for satisfying a memory request gets accounted for\nscheduling enqueue-ing and dequeue-ing operations accordingly. If\nthe requested cache block may be found in L1 caches and with\nrequired coherence permissions then the request is satisfied and\nimmediately returned. Otherwise the request is pushed to the next\nlevel of cache hierarchy through <em>MessageBuffer</em>. A request can go\nall the way up to the Ruby\u2019s Memory Controller (also called\nDirectory in many protocols). Once the request get satisfied it is\npushed upwards in the hierarchy through <em>MessageBuffer</em>s.</li>\n<li>The <em>MessageBuffers</em> also act as entry point of coherence messages\nto the on-chip interconnect modeled. The MesageBuffers are connected\naccording to the interconnect topology specified. The coherence\nmessages thus travel through this on-chip interconnect accordingly.</li>\n<li>Once the requested cache block is available at L1 cache with desired\ncoherence permissions, the L1 cache controller informs the\ncorresponding Sequencer object by calling its <strong><em>readCallback</em></strong> or\n<strong>\u2018writeCallback</strong>\u2019\u2019 method depending upon the type of the request.\nNote that by the time these methods on Sequencer are called the\nlatency of servicing the request has been implicitly accounted for.</li>\n<li>The Sequencer then clears up the accounting information for the\ncorresponding request and then calls the\n<strong><em>RubyPort::ruby_hit_callback</em></strong> method. This ultimately returns\nthe result of the request to the corresponding port of the core/\nhardware context of the frontend (gem5).</li>\n</ol>\n<h2 id=\"directory-structure\">Directory Structure</h2>\n<ul>\n<li><strong>src/mem/</strong>\n<ul>\n<li><strong>protocols</strong>: SLICC specification for coherence protocols</li>\n<li><strong>slicc</strong>: implementation for SLICC parser and code generator</li>\n<li><strong>ruby</strong>\n<ul>\n<li><strong>common</strong>: frequently used data structures, e.g. Address\n(with bit-manipulation methods), histogram, data block</li>\n<li><strong>filters</strong>: various Bloom filters (stale code from GEMS)</li>\n<li><strong>network</strong>: Interconnect implementation, sample topology\nspecification, network power calculations, message buffers\nused for connecting controllers</li>\n<li><strong>profiler</strong>: Profiling for cache events, memory controller\nevents</li>\n<li><strong>recorder</strong>: Cache warmup and access trace recording</li>\n<li><strong>slicc_interface</strong>: Message data structure, various\nmappings (e.g. address to directory node), utility functions\n(e.g. conversion between address &amp; int, convert address to\ncache line address)</li>\n<li><strong>structures</strong>: Protocol independent memory components \u2013\nCacheMemory, DirectoryMemory</li>\n<li><strong>system</strong>: Glue components \u2013 Sequencer, RubyPort,\nRubySystem</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/ruby/heterogarnet/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/ruby/interconnection-network/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/ruby/CHI",
        "title": "CHI",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Tiago M\u00fcck<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"chi\">CHI</h1>\n<p>The CHI ruby protocol provides a single cache controller that can be reused at multiple levels of the cache hierarchy and configured to model multiple instances of MESI and MOESI cache coherency protocols. This implementation is based of <a href=\"https://developer.arm.com/documentation/ihi0050/D/\">Arm\u2019s AMBA 5 CHI specification</a> and provides a scalable framework for the design space exploration of large SoC designs.</p>\n<ul>\n<li><a href=\"#chi-overview\">CHI overview and terminology</a></li>\n<li><a href=\"#protocol-overview\">Protocol overview</a></li>\n<li><a href=\"#protocol-implementation\">Protocol implementation</a>\n<ul>\n<li><a href=\"#transaction-allocation\">Transaction allocation</a></li>\n<li><a href=\"#transaction-initialization\">Transaction initialization</a></li>\n<li><a href=\"#transaction-execution\">Transaction execution</a></li>\n<li><a href=\"#transaction-finalization\">Transaction finalization</a></li>\n<li><a href=\"#hazard-handling\">Hazard handling</a></li>\n<li><a href=\"#performance-modeling\">Performance modeling</a></li>\n<li><a href=\"#cache-block-allocation-and-replacement-modeling\">Cache block allocation and replacement modeling</a></li>\n</ul>\n</li>\n<li><a href=\"#supported-chi-transactions\">Supported CHI transactions</a>\n<ul>\n<li><a href=\"#supported-requests\">Supported requests</a></li>\n<li><a href=\"#supported-snoops\">Supported snoops</a></li>\n<li><a href=\"#writeback-and-evictions\">Writeback and evictions</a></li>\n<li><a href=\"#hazards\">Hazards</a></li>\n<li><a href=\"#other-implementations-notes\">Other implementations notes</a></li>\n<li><a href=\"#protocol-table\">Protocol table</a></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"chi-overview-and-terminology\">CHI overview and terminology</h2>\n<p>CHI (Coherent Hub Interface) provides a component architecture and transaction-level specification to model MESI and MOESI cache coherency. CHI defines three main components as shown in the figure below:</p>\n<p><img alt=\"CHI components\" src=\"/assets/img/ruby_chi/chi_components.png\"/></p>\n<ul>\n<li>the request node initiates transactions and sends requests towards memory. A request node can be a <em>fully coherent request node (<strong>RNF</strong>)</em>, meaning the request node caches data locally and should respond to snoop requests.</li>\n<li>the interconnect (ICN) which is the responder for request nodes. At protocol level the interconnect is a component encapsulating the <em>fully coherent home nodes (<strong>HNF</strong>)</em> of the system.</li>\n<li>the <em>slave nodes (<strong>SNF</strong>)</em>, which interface with the memory controllers.</li>\n</ul>\n<p>An HNF is the point of coherency (PoC) and point of serialization (PoS) for a specific address range. The HNF is responsible for issuing any required snoop requests to RNFs or memory access requests to SNFs in order to complete a transaction. The HNF can also encapsulate a shared last-level cache and include a directory for targeted snoops.</p>\n<p>The <a href=\"https://developer.arm.com/documentation/ihi0050/D/\">CHI specification</a> also defines specific types of nodes for non-coherent requesters (RNI) and non-coherent address ranges (HNI and SNI), e.g., memory ranges belonging to IO components. In Ruby, IO accesses don\u2019t go though the cache coherency protocol so only CHI\u2019s fully coherent node types are implemented. In this documentation we interchangeably use the terms RN / RNF, HN / HNF, and SN/SNF. We also use the terms <strong>upstream</strong> and <strong>downstream</strong> to refer to components in the previous (i.e. towards the cpu) and next  (i.e. towards memory) levels in the memory hierarchy, respectively.</p>\n<h2 id=\"protocol-overview\">Protocol overview</h2>\n<p>The CHI protocol implementation consists mainly of two controllers:</p>\n<ul>\n<li><code class=\"language-plaintext highlighter-rouge\">Memory_Controller</code> (<strong>src/mem/ruby/protocol/chi/CHI-mem.sm</strong>) implements a CHI slave node. It receives memory read or write requests from the home nodes and interfaces with gem5\u2019s classic memory controllers.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">Cache_Controller</code> (<strong>src/mem/ruby/protocol/chi/CHI-cache.sm</strong>) generic cache controller state machine.</li>\n</ul>\n<p>In order to allow fully flexible cache hierarchies, <code class=\"language-plaintext highlighter-rouge\">Cache_Controller</code> can be configured to model any cache level (e.g. L1D, priv. L2, shared L3) within both request and home nodes. Furthermore it also supports multiple features not available in other Ruby protocols:</p>\n<ul>\n<li>configurable cache block allocation and deallocation policies for each request type.</li>\n<li>unified or separate transaction buffers for incoming and outgoing requests.</li>\n<li>MESI or MOESI operation.</li>\n<li>directory and cache tag and data array stalls.</li>\n<li>parameters to inject latency in multiple steps of the request handling flow. This allows us to more closely calibrate the performance.</li>\n</ul>\n<p>The implementation defines the following cache states:</p>\n<ul>\n<li><code class=\"language-plaintext highlighter-rouge\">I</code>: line is invalid</li>\n<li><code class=\"language-plaintext highlighter-rouge\">SC</code>: line is shared and clean</li>\n<li><code class=\"language-plaintext highlighter-rouge\">UC</code>: line is exclusive/unique and clean</li>\n<li><code class=\"language-plaintext highlighter-rouge\">SD</code>: line is shared and dirty</li>\n<li><code class=\"language-plaintext highlighter-rouge\">UD</code>: line exclusive/unique and dirty</li>\n<li><code class=\"language-plaintext highlighter-rouge\">UD_T</code>: <code class=\"language-plaintext highlighter-rouge\">UD</code> with timeout. When a store conditional fails and causes the line to transition from I to UD, we transition to <code class=\"language-plaintext highlighter-rouge\">UD_T</code> instead if the number of failures is above a certain threshold (configuration defined). In <code class=\"language-plaintext highlighter-rouge\">UD_T</code> the line cannot be evicted from the requester for a given number of cycles (also configuration defined); after which the lines goes to UD. This is necessary to avoid livelocks in certain scenarios.</li>\n</ul>\n<p>The figure below gives an overview of the state transitions when the controller is configured as a L1 cache:</p>\n<p><img alt=\"L1 cache state machine\" src=\"/assets/img/ruby_chi/sm_l1_cache.svg\"/></p>\n<p>Transitions are annotated with the incoming request from the cpu (or generated internally, e.g. <em>Replacements</em>) and the resulting outgoing request sent downstream. For simplicity, the figure omits requests that do not change states (e.g., cache hits) and invalidating snoops (final state is always <code class=\"language-plaintext highlighter-rouge\">I</code>). For simplicity, it also shows only the typical state transitions in a MOESI protocol. In CHI the final state will ultimately be determined by the type of data returned by the responder (e.g., requester may receive <code class=\"language-plaintext highlighter-rouge\">UD</code> or <code class=\"language-plaintext highlighter-rouge\">UC</code> data in  response to a <code class=\"language-plaintext highlighter-rouge\">ReadShared</code>).</p>\n<p>The figures below show the transition for a <em>intermediate-level</em> cache controller (e.g., priv. L2, shared L3, HNF, etc):</p>\n<p><img alt=\"Intermediate cache state machine\" src=\"/assets/img/ruby_chi/sm_lx_cache.svg\"/></p>\n<p><img alt=\"Intermediate cache directory states\" src=\"/assets/img/ruby_chi/sm_lx_dir.svg\"/></p>\n<p>As in the previous case, cache hits are omitted for simplicity. In addition to the cache states, the following directory states are defined to track lines present in an upstream cache:</p>\n<ul>\n<li><code class=\"language-plaintext highlighter-rouge\">RU</code>:an upstream requester has line in UC or UD</li>\n<li><code class=\"language-plaintext highlighter-rouge\">RSC</code>: one or more upstream requesters have line in SC</li>\n<li><code class=\"language-plaintext highlighter-rouge\">RSD</code>: one upstream requester has line in SD; others may have it in SC</li>\n<li><code class=\"language-plaintext highlighter-rouge\">RUSC</code>: <code class=\"language-plaintext highlighter-rouge\">RSC</code> + current domain stills has exclusive access</li>\n<li><code class=\"language-plaintext highlighter-rouge\">RUSD</code>: <code class=\"language-plaintext highlighter-rouge\">RSD</code> + current domain stills has exclusive access</li>\n</ul>\n<p>When the line is present both in the local cache and upstream caches the following combined states are possible:</p>\n<ul>\n<li><code class=\"language-plaintext highlighter-rouge\">UD_RSC</code>, <code class=\"language-plaintext highlighter-rouge\">SD_RSC</code>, <code class=\"language-plaintext highlighter-rouge\">UC_RSC</code>, <code class=\"language-plaintext highlighter-rouge\">SC_RSC</code></li>\n<li><code class=\"language-plaintext highlighter-rouge\">UD_RU</code>, <code class=\"language-plaintext highlighter-rouge\">UC_RU</code></li>\n<li><code class=\"language-plaintext highlighter-rouge\">UD_RSD</code>, <code class=\"language-plaintext highlighter-rouge\">SD_RSD</code></li>\n</ul>\n<p>The <code class=\"language-plaintext highlighter-rouge\">RUSC</code> and <code class=\"language-plaintext highlighter-rouge\">RUSD</code> states (omitted in the figures above) are used to keep track of lines for which the controller still has exclusive access permissions without having it in it\u2019s local cache. This is possible in a non-inclusive cache where a local block can be deallocated without back-invalidating upstream copies.</p>\n<p>When a cache controller is a HNF (home node), the state transactions are basically the same as a intermediate level cache, except for these differences:</p>\n<ul>\n<li>A <code class=\"language-plaintext highlighter-rouge\">ReadNoSnp</code> is sent to obtain data from downstream, as the only downstream components are the SNs (slave nodes).</li>\n<li>On a cache and directory miss, DMT (direct memory transfer) is used if enabled.</li>\n<li>On a cache miss and directory hit, DCT (direct cache transfer) is used if enabled.</li>\n</ul>\n<p>For more information on DCT and DMT transactions, see Sections 1.7 and 2.3.1 in the <a href=\"https://developer.arm.com/documentation/ihi0050/D/\">CHI specification</a>. DMT and DCT are CHI features that allow the data source for a request to send data directly to the original requester. On a DMT request, the SN sends data directly to the RN (instead of sending first to the HN, which would then forwards to the RN), while with DCT, the HN requests that a RN being snooped (the snoopee) to send a copy of the line directly the original requester. With DCT enabled, the HN may also request that the snoopee to send the data to both the HN and the original requester, so the HN can also cache the data. This depends on the allocation policy defined by the configuration parameters. Notice that the allocation policy also changes the cache state transitions. For simplicity, the figure above illustrates an inclusive cache.</p>\n<p>The following is a list of the main configuration parameters of the cache controller that affect the protocol behavior (please refer to the protocol SLICC specification for details and a full list of parameters)</p>\n<ul>\n<li><code class=\"language-plaintext highlighter-rouge\">downstream_destinations</code>: defines the destinations for requests sent downstream and is used to build the cache hierarchy. Refer to the <code class=\"language-plaintext highlighter-rouge\">create_system</code> function in <code class=\"language-plaintext highlighter-rouge\">configs/ruby/CHI.py</code> for an example of how to setup a system with private L1I, L1D and L2 caches for each core.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">is_HN</code>: Set when the controller is used as a home node and point of coherency for an address range. Must be false for every other cache level.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">enable_DMT</code> and <code class=\"language-plaintext highlighter-rouge\">enable_DCT</code>: when the controller is a home node, this enables direct memory transfers and direct cache transfers for incoming read requests.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">allow_SD</code>: allow the shared dirty state. This switches between MOESI and MESI operation.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">alloc_on_readshared</code>, <code class=\"language-plaintext highlighter-rouge\">alloc_on_readunique</code>, and <code class=\"language-plaintext highlighter-rouge\">alloc_on_readonce</code>: whether or not to allocate a cache block to store data used to respond to the corresponding read request.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">alloc_on_writeback</code>: whether or not to allocate a cache block to store data received from a writeback request.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">dealloc_on_unique</code> and <code class=\"language-plaintext highlighter-rouge\">dealloc_on_shared</code>: deallocate the local cache block if the line becomes unique or shared in an upstream cache.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">dealloc_backinv_unique</code> and <code class=\"language-plaintext highlighter-rouge\">dealloc_backinv_shared</code>: if a local cache block is deallocated due to a replacement, also invalidates any unique or shared copy of the line in upstream caches.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">number_of_TBEs</code>,<code class=\"language-plaintext highlighter-rouge\">number_of_snoop_TBEs</code>, and <code class=\"language-plaintext highlighter-rouge\">number_of_repl_TBEs</code>: number of entries in the TBE tables for incoming requests, incoming snoops, and replacements.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">unify_repl_TBEs</code>: replacements use the same TBE slot as the request that triggered it. In this case <code class=\"language-plaintext highlighter-rouge\">number_of_repl_TBEs</code> is ignored.</li>\n</ul>\n<p>These parameters affect the cache controller performance:</p>\n<ul>\n<li><code class=\"language-plaintext highlighter-rouge\">read_hit_latency</code> and <code class=\"language-plaintext highlighter-rouge\">read_miss_latency</code>: pipeline latencies for a read request thar hits or misses in the local cache, respectively.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">snoop_latency</code>: pipeline latency for an incoming snoop.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">write_fe_latency</code> and <code class=\"language-plaintext highlighter-rouge\">write_be_latency</code>: front-end and back-end pipeline latencies for handling write requests. Front-end latency is applied between sending the acknowledgement response and the next action to be taken. Back-end is applied to the requester between receiving the acknowledgement and sending the write data.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">allocation_latency</code>: latency between TBE allocation and transaction initialization.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">cache</code>: <code class=\"language-plaintext highlighter-rouge\">CacheMemory</code> attached to this controller includes parameters such as size, associativity, tag and data latency, and number of banks.</li>\n</ul>\n<p>Section <a href=\"#protocol-implementation\">Protocol implementation</a> gives an overview of the protocol implementation while Section <a href=\"#supported-chi-transactions\">Supported CHI transactions</a> describe the implemented subset of the the AMBA 5 CHI spec. The next sections refer to specific files in the protocol source code and include SLICC snippets of the protocol. Some snippets where slightly simplified compared to the actual SLICC specification.</p>\n<h2 id=\"protocol-implementation\">Protocol implementation</h2>\n<p>The Figure below gives an overview of the cache controller implementation.</p>\n<p><img alt=\"Cache controller architecture\" src=\"/assets/img/ruby_chi/cache_cntrl_arch.png\"/></p>\n<p>In Ruby, a cache controller is implemented by defining a state machine using SLICC language. Transitions in the state machine are triggered by messages arriving at input queues. On our particular implementation, separate incoming and outgoing messages queues are defined for each CHI channel. Incoming request and snoop messages that\nstart a new transaction go through the same <em>Request allocation</em> process, where we allocate a transaction buffer entry (TBE) and move the request or snoop to an internal queue of transactions that are ready to\nbe initiated. If the transaction buffer is full, the request is rejected and a retry message is sent.</p>\n<p>The actions to be performed for a message dequeued from the input / rdy queues depends on the state of the target cache line. The data state of the line is stored in the cache if the line is cached locally, while the\ndirectory state is stored in a directory entry if the line is present in any upstream cache. For lines with outstanding requests, the transient state is kept in the TBE and copied back to the cache and/or directory\nwhen the transaction finishes. The figure below describes the phases in the transaction lifetime and the interactions between the main components in the cache controller (input/output ports, TBETable, Cache, Directory and the SLICC state machine). The phases are described in more details in the subsequent sections.</p>\n<p><img alt=\"Transaction lifetime\" src=\"/assets/img/ruby_chi/transaction_phases.png\"/></p>\n<h3 id=\"transaction-allocation\">Transaction allocation</h3>\n<p>The code snippet below shows how an incoming request in the <code class=\"language-plaintext highlighter-rouge\">reqIn</code> port is handled. The <code class=\"language-plaintext highlighter-rouge\">reqIn</code> port receives incoming messages from CHI\u2019s request channel:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>in_port(reqInPort, CHIRequestMsg, reqIn) {\n  if (reqInPort.isReady(clockEdge())) {\n    peek(reqInPort, CHIRequestMsg) {\n      if (in_msg.allowRetry) {\n        trigger(Event:AllocRequest, in_msg.addr, \n              getCacheEntry(in_msg.addr), getCurrentActiveTBE(in_msg.addr));\n      } else {\n        trigger(Event:AllocRequestWithCredit, in_msg.addr,\n              getCacheEntry(in_msg.addr), getCurrentActiveTBE(in_msg.addr));\n      }\n    }\n  }\n}\n</code></pre></div></div>\n<p>The <code class=\"language-plaintext highlighter-rouge\">allowRetry</code> field indicates messages that can be retried. Requests that cannot be retried are only sent by a requester that previously received credit (see <code class=\"language-plaintext highlighter-rouge\">RetryAck</code> and <code class=\"language-plaintext highlighter-rouge\">PCrdGrant</code> in the CHI specification). The transition triggered by <code class=\"language-plaintext highlighter-rouge\">Event:AllocRequest</code> or <code class=\"language-plaintext highlighter-rouge\">Event:AllocRequestWithCredit</code> executes a single action which either reserves space in the TBE table for the request and moves it to the <code class=\"language-plaintext highlighter-rouge\">reqRdy</code> queue, or sends a <code class=\"language-plaintext highlighter-rouge\">RetryAck</code> message):</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>action(AllocateTBE_Request) {\n  if (storTBEs.areNSlotsAvailable(1)) {\n    // reserve a slot for this request\n    storTBEs.incrementReserved();\n    // Move request to rdy queue\n    peek(reqInPort, CHIRequestMsg) {\n      enqueue(reqRdyOutPort, CHIRequestMsg, allocation_latency) {\n        out_msg := in_msg;\n      }\n    }\n  } else {\n    // we don't have resources to track this request; enqueue a retry\n    peek(reqInPort, CHIRequestMsg) {\n      enqueue(retryTriggerOutPort, RetryTriggerMsg, 0) {\n        out_msg.addr := in_msg.addr;\n        out_msg.event := Event:SendRetryAck;\n        out_msg.retryDest := in_msg.requestor;\n        retryQueue.emplace(in_msg.addr,in_msg.requestor);\n      }\n    }\n  }\n  reqInPort.dequeue(clockEdge());\n}\n</code></pre></div></div>\n<p>Notice we don\u2019t create and send a <code class=\"language-plaintext highlighter-rouge\">RetryAck</code> message directly from this action. Instead we create a separate trigger event in the internal <code class=\"language-plaintext highlighter-rouge\">retryTrigger</code> queue. This is necessary to prevent resource stalls from halting this action. Section <a href=\"#performance-modeling\">Performance modeling</a> below explains resource stalls in more details.</p>\n<p>Incoming request from a <code class=\"language-plaintext highlighter-rouge\">Sequencer</code> object (typically connected to a CPU when the controller is used as a L1 cache) and snoop requests arrive through the <code class=\"language-plaintext highlighter-rouge\">seqIn</code> and <code class=\"language-plaintext highlighter-rouge\">snpIn</code> ports and are handled similarly, except for:</p>\n<ul>\n<li>they do not support retries. If there are no TBEs available, a resource stall is generated and we try again next cycle.</li>\n<li>snoops allocate TBEs from a separate TBETable to avoid deadlocks.</li>\n</ul>\n<h3 id=\"transaction-initialization\">Transaction initialization</h3>\n<p>Once a request has been allocated a TBE and moved to the <code class=\"language-plaintext highlighter-rouge\">reqRdy</code> queue, an event is triggered to initiate the transaction. We trigger a different event for each different request type:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>in_port(reqRdyPort, CHIRequestMsg, reqRdy) {\n  if (reqRdyPort.isReady(clockEdge())) {\n    peek(reqRdyPort, CHIRequestMsg) {\n      CacheEntry cache_entry := getCacheEntry(in_msg.addr);\n      TBE tbe := getCurrentActiveTBE(in_msg.addr);\n      trigger(reqToEvent(in_msg.type), in_msg.addr, cache_entry, tbe);\n    }\n  }\n}\n</code></pre></div></div>\n<p>Each request requires different initialization actions depending on the initial state of the line. To illustrate this processes, let\u2019s use as example a <code class=\"language-plaintext highlighter-rouge\">ReadShared</code> request for a line in the <code class=\"language-plaintext highlighter-rouge\">SC_RSC</code> state (shared\nclean in local cache and shared clean in an upstream cache):</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>transition(SC_RSC, ReadShared, BUSY_BLKD) {\n  Initiate_Request;\n  Initiate_ReadShared_Hit;\n  Profile_Hit;\n  Pop_ReqRdyQueue;\n  ProcessNextState;\n}\n</code></pre></div></div>\n<ul>\n<li><code class=\"language-plaintext highlighter-rouge\">Initiate_Request</code> initializes the allocated TBE. This actions copies any state and data allocated in the local cache and directory to the TBE.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">Initiate_ReadShared_Hit</code> sets-up the set of actions that need to be executed to complete this specific request (see below).</li>\n<li><code class=\"language-plaintext highlighter-rouge\">Profile_Hit</code> updates cache statistics.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">Pop_ReqRdyQueue</code> removes request message form the <code class=\"language-plaintext highlighter-rouge\">reqRdy</code> queue.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">ProcessNextState</code> executes the next action defined by <code class=\"language-plaintext highlighter-rouge\">Initiate_ReadShared_Hit</code>.</li>\n</ul>\n<p><code class=\"language-plaintext highlighter-rouge\">Initiate_ReadShared_Hit</code> is defined as follows:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>action(Initiate_ReadShared_Hit) {\n  tbe.actions.push(Event:TagArrayRead);\n  tbe.actions.push(Event:ReadHitPipe);\n  tbe.actions.push(Event:DataArrayRead);\n  tbe.actions.push(Event:SendCompData);\n  tbe.actions.push(Event:WaitCompAck);\n  tbe.actions.pushNB(Event:TagArrayWrite);\n}\n</code></pre></div></div>\n<p><code class=\"language-plaintext highlighter-rouge\">tbe.actions</code> stores the list of events that need to be triggered in order to complete an action. In this particular case, <code class=\"language-plaintext highlighter-rouge\">TagArrayRead</code>, <code class=\"language-plaintext highlighter-rouge\">ReadHitPipe</code>, and <code class=\"language-plaintext highlighter-rouge\">DataArrayRead</code> introduces delays to model the cache\ncontroller pipeline latency and reading the cache/directory tag array and cache data array (see Section <a href=\"#performance-modeling\">Performance modeling</a>). <code class=\"language-plaintext highlighter-rouge\">SendCompData</code> sets-up and sends the data responses for the <code class=\"language-plaintext highlighter-rouge\">ReadShared</code> request and <code class=\"language-plaintext highlighter-rouge\">WaitCompAck</code> sets-up the TBE to expect the completion acknowledgement from the requester. Finally, <code class=\"language-plaintext highlighter-rouge\">TagArrayWrite</code> introduces the delay of updating the directory state to track the new sharer.</p>\n<h3 id=\"transaction-execution\">Transaction execution</h3>\n<p>After initialization, the line will transition to the <code class=\"language-plaintext highlighter-rouge\">BUSY_BLKD</code> state as show in <code class=\"language-plaintext highlighter-rouge\">transition(SC_RSC, ReadShared, BUSY_BLKD)</code>. <code class=\"language-plaintext highlighter-rouge\">BUSY_BLKD</code> is a transient state indicating the line has now an outstanding transaction. In this state, the transaction is driven either by incoming response messages in the <code class=\"language-plaintext highlighter-rouge\">rspIn</code> and <code class=\"language-plaintext highlighter-rouge\">datIn</code> ports or trigger events defined in <code class=\"language-plaintext highlighter-rouge\">tbe.actions</code>.</p>\n<p>The <code class=\"language-plaintext highlighter-rouge\">ProcessNextState</code> action is responsible for checking <code class=\"language-plaintext highlighter-rouge\">tbe.actions</code> and enqueuing trigger event messages into <code class=\"language-plaintext highlighter-rouge\">actionTriggers</code> at the end of all transitions to the <code class=\"language-plaintext highlighter-rouge\">BUSY_BLKD</code> state. <code class=\"language-plaintext highlighter-rouge\">ProcessNextState</code> first checks for pending response messages. If there are no pending messages, it enqueues a message to <code class=\"language-plaintext highlighter-rouge\">actionTriggers</code> in order to trigger the the event at the head of <code class=\"language-plaintext highlighter-rouge\">tbe.actions</code>. If there are pending responses, then <code class=\"language-plaintext highlighter-rouge\">ProcessNextState</code> does nothing as the transaction will proceed once all expected responses are received.</p>\n<p>Pending responses are tracked by the <code class=\"language-plaintext highlighter-rouge\">expected_req_resp</code> and <code class=\"language-plaintext highlighter-rouge\">expected_snp_resp</code> fields in the TBE. For instance, the <code class=\"language-plaintext highlighter-rouge\">ExpectCompAck</code> action, executed from the transition triggered by <code class=\"language-plaintext highlighter-rouge\">WaitCompAck</code>, is defined as follows:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>action(ExpectCompAck) {\n  tbe.expected_req_resp.addExpectedRespType(CHIResponseType:CompAck);\n  tbe.expected_req_resp.addExpectedCount(1);\n}\n</code></pre></div></div>\n<p>This causes the transaction to wait until a <code class=\"language-plaintext highlighter-rouge\">CompAck</code> response is received.</p>\n<p>Some actions can be allowed to execute when the transaction has pending responses. This actions are enqueued using <code class=\"language-plaintext highlighter-rouge\">tbe.actions.pushNB</code> (i.e., push / non-blocking). In the example above <code class=\"language-plaintext highlighter-rouge\">tbe.actions.pushNB(Event:TagArrayWrite)</code> models a tag write being performed while the transactions waits for the <code class=\"language-plaintext highlighter-rouge\">CompAck</code> response.</p>\n<h3 id=\"transaction-finalization\">Transaction finalization</h3>\n<p>The transaction ends when it has no more pending responses and <code class=\"language-plaintext highlighter-rouge\">tbe.actions</code> is empty. <code class=\"language-plaintext highlighter-rouge\">ProcessNextState</code> checks for this condition and enqueues a \u201cfinalizer\u201d trigger message into <code class=\"language-plaintext highlighter-rouge\">actionTriggers</code>. When handling this event, the current cache line state and sharing/ownership information determines the final stable state of the line. Data and state information are updated in the cache and directory, if necessary, and the TBE is deallocated.</p>\n<h3 id=\"hazard-handling\">Hazard handling</h3>\n<p>Each controller allows only one active transaction per cache line. If a new request or snoop arrives while the cache line is in a transient state, this creates a hazard as defined in the CHI standard. We handle hazards as follows:</p>\n<p><strong>Request hazards:</strong> a TBE is allocated as described previously, but the new transaction initialization is delayed until the current transaction finishes and the line is back to a stable state. This is done by moving\nthe request message from <code class=\"language-plaintext highlighter-rouge\">reqRdy</code> to a separate <em>stall buffer</em>. All stalled messages are added back to <code class=\"language-plaintext highlighter-rouge\">reqRdy</code> when the current transaction finishes and are handled in their original order of arrival.</p>\n<p><strong>Snoop hazards:</strong> the CHI spec does not allow snoops to be stalled by an existing request. If a transaction is waiting on a response for a request sent downstream (e.g. we sent a <code class=\"language-plaintext highlighter-rouge\">ReadShared</code> and are waiting for\nthe data response) we must accept and handle the snoop. The snoop can be stalled only if the request has already been accepted by the responder and is guaranteed to complete (e.g. a <code class=\"language-plaintext highlighter-rouge\">ReadShared</code> with pending data but\nalready acked with a <code class=\"language-plaintext highlighter-rouge\">RespSepData</code> response). To distinguish between these conditions we use the <code class=\"language-plaintext highlighter-rouge\">BUSY_INTR</code> transient state.</p>\n<p><code class=\"language-plaintext highlighter-rouge\">BUSY_INTR</code> indicates the transaction can be interrupted by a snoop. When a snoop arrives for a line in this state, a snoop TBE is allocated as described previously and its state is initialized based on the currently active TBE. The snoop TBE then becomes the currently active TBE. Any cache state and sharing/ownership changes caused by snoop are copied back to the original TBE before deallocating the snoop. When a snoop arrives for a line in <code class=\"language-plaintext highlighter-rouge\">BUSY_BLKD</code> state, we stall the snoop until the current transaction either finishes or transitions to <code class=\"language-plaintext highlighter-rouge\">BUSY_INTR</code>.</p>\n<h3 id=\"performance-modeling\">Performance modeling</h3>\n<p>As described previously, the cache line state is known immediately when a transaction is initialized and the cache line can be read and written without any latency. This makes it easier to implement the functional\naspects of the protocol. To model timing we use explicit actions to introduce latency to a transaction. For example, in the <code class=\"language-plaintext highlighter-rouge\">ReadShared</code> code snippet:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>action(Initiate_ReadShared_Hit) {\n  tbe.actions.push(Event:TagArrayRead);\n  tbe.actions.push(Event:ReadHitPipe);\n  tbe.actions.push(Event:DataArrayRead);\n  tbe.actions.push(Event:SendCompData);\n  tbe.actions.push(Event:WaitCompAck);\n  tbe.actions.pushNB(Event:TagArrayWrite);\n}\n</code></pre></div></div>\n<p><code class=\"language-plaintext highlighter-rouge\">TagArrayRead</code>, <code class=\"language-plaintext highlighter-rouge\">ReadHitPipe</code>, <code class=\"language-plaintext highlighter-rouge\">DataArrayRead</code>, and <code class=\"language-plaintext highlighter-rouge\">TagArrayWrite</code> don\u2019t have any functional significance. They are there to introduce latencies that would exist in a real cache controller pipeline, in this case: tag read latency, hit pipeline latency, data array read latency, and tag update latency. The latency introduced by these action is defined by configuration parameters.</p>\n<p>In addition to explicitly added latencies. SLICC has the concept of <em>resource stalls</em> to model resource contention. Given a set of actions executed during a transition, the SLICC compiler automatically generates\ncode which checks if all resources needed by those actions are available. If any resource is unavailable, a resource stall is generated and the transition is not executed. A message that causes a resource stall remains in the input queue and the protocol attempts to trigger the transition again the next cycle.</p>\n<p>Resources are detected by the SLICC compiler in different ways:</p>\n<ol>\n<li>Implicitly. This is the case for output ports. If an action enqueues new messages, the availability of the output port is automatically checked.</li>\n<li>Adding the <code class=\"language-plaintext highlighter-rouge\">check_allocate</code> statement to an action.</li>\n<li>Annotating the transition with a resource type.</li>\n</ol>\n<p>We use (2) to check availability of TBEs. See the snippet below:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>action(AllocateTBE_Snoop) {\n  // No retry for snoop requests; just create resource stall\n  check_allocate(storSnpTBEs);\n  ...\n}\n</code></pre></div></div>\n<p>This signals the SLICC compiler to check if the <code class=\"language-plaintext highlighter-rouge\">storSnpTBEs</code> structure has a TBE slot available before executing any transition that includes the <code class=\"language-plaintext highlighter-rouge\">AllocateTBE_Snoop</code> action.</p>\n<p>The snippet below exemplifies (3):</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>transition({BUSY_INTR,BUSY_BLKD}, DataArrayWrite) {DataArrayWrite} {\n  ...\n}\n</code></pre></div></div>\n<p>The <code class=\"language-plaintext highlighter-rouge\">DataArrayWrite</code> annotation signals the SLICC compiler to check for availability of the <code class=\"language-plaintext highlighter-rouge\">DataArrayWrite</code> resource type. <em>Resource request types</em> used in these annotations must be explicitly defined by the protocol, as well as how to check them. In our protocol we defined the following types to check for the availability of banks in the cache tag and data arrays:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>enumeration(RequestType) {\n  TagArrayRead;\n  TagArrayWrite;\n  DataArrayRead;\n  DataArrayWrite;\n}\n\nvoid recordRequestType(RequestType request_type, Addr addr) {\n  if (request_type == RequestType:DataArrayRead) {\n    cache.recordRequestType(CacheRequestType:DataArrayRead, addr);\n  }\n  ...\n}\n\nbool checkResourceAvailable(RequestType request_type, Addr addr) {\n  if (request_type == RequestType:DataArrayRead) {\n    return cache.checkResourceAvailable(CacheResourceType:DataArray, addr);\n  }\n  ...\n}\n</code></pre></div></div>\n<p>The implementation of <code class=\"language-plaintext highlighter-rouge\">checkResourceAvailable</code> and <code class=\"language-plaintext highlighter-rouge\">recordRequestType</code> are required by SLICC compiler when we use annotations on transactions.</p>\n<h3 id=\"cache-block-allocation-and-replacement-modeling\">Cache block allocation and replacement modeling</h3>\n<p>Consider the following transaction initialization code for a ReadShared miss:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>action(Initiate_ReadShared_Miss) {\n  tbe.actions.push(Event:ReadMissPipe);\n  tbe.actions.push(Event:TagArrayRead);\n  tbe.actions.push(Event:SendReadShared);\n  tbe.actions.push(Event:SendCompData);\n  tbe.actions.push(Event:WaitCompAck);\n  tbe.actions.push(Event:CheckCacheFill);\n  tbe.actions.push(Event:TagArrayWrite);\n}\n</code></pre></div></div>\n<p>All transactions that modify a cache line or received cache line data as a result of a snoop or a request sent downstream, use the <code class=\"language-plaintext highlighter-rouge\">CheckCacheFill</code> action trigger event. This event triggers a transition that perform the following actions:</p>\n<ul>\n<li>Checks if we need to store the current cache line data in the local cache.</li>\n<li>Checks if we already have a cache block allocated for that line. If not, attempts to allocate a block. If block not available, a victim block is selected for replacement.</li>\n<li>Models the latency of a cache fill.</li>\n</ul>\n<p>When a replacement is performed, a new transaction is initialized to keep track of any WriteBack or Evict request sent downstream and/or snoops for backinvalidation (if the cache controller is configured the\nenforce inclusivity). Depending on the configuration parameters, the TBE for the replacement uses resources from a dedicated TBETable or reuses the same resources of the TBE that triggered the replacement. In both\ncases, the transaction that triggered the replacement completes without waiting for the replacement process.</p>\n<p>Notice <code class=\"language-plaintext highlighter-rouge\">CheckCacheFill</code> does not actually writes data to the cache block. If only ensures a cache block is allocated if needed, triggers replacements, and models the cache fill latencies. As described previously, TBE data is copied to the cache if needed during the transaction finalization.</p>\n<h2 id=\"supported-chi-transactions\">Supported CHI transactions</h2>\n<p>All transactions are implemented as described in the <a href=\"https://developer.arm.com/documentation/ihi0050/D/\">AMBA5 CHI Issue D specification</a>. The next sections provide a more detailed explanation of the implementation-specific choices not fixed by the public document.</p>\n<h3 id=\"supported-requests\">Supported requests</h3>\n<p>The following incoming requests are supported:</p>\n<ul>\n<li><code class=\"language-plaintext highlighter-rouge\">ReadShared</code></li>\n<li><code class=\"language-plaintext highlighter-rouge\">ReadNotSharedDirty</code></li>\n<li><code class=\"language-plaintext highlighter-rouge\">ReadUnique</code></li>\n<li><code class=\"language-plaintext highlighter-rouge\">CleanUnique</code></li>\n<li><code class=\"language-plaintext highlighter-rouge\">ReadOnce</code></li>\n<li><code class=\"language-plaintext highlighter-rouge\">WriteUniquePtl</code> and <code class=\"language-plaintext highlighter-rouge\">WriteUniqueFull</code></li>\n</ul>\n<p>When receiving any request the\u00a0clusivity configuration parameters are evaluated during the transaction initialization and the <code class=\"language-plaintext highlighter-rouge\">doCacheFill</code> and\u00a0<code class=\"language-plaintext highlighter-rouge\">dataToBeInvalid</code> flags are set in the transaction buffer entry allocated for the request.\u00a0<code class=\"language-plaintext highlighter-rouge\">doCacheFill</code> indicates we should keep any valid copy of the line in the local cache;<code class=\"language-plaintext highlighter-rouge\">dataToBeInvalid</code> indicates we must invalidate the local copy when completing the transaction.</p>\n<p>When receiving <code class=\"language-plaintext highlighter-rouge\">ReadShared</code> or <code class=\"language-plaintext highlighter-rouge\">ReadUnique</code>, if the data is present at the local cache in the required state (e.g. <code class=\"language-plaintext highlighter-rouge\">UC</code> or <code class=\"language-plaintext highlighter-rouge\">UD</code> for <code class=\"language-plaintext highlighter-rouge\">ReadUnique</code>), a <code class=\"language-plaintext highlighter-rouge\">CompData</code> response is send to the requester. The response type depends on the value of\u00a0<code class=\"language-plaintext highlighter-rouge\">dataToBeInvalid</code>.</p>\n<ul>\n<li>If <code class=\"language-plaintext highlighter-rouge\">dataToBeInvalid==true</code>\n<ul>\n<li>The unique and/or dirty state is always propagated</li>\n<li>For a <code class=\"language-plaintext highlighter-rouge\">ReadNotSharedDirty</code>, <code class=\"language-plaintext highlighter-rouge\">CompData_SC</code> is always sent if local state is <code class=\"language-plaintext highlighter-rouge\">SD</code> and the line is written-back using <code class=\"language-plaintext highlighter-rouge\">WriteCleanFull</code></li>\n</ul>\n</li>\n<li>Else:\n    <ul>\n<li>In response to a <code class=\"language-plaintext highlighter-rouge\">ReadUnique</code>: propagate dirty state, i.e.,\u00a0<code class=\"language-plaintext highlighter-rouge\">CompData_UD</code> or\u00a0<code class=\"language-plaintext highlighter-rouge\">CompData_UC</code>.</li>\n<li>In response to a\u00a0<code class=\"language-plaintext highlighter-rouge\">ReadShared</code> or\u00a0<code class=\"language-plaintext highlighter-rouge\">ReadNotSharedDirty</code>: send\u00a0<code class=\"language-plaintext highlighter-rouge\">CompData_SC</code>. If\u00a0<code class=\"language-plaintext highlighter-rouge\">fwd_unique_on_readshared</code> configuration parameter is set, the\u00a0<code class=\"language-plaintext highlighter-rouge\">ReadShared</code> is handled as a <code class=\"language-plaintext highlighter-rouge\">ReadUnique</code> if the line doesn\u2019t have other sharers.</li>\n</ul>\n</li>\n</ul>\n<p>When receiving a <code class=\"language-plaintext highlighter-rouge\">ReadOnce</code>, <code class=\"language-plaintext highlighter-rouge\">CompData_I</code> is always sent\u00a0if the data is present at the local cache. For\u00a0<code class=\"language-plaintext highlighter-rouge\">WriteUniquePtl</code> handling see below.</p>\n<p>If there is a cache miss, multiple actions may be performed depending on whether or not\u00a0<code class=\"language-plaintext highlighter-rouge\">doCacheFill</code> and <code class=\"language-plaintext highlighter-rouge\">dataToBeInvalid==false</code>; and DCT or DMT is enabled:</p>\n<ul>\n<li><code class=\"language-plaintext highlighter-rouge\">ReadShared</code> / <code class=\"language-plaintext highlighter-rouge\">ReadNotSharedDirty</code>:\n    <ul>\n<li>If dir state is <code class=\"language-plaintext highlighter-rouge\">RSD</code> or <code class=\"language-plaintext highlighter-rouge\">RU</code>:\n        <ul>\n<li>If DCT disabled: send <code class=\"language-plaintext highlighter-rouge\">SnpShared</code> to owner; cache the line locally (if\u00a0<code class=\"language-plaintext highlighter-rouge\">doCacheFill</code>) and send response to requester.</li>\n<li>If DCT enabled: send\u00a0<code class=\"language-plaintext highlighter-rouge\">SnpSharedFwd</code> to owner;\u00a0if\u00a0<code class=\"language-plaintext highlighter-rouge\">doCacheFill==true</code>,\u00a0the <code class=\"language-plaintext highlighter-rouge\">retToSrc</code> field is set so the line can be cached locally.</li>\n</ul>\n</li>\n<li>If dir state is <code class=\"language-plaintext highlighter-rouge\">RSC</code>:\n        <ul>\n<li>If DCT disabled: send <code class=\"language-plaintext highlighter-rouge\">SnpOnce</code> to one of the sharers;\u00a0cache the line locally (if <code class=\"language-plaintext highlighter-rouge\">doCacheFill</code>) and send\n  response to requester.</li>\n<li>If DCT enabled:\u00a0send\u00a0<code class=\"language-plaintext highlighter-rouge\">SnpSharedFwd</code> to one of the sharers;\u00a0if\u00a0<code class=\"language-plaintext highlighter-rouge\">doCacheFill==true</code>, the\u00a0<code class=\"language-plaintext highlighter-rouge\">retToSrc</code> field is set so the line can be cached locally.</li>\n</ul>\n</li>\n<li>Otherwise: issue a <code class=\"language-plaintext highlighter-rouge\">ReadShared</code> / <code class=\"language-plaintext highlighter-rouge\">ReadNotSharedDirty</code> or\u00a0<code class=\"language-plaintext highlighter-rouge\">ReadNoSnp</code> (if HNF). In the HNF configuration,\u00a0<code class=\"language-plaintext highlighter-rouge\">ReadNoSnp</code> is issued with DMT if DMT is enabled.</li>\n<li>For\u00a0<code class=\"language-plaintext highlighter-rouge\">ReadNotSharedDirty</code>, <code class=\"language-plaintext highlighter-rouge\">SnpNotSharedDirty</code> and <code class=\"language-plaintext highlighter-rouge\">SnpNotSharedDirtyFwd</code> is sent instead.</li>\n</ul>\n</li>\n<li><code class=\"language-plaintext highlighter-rouge\">ReadUnique</code>:\n    <ul>\n<li>If dir state is <code class=\"language-plaintext highlighter-rouge\">RU,RUSD,RUSC</code>:\n        <ul>\n<li>If DCT disabled or clusivity is inclusive: send\u00a0<code class=\"language-plaintext highlighter-rouge\">SnpUnique</code> to owner; cache the line locally (if <code class=\"language-plaintext highlighter-rouge\">doCacheFill\u00a0</code>) and sent response to requester.</li>\n<li>If DCT enabled and clusivity is exclusive: send\u00a0<code class=\"language-plaintext highlighter-rouge\">SnpUniqueFwd</code> to owner.</li>\n</ul>\n</li>\n<li>If dir state is <code class=\"language-plaintext highlighter-rouge\">RSC</code>/<code class=\"language-plaintext highlighter-rouge\">RSD</code>:\n        <ul>\n<li>Send\u00a0<code class=\"language-plaintext highlighter-rouge\">SnpUnique</code> with\u00a0<code class=\"language-plaintext highlighter-rouge\">retToSrc=true</code>\u00a0to invalidate sharers and obtain dirty line (in case of <code class=\"language-plaintext highlighter-rouge\">RSD</code>)</li>\n<li>If not HNF: send <code class=\"language-plaintext highlighter-rouge\">CleanUnique</code> downstream to obtain unique permissions.</li>\n</ul>\n</li>\n<li>Otherwise:\u00a0issue a <code class=\"language-plaintext highlighter-rouge\">ReadUnique</code> or\u00a0<code class=\"language-plaintext highlighter-rouge\">ReadNoSnp</code> (if HNF). In the HNF configuration,\u00a0<code class=\"language-plaintext highlighter-rouge\">ReadNoSnp</code> is issued with DMT if DMT is enabled.</li>\n<li>For\u00a0<code class=\"language-plaintext highlighter-rouge\">RUSC</code> amd <code class=\"language-plaintext highlighter-rouge\">RSC</code>, if multiple sharers, only one sharer is selected as target of the above snoops. The other sharers are invalidated using\u00a0<code class=\"language-plaintext highlighter-rouge\">SnpUnique</code> with <code class=\"language-plaintext highlighter-rouge\">retToSrc=false</code>.</li>\n</ul>\n</li>\n<li><code class=\"language-plaintext highlighter-rouge\">ReadOnce</code>:\n    <ul>\n<li>If dir entry exists:\n        <ul>\n<li>If DCT disabled: send\u00a0<code class=\"language-plaintext highlighter-rouge\">SnpOnce</code> to one of the sharers; send received data response to requester.</li>\n<li>If DCT enabled: send\u00a0<code class=\"language-plaintext highlighter-rouge\">SnpOnceFwd</code> to one of the sharers.</li>\n</ul>\n</li>\n<li>Otherwise:\u00a0issue a <code class=\"language-plaintext highlighter-rouge\">ReadOnce</code> or\u00a0<code class=\"language-plaintext highlighter-rouge\">ReadNoSnp</code> (if HNF). In the HNF configuration,\u00a0<code class=\"language-plaintext highlighter-rouge\">ReadNoSnp</code> is issued with DMT if DMT is enabled.</li>\n</ul>\n</li>\n<li><code class=\"language-plaintext highlighter-rouge\">CleanUnique</code>:\n    <ul>\n<li>Send\u00a0<code class=\"language-plaintext highlighter-rouge\">SnpCleanInvalid</code> to all sharers/owner except original requestor.</li>\n<li>If not HNF: send\u00a0<code class=\"language-plaintext highlighter-rouge\">CleanUnique</code> downstream to obtain unique permissions.</li>\n<li>If has dirty line, requestor has clean line, and\u00a0<code class=\"language-plaintext highlighter-rouge\">doCacheFill==false</code>: writeback the line with <code class=\"language-plaintext highlighter-rouge\">WriteCleanFull</code>.</li>\n</ul>\n</li>\n<li><code class=\"language-plaintext highlighter-rouge\">WriteUniquePtl</code>/<code class=\"language-plaintext highlighter-rouge\">WriteUniqueFull</code>:\n    <ul>\n<li>If data present in local cache on UC or UD states:\n        <ul>\n<li>Issue\u00a0<code class=\"language-plaintext highlighter-rouge\">SnpCleanInvalid</code> if there are any sharers.</li>\n<li>Perform the write in the local cache.</li>\n</ul>\n</li>\n<li>If no UC/UD data locally:\n        <ul>\n<li>If HNF:\n            <ul>\n<li>Issue\u00a0<code class=\"language-plaintext highlighter-rouge\">SnpCleanInvalid</code> if there are any sharers.</li>\n<li>Merge any received snoop response data with the WriteUnique data.</li>\n<li>If has a full line and <code class=\"language-plaintext highlighter-rouge\">doCacheFill</code> set, cache the line locally, otherwise writeback to memory (<code class=\"language-plaintext highlighter-rouge\">WriteNoSnp</code> or\u00a0<code class=\"language-plaintext highlighter-rouge\">WriteNoSnpPtl</code>).</li>\n</ul>\n</li>\n<li>If no HNF:\n            <ul>\n<li>Forwards the\u00a0<code class=\"language-plaintext highlighter-rouge\">WriteUniquePtl</code> and any received data to the downstream cache.</li>\n<li>Incoming snoops will cause any locally cached data to become invalid while handling the request.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"supported-snoops\">Supported snoops</h3>\n<p>The cache controller issues and accepts the following snoops:</p>\n<ul>\n<li><code class=\"language-plaintext highlighter-rouge\">SnpShared</code> and <code class=\"language-plaintext highlighter-rouge\">SnpSharedFwd</code></li>\n<li><code class=\"language-plaintext highlighter-rouge\">SnpNotSharedDirty</code>\u00a0and\u00a0<code class=\"language-plaintext highlighter-rouge\">SnpNotSharedDirtyFwd</code></li>\n<li><code class=\"language-plaintext highlighter-rouge\">SnpUnique</code> and <code class=\"language-plaintext highlighter-rouge\">SnpUniqueFwd</code></li>\n<li><code class=\"language-plaintext highlighter-rouge\">SnpCleanInvalid</code></li>\n<li><code class=\"language-plaintext highlighter-rouge\">SnpOnce</code> and <code class=\"language-plaintext highlighter-rouge\">SnpOnceFwd</code></li>\n</ul>\n<p>The snoop response is generated according to the current state of the line as defined in the specification. Data is returned with the snoop response depending on the data state and the value of\u00a0<code class=\"language-plaintext highlighter-rouge\">retToSrc</code>\u00a0 set by the snooper. If <code class=\"language-plaintext highlighter-rouge\">retToSrc</code> is set, the snoop response always includes data.</p>\n<ul>\n<li><code class=\"language-plaintext highlighter-rouge\">SnpShared</code> / <code class=\"language-plaintext highlighter-rouge\">SnpNotSharedDirty</code>:\n    <ul>\n<li>Snoopee always returns data is the line is dirty, unique or <code class=\"language-plaintext highlighter-rouge\">retToSrc</code>.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">retToSrc</code> is set if the snooper needs to cache the line.</li>\n<li>Final snoopee state always shared clean.</li>\n</ul>\n</li>\n<li><code class=\"language-plaintext highlighter-rouge\">SnpUnique</code>:\n    <ul>\n<li>Snoopee always returns data is the line is dirty, unique or <code class=\"language-plaintext highlighter-rouge\">retToSrc</code>.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">retToSrc</code> is set if the snooper needs to cache the line.</li>\n<li>Final snoopee state always invalid.</li>\n</ul>\n</li>\n<li><code class=\"language-plaintext highlighter-rouge\">SnpCleanInvalid</code>:\n    <ul>\n<li>Same as <em>SnpUnique</em>, except data is not returned if line is unique and clean.</li>\n</ul>\n</li>\n<li><code class=\"language-plaintext highlighter-rouge\">SnpSharedFwd</code>:\n    <ul>\n<li><code class=\"language-plaintext highlighter-rouge\">retToSrc</code> is set if the snooper needs to cache the line.</li>\n<li>Line forwarded as dirty if dirty</li>\n<li>Final snoopee state always shared clean</li>\n</ul>\n</li>\n<li><code class=\"language-plaintext highlighter-rouge\">SnpNotSharedDirtyFwd</code>:\n    <ul>\n<li><code class=\"language-plaintext highlighter-rouge\">retToSrc</code> is set if the snooper needs to cache the line.</li>\n<li>Always returns data if line was dirty at the snoopee; line always forwarded as clean.</li>\n<li>Final snoopee state always shared clean.</li>\n</ul>\n</li>\n<li><code class=\"language-plaintext highlighter-rouge\">SnpUniqueFwd</code>:\n    <ul>\n<li>Same as SnpUnique, except data is never returned to the snooper (as defined by the spec)</li>\n</ul>\n</li>\n<li><code class=\"language-plaintext highlighter-rouge\">SnpOnce</code>:\n    <ul>\n<li>Always generated with <code class=\"language-plaintext highlighter-rouge\">retToSrc=true</code> and\u00a0snoopee always returns data.</li>\n<li>Accepted in any state\u00a0(except invalid). Final snoopee state does not change.</li>\n</ul>\n</li>\n<li><code class=\"language-plaintext highlighter-rouge\">SnpOnceFwd</code>:\n    <ul>\n<li>Same as SnpOnce, except data is never returned to the snooper.</li>\n</ul>\n</li>\n</ul>\n<p>If the snoopee has sharers in any state, the same request is sent upstream to all sharers. For\u00a0SnpSharedFwd/SnpNotSharedDirtyFwd and SnpUniqueFwd, a SnpShared/SnpNotSharedFwd or SnpUnique is sent, respectively. For a received SnpOnce, a SnpOnce is sent upstream only if the line is not present locally. In this particular implementation, there\u00a0is always a directory entry for upstream caches that have the line. <em>Snoops are never sent to caches that do not have the line</em>.</p>\n<h3 id=\"writeback-and-evictions\">Writeback and evictions</h3>\n<p>A writeback is triggered internally by the controller when a cache line needs to be evicted due to capacity reasons (<em>cache maintenance operations are currently not supported</em>). See Section <a href=\"#cache-block-allocation-and-replacement-modeling\">Cache block allocation and replacement modeling</a>\u00a0for more information on replacements. These internal events are generated depending on the configurations parameters of the controller:</p>\n<ul>\n<li><code class=\"language-plaintext highlighter-rouge\">GlobalEviction</code>: evict a line from the current and all upstream caches. This applies if\u00a0<code class=\"language-plaintext highlighter-rouge\">dealloc_backinv_unique</code> or <code class=\"language-plaintext highlighter-rouge\">dealloc_backinv_shared</code> parameters are set.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">LocalEviction</code>: evict a line without backinvaliding upstream caches.</li>\n</ul>\n<p>First we deallocate the local cache block (so the request that cause the eviction can allocate a new block and finish).\u00a0For GlobalEviction, a <code class=\"language-plaintext highlighter-rouge\">SnpCleanInvalid</code> is sent to all upstream caches. Once all snoops responses are received (possibly with dirty data), a LocalEviction is performed. The LocalEviction is done by issuing the appropriate request as follows:</p>\n<ul>\n<li><code class=\"language-plaintext highlighter-rouge\">WriteBackFull</code>,\u00a0if the the line is dirty</li>\n<li><code class=\"language-plaintext highlighter-rouge\">WriteEvictFull</code>,\u00a0if the line is unique and clean</li>\n<li><code class=\"language-plaintext highlighter-rouge\">WriteCleanFull</code>,\u00a0if the the line is dirty, but there are clean sharers</li>\n<li><code class=\"language-plaintext highlighter-rouge\">Evict</code>, if the line is shared and clean</li>\n</ul>\n<p>For a HNF configuration the behavior changes slightly: <code class=\"language-plaintext highlighter-rouge\">WriteNoSnp</code> to the SNF is used instead of\u00a0<code class=\"language-plaintext highlighter-rouge\">WriteBackFull</code> and no requests are issued if the line is clean.</p>\n<p>The <code class=\"language-plaintext highlighter-rouge\">WriteBack*</code> and <code class=\"language-plaintext highlighter-rouge\">Evict</code> requests are handled at the downstream cache as follows:</p>\n<ul>\n<li><code class=\"language-plaintext highlighter-rouge\">WriteBackFull</code> / <code class=\"language-plaintext highlighter-rouge\">WriteEvictFull</code> / <code class=\"language-plaintext highlighter-rouge\">WriteCleanFull</code>:\n    <ul>\n<li>If <code class=\"language-plaintext highlighter-rouge\">alloc_on_writeback</code>, a cache block may need to be allocated. If there are no free blocks, a LocalEviction is triggered for a cache line in the target cache set. The victim line is selected based on the replacement policy implemented by object pointed by the <code class=\"language-plaintext highlighter-rouge\">cache</code> parameter (which can be configured separately).</li>\n<li>Send a\u00a0<code class=\"language-plaintext highlighter-rouge\">CompDBIDResp</code> to the requester.</li>\n<li>Once data is received, update local cache and remove requestor from directory (if <code class=\"language-plaintext highlighter-rouge\">WriteBackFull</code> / <code class=\"language-plaintext highlighter-rouge\">WriteEvictFull</code>).</li>\n</ul>\n</li>\n<li><code class=\"language-plaintext highlighter-rouge\">Evict</code>:\n    <ul>\n<li>Remove requestor from directory and reply with <code class=\"language-plaintext highlighter-rouge\">Comp\\_I</code>.</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"hazards\">Hazards</h3>\n<p>A request for a line that currently has an outstanding transaction is always stalled until the transaction completes. Snoops received while there is an outstanding request are handled following the requirements\nin the specification:</p>\n<ul>\n<li>For an outstanding <code class=\"language-plaintext highlighter-rouge\">CleanUnique</code>:\n    <ul>\n<li>Snoop response is sent immediately and the current line state is changed accordingly.</li>\n<li>Notice we don\u2019t model the\u00a0<strong>UCE</strong>\u00a0and\u00a0<strong>UDP</strong>\u00a0states from the CHI spec. If the line is invalidated while the requester waits for a\u00a0<code class=\"language-plaintext highlighter-rouge\">CleanUnique</code> response, it immediately follows up with a <code class=\"language-plaintext highlighter-rouge\">ReadUnique</code>.</li>\n</ul>\n</li>\n<li>For outstanding\u00a0<code class=\"language-plaintext highlighter-rouge\">WriteBackFull</code>/<code class=\"language-plaintext highlighter-rouge\">WriteEvictFull</code>/<code class=\"language-plaintext highlighter-rouge\">WriteCleanFull</code> that have not yet been acked with a <code class=\"language-plaintext highlighter-rouge\">CompDBIDResp</code>; or Evict before\u00a0<code class=\"language-plaintext highlighter-rouge\">Comp_I</code> is received:\n    <ul>\n<li>Snoop response is sent immediately and the current line state is changed accordingly.</li>\n<li>The state of the line that will be written back will the state after the snoop.</li>\n</ul>\n</li>\n<li>If a snoop is received while the current transaction is waiting for snoop responses from upstream caches, the incoming snoop is stalled until all pending responses from upstream are received and any follow-up request is sent. This can happen in these scenarios:\n    <ul>\n<li>During a global replacement</li>\n<li>An accepted <code class=\"language-plaintext highlighter-rouge\">ReadUnique</code> that required snooping upstream caches</li>\n</ul>\n</li>\n</ul>\n<p>Multiple snoops may be received while there is an outstanding transaction. In this particular implementation, a <code class=\"language-plaintext highlighter-rouge\">SnpShared</code> or <code class=\"language-plaintext highlighter-rouge\">SnpSharedFwd</code> may be followed by a <code class=\"language-plaintext highlighter-rouge\">SnpUnique</code> or <code class=\"language-plaintext highlighter-rouge\">SnpCleanInvalid</code>. However, it\u2019s not possible to have concurrent snoops coming from the downstream cache.</p>\n<p>Both incoming requests and snoops require the allocation of a TBE. To prevent deadlocks when transaction buffers are full, a separate buffer is used to allocate snoop TBEs. Snoops do not allow retry, so if the snoop TBE table is full messages in the snpIn port are stalled, potentially causing severe congestion in the snoop channel in the interconnect.</p>\n<h3 id=\"other-implementations-notes\">Other implementations notes</h3>\n<ul>\n<li>If an HNF uses DMT, it will send <code class=\"language-plaintext highlighter-rouge\">ReadNoSnpSep</code> instead of\u00a0<code class=\"language-plaintext highlighter-rouge\">ReadNoSnp</code> if the\u00a0<code class=\"language-plaintext highlighter-rouge\">enable_DMT_early_dealloc</code> configuration parameter is set. This allow the HNF to deallocate the TBE earlier.</li>\n<li>Order bit field is not implemented, thus\u00a0<code class=\"language-plaintext highlighter-rouge\">ReadReceipt</code> responses are never used except for <code class=\"language-plaintext highlighter-rouge\">ReadNoSnpSep</code>.\u00a0Request ordering, when required, is enforced by Ruby by serializing requests at the requester. At the cache controller, requests to the same line are handled in the order of arrival. Requests to different lines can be handled in any order, however they are typically handled in order of arrival given that there are resources available.</li>\n<li>Exclusive accesses and atomic requests\u00a0are not implemented. Ruby has its own global monitor in the Sequencer to manage exclusive load and stores. Atomic operations also handled by Ruby and they only require a <code class=\"language-plaintext highlighter-rouge\">ReadUnique</code> at the protocol level.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">CompAck</code> response is always sent when stated as optional in the spec. Requesters always wait for <code class=\"language-plaintext highlighter-rouge\">CompAck</code> (if required or optional) before finalizing the transaction and deallocating resources.</li>\n<li>Separate <code class=\"language-plaintext highlighter-rouge\">Comp</code> and <code class=\"language-plaintext highlighter-rouge\">DBIDresp</code> used only for <code class=\"language-plaintext highlighter-rouge\">WriteUnique</code> requests.\u00a0<code class=\"language-plaintext highlighter-rouge\">DBIDresp</code> is sent after receiving all snoop responses; <code class=\"language-plaintext highlighter-rouge\">Comp</code> is sent after\u00a0<code class=\"language-plaintext highlighter-rouge\">DBIDresp</code> and accounting for the front-end write latency (<code class=\"language-plaintext highlighter-rouge\">write_fe_latency</code>).</li>\n<li>Memory attribute fields are not implemented.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">DoNotGoToSD</code> field is not implemented.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">CBusy</code> is not implemented.</li>\n<li><code class=\"language-plaintext highlighter-rouge\">WriteDataCancel</code> responses are never used.</li>\n<li>Error handling is not implemented.</li>\n<li>Cache stashing is not implemented.</li>\n<li>Atomic transactions are not implemented.</li>\n<li>DMV transactions are not implemented.</li>\n<li>Any request not listed in the protocol table below is not supported in this implementation.</li>\n</ul>\n<h3 id=\"protocol-table\">Protocol table</h3>\n<p><a href=\"/assets/img/ruby_chi/protocol_table.htm\">Click here</a></p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/moving_to_github/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/ruby/Garnet_standalone/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/ruby/Garnet_standalone",
        "title": "Garnet Standalone",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Jason Lowe-Power<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"garnet-standalone\">Garnet Standalone</h1>\n<p>This is a dummy cache coherence protocol that is used to operate Garnet\nin a standalone manner. This protocol works in conjunction with the\n<a href=\"/documentation/general_docs/ruby/garnet_synthetic_traffic\">Garnet Synthetic Traffic</a>\ninjector.</p>\n<h3 id=\"related-files\">Related Files</h3>\n<ul>\n<li><strong>src/mem/protocols</strong>\n<ul>\n<li><strong>Garnet_standalone-cache.sm</strong>: cache controller specification</li>\n<li><strong>Garnet_standalone-dir.sm</strong>: directory controller\nspecification</li>\n<li><strong>Garnet_standalone-msg.sm</strong>: message type specification</li>\n<li><strong>Garnet_standalone.slicc</strong>: container file</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"cache-hierarchy\">Cache Hierarchy</h3>\n<p>This protocol assumes a 1-level cache hierarchy. The role of the cache\nis to simply send messages from the cpu to the appropriate directory\n(based on the address), in the appropriate virtual network (based on the\nmessage type). It does not track any state. Infact, no CacheMemory is\ncreated unlike other protocols. The directory receives the messages from\nthe caches, but does not send any back. The goal of this protocol is to\nenable simulation/testing of just the interconnection network.</p>\n<h3 id=\"stable-states-and-invariants\">Stable States and Invariants</h3>\n<table>\n<thead>\n<tr>\n<th>States</th>\n<th>Invariants</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>I</strong></td>\n<td>Default state of all cache blocks</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"cache-controller\">Cache controller</h3>\n<ul>\n<li>Requests, Responses, Triggers:\n    <ul>\n<li>Load, Instruction fetch, Store from the core.</li>\n</ul>\n</li>\n</ul>\n<p>The network tester (in src/cpu/testers/networktest/networktest.cc)\ngenerates packets of the type <strong>ReadReq</strong>, <strong>INST_FETCH</strong>, and\n<strong>WriteReq</strong>, which are converted into <strong>RubyRequestType:LD</strong>,\n<strong>RubyRequestType:IFETCH</strong>, and <strong>RubyRequestType:ST</strong>, respectively, by\nthe RubyPort (in src/mem/ruby/system/RubyPort.hh/cc). These messages\nreach the cache controller via the Sequencer. The destination for these\nmessages is determined by the traffic type, and embedded in the address.\nMore details can be found <a href=\"/documentation/general_docs/debugging_and_testing/directed_testers/ruby_random_tester\">here</a>.</p>\n<ul>\n<li>Main Operation:\n    <ul>\n<li>The goal of the cache is only to act as a source node in the\nunderlying interconnection network. It does not track any\nstates.</li>\n<li>On a <strong>LD</strong> from the core:\n        <ul>\n<li>it returns a hit, and</li>\n<li>maps the address to a directory, and issues a message for it\nof type <strong>MSG</strong>, and size <strong>Control</strong> (8 bytes) in the\nrequest vnet (0).</li>\n<li>Note: vnet 0 could also be made to broadcast, instead of\nsending a directed message to a particular directory, by\nuncommenting the appropriate line in the <em>a_issueRequest</em>\naction in Network_test-cache.sm</li>\n</ul>\n</li>\n<li>On a <strong>IFETCH</strong> from the core:\n        <ul>\n<li>it returns a hit, and</li>\n<li>maps the address to a directory, and issues a message for it\nof type <strong>MSG</strong>, and size <strong>Control</strong> (8 bytes) in the\nforward vnet (1).</li>\n</ul>\n</li>\n<li>On a <strong>ST</strong> from the core:\n        <ul>\n<li>it returns a hit, and</li>\n<li>maps the address to a directory, and issues a message for it\nof type <strong>MSG</strong>, and size <strong>Data</strong> (72 bytes) in the\nresponse vnet (2).</li>\n</ul>\n</li>\n<li>Note: request, forward and response are just used to\ndifferentiate the vnets, but do not have any physical\nsignificance in this protocol.</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"directory-controller\">Directory controller</h3>\n<ul>\n<li>Requests, Responses, Triggers:\n    <ul>\n<li><strong>MSG</strong> from the cores</li>\n</ul>\n</li>\n<li>Main Operation:\n    <ul>\n<li>The goal of the directory is only to act as a destination node\nin the underlying interconnection network. It does not track any\nstates.</li>\n<li>The directory simply pops its incoming queue upon receiving the\nmessage.</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"other-features\">Other features</h3>\n<p>This protocol assumes only 3 vnets.</p>\n<ul>\n<li>It should only be used when running <a href=\"/documentation/general_docs/ruby/garnet_synthetic_traffic\">Garnet Synthetic\n    Traffic</a>.</li>\n</ul>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/ruby/CHI/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/ruby/MESI_Two_Level/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/ruby/MESI_Two_Level",
        "title": "MESI Two Level",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Jason Lowe-Power<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"mesi-two-level\">MESI Two Level</h1>\n<h3 id=\"protocol-overview\"><strong>Protocol Overview</strong></h3>\n<ul>\n<li>This protocol models <strong>two-level cache hierarchy</strong>. The L1 cache is\nprivate to a core, while the L2 cache is shared among the cores. L1\nCache is split into Instruction and Data cache.</li>\n<li><strong>Inclusion</strong> is maintained between the L1 and L2 cache.</li>\n<li>At high level the protocol has four stable states, <strong>M</strong>, <strong>E</strong>,\n<strong>S</strong> and <strong>I</strong>. A block in <strong>M</strong> state means the blocks is writable\n(i.e. has exclusive permission) and has been dirtied (i.e. its the\nonly valid copy on-chip). <strong>E</strong> state represent a cache block with\nexclusive permission (i.e. writable) but is not written yet. <strong>S</strong>\nstate means the cache block is only readable and possible multiple\ncopies of it exists in multiple private cache and as well as in the\nshared cache. <strong>I</strong> means that the cache block is invalid.</li>\n<li>The on-chip cache coherence is maintained through <strong>Directory\nCoherence</strong> scheme, where the directory information is co-located\nwith the corresponding cache blocks in the shared L2 cache.</li>\n<li>The protocol has four types of controllers \u2013 <strong>L1 cache controller,\nL2 cache controller, Directory controller</strong> and <strong>DMA controller</strong>.\nL1 cache controller is responsible for managing L1 Instruction and\nL1 Data Cache. Number of instantiations of L1 cache controller is\nequal to the number of cores in the simulated system. L2 cache\ncontroller is responsible for managing the shared L2 cache and for\nmaintaining coherence of on-chip data through directory coherence\nscheme. The Directory controller acts as interface to the Memory\nController/Off-chip main memory and is also responsible for coherence\nacross multiple chips/and external coherence request from DMA\ncontroller. DMA controller is responsible for satisfying coherent\nDMA requests.</li>\n<li>One of the primary optimizations in this protocol is that if a L1\nCache request a data block even for read permission, the L2 cache\ncontroller if finds that no other core has the block, it returns the\ncache block with exclusive permission. This is an optimization done\nin anticipation that a cache blocks read would be written by the\nsame core soon and thus save an extra request with this\noptimization. This is exactly why <strong>E</strong> state exists (i.e. when a\ncache block is writable but not yet written).</li>\n<li>The protocol supports <em>silent eviction</em> of <em>clean</em> cache blocks from\nthe private L1 caches. This means that cache blocks which have not\nbeen written to and has readable permission only can drop the cache\nblock from the private L1 cache without informing the L2 cache. This\noptimization helps reducing write-back traffic to the L2 cache\ncontroller.</li>\n</ul>\n<h3 id=\"related-files\"><strong>Related Files</strong></h3>\n<ul>\n<li><strong>src/mem/protocols</strong>\n<ul>\n<li><strong>MESI_CMP_directory-L1cache.sm</strong>: L1 cache controller\nspecification</li>\n<li><strong>MESI_CMP_directory-L2cache.sm</strong>: L2 cache controller\nspecification</li>\n<li><strong>MESI_CMP_directory-dir.sm</strong>: directory controller\nspecification</li>\n<li><strong>MESI_CMP_directory-dma.sm</strong>: dma controller specification</li>\n<li><strong>MESI_CMP_directory-msg.sm</strong>: coherence message type\nspecifications. This defines different field of different type\nof messages that would be used by the given protocol</li>\n<li><strong>MESI_CMP_directory.slicc</strong>: container file</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"controller-description\"><strong>Controller Description</strong></h3>\n<h3 id=\"l1-cache\">**L1 cache</h3>\n<p>controller**</p>\n<table>\n<thead>\n<tr>\n<th>States</th>\n<th>Invariants and Semantic/Purpose of the state</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>M</strong></td>\n<td>The cache block is held in exclusive state by <strong>only one L1 cache</strong>. There are no sharers of this block. The data is potentially is the only valid copy in the system. The copy of the cache block is <strong>writable</strong> and as well as <strong>readable</strong>.</td>\n</tr>\n<tr>\n<td><strong>E</strong></td>\n<td>The cache block is held with exclusive permission by exactly <strong>only one L1 cache</strong>. The difference with the <strong>M</strong> state is that the cache block is writable (and readable) but not yet written.</td>\n</tr>\n<tr>\n<td><strong>S</strong></td>\n<td>The cache block is held in shared state by 1 or more L1 caches and/or by the L2 cache. The block is only <strong>readable</strong>. No cache can have the cache block with exclusive permission.</td>\n</tr>\n<tr>\n<td><strong>I / NP</strong></td>\n<td>The cache block is invalid.</td>\n</tr>\n<tr>\n<td><strong>IS</strong></td>\n<td>Transient state. This means that <strong>GETS (Read)</strong> request has been issued for the cache block and awaiting for response. The cache block is neither readable nor writable.</td>\n</tr>\n<tr>\n<td><strong>IM</strong></td>\n<td>Transient state. This means that <strong>GETX (Write)</strong> request has been issued for the cache block and awaiting for response. The cache block is neither readable nor writable.</td>\n</tr>\n<tr>\n<td><strong>SM</strong></td>\n<td>Transient state. This means the cache block was originally in S state and then <strong>UPGRADE (Write)</strong> request was issued to get exclusive permission for the blocks and awaiting response. The cache block is <strong>readable</strong>.</td>\n</tr>\n<tr>\n<td><strong>IS_I</strong></td>\n<td>Transient state. This means that while in IS state the cache controller received Invalidation from the L2 Cache\u2019s directory. This happens due to race condition due to write to the same cache block by other core, while the given core was trying to get the same cache blocks for reading. The cache block is neither readable nor writable..</td>\n</tr>\n<tr>\n<td><strong>M_I</strong></td>\n<td>Transient state. This state indicates that the cache is trying to replace a cache block in <strong>M</strong> state from its cache and the write-back (PUTX) to the L2 cache\u2019s directory has been issued but awaiting write-back acknowledgement.</td>\n</tr>\n<tr>\n<td><strong>SINK_WB_ACK</strong></td>\n<td>Transient state. This state is reached when waiting for write-back acknowledgement from the L2 cache\u2019s directory, the L1 cache received intervention (forwarded request from other cores). This indicates a race between the issued write-back to the directory and another request from the another cache has happened. This also indicates that the write-back has lost the race (i.e. before it reached the L2 cache\u2019s directory, another core\u2019s request has reached the L2). This state is essential to avoid possibility of complicated race condition that can happen if write-backs are silently dropped at the directory.</td>\n</tr>\n<tr>\n<td>\u00a0</td>\n<td>\u00a0</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"l2-cache-controller\"><strong>L2 cache controller</strong></h3>\n<p>Recall that the on-chip directory is co-located with the corresponding\ncache blocks in the L2 Cache. Thus following states in the L2 cache\nblock encodes the information about the status and permissions of the\ncache blocks in the L2 cache as well as the coherence status of the\ncache block that may be present in one or more private L1 caches. Beyond\nthe coherence states there are also two more important fields per cache\nblock that aids to make proper coherence actions. These fields are\n<strong>Sharers</strong> field, which can be thought of as a bit-vector indicating\nwhich of the private L1 caches potentially have the given cache block.\nThe other important field is the <strong>Owner</strong> field, which is the identity\nof the private L1 cache in case the cache block is held with exclusive\npermission in a L1\ncache.</p>\n<table>\n<thead>\n<tr>\n<th>States</th>\n<th>Invariants and Semantic/Purpose of the state</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>NP</strong></td>\n<td>The cache blocks is not present in the on-chip cache hierarchy.</td>\n</tr>\n<tr>\n<td><strong>SS</strong></td>\n<td>The cache block is present in potentially multiple private caches in only readable mode (i.e.in \u201cS\u201d state in private caches). Corresponding \u201cSharers\u201d vector with the block should give the identity of the private caches which possibly have the cache block in its cache. The cache block in the L2 cache is valid and <strong>readable</strong>.</td>\n</tr>\n<tr>\n<td><strong>M</strong></td>\n<td>The cache block is present ONLY in the L2 cache and has exclusive permission. L1 Cache\u2019s read/write requests (GETS/GETX) can be satisfied directly from the L2 cache.</td>\n</tr>\n<tr>\n<td><strong>MT</strong></td>\n<td>The cache block is in ONE of the private L1 caches with exclusive permission. The data in the L2 cache is potentially stale. The identity of the L1 cache which has the block can be found in the \u201cOwner\u201d field associated with the cache block. Any request for read/write (GETS/GETX) from other cores/private L1 caches need to be forwarded to the owner of the cache block. L2 can not service requests itself.</td>\n</tr>\n<tr>\n<td><strong>M_I</strong></td>\n<td>Its a transient state. This state indicates that the cache is trying to replace the cache block from its cache and the write-back (PUTX/PUTS) to the Directory controller (which act as interface to Main memory) has been issued but awaiting write-back acknowledgement. The data is neither readable nor writable.</td>\n</tr>\n<tr>\n<td><strong>MT_I</strong></td>\n<td>Its a transient state. This state indicates that the cache is trying to replace a cache block in <strong>MT</strong> state from its cache. Invalidation to the current owner (private L1 cache) of the cache block has been issued and awaiting write-back from the Owner L1 cache. Note that the this Invalidation (called back-invalidation) is instrumental in making sure that the inclusion is maintained between L1 and L2 caches. The data is neither readable nor writable.</td>\n</tr>\n<tr>\n<td><strong>MCT_I</strong></td>\n<td>Its a transient state.This state is same as <strong>MT_I</strong>, except that it is known that the data in the L2 cache is in <em>clean</em> state. The data is neither readable nor writable.</td>\n</tr>\n<tr>\n<td><strong>I_I</strong></td>\n<td>Its a transient state. The L2 cache is trying to replace a cache block in the <strong>SS</strong> state and the cache block in the L2 is in <em>clean</em> state. Invalidations has been sent to all potential sharers (L1 caches) of the cache block. The L2 cache\u2019s directory is waiting for all the required Acknowledgements to arrive from the L1 caches. Note that the this Invalidation (called back-invalidation) is instrumental in making sure that the inclusion is maintained between L1 and L2 caches. The data is neither readable nor writable.</td>\n</tr>\n<tr>\n<td><strong>S_I</strong></td>\n<td>Its a transient state.Same as <strong>I_I</strong>, except the data in L2 cache for the cache block is <em>dirty</em>. This means unlike in the case of <strong>I_I</strong>, the data needs to be sent to the Main memory. The cache block is neither readable nor writable..</td>\n</tr>\n<tr>\n<td><strong>ISS</strong></td>\n<td>Its a transient state. L2 has received a <strong>GETS (read)</strong> request from one of the private L1 caches, for a cache block that it not present in the on-chip caches. A read request has been sent to the Main Memory (Directory controller) and waiting for the response from the memory. This state is reached only when the request is for data cache block (not instruction cache block). The purpose of this state is that if it is found that only one L1 cache has requested the cache block then the block is returned to the requester with exclusive permission (although it was requested for reading permission). The cache block is neither readable nor writable.</td>\n</tr>\n<tr>\n<td><strong>IS</strong></td>\n<td>Its a transient state. The state is similar to <strong>ISS</strong>, except the fact that if the requested cache block is Instruction cache block or more than one core request the same cache block while waiting for the response from the memory, this state is reached instead of <strong>ISS</strong>. Once the requested cache block arrives from the Main Memory, the block is sent to the requester(s) with read-only permission. The cache block is neither readable nor writable at this state.</td>\n</tr>\n<tr>\n<td><strong>IM</strong></td>\n<td>Its a transient state. This state is reached when a L1 GETX (write) request is received by the L2 cache for a cache blocks that is not present in the on-chip cache hierarchy. The request for the cache block in exclusive mode has been issued to the main memory but response is yet to arrive.The cache block is neither readable nor writable at this state.</td>\n</tr>\n<tr>\n<td><strong>SS_MB</strong></td>\n<td>Its a transient state. In general any state whose name ends with \u201cB\u201d (like this one) also means that it is a <em>blocking</em> coherence state. This means the directory awaiting for some response from the private L1 cache ans until it receives the desired response any other request is not entertained (i.e. request are effectively serialized). This particular state is reached when a L1 cache requests a cache block with exclusive permission (i.e. GETX or UPGRADE) and the coherence state of the cache blocks was in <strong>SS</strong> state. This means that the requested cache blocks potentially has readable copies in the private L1 caches. Thus before giving the exclusive permission to the requester, all the readable copies in the L1 caches need to be invalidated. This state indicate that the required invalidations has been sent to the potential sharers (L1 caches) and the requester has been informed about the required number of Invalidation Acknowledgement it needs before it can have the exclusive permission for the cache block. Once the requester L1 cache gets the required number of Invalidation Acknowledgement it informs the director about this by <em>UNBLOCK</em> message which allows the directory to move out of this blocking coherence state and thereafter it can resume entertaining other request for the given cache block. The cache block is neither readable nor writable at this state.</td>\n</tr>\n<tr>\n<td><strong>MT_MB</strong></td>\n<td>Its a transient state and also a <em>blocking</em> state. This state is reached when L2 cache\u2019s directory has sent out a cache block with exclusive permission to a requester L1 cache but yet to receive <em>UNBLOCK</em> from the requester L1 cache acknowledging the receipt of exclusive permission. The cache block is neither readable nor writable at this state.</td>\n</tr>\n<tr>\n<td><strong>MT_IIB</strong></td>\n<td>Its a transient state and also a <em>blocking</em> state. This state is reached when a read request (GETS) request is received for a cache blocks which is currently held with exclusive permission in another private L1 cache (i.e. directory state is <strong>MT</strong>). On such requests the L2 cache\u2019s directory forwards the request to the current owner L1 cache and transitions to this state. Two events need to happen before this cache block can be unblocked (and thus start entertaining further request for this cache block). The current owner cache block need to send a write-back to the L2 cache to update the L2\u2019s copy with latest value. The requester L1 cache also needs to send <em>UNBLOCK</em> to the L2 cache indicating that it has got the requested cache block with desired coherence permissions. The cache block is neither readable nor writable at this state in the L2 cache.</td>\n</tr>\n<tr>\n<td><strong>MT_IB</strong></td>\n<td>Its a transient state and also a <em>blocking</em> state. This state is reached when at <strong>MT_IIB</strong> state the L2 cache controller receives the <em>UNBLOCK</em> from the requester L1 cache but yet to receive the write-back from the previous owner L1 cache of the block. The cache block is neither readable nor writable at this state in the L2 cache.</td>\n</tr>\n<tr>\n<td><strong>MT_SB</strong></td>\n<td>Its a transient state and also a <em>blocking</em> state. This state is reached when at <strong>MT_IIB</strong> state the L2 cache controller receives write-back from the previous owner L1 cache for the blocks, while yet to receive the <em>UNBLOCK</em> from the current requester for the cache block. The cache block is neither readable nor writable at this state in the L2 cache.</td>\n</tr>\n</tbody>\n</table>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/ruby/Garnet_standalone/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/ruby/MI_example/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/ruby/MI_example",
        "title": "MI Example",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Jason Lowe-Power<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"mi-example\">MI Example</h1>\n<h3 id=\"protocol-overview\">Protocol Overview</h3>\n<ul>\n<li>This is a simple cache coherence protocol that is used to illustrate\nprotocol specification using SLICC.</li>\n<li>This protocol assumes a 1-level cache hierarchy. The cache is\nprivate to each node. The caches are kept coherent by a directory\ncontroller. Since the hierarchy is only 1-level, there is no\ninclusion/exclusion requirement.</li>\n<li>This protocol does not differentiate between loads and stores.</li>\n<li>This protocol cannot implement the semantics of LL/SC instructions,\nbecause external GETS requests that hit a block within a LL/SC\nsequence steal exclusive permissions, thus causing the SC\ninstruction to fail.</li>\n</ul>\n<h3 id=\"related-files\">Related Files</h3>\n<ul>\n<li><strong>src/mem/protocols</strong>\n<ul>\n<li><strong>MI_example-cache.sm</strong>: cache controller specification</li>\n<li><strong>MI_example-dir.sm</strong>: directory controller specification</li>\n<li><strong>MI_example-dma.sm</strong>: dma controller specification</li>\n<li><strong>MI_example-msg.sm</strong>: message type specification</li>\n<li><strong>MI_example.slicc</strong>: container file</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"stable-states-and-invariants\">Stable States and Invariants</h3>\n<table>\n<thead>\n<tr>\n<th>States</th>\n<th>Invariants</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>M</strong></td>\n<td>The cache block has been accessed (read/written) by this node. No other node holds a copy of the cache block</td>\n</tr>\n<tr>\n<td><strong>I</strong></td>\n<td>The cache block at this node is invalid</td>\n</tr>\n</tbody>\n</table>\n<p><strong>The notation used in the controller FSM diagrams is described\n<a href=\"#Coherence_controller_FSM_Diagrams\" title=\"wikilink\">here</a>.</strong></p>\n<h3 id=\"cache-controller\">Cache controller</h3>\n<ul>\n<li>Requests, Responses, Triggers:\n    <ul>\n<li>Load, Instruction fetch, Store from the core</li>\n<li>Replacement from self</li>\n<li>Data from the directory controller</li>\n<li>Forwarded request (intervention) from the directory controller</li>\n<li>Writeback acknowledgement from the directory controller</li>\n<li>Invalidations from directory controller (on dma activity)</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"MI_example_cache_FSM.jpg\" src=\"/assets/img/MI_example_cache_FSM.jpg\" title=\"MI_example_cache_FSM.jpg\"/></p>\n<ul>\n<li>Main Operation:\n    <ul>\n<li>On a <strong>load/Instruction fetch/Store</strong> request from the core:\n        <ul>\n<li>it checks whether the corresponding block is present in the\nM state. If so, it returns a hit</li>\n<li>otherwise, if in I state, it initiates a GETX request from\nthe directory controller</li>\n</ul>\n</li>\n<li>On a <strong>replacement</strong> trigger from self:\n        <ul>\n<li>it evicts the block, issues a writeback request to the\ndirectory controller</li>\n<li>it waits for acknowledgement from the directory controller\n(to prevent races)</li>\n</ul>\n</li>\n<li>On a <strong>forwarded request</strong> from the directory controller:\n        <ul>\n<li>This means that the block was in M state at this node when\nthe request was generated by some other node</li>\n<li>It sends the block directly to the requesting node\n(cache-to-cache transfer)</li>\n<li>It evicts the block from this node</li>\n</ul>\n</li>\n<li><strong>Invalidations</strong> are similar to replacements</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"directory-controller\">Directory controller</h3>\n<ul>\n<li>Requests, Responses, Triggers:\n    <ul>\n<li>GETX from the cores, Forwarded GETX to the cores</li>\n<li>Data from memory, Data to the cores</li>\n<li>Writeback requests from the cores, Writeback acknowledgements to\nthe cores</li>\n<li>DMA read, write requests from the DMA controllers</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"MI_example_dir_FSM.jpg\" src=\"/assets/img/MI_example_dir_FSM.jpg\" title=\"MI_example_dir_FSM.jpg\"/></p>\n<ul>\n<li>Main Operation:\n    <ul>\n<li>The directory maintains track of which core has a block in the M\nstate. It designates this core as owner of the block.</li>\n<li>On a <strong>GETX</strong> request from a core:\n        <ul>\n<li>If the block is not present, a memory fetch request is\ninitiated</li>\n<li>If the block is already present, then it means the request\nis generated from some other core\n            <ul>\n<li>In this case, a forwarded request is sent to the\noriginal owner</li>\n<li>Ownership of the block is transferred to the requestor</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>On a <strong>writeback</strong> request from a core:\n        <ul>\n<li>If the core is owner, the data is written to memory and\nacknowledgement is sent back to the core</li>\n<li>If the core is not owner, a NACK is sent back\n            <ul>\n<li>This can happen in a race condition</li>\n<li>The core evicted the block while a forwarded request\nsome other core was on the way and the directory has\nalready changed ownership for the core</li>\n<li>The evicting core holds the data till the forwarded\nrequest arrives</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>On <strong>DMA</strong> accesses (read/write)\n        <ul>\n<li>Invalidation is sent to the owner node (if any). Otherwise\ndata is fetched from memory.</li>\n<li>This ensures that the most recent data is available.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"other-features\">Other features</h3>\n<ul>\n<li>MI protocols don\u2019t support LL/SC semantics. A load from a remote\n    core will invalidate the cache block.</li>\n<li>This protocol has no timeout mechanisms.</li>\n</ul>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/ruby/MESI_Two_Level/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/ruby/MOESI_CMP_directory/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/ruby/MOESI_CMP_directory",
        "title": "MOESI CMP Directory",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Jason Lowe-Power<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"moesi-cmp-directory\">MOESI CMP Directory</h1>\n<h3 id=\"protocol-overview\">Protocol Overview</h3>\n<ul>\n<li>TODO: cache hierarchy</li>\n</ul>\n<!-- end list -->\n<ul>\n<li>In contrast with the MESI protocol, the MOESI protocol introduces an\nadditional <strong>Owned</strong> state.</li>\n<li>The MOESI protocol also includes many coalescing optimizations not\navailable in the MESI protocol.</li>\n</ul>\n<h3 id=\"related-files\">Related Files</h3>\n<ul>\n<li><strong>src/mem/protocols</strong>\n<ul>\n<li><strong>MOESI_CMP_directory-L1cache.sm</strong>: L1 cache controller\nspecification</li>\n<li><strong>MOESI_CMP_directory-L2cache.sm</strong>: L2 cache controller\nspecification</li>\n<li><strong>MOESI_CMP_directory-dir.sm</strong>: directory controller\nspecification</li>\n<li><strong>MOESI_CMP_directory-dma.sm</strong>: dma controller specification</li>\n<li><strong>MOESI_CMP_directory-msg.sm</strong>: message type specification</li>\n<li><strong>MOESI_CMP_directory.slicc</strong>: container file</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"l1-cache-controller\">L1 Cache Controller</h3>\n<h4 id=\"stable-states-and-invariants\"><strong>Stable States and Invariants</strong></h4>\n<table>\n<thead>\n<tr>\n<th>States</th>\n<th>Invariants</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>MM</strong></td>\n<td>The cache block is held exclusively by this node and is potentially modified (similar to conventional \u201cM\u201d state).</td>\n</tr>\n<tr>\n<td><strong>MM_W</strong></td>\n<td>The cache block is held exclusively by this node and is potentially modified (similar to conventional \u201cM\u201d state). Replacements and DMA accesses are not allowed in this state. The block automatically transitions to MM state after a timeout.</td>\n</tr>\n<tr>\n<td><strong>O</strong></td>\n<td>The cache block is owned by this node. It has not been modified by this node. No other node holds this block in exclusive mode, but sharers potentially exist.</td>\n</tr>\n<tr>\n<td><strong>M</strong></td>\n<td>The cache block is held in exclusive mode, but not written to (similar to conventional \u201cE\u201d state). No other node holds a copy of this block. Stores are not allowed in this state.</td>\n</tr>\n<tr>\n<td><strong>M_W</strong></td>\n<td>The cache block is held in exclusive mode, but not written to (similar to conventional \u201cE\u201d state). No other node holds a copy of this block. Only loads and stores are allowed. Silent upgrade happens to MM_W state on store. Replacements and DMA accesses are not allowed in this state. The block automatically transitions to M state after a timeout.</td>\n</tr>\n<tr>\n<td><strong>S</strong></td>\n<td>The cache block is held in shared state by 1 or more nodes. Stores are not allowed in this state.</td>\n</tr>\n<tr>\n<td><strong>I</strong></td>\n<td>The cache block is invalid.</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"fsm-abstraction\"><strong>FSM Abstraction</strong></h4>\n<p><strong>The notation used in the controller FSM diagrams is described\n<a href=\"#Coherence_controller_FSM_Diagrams\" title=\"wikilink\">here</a>.</strong></p>\n<p><img alt=\"MOESI_CMP_directory_L1cache_FSM.jpg\" src=\"/assets/img/MOESI_CMP_directory_L1cache_FSM.jpg\" title=\"MOESI_CMP_directory_L1cache_FSM.jpg\"/></p>\n<h4 id=\"optimizations\"><strong>Optimizations</strong></h4>\n<table>\n<thead>\n<tr>\n<th>States</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>SM</strong></td>\n<td>A GETX has been issued to get exclusive permissions for an impending store to the cache block, but an old copy of the block is still present. Stores and Replacements are not allowed in this state.</td>\n</tr>\n<tr>\n<td><strong>OM</strong></td>\n<td>A GETX has been issued to get exclusive permissions for an impending store to the cache block, the data has been received, but all expected acknowledgments have not yet arrived. Stores and Replacements are not allowed in this state.</td>\n</tr>\n</tbody>\n</table>\n<p><strong>The notation used in the controller FSM diagrams is described\n<a href=\"#Coherence_controller_FSM_Diagrams\" title=\"wikilink\">here</a>.</strong></p>\n<p><img alt=\"MOESI_CMP_directory_L1cache_optim_FSM.jpg\" src=\"/assets/img/MOESI_CMP_directory_L1cache_optim_FSM.jpg\" title=\"MOESI_CMP_directory_L1cache_optim_FSM.jpg\"/></p>\n<h3 id=\"l2-cache-controller\">L2 Cache Controller</h3>\n<h4 id=\"stable-states-and-invariants-1\"><strong>Stable States and Invariants</strong></h4>\n<table>\n<thead>\n<tr>\n<th> Intra-chip Inclusion </th>\n<th> Inter-chip Exclusion </th>\n<th> States </th>\n<th> Description\n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td> <b><span style=\"color:#808080\">Not in any L1 or L2 at this chip</span></b> </td>\n<td> <b>May be present at other chips</b> </td>\n<td> <b>NP/I</b> </td>\n<td> The cache block at this chip is invalid.\n</td></tr>\n<tr>\n<td rowspan=\"6\"> <b><span style=\"color:#00CC99\">Not in L2, but in 1 or more L1s at this chip</span></b> </td>\n<td rowspan=\"3\"><b>May be present at other chips</b> </td>\n<td> <b>ILS</b> </td>\n<td> The cache block is not present at L2 on this chip. It is shared locally by L1 nodes in this chip.\n</td></tr>\n<tr>\n<td> <b>ILO</b> </td>\n<td> The cache block is not present at L2 on this chip. Some L1 node in this chip is an owner of this cache block.\n</td></tr>\n<tr>\n<td> <b>ILOS</b> </td>\n<td> The cache block is not present at L2 on this chip. Some L1 node in this chip is an owner of this cache block. There are also L1 sharers of this cache block in this chip.\n</td></tr>\n<tr>\n<td rowspan=\"3\"><b>Not present at any other chip</b> </td>\n<td> <b>ILX</b> </td>\n<td> The cache block is not present at L2 on this chip. It is held in exclusive mode by some L1 node in this chip.\n</td></tr>\n<tr>\n<td> <b>ILOX</b> </td>\n<td> The cache block is not present at L2 on this chip. It is held exclusively by this chip and some L1 node in this chip is an owner of the block.\n</td></tr>\n<tr>\n<td> <b>ILOSX</b> </td>\n<td> The cache block is not present at L2 on this chip. It is held exclusively by this chip. Some L1 node in this chip is an owner of the block. There are also L1 sharers of this cache block in this chip.\n</td></tr>\n<tr>\n<td rowspan=\"3\"> <b><span style=\"color:#99CCFF\">In L2, but not in any L1 at this chip</span></b> </td>\n<td rowspan=\"2\"><b>May be present at other chips</b> </td>\n<td> <b>S</b> </td>\n<td> The cache block is not present at L1 on this chip. It is held in shared mode at L2 on this chip and is also potentially shared across chips.\n</td></tr>\n<tr>\n<td> <b>O</b> </td>\n<td> The cache block is not present at L1 on this chip. It is held in owned mode at L2 on this chip. It is also potentially shared across chips.\n</td></tr>\n<tr>\n<td> <b>Not present at any other chip</b> </td>\n<td> <b>M</b> </td>\n<td> The cache block is not present at L1 on this chip. It is present at L2 on this chip and is potentially modified.\n</td></tr>\n<tr>\n<td rowspan=\"3\"> <b><span style=\"color:#CC99FF\">Both in L2, and 1 or more L1s at this chip</span></b> </td>\n<td rowspan=\"2\"><b>May be present at other chips</b> </td>\n<td> <b>SLS</b> </td>\n<td> The cache block is present at L2 in shared mode on this chip. There exists local L1 sharers of the block on this chip. It is also potentially shared across chips.\n</td></tr>\n<tr>\n<td> <b>OLS</b> </td>\n<td> The cache block is present at L2 in owned mode on this chip. There exists local L1 sharers of the block on this chip. It is also potentially shared across chips.\n</td></tr>\n<tr>\n<td> <b>Not present at any other chip</b> </td>\n<td> <b>OLSX</b> </td>\n<td> The cache block is present at L2 in owned mode on this chip. There exists local L1 sharers of the block on this chip. It is held exclusively by this chip.\n</td></tr>\n</tbody>\n</table>\n<h4 id=\"fsm-abstraction-1\"><strong>FSM Abstraction</strong></h4>\n<p>The controller is described in 2 parts. The first picture shows\ntransitions between all \u201cintra-chip inclusion\u201d categories and within\ncategories 1, 3, 4. Transitions within category 2 (Not in L2, but in 1\nor more L1s at this chip) are shown in the second picture.</p>\n<p><strong>The notation used in the controller FSM diagrams is described\n<a href=\"#Coherence_controller_FSM_Diagrams\" title=\"wikilink\">here</a>. Transitions\ninvolving other chips are annotated in\n<span style=\"color:#CC3300\">brown</span>.</strong></p>\n<p><img alt=\"MOESI_CMP_directory_L2cache_FSM_part_1.jpg\" src=\"/assets/img/MOESI_CMP_directory_L2cache_FSM_part_1.jpg\" title=\"MOESI_CMP_directory_L2cache_FSM_part_1.jpg\"/></p>\n<p>The second picture below expands the central hexagonal portion of the\nabove picture to show transitions within category 2 (Not in L2, but in 1\nor more L1s at this chip).</p>\n<p><strong>The notation used in the controller FSM diagrams is described\n<a href=\"#Coherence_controller_FSM_Diagrams\" title=\"wikilink\">here</a>. Transitions\ninvolving other chips are annotated in\n<span style=\"color:#CC3300\">brown</span>.</strong></p>\n<p><img alt=\"MOESI_CMP_directory_L2cache_FSM_part_2.jpg\" src=\"/assets/img/MOESI_CMP_directory_L2cache_FSM_part_2.jpg\" title=\"MOESI_CMP_directory_L2cache_FSM_part_2.jpg\"/></p>\n<h3 id=\"directory-controller\">Directory Controller</h3>\n<h4 id=\"stable-states-and\">**Stable States and</h4>\n<p>Invariants**</p>\n<table>\n<thead>\n<tr>\n<th>States</th>\n<th>Invariants</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>M</strong></td>\n<td>The cache block is held in exclusive state by only 1 node (which is also the owner). There are no sharers of this block. The data is potentially different from that in memory.</td>\n</tr>\n<tr>\n<td><strong>O</strong></td>\n<td>The cache block is owned by exactly 1 node. There may be sharers of this block. The data is potentially different from that in memory.</td>\n</tr>\n<tr>\n<td><strong>S</strong></td>\n<td>The cache block is held in shared state by 1 or more nodes. No node has ownership of the block. The data is consistent with that in memory (Check).</td>\n</tr>\n<tr>\n<td><strong>I</strong></td>\n<td>The cache block is invalid.</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"fsm-abstraction-2\"><strong>FSM Abstraction</strong></h4>\n<p><strong>The notation used in the controller FSM diagrams is described\n<a href=\"#Coherence_controller_FSM_Diagrams\" title=\"wikilink\">here</a>.</strong></p>\n<p><img alt=\"MOESI_CMP_directory_dir_FSM.jpg\" src=\"/assets/img/MOESI_CMP_directory_dir_FSM.jpg\" title=\"MOESI_CMP_directory_dir_FSM.jpg\"/></p>\n<h3 id=\"other-features\">Other features</h3>\n<h4 id=\"timeouts\"><strong>Timeouts</strong>:</h4>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/ruby/MI_example/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/ruby/MOESI_CMP_token/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/ruby/MOESI_CMP_token",
        "title": "MOESI CMP token",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Jason Lowe-Power<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"moesi-cmp-token\">MOESI CMP token</h1>\n<h3 id=\"protocol-overview\">Protocol Overview</h3>\n<ul>\n<li>This protocol also models a 2-level cache hierarchy.</li>\n<li>It maintains coherence permission by explicitly exchanging and\ncounting tokens.</li>\n<li>A fix number of token are assigned to each cache block in the\nbeginning, the number of token remains unchanged.</li>\n<li>To write a block, the processor must have all the token for that\nblock. For reading at least one token is required.</li>\n<li>The protocol also has a persistent message support to avoid\nstarvation.</li>\n</ul>\n<h3 id=\"related-files\">Related Files</h3>\n<ul>\n<li><strong>src/mem/protocols</strong>\n<ul>\n<li><strong>MOESI_CMP_token-L1cache.sm</strong>: L1 cache controller\nspecification</li>\n<li><strong>MOESI_CMP_token-L2cache.sm</strong>: L2 cache controller\nspecification</li>\n<li><strong>MOESI_CMP_token-dir.sm</strong>: directory controller specification</li>\n<li><strong>MOESI_CMP_token-dma.sm</strong>: dma controller specification</li>\n<li><strong>MOESI_CMP_token-msg.sm</strong>: message type specification</li>\n<li><strong>MOESI_CMP_token.slicc</strong>: container file</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"controller-description\">Controller Description</h3>\n<h3 id=\"l1-cache\"><strong>L1 Cache</strong></h3>\n<table>\n<thead>\n<tr>\n<th>States</th>\n<th>Invariants</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>MM</strong></td>\n<td>The cache block is held exclusively by this node and is potentially modified (similar to conventional \u201cM\u201d state).</td>\n</tr>\n<tr>\n<td><strong>MM_W</strong></td>\n<td>The cache block is held exclusively by this node and is potentially modified (similar to conventional \u201cM\u201d state). Replacements and DMA accesses are not allowed in this state. The block automatically transitions to MM state after a timeout.</td>\n</tr>\n<tr>\n<td><strong>O</strong></td>\n<td>The cache block is owned by this node. It has not been modified by this node. No other node holds this block in exclusive mode, but sharers potentially exist.</td>\n</tr>\n<tr>\n<td><strong>M</strong></td>\n<td>The cache block is held in exclusive mode, but not written to (similar to conventional \u201cE\u201d state). No other node holds a copy of this block. Stores are not allowed in this state.</td>\n</tr>\n<tr>\n<td><strong>M_W</strong></td>\n<td>The cache block is held in exclusive mode, but not written to (similar to conventional \u201cE\u201d state). No other node holds a copy of this block. Only loads and stores are allowed. Silent upgrade happens to MM_W state on store. Replacements and DMA accesses are not allowed in this state. The block automatically transitions to M state after a timeout.</td>\n</tr>\n<tr>\n<td><strong>S</strong></td>\n<td>The cache block is held in shared state by 1 or more nodes. Stores are not allowed in this state.</td>\n</tr>\n<tr>\n<td><strong>I</strong></td>\n<td>The cache block is invalid.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"l2-cache\"><strong>L2 cache</strong></h3>\n<table>\n<thead>\n<tr>\n<th>States</th>\n<th>Invariants</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>NP</strong></td>\n<td>The cache block is held exclusively by this node and is potentially locally modified (similar to conventional \u201cM\u201d state).</td>\n</tr>\n<tr>\n<td><strong>O</strong></td>\n<td>The cache block is owned by this node. It has not been modified by this node. No other node holds this block in exclusive mode, but sharers potentially exist.</td>\n</tr>\n<tr>\n<td><strong>M</strong></td>\n<td>The cache block is held in exclusive mode, but not written to (similar to conventional \u201cE\u201d state). No other node holds a copy of this block. Stores are not allowed in this state.</td>\n</tr>\n<tr>\n<td><strong>S</strong></td>\n<td>The cache line holds the most recent, correct copy of the data. Other processors in the system may hold copies of the data in the shared state, as well. The cache line can be read, but not written in this state.</td>\n</tr>\n<tr>\n<td><strong>I</strong></td>\n<td>The cache line is invalid and does not hold a valid copy of the data.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"directory-controller\"><strong>Directory controller</strong></h3>\n<table>\n<thead>\n<tr>\n<th>States</th>\n<th>Invariants</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>O</strong></td>\n<td>Owner .</td>\n</tr>\n<tr>\n<td><strong>NO</strong></td>\n<td>Not Owner.</td>\n</tr>\n<tr>\n<td><strong>L</strong></td>\n<td>Locked.</td>\n</tr>\n</tbody>\n</table>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/ruby/MOESI_CMP_directory/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/ruby/MOESI_hammer/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/ruby/MOESI_hammer",
        "title": "MOESI Hammer",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Jason Lowe-Power<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"moesi-hammer\">MOESI Hammer</h1>\n<p>This is an implementation of AMD\u2019s Hammer protocol, which is used in\nAMD\u2019s Hammer chip (also know as the Opteron or Athlon 64). The protocol\nimplements both the original a HyperTransport protocol, as well as the\nmore recent ProbeFilter protocol. The protocol also includes a full-bit\ndirectory mode.</p>\n<h3 id=\"related-files\">Related Files</h3>\n<ul>\n<li><strong>src/mem/protocols</strong>\n<ul>\n<li><strong>MOESI_hammer-cache.sm</strong>: cache controller specification</li>\n<li><strong>MOESI_hammer-dir.sm</strong>: directory controller specification</li>\n<li><strong>MOESI_hammer-dma.sm</strong>: dma controller specification</li>\n<li><strong>MOESI_hammer-msg.sm</strong>: message type specification</li>\n<li><strong>MOESI_hammer.slicc</strong>: container file</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"cache-hierarchy\">Cache Hierarchy</h3>\n<p>This protocol implements a 2-level private cache hierarchy. It assigns\nseparate Instruction and Data L1 caches, and a unified L2 cache to each\ncore. These caches are private to each core and are controlled with one\nshared cache controller. This protocol enforce exclusion between L1 and\nL2\ncaches.</p>\n<h3 id=\"stable-states-and-invariants\">Stable States and Invariants</h3>\n<table>\n<thead>\n<tr>\n<th>States</th>\n<th>Invariants</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>MM</strong></td>\n<td>The cache block is held exclusively by this node and is potentially locally modified (similar to conventional \u201cM\u201d state).</td>\n</tr>\n<tr>\n<td><strong>O</strong></td>\n<td>The cache block is owned by this node. It has not been modified by this node. No other node holds this block in exclusive mode, but sharers potentially exist.</td>\n</tr>\n<tr>\n<td><strong>M</strong></td>\n<td>The cache block is held in exclusive mode, but not written to (similar to conventional \u201cE\u201d state). No other node holds a copy of this block. Stores are not allowed in this state.</td>\n</tr>\n<tr>\n<td><strong>S</strong></td>\n<td>The cache line holds the most recent, correct copy of the data. Other processors in the system may hold copies of the data in the shared state, as well. The cache line can be read, but not written in this state.</td>\n</tr>\n<tr>\n<td><strong>I</strong></td>\n<td>The cache line is invalid and does not hold a valid copy of the data.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"cache-controller\">Cache controller</h3>\n<p><strong>The notation used in the controller FSM diagrams is described\n<a href=\"#Coherence_controller_FSM_Diagrams\" title=\"wikilink\">here</a>.</strong></p>\n<p>MOESI_hammer supports cache flushing. To flush a cache line, the cache\ncontroller first issues a GETF request to the directory to block the\nline until the flushing is completed. It then issues a PUTF and writes\nback the cache line.</p>\n<p><img alt=\"MOESI_hammer_cache_FSM.jpg\" src=\"/assets/img/MOESI_hammer_cache_FSM.jpg\" title=\"MOESI_hammer_cache_FSM.jpg\"/></p>\n<h3 id=\"directory-controller\">Directory controller</h3>\n<p>MOESI_hammer memory module, unlike a typical directory protocol, does\nnot contain any directory state and instead broadcasts requests to all\nthe processors in the system. In parallel, it fetches the data from the\nDRAM and forward the response to the requesters.</p>\n<p>probe filter: TODO</p>\n<h4 id=\"stable-states-and-invariants-1\"><strong>Stable States and Invariants</strong></h4>\n<table>\n<thead>\n<tr>\n<th>States</th>\n<th>Invariants</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>NX</strong></td>\n<td>Not Owner, probe filter entry exists, block in O at Owner.</td>\n</tr>\n<tr>\n<td><strong>NO</strong></td>\n<td>Not Owner, probe filter entry exists, block in E/M at Owner.</td>\n</tr>\n<tr>\n<td><strong>S</strong></td>\n<td>Data clean, probe filter entry exists pointing to the current owner.</td>\n</tr>\n<tr>\n<td><strong>O</strong></td>\n<td>Data clean, probe filter entry exists.</td>\n</tr>\n<tr>\n<td><strong>E</strong></td>\n<td>Exclusive Owner, no probe filter entry.</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"controller\"><strong>Controller</strong></h4>\n<p><strong>The notation used in the controller FSM diagrams is described\n<a href=\"#Coherence_controller_FSM_Diagrams\" title=\"wikilink\">here</a>.</strong></p>\n<p><img alt=\"MOESI_hammer_dir_FSM.jpg\" src=\"/assets/img/MOESI_hammer_dir_FSM.jpg\" title=\"MOESI_hammer_dir_FSM.jpg\"/></p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/ruby/MOESI_CMP_token/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/ruby/cache-coherence-protocols/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/ruby/cache-coherence-protocols",
        "title": "Cache Coherence Protocols",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Jason Lowe-Power<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"cache-coherence-protocols\">Cache Coherence Protocols</h1>\n<h2 id=\"common-notations-and-data-structures\">Common Notations and Data Structures</h2>\n<h3 id=\"coherence-messages\"><strong>Coherence Messages</strong></h3>\n<p>These are described in the &lt;<em>protocol-name</em>&gt;-msg.sm file for each\nprotocol.</p>\n<table>\n<thead>\n<tr>\n<th>Message</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>ACK/NACK</strong></td>\n<td>positive/negative acknowledgement for requests that wait for the direction of resolution before deciding on the next action. Examples are writeback requests, exclusive requests.</td>\n</tr>\n<tr>\n<td><strong>GETS</strong></td>\n<td>request for shared permissions to satisfy a CPU\u2019s load or IFetch.</td>\n</tr>\n<tr>\n<td><strong>GETX</strong></td>\n<td>request for exclusive access.</td>\n</tr>\n<tr>\n<td><strong>INV</strong></td>\n<td>invalidation request. This can be triggered by the coherence protocol itself, or by the next cache level/directory to enforce inclusion or to trigger a writeback for a DMA access so that the latest copy of data is obtained.</td>\n</tr>\n<tr>\n<td><strong>PUTX</strong></td>\n<td>request for writeback of cache block. Some protocols (e.g. MOESI_CMP_directory) may use this only for writeback requests of exclusive data.</td>\n</tr>\n<tr>\n<td><strong>PUTS</strong></td>\n<td>request for writeback of cache block in shared state.</td>\n</tr>\n<tr>\n<td><strong>PUTO</strong></td>\n<td>request for writeback of cache block in owned state.</td>\n</tr>\n<tr>\n<td><strong>PUTO_Sharers</strong></td>\n<td>request for writeback of cache block in owned state but other sharers of the block exist.</td>\n</tr>\n<tr>\n<td><strong>UNBLOCK</strong></td>\n<td>message to unblock next cache level/directory for blocking protocols.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"accesspermissions\"><strong>AccessPermissions</strong></h3>\n<p>These are associated with each cache block and determine what operations\nare permitted on that block. It is closely correlated with coherence\nprotocol\nstates.</p>\n<table>\n<thead>\n<tr>\n<th>Permissions</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Invalid</strong></td>\n<td>The cache block is invalid. The block must first be obtained (from elsewhere in the memory hierarchy) before loads/stores can be performed. No action on invalidates (except maybe sending an ACK). No action on replacements. The associated coherence protocol states are I or NP and are stable states in every protocol.</td>\n</tr>\n<tr>\n<td><strong>Busy</strong></td>\n<td>TODO</td>\n</tr>\n<tr>\n<td><strong>Read_Only</strong></td>\n<td>Only operations permitted are loads, writebacks, invalidates. Stores cannot be performed before transitioning to some other state.</td>\n</tr>\n<tr>\n<td><strong>Read_Write</strong></td>\n<td>Loads, stores, writebacks, invalidations are allowed. Usually indicates that the block is dirty.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"data-structures\">Data Structures</h3>\n<ul>\n<li><strong>Message Buffers</strong>:TODO</li>\n<li><strong>TBE Table</strong>: TODO</li>\n<li>\n<p><strong>Timer Table</strong>: This maintains a map of address-based timers. For\neach target address, a timeout value can be associated and added to\nthe Timer table. This data structure is used, for example, by the L1\ncache controller implementation of the MOESI_CMP_directory\nprotocol to trigger separate timeouts for cache blocks. Internally,\nthe Timer Table uses the event queue to schedule the timeouts. The\nTimerTable supports a polling-based interface, <strong>isReady()</strong> to\ncheck if a timeout has occurred. Timeouts on addresses can be set\nusing the <strong>set()</strong> method and removed using the <strong>unset()</strong> method.</p>\n</li>\n<li><strong>Related Files</strong>:\n    <ul>\n<li>src/mem/ruby/system/TimerTable.hh: Declares the\n        TimerTable class</li>\n<li>src/mem/ruby/system/TimerTable.cc: Implementation of the\n        methods of the TimerTable class, that deals with setting\n        addresses &amp; timeouts, scheduling events using the event\n        queue.</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"coherence-controller-fsm-diagrams\">Coherence controller FSM Diagrams</h3>\n<ul>\n<li>The Finite State Machines show only the stable states</li>\n<li>Transitions are annotated using the notation \u201c<strong>Event list</strong>\u201d or\n\u201c<strong>Event list : Action list</strong>\u201d or \u201c<strong>Event list : Action list :\nEvent list</strong>\u201d. For example, Store : GETX indicates that on a Store\nevent, a GETX message was sent whereas GETX : Mem Read indicates\nthat on receiving a GETX message, a memory read request was sent.\nOnly the main triggers and actions are listed.</li>\n<li>Optional actions (e.g. writebacks depending on whether or not the\nblock is dirty) are enclosed within <strong>[ ]</strong></li>\n<li>In the diagrams, the transition labels are associated with the arc\nthat cuts across the transition label or the closest arc.</li>\n</ul>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/ruby/MOESI_hammer/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/ruby/garnet-2/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/ruby/garnet-2",
        "title": "No Title Found",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Jason Lowe-Power<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<p><strong>More details of the gem5 Ruby Interconnection Network are\n<a href=\"/documentation/general_docs/ruby/interconnection-network/\">here</a>.</strong></p>\n<h3 id=\"garnet20-an-on-chip-network-model-for-heterogeneous-socs\">Garnet2.0: An On-Chip Network Model for Heterogeneous SoCs</h3>\n<p>Garnet2.0 is a detailed interconnection network model inside gem5. It is\nin active development, and patches with more features will be\nperiodically pushed into gem5. <strong>Additional garnet-related patches and\ntool support under development (not part of the repo) can be found at\nthe</strong> <a href=\"http://synergy.ece.gatech.edu/tools/garnet\">Garnet page at Georgia\nTech</a>.</p>\n<p>Garnet2.0 builds upon the original Garnet model which was published in\n<a href=\"http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919636%7CISPASS\">2009</a>.</p>\n<p>If your use of Garnet contributes to a published paper, please cite the\nfollowing paper:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    @inproceedings{garnet,\n      title={GARNET: A detailed on-chip network model inside a full-system simulator},\n      author={Agarwal, Niket and Krishna, Tushar and Peh, Li-Shiuan and Jha, Niraj K},\n      booktitle={Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},\n      pages={33--42},\n      year={2009},\n      organization={IEEE}\n    }\n</code></pre></div></div>\n<p>Garnet2.0 provides a cycle-accurate micro-architectural implementation\nof an on-chip network router. It leverages the <a href=\"/documentation/general_docs/ruby/interconnection-network#Topology\">Topology</a> and <a href=\"/documentation/general_docs/ruby/interconnection-network#Routing\">Routing</a> frastructure\nprovided by gem5\u2019s ruby memory system model. The default router is a\nstate-of-the-art 1-cycle pipeline. There is support to add additional\ndelay of any number of cycles in any router, by specifying it within the\ntopology.</p>\n<p>Garnet2.0 can also be used to model an off-chip interconnection network\nby setting appropriate delays in the routers and links.</p>\n<ul>\n<li><strong>Related Files</strong>:\n    <ul>\n<li><strong>src/mem/ruby/network/Network.py</strong></li>\n<li><strong>src/mem/ruby/network/garnet2.0/GarnetNetwork.py</strong></li>\n<li><strong>src/mem/ruby/network/Topology.cc</strong></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"invocation\">Invocation</h2>\n<p>The garnet networks can be enabled by adding <strong>\u2013network=garnet2.0</strong>.</p>\n<h2 id=\"configuration\">Configuration</h2>\n<p>Garnet2.0 uses the generic network parameters in Network.py:</p>\n<ul>\n<li><strong>number_of_virtual_networks</strong>: This is the maximum number of\nvirtual networks. The actual number of active virtual networks\nis determined by the protocol.</li>\n<li><strong>control_msg_size</strong>: The size of control messages in bytes.\nDefault is 8. <strong>m_data_msg_size</strong> in Network.cc is set to the\nblock size in bytes + control_msg_size.</li>\n</ul>\n<p>Additional parameters are specified in garnet2.0/GarnetNetwork.py:</p>\n<ul>\n<li><strong>ni_flit_size</strong>: flit size in bytes. Flits are the\ngranularity at which information is sent from one router to the\nother. Default is 16 (=&gt; 128 bits). [This default value of 16\nresults in control messages fitting within 1 flit, and data\nmessages fitting within 5 flits]. Garnet requires the\nni_flit_size to be the same as the bandwidth_factor (in\nnetwork/BasicLink.py) as it does not model variable bandwidth\nwithin the network. This can also be set from the command line\nwith <strong>\u2013link-width-bits</strong>.</li>\n<li><strong>vcs_per_vnet</strong>: number of virtual channels (VC) per virtual\nnetwork. Default is 4. This can also be set from the command\nline with <strong>\u2013vcs-per-vnet</strong>.</li>\n<li><strong>buffers_per_data_vc</strong>: number of flit-buffers per VC in the\ndata message class. Since data messages occupy 5 flits, this\nvalue can lie between 1-5. Default is 4.</li>\n<li><strong>buffers_per_ctrl_vc</strong>: number of flit-buffers per VC in the\ncontrol message class. Since control messages occupy 1 flit, and\na VC can only hold one message at a time, this value has to be\n    <ol>\n<li>Default is 1.</li>\n</ol>\n</li>\n<li><strong>routing_algorithm</strong>: 0: Weight-based table (default), 1: XY,\n2: Custom. More details below.</li>\n</ul>\n<h2 id=\"topology\">Topology</h2>\n<p>Garnet2.0 leverages the\n<a href=\"/documentation/general_docs/ruby/interconnection-network#Topology\">Topology</a>\ninfrastructure\nprovided by gem5\u2019s ruby memory system model. Any heterogeneous topology\ncan be modeled. Each router in the topology file can be given an\nindependent latency, which overrides the default. In addition, each link\nhas 2 optional parameters: src_outport and dst_inport, which are\nstrings with names of the output and input ports of the source and\ndestination routers for each link. These can be used inside garnet2.0 to\nimplement custom routing algorithms, as described next. For instance, in\na Mesh, the west to east links have src_outport set to \u201cwest\u201d and\ndst_inport\u201d set to \u201ceast\u201d.</p>\n<ul>\n<li><strong>Network Components</strong>:\n    <ul>\n<li><strong>GarnetNetwork</strong>: This is the top level object that\ninstantiates all network interfaces, routers, and links.\nTopology.cc calls the methods to add \u201cexternal links\u201d between\nNIs and routers, and \u201cinternal links\u201d between routers.</li>\n<li><strong>NetworkInterface</strong>: Each NI connects to one coherence\ncontroller via MsgBuffer interfaces on one side. It has a link\nto a router on the other. Every protocol message is put into a\none-flit control or multi (default=5)-flit data (depending on\nits vnet), and injected into the router. Multiple NIs can\nconnect to the same router (for e.g., in the Mesh topology,\ncache and dir controllers connect via individual NIs to the same\nrouter).</li>\n<li><strong>Router</strong>: The router manages arbitration for output links, and\nflow control between routers.</li>\n<li><strong>NetworkLink</strong>: Network links carry flits. They can be of one\nof 3 types: EXT_OUT_ (router to NI), EXT_IN_ (NI to router),\nand INT_ (internal router to router)</li>\n<li><strong>CreditLink</strong>: Credit links carry VC/buffer credits between\nrouters for flow control.</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"routing\">Routing</h2>\n<p>Garnet2.0 leverages the\n<a href=\"/documentation/general_docs/ruby/interconnection-network#Routing\">Routing</a> infrastructure\nprovided by gem5\u2019s ruby memory system model. The default routing\nalgorithm is a deterministic table-based routing algorithm with shortest\npaths. Link weights can be used to prioritize certain links over others.\nSee src/mem/ruby/network/Topology.cc for details about how the routing\ntable is populated.</p>\n<p><strong>Custom Routing</strong>: To model custom routing algorithms, say adaptive, we\nprovide a framework to name each link with a src_outport and\ndst_inport direction, and use these inside garnet to implement routing\nalgorithms. For instance, in a Mesh, West-first can be implemented by\nsending a flit along the \u201cwest\u201d outport link till the flit no longer has\nany X- hops remaining, and then randomly (or based on next router VC\navailability) choosing one of the remaining links. See how\noutportComputeXY() is implemented in\nsrc/mem/ruby/network/garnet2.0/RoutingUnit.cc. Similarly,\noutportComputeCustom() can be implemented, and invoked by adding\n\u2013routing-algorithm=2 in the command line.</p>\n<p><strong>Multicast messages</strong>: The network modeled does not have hardware\nmulti-cast support within the network. A multi-cast message gets broken\ninto multiple uni-cast messages at the Network Interface.</p>\n<h2 id=\"flow-control\">Flow Control</h2>\n<p>Virtual Channel Flow Control is used in the design. Each VC can hold one\npacket. There are two kinds of VCs in the design - control and data. The\nbuffer depth in each can be independently controlled from\nGarnetNetwork.py. The default values are 1-flit deep control VCs, and\n4-flit deep data VCs. Default size of control packets is 1-flit, and\ndata packets is 5-flit.</p>\n<h2 id=\"router-microarchitecture\">Router Microarchitecture</h2>\n<p>The garnet2.0 router performs the following actions:</p>\n<ol>\n<li><strong>Buffer Write (BW)</strong>: The incoming flit gets buffered in its VC.</li>\n<li><strong>Route Compute (RC)</strong> The buffered flit computes its output port,\nand this information is stored in its VC.</li>\n<li><strong>Switch Allocation (SA)</strong>: All buffered flits try to reserve the\nswitch ports for the next cycle. [The allocation occurs in a\n<em>separable</em> manner: First, each input chooses one input VC, using\ninput arbiters, which places a switch request. Then, each output\nport breaks conflicts via output arbiters]. All arbiters in ordered\nvirtual networks are <em>queueing</em> to maintain point-to-point ordering.\nAll other arbiters are <em>round-robin</em>.</li>\n<li><strong>VC Selection (VS)</strong>: The winner of SA selects a free VC (if\nHEAD/HEAD_TAIL flit) from its output port.</li>\n<li><strong>Switch Traversal (ST)</strong>: Flits that won SA traverse the crossbar\nswitch.</li>\n<li><strong>Link Traversal (LT)</strong>: Flits from the crossbar traverse links to\nreach the next routers.</li>\n</ol>\n<p>In the default design, BW, RC, SA, VS, and ST all happen in 1-cycle. LT\nhappens in the next cycle.</p>\n<p><strong>Multi-cycle Router</strong>: Multi-cycle routers can be modeled by specifying\na per-router latency in the topology file, or changing the default\nrouter latency in src/mem/ruby/network/BasicRouter.py. This is\nimplemented by making a buffered flit wait in the router for (latency-1)\ncycles before becoming eligible for SA.</p>\n<h2 id=\"buffer-management\">Buffer Management</h2>\n<p>Each router input port has number_of_virtual_networks Vnets, each\nwith vcs_per_vnet VCs. VCs in control Vnets have a depth of\nbuffers_per_ctrl_vc (default = 1) and VCs in data Vnets have a depth\nof buffers_per_data_vc (default = 4). <strong>Credits are used to relay\ninformation about free VCs, and number of buffers within each VC.</strong></p>\n<h2 id=\"lifecycle-of-a-network-traversal\">Lifecycle of a Network Traversal</h2>\n<ul>\n<li>NetworkInterface.cc::wakeup()\n    <ul>\n<li>Every NI connected to one coherence protocol controller on one\nend, and one router on the other.</li>\n<li>receives messages from coherence protocol buffer in appropriate\nvnet and converts them into network packets and sends them into\nthe network.\n        <ul>\n<li>garnet2.0 adds the ability to capture a network trace at\nthis point [under development].</li>\n</ul>\n</li>\n<li>receives flits from the network, extracts the protocol message\nand sends it to the coherence protocol buffer in appropriate\nvnet.</li>\n<li>manages flow-control (i.e., credits) with its attached router.</li>\n<li>The consuming flit/credit output link of the NI is put in the\nglobal event queue with a timestamp set to next cycle. The\neventqueue calls the wakeup function in the consumer.</li>\n</ul>\n</li>\n</ul>\n<!-- end list -->\n<ul>\n<li>NetworkLink.cc::wakeup()\n    <ul>\n<li>receives flits from NI/router and sends it to NI/router after\nm_latency cycles delay</li>\n<li>Default latency value for every link can be set from command\nline (see configs/network/Network.py)</li>\n<li>Per link latency can be overwritten in the topology file</li>\n<li>The consumer of the link (NI/router) is put in the global event\nqueue with a timestamp set after m_latency cycles. The\neventqueue calls the wakeup function in the consumer.</li>\n</ul>\n</li>\n</ul>\n<!-- end list -->\n<ul>\n<li>Router.cc::wakeup()\n    <ul>\n<li>Loop through all InputUnits and call their wakeup()</li>\n<li>Loop through all OutputUnits and call their wakeup()</li>\n<li>Call SwitchAllocator\u2019s wakeup()</li>\n<li>Call CrossbarSwitch\u2019s wakeup()</li>\n<li>The router\u2019s wakeup function is called whenever any of its\nmodules (InputUnit, OutputUnit, SwitchAllocator, CrossbarSwitch)\nhave a ready flit/credit to act upon this cycle.</li>\n</ul>\n</li>\n</ul>\n<!-- end list -->\n<ul>\n<li>InputUnit.cc::wakeup()\n    <ul>\n<li>Read input flit from upstream router if it is ready for this\ncycle</li>\n<li>For HEAD/HEAD_TAIL flits, perform route computation, and update\nroute in the VC.</li>\n<li>Buffer the flit for (m_latency - 1) cycles and mark it valid\nfor SwitchAllocation starting that cycle.\n        <ul>\n<li>Default latency for every router can be set from command\nline (see configs/network/Network.py)</li>\n<li>Per router latency (i.e., num pipeline stages) can be set in\nthe topology file.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<!-- end list -->\n<ul>\n<li>OutputUnit.cc::wakeup()\n    <ul>\n<li>Read input credit from downstream router if it is ready for this\ncycle</li>\n<li>Increment the credit in the appropriate output VC state.</li>\n<li>Mark output VC as free if the credit carries is_free_signal as\ntrue</li>\n</ul>\n</li>\n</ul>\n<!-- end list -->\n<ul>\n<li>SwitchAllocator.cc::wakeup()\n    <ul>\n<li>Note: SwitchAllocator performs VC arbitration and selection\nwithin it.</li>\n<li>SA-I (or SA-i): Loop through all input VCs at every input port,\nand select one in a round robin manner.\n        <ul>\n<li>For HEAD/HEAD_TAIL flits only select an input VC whose\noutput port has at least one free output VC.</li>\n<li>For BODY/TAIL flits, only select an input VC that has\ncredits in its output VC.</li>\n</ul>\n</li>\n<li>Place a request for the output port from this VC.</li>\n<li>SA-II (or SA-o): Loop through all output ports, and select one\ninput VC (that placed a request during SA-I) as the winner for\nthis output port in a round robin manner.\n        <ul>\n<li>For HEAD/HEAD_TAIL flits, perform outvc allocation (i.e.,\nselect a free VC from the output port.</li>\n<li>For BODY/TAIL flits, decrement a credit in the output vc.</li>\n</ul>\n</li>\n<li>Read the flit out from the input VC, and send it to the\nCrossbarSwitch</li>\n<li>Send a increment_credit signal to the upstream router for this\ninput VC.\n        <ul>\n<li>for HEAD_TAIL/TAIL flits, mark is_free_signal as true in\nthe credit.</li>\n<li>The input unit sends the credit out on the credit link to\nthe upstream router.</li>\n</ul>\n</li>\n<li>Reschedule the Router to wakeup next cycle for any flits ready\nfor SA next cycle.</li>\n</ul>\n</li>\n</ul>\n<!-- end list -->\n<ul>\n<li>CrossbarSwitch.cc::wakeup()\n    <ul>\n<li>Loop through all input ports, and send the winning flit out of\nits output port onto the output link.</li>\n<li>The consuming flit output link of the router is put in the\nglobal event queue with a timestamp set to next cycle. The\neventqueue calls the wakeup function in the consumer.</li>\n</ul>\n</li>\n</ul>\n<!-- end list -->\n<ul>\n<li>NetworkLink.cc::wakeup()\n    <ul>\n<li>receives flits from NI/router and sends it to NI/router after\nm_latency cycles delay</li>\n<li>Default latency value for every link can be set from command\nline (see configs/network/Network.py)</li>\n<li>Per link latency can be overwritten in the topology file</li>\n<li>The consumer of the link (NI/router) is put in the global event\nqueue with a timestamp set after m_latency cycles. The\neventqueue calls the wakeup function in the consumer.</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"running-garnet20-with-synthetic-traffic\">Running Garnet2.0 with Synthetic Traffic</h2>\n<p>Garnet2.0 can be run in a standalone manner and fed with synthetic\ntraffic. The details are described here: <strong><a href=\"/documentation/general_docs/ruby/garnet_synthetic_traffic\">Garnet Synthetic\nTraffic</a></strong></p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/ruby/cache-coherence-protocols/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/ruby/garnet_synthetic_traffic/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/ruby/garnet_synthetic_traffic",
        "title": "Garnet Synthetic Traffic",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Jason Lowe-Power<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"garnet-synthetic-traffic\">Garnet Synthetic Traffic</h1>\n<p>The Garnet Synthetic Traffic provides a framework for simulating the <a href=\"/documentation/general_docs/ruby/garnet-2\">Garnet network</a> with controlled inputs. This is useful for network testing/debugging, or for network-only simulations with synthetic traffic.</p>\n<p><strong>Note: The garnet synthetic traffic injector only works with the <a href=\"/documentation/general_docs/ruby/Garnet_standalone.md\">Garnet_standalone</a> coherence protocol.</strong></p>\n<h2 id=\"related-files\">Related files</h2>\n<ul>\n<li>configs/example/garnet_synth_traffic.py: file to invoke the network tester</li>\n<li>src/cpu/testers/garnet_synthetic_traffic: files implementing the tester.\n    <ul>\n<li>GarnetSyntheticTraffic.py</li>\n<li>GarnetSyntheticTraffic.hh</li>\n<li>GarnetSyntheticTraffic.cc</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"how-to-run\">How to run</h2>\n<p>First build gem5 with the <a href=\"/documentation/general_docs/ruby/Garnet_standalone.md\">Garnet_standalone</a> coherence protocol. The Garnet_standalone protocol is ISA-agnostic, and hence we build it with the NULL ISA.</p>\n<p>For gem5 &lt;= 23.0:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>scons build/NULL/gem5.debug PROTOCOL=Garnet_standalone\n</code></pre></div></div>\n<p>For gem5 &gt;= 23.1</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>scons defconfig build/NULL build_opts/NULL\nscons setconfig build/NULL RUBY_PROTOCOL_GARNET_STANDALONE=y\nscons build/NULL/gem5.debug\n</code></pre></div></div>\n<p>Example command:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>./build/NULL/gem5.debug configs/example/garnet_synth_traffic.py  \\\n        --num-cpus=16 \\\n        --num-dirs=16 \\\n        --network=garnet \\\n        --topology=Mesh_XY \\\n        --mesh-rows=4  \\\n        --sim-cycles=1000 \\\n        --synthetic=uniform_random \\\n        --injectionrate=0.01\n</code></pre></div></div>\n<h2 id=\"parameterized-options\">Parameterized Options</h2>\n<table>\n<thead>\n<tr>\n<th><strong>System Configuration</strong></th>\n<th><strong>Description</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>\u2013num-cpus</strong></td>\n<td>Number of cpus. This is the number of source (injection) nodes in the network.</td>\n</tr>\n<tr>\n<td><strong>\u2013num-dirs</strong></td>\n<td>Number of directories. This is the number of destination (ejection) nodes in the network.</td>\n</tr>\n<tr>\n<td><strong>\u2013network</strong></td>\n<td>Network model: simple or garnet. Use garnet for running synthetic traffic.</td>\n</tr>\n<tr>\n<td><strong>\u2013topology</strong></td>\n<td>Topology for connecting the cpus and dirs to the network routers/switches. More detail about different topologies can be found (here)[Interconnection_Network#Topology].</td>\n</tr>\n<tr>\n<td><strong>\u2013mesh-rows</strong></td>\n<td>The number of rows in the mesh. Only valid when \u2018\u2019\u2013topology\u2019\u2019 is \u2018\u2018Mesh_<em>\u2019\u2019 or \u2018\u2018MeshDirCorners_</em>\u2019\u2019.</td>\n</tr>\n</tbody>\n</table>\n<table>\n<thead>\n<tr>\n<th><strong>Network Configuration</strong></th>\n<th><strong>Description</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>\u2013router-latency</strong></td>\n<td>Default number of pipeline stages in the garnet router. Has to be &gt;= 1.  Can be over-ridden on a per router basis in the topology file.</td>\n</tr>\n<tr>\n<td><strong>\u2013link-latency</strong></td>\n<td>Default latency of each link in the network. Has to be &gt;= 1.  Can be over-ridden on a per link basis in the topology file.</td>\n</tr>\n<tr>\n<td><strong>\u2013vcs-per-vnet</strong></td>\n<td>Number of VCs per Virtual Network.</td>\n</tr>\n<tr>\n<td><strong>\u2013link-width-bits</strong></td>\n<td>Width in bits for all links inside the garnet network. Default = 128.</td>\n</tr>\n</tbody>\n</table>\n<table>\n<thead>\n<tr>\n<th><strong>Traffic Injection</strong></th>\n<th><strong>Description</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>\u2013sim-cycles</strong></td>\n<td>Total number of cycles for which the simulation should run.</td>\n</tr>\n<tr>\n<td><strong>\u2013synthetic</strong></td>\n<td>The type of synthetic traffic to be injected. The following synthetic traffic patterns are currently supported: \u2018uniform_random\u2019, \u2018tornado\u2019, \u2018bit_complement\u2019, \u2018bit_reverse\u2019, \u2018bit_rotation\u2019, \u2018neighbor\u2019, \u2018shuffle\u2019,  and \u2018transpose\u2019.</td>\n</tr>\n<tr>\n<td><strong>\u2013injectionrate</strong></td>\n<td>Traffic Injection Rate in packets/node/cycle. It can take any decimal value between 0 and 1. The number of digits of precision after the decimal point can be controlled by \u2018\u2019\u2013precision\u2019\u2019 which is set to 3 as default in \u2018\u2018garnet_synth_traffic.py\u2019\u2019.</td>\n</tr>\n<tr>\n<td><strong>\u2013single-sender-id</strong></td>\n<td>Only inject from this sender. To send from all nodes, set to -1.</td>\n</tr>\n<tr>\n<td><strong>\u2013single-dest-id</strong></td>\n<td>Only send to this destination. To send to all destinations as specified by the synthetic traffic pattern, set to -1.</td>\n</tr>\n<tr>\n<td><strong>\u2013num-packets-max</strong></td>\n<td>Maximum number of packets to be injected by each cpu node. Default value is -1 (keep injecting till sim-cycles).</td>\n</tr>\n<tr>\n<td><strong>\u2013inj-vnet</strong></td>\n<td>Only inject in this vnet (0, 1 or 2). 0 and 1 are 1-flit, 2 is 5-flit. Set to -1 to inject randomly in all vnets.</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"implementation-of-garnet-synthetic-traffic\">Implementation of Garnet synthetic traffic</h2>\n<p>The synthetic traffic injector is implemented in GarnetSyntheticTraffic.cc. The sequence of steps involved in generating and sending a packet are as follows.</p>\n<ul>\n<li>Every cycle, each cpu performs a bernouli trial with probability equal to \u2013injectionrate to determine whether to generate a packet or not.</li>\n<li>If \u2013num-packets-max is non negative, each cpu stops generating new packets after generating \u2013num-packets-max number of packets. The injector terminates after \u2013sim-cycles.</li>\n<li>If the cpu has to generate a new packet, it computes the destination for the new packet based on the synthetic traffic type (\u2013synthetic).</li>\n<li>This destination is embedded into the bits after block offset in the packet address.</li>\n<li>The generated packet is randomly tagged as a ReadReq, or an INST_FETCH, or a WriteReq, and sent to the Ruby Port (src/mem/ruby/system/RubyPort.hh/cc).</li>\n<li>The Ruby Port converts the packet into a RubyRequestType:LD, RubyRequestType:IFETCH, and RubyRequestType:ST, respectively, and sends it to the Sequencer, which in turn sends it to the Garnet_standalone cache controller.</li>\n<li>The cache controller extracts the destination directory from the packet address.</li>\n<li>The cache controller injects the LD, IFETCH and ST into virtual networks 0, 1 and 2 respectively.\n    <ul>\n<li>LD and IFETCH are injected as control packets (8 bytes), while ST is injected as a data packet (72 bytes).</li>\n</ul>\n</li>\n<li>The packet traverses the network and reaches the directory.</li>\n<li>The directory controller simply drops it.</li>\n</ul>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/ruby/garnet-2/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/ruby/heterogarnet/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/ruby/heterogarnet",
        "title": "No Title Found",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Srikant Bharadwaj<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<p><strong>More details of the gem5 Ruby Interconnection Network are <a href=\"/documentation/general_docs/ruby/interconnection-network\" title=\"wikilink\">here</a>.</strong>\n<strong>Details about the earlier Garnet version can be found <a href=\"/documentation/general_docs/ruby/garnet-2\" title=\"wikilink\">here</a>.</strong></p>\n<h3 id=\"heterogarnet-a-detailed-simulator-for-diverse-interconnect-systems\">HeteroGarnet: A Detailed Simulator for Diverse Interconnect Systems</h3>\n<p><a href=\"https://doi.org/10.1109/DAC18072.2020.9218539\">HeteroGarnet</a> improves upon the widely-popular Garnet 2.0 network model by enabling accurate simulation of emerging interconnect systems. Specifically, HeteroGarnet adds support for clock-domain islands, network crossings supporting multiple frequency domains, and network interface controllers capable of attaching to multiple physical links. It also supports variable bandwidth links and routers by introducing a new configurable Serializer-Deserializer component. HeteroGarnet is integrated into the gem5 repository as Garnet 3.0.</p>\n<p>HeteroGarnet builds upon the original Garnet model which was published in\n<a href=\"https://doi.org/10.1109/ISPASS.2009.4919636\">2009</a>.</p>\n<p>If your use of HeteroGarnet contributes to a published paper, please cite the\nfollowing paper:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    @inproceedings{heterogarnet,\n        author={Bharadwaj, Srikant and Yin, Jieming and Beckmann, Bradford and Krishna, Tushar},\n        booktitle={2020 57th ACM/IEEE Design Automation Conference (DAC)},\n        title={Kite: A Family of Heterogeneous Interposer Topologies Enabled via Accurate Interconnect Modeling},\n        year={2020},\n        volume={},\n        number={},\n        pages={1-6},\n        doi={10.1109/DAC18072.2020.9218539}\n\t}\n</code></pre></div></div>\n<h2 id=\"topology-construction\">Topology Construction</h2>\n<p>HeteroGarnet allows users to configure complex topologies using a python configuration file as the topology.\nThe overall topology configuration could include the complete interconnect definition of the system including\nany heterogeneous components. The general flow of defining a topology involves the following steps:</p>\n<ol>\n<li>Determine the total number of routers in the system and instantiate them.\n    <ol>\n<li>Use the <strong>Router</strong> class to instantiate individual routers.</li>\n<li>Configure properties of each router, such as clock domain, supported flit width, depending on the requirements.\n        <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>routers = Router(id, latency, clock_domain,\n         flit_width, supported_vnets,\n         vcs_per_vnet)\n</code></pre></div> </div>\n</li>\n</ol>\n</li>\n<li>Connect the routers which connect to the end points (e.g, Cores, Caches, Directories) using external physical interconnects.\n    <ol>\n<li>Use <strong>ExternalLink</strong> class to instantiate the links connecting the end points.</li>\n<li>Configure properties of each external link, such as clock domain, link width, depending on the requirements.</li>\n<li>Enable clock-domain crossings(CDC) and Serializer-Deserializer(SerDes) units at either depending on the interconnect topology.\n        <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>external_link = ExternalLink(id, latency, clock_domain,\n                      flit_width, supported_vnets,\n                      serdes_enable, cdc_enable)\n</code></pre></div> </div>\n</li>\n</ol>\n</li>\n<li>Connect the individual routers within the network depending upon the topology.\n    <ol>\n<li>Use <strong>InternalLink</strong> class to instantiate the links connecting the end points.</li>\n<li>Configure properties of each internal link, such as clock domain, link width, depending on the requirements.</li>\n<li>Enable clock-domain crossings and Serializer-Deserializer units at either depending on the interconnect topology.\n        <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>internal_link = InternalLink(id, latency, clock_domain,\n                      flit_width, supported_vnets,\n                      serdes_enable, cdc_enable)\n</code></pre></div> </div>\n</li>\n</ol>\n</li>\n</ol>\n<p>Garnet 3.0 also provides several pre-configuration scripts(./configs/Network/Network.py) which automatically do some of the other steps, such as instantiating network interfaces, domain crossings, and SerDes units. The several types of units used to configure the topologies are discussed below.</p>\n<h2 id=\"physical-links\">Physical Links</h2>\n<p>The physical link model in Garnet represents the interconnect wire itself. A link is a single entity which has its own latency, width and the types of flit it can transmit. The links also support a credit based back-pressuring mechanism. Similar to the upgraded Garnet 3.0 router, each Garnet 3.0 link can be configured to an operating frequency and width using appropriate parameters. This allows links and routers operating at different frequencies to be connected to each other.</p>\n<h2 id=\"network-interface\">Network Interface</h2>\n<p>The network interface controller (NIC) is an object which sits between the network end points (e.g., Caches, DMA nodes) and the interconnection system. The NIC receives messages form the controllers and converts them into fixed-length flits, short for flow control units. These flits are sized appropriately according to the outgoing physical links. The network interface also governs the flow control and buffer management for the outgoing and incoming flits. Garnet 3.0 allows multiple ports to be attached to a single end points. Thus, the NIC decides where a certain message/flit must be scheduled.</p>\n<h2 id=\"clock-domain-crossing-units\">Clock Domain Crossing Units</h2>\n<p>To support multiple clock domains, Garnet 3.0 introduces Clock Domain Crossing (CDC) unit, as shown in the Figure below (left), which consists of first-In-First-Out (FIFO) buffers and can be instantiated anywhere within the network model. The CDC unit enables architectures with different clock domains across the system. The delay of each CDC unit configurable. The latency can also be calculated dynamically depending on the clock domains connected to it. This enables accurate modeling of DVFS techniques as CDC latencies are generally a function of the operating frequency of producer and consumer.</p>\n<h2 id=\"serializer-deserializer-units\">Serializer-Deserializer Units</h2>\n<p>Another critical feature necessary in modeling SoCs and heterogeneous architectures is supporting various interconnect widths across the system. Consider a link between two routers within a GPU and a link between a memory controller and on-chip memory. These two links might be of different widths. To enable such configuration, Garnet 3.0 introduces the Serializer-Deserializer unit as shown in the figure below, which converts flits into appropriate widths at bit-width boundaries. These SerDes units can be instantiated anywhere in the Garnet 3.0 topology similar to the CDC unit described in the previous sub-section.</p>\n<p><img alt=\"SerDes_CDC.png\" src=\"/assets/img/SerDes_CDC.png\"/></p>\n<h2 id=\"routing\">Routing</h2>\n<p>The routing algorithm decides how the flits travel through the topology. The objective of a routing policy is to minimize contention while maximizing the bandwidth offered by the interconnect. Garnet 3.0 provides several standard routing policies that the user can select from.</p>\n<h3 id=\"routing-policies\">Routing Policies.</h3>\n<p>There are several generic routing  policies that have been proposed for deadlock free routing of flits through the interconnect network.</p>\n<h3 id=\"table-based-routing\">Table based routing</h3>\n<p>Garnet also features table based routing policy which users can select to set custom routing policies using a weight-age based system. Lower weighted links are preferred over links which are configured to have higher weights.</p>\n<h2 id=\"flow-control-and-buffer-management\">Flow Control and Buffer Management</h2>\n<p>Flow control mechanisms determine the buffer allocation in interconnect systems. The aim of a good flow control system is minimize the impact of buffer allocation to the overall latency of a message in the system. Implementation of these mechanisms often involve micro-management of physical packets within the interconnect system.</p>\n<p>Coherence messages generated by cache controllers are often broken down into fixed-length flits (flow control units). A set of flits carrying a message is often termed as a packet. A packet could have a head-flit, body-flit, and a tail-flit to carry the contents of the message along with any additional meta data of the packet itself. Several flow control techniques have been proposed and implemented at various granularities of resource allocation.</p>\n<p>Garnet 3.0 implements a credit-based flit-level flow control mechanism with support for virtual channels.</p>\n<h3 id=\"virtual-channels\">Virtual Channels</h3>\n<p>Virtual Channels (VCs) in a network act as separate queues which can share physical wires (physical links) between two routers or arbiters. Virtual channels are mainly used to alleviate head-of-line blocking. However, they are also used as a means for deadlock-avoidance.</p>\n<h3 id=\"buffer-backpressure\">Buffer Backpressure</h3>\n<p>Most implementations of interconnection networks do not tolerate dropping of packets or flits during traversal. Thus, there is a need to strictly manage the flits using backpressuring mechanisms.</p>\n<h3 id=\"credit-based-backpressuring\">Credit-based backpressuring</h3>\n<p>Credit-based backpressuring mechanism is often used for low-latency implementation of flit-stalling. Credits track the number of buffers available at the next intermediate destination by decrementing the overall buffers every time a flit is sent. A credit is then sent back by the destination when it is vacated.</p>\n<p>Routers in interconnect systems perform arbitration, allocation of buffers, and flow control within the network. The objective of the router microarchitecture is to minimize the contention within the router while offering minimal per-hop latency for the flits. The complexity of the router microarchitecture also affects the overall energy and area consumption of the interconnect system.</p>\n<h2 id=\"life-of-a-message-in-garnet-30\">Life of a Message in Garnet 3.0</h2>\n<p>In this section we describe the life of a message in the NoC after it is generated by a cache controller unit. We take the case of Garnet 3.0 for describing the process, but the general modeling principles can be extended to other software simulation/modeling tools as well.</p>\n<p><img alt=\"HeteroGarnet_Life.png\" src=\"/assets/img/HeteroGarnet_Life.png\"/></p>\n<p>The overall flow of the system is shown in detail in figure above. It shows a simple example scenario where a message is generated by a cache controller destined for another cache controller which is connected through routers via physical links, serializer-deserializer units, and clock-domain crossings.</p>\n<h3 id=\"injection-of-message\">Injection of Message</h3>\n<p>The source cache controller creates a message and assigns one or more  cache controllers as the destination. This message is then injected into message queues. A cache controller often has several outgoing and incoming message buffers for different kinds of messages.</p>\n<h3 id=\"conversion-to-flits\">Conversion to Flits.</h3>\n<p>A network interface controller unit (NIC) is attached to each cache controller. This NIC wakes up and consumes the messages from the message queues. Each message is then converted to unicast messages before being broken down into fixed-length flits according to the size supported by the outgoing physical links. These flits are then scheduled for transmission depending on the availability of buffers at the next hop through one of the output links. The outgoing link is chosen depending on the destination, routing policy, and the type of message.</p>\n<h3 id=\"transmission-to-local-router\">Transmission to Local Router.</h3>\n<p>Each network interface is connected to one or more \u201clocal\u201d routers which is could be connected through an \u201cExternal\u201d link. Once a flit is scheduled, it is transmitted over these external links which deliver the flit to the router after a period of defined latency.</p>\n<h3 id=\"router-arbitration\">Router Arbitration.</h3>\n<p>The flit wakes up the router which is a multi-stage unit. The router houses the input buffers, VC allocation, switch arbitration, and crossbar units. On arrival the flit is first placed in a input buffer queue. There are several input buffer queues in a router which contend for an output link and a VC for the next hop. This is done using the VC allocation and switch arbitration stages. Once a flit is selected for transmission, the crossbar stage directs the flit to the output link. A credit is then sent back to the NIC as the input buffer space is vacated for the next flit to arrive.</p>\n<h3 id=\"serialization-deserialization\">Serialization-Deserialization.</h3>\n<p>The serialization-deserialization (SerDes) is an optional unit that can be enabled depending on the design requirements. The SerDes units consumes the flits and appropriately converts it into outgoing flit size. In addition to manipulating the data packets, the SerDes also handles the credit system, by serializing or deserializing the credit units.</p>\n<h2 id=\"area-power-and-energy-model\">Area, Power and Energy Model</h2>\n<p>Frameworks like Orion2.0 and DSENT provide models for the area and power for the various building blocks of a NoC router and links. HeteroGarnet integrates DSENT as an external tool to report area, power and energy (which depends on activity) at the end of the simulation.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/ruby/garnet_synthetic_traffic/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/ruby/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/ruby/interconnection-network",
        "title": "Interconnection Network",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Jason Lowe-Power<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"interconnection-network\">Interconnection Network</h1>\n<p>The various components of the interconnection network model inside\ngem5\u2019s ruby memory system are described here.</p>\n<h2 id=\"how-to-invoke-the-network\">How to invoke the network</h2>\n<p><strong>Simple Network</strong>:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>./build/&lt;ISA&gt;/gem5.debug \\\n                      configs/example/ruby_random_test.py \\\n                      --num-cpus=16  \\\n                      --num-dirs=16  \\\n                      --network=simple\n                      --topology=Mesh_XY  \\\n                      --mesh-rows=4\n</code></pre></div></div>\n<p>The default network is simple, and the default topology is crossbar.</p>\n<p><strong>Garnet network</strong>:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>./build/&lt;ISA&gt;/gem5.debug \\\n                      configs/example/ruby_random_test.py  \\\n                      --num-cpus=16 \\\n                      --num-dirs=16  \\\n                      --network=garnet2.0 \\\n                      --topology=Mesh_XY \\\n                      --mesh-rows=4\n</code></pre></div></div>\n<h2 id=\"topology\">Topology</h2>\n<p>The connection between the various controllers are specified via python\nfiles. All external links (between the controllers and routers) are\nbi-directional. All internal links (between routers) are uni-directional\n\u2013 this allows a per-direction weight on each link to bias routing\ndecisions.</p>\n<ul>\n<li><strong>Related Files</strong>:\n    <ul>\n<li><strong>src/mem/ruby/network/topologies/Crossbar.py</strong></li>\n<li><strong>src/mem/ruby/network/topologies/CrossbarGarnet.py</strong></li>\n<li><strong>src/mem/ruby/network/topologies/Mesh_XY.py</strong></li>\n<li><strong>src/mem/ruby/network/topologies/Mesh_westfirst.py</strong></li>\n<li><strong>src/mem/ruby/network/topologies/MeshDirCorners_XY.py</strong></li>\n<li><strong>src/mem/ruby/network/topologies/Pt2Pt.py</strong></li>\n<li><strong>src/mem/ruby/network/Network.py</strong></li>\n<li><strong>src/mem/ruby/network/BasicLink.py</strong></li>\n<li><strong>src/mem/ruby/network/BasicRouter.py</strong></li>\n</ul>\n</li>\n<li><strong>Topology Descriptions</strong>:\n    <ul>\n<li><strong>Crossbar</strong>: Each controller (L1/L2/Directory) is connected to\na simple switch. Each switch is connected to a central switch\n(modeling the crossbar). This can be invoked from command line\nby <strong>\u2013topology=Crossbar</strong>.</li>\n<li><strong>CrossbarGarnet</strong>: Each controller (L1/L2/Directory) is\nconnected to every other controller via one garnet router (which\ninternally models the crossbar and allocator). This can be\ninvoked from command line by <strong>\u2013topology=CrossbarGarnet</strong>.</li>\n<li><strong>Mesh_*</strong>: This topology requires the number of directories\nto be equal to the number of cpus. The number of\nrouters/switches is equal to the number of cpus in the system.\nEach router/switch is connected to one L1, one L2 (if present),\nand one Directory. The number of rows in the mesh <strong>has to be\nspecified</strong> by <strong>\u2013mesh-rows</strong>. This parameter enables the\ncreation of non-symmetrical meshes too.\n        <ul>\n<li><strong>Mesh_XY</strong>: Mesh with XY routing. All x-directional links\nare biased with a weight of 1, while all y-directional links\nare biased with a weight of 2. This forces all messages to\nuse X-links first, before using Y-links. It can be invoked\nfrom command line by <strong>\u2013topology=Mesh_XY</strong></li>\n<li><strong>Mesh_westfirst</strong>: Mesh with west-first routing. All\nwest-directional links are biased with a weight of 1, al\nother links are biased with a weight of 2. This forces all\nmessages to use west-directional links first, before using\nother links. It can be invoked from command line by\n<strong>\u2013topology=Mesh_westfirst</strong></li>\n</ul>\n</li>\n<li><strong>MeshDirCorners_XY</strong>: This topology requires the number of\ndirectories to be equal to 4. number of routers/switches is\nequal to the number of cpus in the system. Each router/switch is\nconnected to one L1, one L2 (if present). Each corner\nrouter/switch is connected to one Directory. It can be invoked\nfrom command line by <strong>\u2013topology=MeshDirCorners_XY</strong>. The\nnumber of rows in the mesh <strong>has to be specified</strong> by\n<strong>\u2013mesh-rows</strong>. The XY routing algorithm is used.</li>\n<li><strong>Pt2Pt</strong>: Each controller (L1/L2/Directory) is connected to\nevery other controller via a direct link. This can be invoked\nfrom command line by</li>\n<li><strong>Pt2Pt</strong>: All to all point-to-point connection</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"\" src=\"http://pwp.gatech.edu/ece-synergy/wp-content/uploads/sites/332/2016/10/topologies.jpg\"/></p>\n<p><strong>In each topology, each link and each router can independently be\npassed a parameter that overrides the defaults (in BasicLink.py and\nBasicRouter.py)</strong>:</p>\n<ul>\n<li><strong>Link Parameters:</strong>\n<ul>\n<li><strong>latency</strong>: latency of traversal within the link.</li>\n<li><strong>weight</strong>: weight associated with this link. This parameter is\nused by the routing table while deciding routes, as explained\nnext in <a href=\"Interconnection_Network#Routing\" title=\"wikilink\">Routing</a>.</li>\n<li><strong>bandwidth_factor</strong>: Only used by simple network to specify\nwidth of the link in bytes. This translates to a bandwidth\nmultiplier (simple/SimpleLink.cc) and the individual link\nbandwidth becomes bandwidth multiplier x endpoint_bandwidth\n(specified in SimpleNetwork.py). In garnet, the bandwidth is\nspecified by ni_flit_size in GarnetNetwork.py)</li>\n</ul>\n</li>\n<li><strong>Internal Link Parameters:</strong>\n<ul>\n<li><strong>src_outport</strong>: String with name for output port from source\nrouter.</li>\n<li><strong>dst_inport</strong>: String with name for input port at destination\nrouter.</li>\n</ul>\n</li>\n</ul>\n<p>These two parameters can be used by routers to implement custom routing\nalgorithms in garnet2.0</p>\n<ul>\n<li><strong>Router Parameters:</strong>\n<ul>\n<li><strong>latency</strong>: latency of each router. Only supported by\ngarnet2.0.</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"routing\">Routing</h2>\n<p><strong>Table-based Routing (Default):</strong> Based on the topology, shortest\npath graph traversals are used to populate <em>routing tables</em> at each\nrouter/switch. This is done in src/mem/ruby/network/Topology.cc The\ndefault routing algorithm is table-based and tries to choose the route\nwith minimum number of link traversals. Links can be given weights in\nthe topology files to model different routing algorithms. For example,\nin Mesh_XY.py and MeshDirCorners_XY.py Y-direction links are given\nweights of 2, while X-direction links are given weights of 1, resulting\nin XY traversals. In Mesh_westfirst.py, the west-links are given\nweights of 1, and all other links are given weights of 2. In garnet2.0,\nthe routing algorithm randomly chooses between links with equal weights.\nIn simple network, it statically chooses between links with equal\nweights.</p>\n<p><strong>Custom Routing algorithms:</strong> In garnet2.0, we provide additional\nsupport to implement custom (including adaptive) routing algorithms (See\noutportComputeXY() in src/mem/ruby/network/garnet2.0/RoutingUnit.cc).\nThe src_outport and dst_inport fields of the links can be used to give\ncustom names to each link (e.g., directions if a mesh), and these can be\nused inside garnet to implement any routing algorithm. A custom routing\nalgorithm can be selected from the command line by setting\n\u2013routing-algorithm=2. See configs/network/Network.py and\nsrc/mem/ruby/network/garnet2.0/GarnetNetwork.py</p>\n<h2 id=\"flow-control-and-router-microarchitecture\">Flow-Control and Router Microarchitecture</h2>\n<p>Ruby supports two network models, Simple and Garnet, which trade-off\ndetailed modeling versus simulation speed respectively.</p>\n<h3 id=\"simple-network\">Simple Network</h3>\n<p>The default network model in Ruby is the simple network.</p>\n<ul>\n<li><strong>Related Files</strong>:\n    <ul>\n<li><strong>src/mem/ruby/network/Network.py</strong></li>\n<li><strong>src/mem/ruby/network/simple</strong></li>\n<li><strong>src/mem/ruby/network/simple/SimpleNetwork.py</strong></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"configuration\">Configuration</h2>\n<p>Simple network uses the generic network parameters in Network.py:</p>\n<ul>\n<li><strong>number_of_virtual_networks</strong>: This is the maximum number of\n    virtual networks. The actual number of active virtual networks\n    is determined by the protocol.</li>\n<li><strong>control_msg_size</strong>: The size of control messages in bytes.\n    Default is 8. <strong>m_data_msg_size</strong> in Network.cc is set to the\n    block size in bytes + control_msg_size.</li>\n</ul>\n<p>Additional parameters are specified in simple/SimpleNetwork.py:</p>\n<ul>\n<li><strong>buffer_size</strong>: Size of buffers at each switch input and\noutput ports. A value of 0 implies infinite buffering.</li>\n<li><strong>endpoint_bandwidth</strong>: Bandwidth at the end points of the\nnetwork in 1000th of byte.</li>\n<li><strong>adaptive_routing</strong>: This enables adaptive routing based on\noccupancy of output buffers.</li>\n</ul>\n<h2 id=\"switch-model\">Switch Model</h2>\n<p>The simple network models hop-by-hop network traversal, but abstracts\nout detailed modeling within the switches. The switches are modeled in\nsimple/PerfectSwitch.cc while the links are modeled in\nsimple/Throttle.cc. The flow-control is implemented by monitoring the\navailable buffers and available bandwidth in output links before\nsending.</p>\n<p><img alt=\"Simple_network.jpg\" src=\"/assets/img/Simple_network.jpg\" title=\"Simple_network.jpg\"/></p>\n<h3 id=\"garnet20\">Garnet2.0</h3>\n<p>Details of the new (2016) Garnet2.0 network are\n<strong><a href=\"garnet-2\">here</a></strong>.</p>\n<h2 id=\"running-the-network-with-synthetic-traffic\">Running the Network with Synthetic Traffic</h2>\n<p>The interconnection networks can be run in a standalone manner and fed\nwith synthetic traffic. We recommend doing this with garnet2.0.</p>\n<p><strong><a href=\"/documentation/general_docs/ruby/garnet_synthetic_traffic\">Running Garnet Standalone with Synthetic Traffic</a></strong></p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/ruby/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/ruby/slicc/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/ruby/slicc",
        "title": "SLICC",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>authors:</b> Jason Lowe-Power<br/>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"slicc\">SLICC</h1>\n<p>SLICC is a domain specific language for specifying cache coherence\nprotocols. The SLICC compiler generates C++ code for different\ncontrollers, which can work in tandem with other parts of Ruby. The\ncompiler also generates an HTML specification of the protocol. HTML\ngeneration is turned off by default. To enable HTML output, pass the\noption \u201cSLICC_HTML=True\u201d to scons when compiling.</p>\n<h3 id=\"input-to-the-compiler\">Input To the Compiler</h3>\n<p>The SLICC compiler takes, as input, files that specify the controllers\ninvolved in the protocol. The .slicc file specifies the different files\nused by the particular protocol under consideration. For example, if\ntrying to specify the MI protocol using SLICC, then we may use MI.slicc\nas the file that specifies all the files necessary for the protocol. The\nfiles necessary for specifying a protocol include the definitions of the\nstate machines for different controllers, and of the network messages\nthat are passed on between these controllers.</p>\n<p>The files have a syntax similar to that of C++. The compiler, written\nusing <a href=\"http://www.dabeaz.com/ply/\">PLY (Python Lex-Yacc)</a>, parses these\nfiles to create an Abstract Syntax Tree (AST). The AST is then traversed\nto build some of the internal data structures. Finally the compiler\noutputs the C++ code by traversing the tree again. The AST represents\nthe hierarchy of different structures present with in a state machine.\nWe describe these structures next.</p>\n<h3 id=\"protocol-state-machines\">Protocol State Machines</h3>\n<p>In this section we take a closer look at what goes in to a file\ncontaining specification of a state machine.</p>\n<h4 id=\"specifying-data-members\">Specifying Data Members</h4>\n<p>Each state machine is described using SLICC\u2019s <strong>machine</strong> datatype. Each\nmachine has several different types of members. Machines for cache and\ndirectory controllers include cache memory and directory memory data\nmembers respectively. We will use the MI protocol available in\nsrc/mem/protocol as our running example. So here is how you might want\nto start writing a state machine</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>machine(MachineType:L1Cache,\u00a0\"MI\u00a0Example\u00a0L1\u00a0Cache\")\n\u00a0\u00a0:\u00a0Sequencer\u00a0*\u00a0sequencer,\n\u00a0\u00a0\u00a0\u00a0CacheMemory\u00a0*\u00a0cacheMemory,\n\u00a0\u00a0\u00a0\u00a0int\u00a0cache_response_latency\u00a0=\u00a012,\n\u00a0\u00a0\u00a0\u00a0int\u00a0issue_latency\u00a0=\u00a02\u00a0{\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0//\u00a0Add\u00a0rest\u00a0of\u00a0the\u00a0stuff\n\u00a0\u00a0\u00a0\u00a0}\n</code></pre></div></div>\n<p>In order to let the controller receive messages from different\nentities in the system, the machine has a number of <strong>Message\nBuffers</strong>. These act as input and output ports for the machine. Here\nis an example specifying the output ports.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>\u00a0MessageBuffer\u00a0requestFromCache,\u00a0network=\"To\",\u00a0virtual_network=\"2\",\u00a0ordered=\"true\";\n\u00a0MessageBuffer\u00a0responseFromCache,\u00a0network=\"To\",\u00a0virtual_network=\"4\",\u00a0ordered=\"true\";\n</code></pre></div></div>\n<p>Note that Message Buffers have some attributes that need to be specified\ncorrectly. Another example, this time for specifying the input\nports.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>\u00a0MessageBuffer\u00a0forwardToCache,\u00a0network=\"From\",\u00a0virtual_network=\"3\",\u00a0ordered=\"true\";\n\u00a0MessageBuffer\u00a0responseToCache,\u00a0network=\"From\",\u00a0virtual_network=\"4\",\u00a0ordered=\"true\";\n</code></pre></div></div>\n<p>Next the machine includes a declaration of the <strong>states</strong> that\nmachine can possibly reach. In cache coherence protocol, states can\nbe of two types \u2013 stable and transient. A cache block is said to be\nin a stable state if in the absence of any activity (in coming\nrequest for the block from another controller, for example), the\ncache block would remain in that state for ever. Transient states\nare required for transitioning between stable states. They are\nneeded when ever the transition between two stable states can not be\ndone in an atomic fashion. Next is an example that shows how states\nare declared. SLICC has a keyword <strong>state_declaration</strong> that has to\nbe used for declaring\nstates.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>state_declaration(State,\u00a0desc=\"Cache\u00a0states\")\u00a0{\n\u00a0\u00a0\u00a0I,\u00a0AccessPermission:Invalid,\u00a0desc=\"Not\u00a0Present/Invalid\";\n\u00a0\u00a0\u00a0II,\u00a0AccessPermission:Busy,\u00a0desc=\"Not\u00a0Present/Invalid,\u00a0issued\u00a0PUT\";\n\u00a0\u00a0\u00a0M,\u00a0AccessPermission:Read_Write,\u00a0desc=\"Modified\";\n\u00a0\u00a0\u00a0MI,\u00a0AccessPermission:Busy,\u00a0desc=\"Modified,\u00a0issued\u00a0PUT\";\n\u00a0\u00a0\u00a0MII,\u00a0AccessPermission:Busy,\u00a0desc=\"Modified,\u00a0issued\u00a0PUTX,\u00a0received\u00a0nack\";\n\u00a0\u00a0\u00a0IS,\u00a0AccessPermission:Busy,\u00a0desc=\"Issued\u00a0request\u00a0for\u00a0LOAD/IFETCH\";\n\u00a0\u00a0\u00a0IM,\u00a0AccessPermission:Busy,\u00a0desc=\"Issued\u00a0request\u00a0for\u00a0STORE/ATOMIC\";\n}\n</code></pre></div></div>\n<p>The states I and M are the only stable states in this example. Again\nnote that certain attributes have to be specified with the states.</p>\n<p>The state machine needs to specify the <strong>events</strong> it can handle and\nthus transition from one state to another. SLICC provides the\nkeyword <strong>enumeration</strong> which can be used for specifying the set of\npossible events. An example to shed more light on this -</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>enumeration(Event,\u00a0desc=\"Cache\u00a0events\")\u00a0{\n\u00a0\u00a0\u00a0//\u00a0From\u00a0processor\n\u00a0\u00a0\u00a0Load,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0desc=\"Load\u00a0request\u00a0from\u00a0processor\";\n\u00a0\u00a0\u00a0Ifetch,\u00a0\u00a0\u00a0\u00a0\u00a0desc=\"Ifetch\u00a0request\u00a0from\u00a0processor\";\n\u00a0\u00a0\u00a0Store,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0desc=\"Store\u00a0request\u00a0from\u00a0processor\";\n\u00a0\u00a0\u00a0Data,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0desc=\"Data\u00a0from\u00a0network\";\n\u00a0\u00a0\u00a0Fwd_GETX,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0desc=\"Forward\u00a0from\u00a0network\";\n\u00a0\u00a0\u00a0Inv,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0desc=\"Invalidate\u00a0request\u00a0from\u00a0dir\";\n\u00a0\u00a0\u00a0Replacement,\u00a0\u00a0desc=\"Replace\u00a0a\u00a0block\";\n\u00a0\u00a0\u00a0Writeback_Ack,\u00a0\u00a0\u00a0desc=\"Ack\u00a0from\u00a0the\u00a0directory\u00a0for\u00a0a\u00a0writeback\";\n\u00a0\u00a0\u00a0Writeback_Nack,\u00a0\u00a0\u00a0desc=\"Nack\u00a0from\u00a0the\u00a0directory\u00a0for\u00a0a\u00a0writeback\";\n}\n</code></pre></div></div>\n<p>While developing a protocol machine, we may need to define\nstructures that represent different entities in a memory system.\nSLICC provides the keyword <strong>structure</strong> for this purpose. An\nexample\nfollows</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>structure(Entry,\u00a0desc=\"...\",\u00a0interface=\"AbstractCacheEntry\")\u00a0{\n\u00a0\u00a0\u00a0State\u00a0CacheState,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0desc=\"cache\u00a0state\";\n\u00a0\u00a0\u00a0bool\u00a0Dirty,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0desc=\"Is\u00a0the\u00a0data\u00a0dirty\u00a0(different\u00a0than\u00a0memory)?\";\n\u00a0\u00a0\u00a0DataBlock\u00a0DataBlk,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0desc=\"Data\u00a0in\u00a0the\u00a0block\";\n}\n</code></pre></div></div>\n<p>The cool thing about using SLICC\u2019s structure is that it automatically\ngenerates for you the get and set functions on different fields. It also\nwrites a nice print function and overloads the &lt;&lt; operator. But in\ncase you would prefer do everything on your own, you can make use of the\nkeyword <strong>external</strong> in the declaration of the structure. This would\nprevent SLICC from generating C++ code for this structure.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>structure(TBETable,\u00a0external=\"yes\")\u00a0{\n\u00a0\u00a0\u00a0TBE\u00a0lookup(Address);\n\u00a0\u00a0\u00a0void\u00a0allocate(Address);\n\u00a0\u00a0\u00a0void\u00a0deallocate(Address);\n\u00a0\u00a0\u00a0bool\u00a0isPresent(Address);\n}\n</code></pre></div></div>\n<p>In fact many predefined types exist in src/mem/protocol/RubySlicc_*.sm\nfiles. You can make use of them, or if you need new types, you can\ndefine new ones as well. You can also use the keyword <strong>interface</strong> to\nmake use of inheritance features available in C++. Note that currently\nSLICC supports public inheritance only.</p>\n<p>We can also declare and define functions as we do in C++. There are\ncertain functions that the compiler expects would always be defined\nby the controller. These include</p>\n<ul>\n<li>getState()</li>\n<li>setState()</li>\n</ul>\n<h4 id=\"input-for-the-machine\">Input for the Machine</h4>\n<p>Since protocol is state machine, we need to specify how to machine\ntransitions from one state to another on receiving inputs. As mentioned\nbefore, each machine has several input and output ports. For each input\nport, the <strong>in_port</strong> keyword is used for specifying the behavior of\nthe machine, when a message is received on that input port. An example\nfollows that shows the syntax for declaring an input\nport.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>in_port(mandatoryQueue_in,\u00a0RubyRequest,\u00a0mandatoryQueue,\u00a0desc=\"...\")\u00a0{\n\u00a0\u00a0if\u00a0(mandatoryQueue_in.isReady())\u00a0{\n\u00a0\u00a0\u00a0\u00a0peek(mandatoryQueue_in,\u00a0RubyRequest,\u00a0block_on=\"LineAddress\")\u00a0{\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Entry\u00a0cache_entry\u00a0:=\u00a0getCacheEntry(in_msg.LineAddress);\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if\u00a0(is_invalid(cache_entry)\u00a0&amp;&amp;\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0cacheMemory.cacheAvail(in_msg.LineAddress)\u00a0==\u00a0false\u00a0)\u00a0{\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0//\u00a0make\u00a0room\u00a0for\u00a0the\u00a0block\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0trigger(Event:Replacement,\u00a0cacheMemory.cacheProbe(in_msg.LineAddress),\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0getCacheEntry(cacheMemory.cacheProbe(in_msg.LineAddress)),\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TBEs[cacheMemory.cacheProbe(in_msg.LineAddress)]);\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0else\u00a0{\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0trigger(mandatory_request_type_to_event(in_msg.Type),\u00a0in_msg.LineAddress,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0cache_entry,\u00a0TBEs[in_msg.LineAddress]);\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}\n\u00a0\u00a0\u00a0\u00a0}\n\u00a0\u00a0}\n}\n</code></pre></div></div>\n<p>As you can see, in_port takes in multiple arguments. The first\nargument, mandatoryQueue_in, is the identifier for the in_port\nthat is used in the file. The next argument, RubyRequest, is the\ntype of the messages that this input port receives. Each input port\nuses a queue to store the messages, the name of the queue is the\nthird argument.</p>\n<p>The keyword <strong>peek</strong> is used to extract messages from the queue of\nthe input port. The use of this keyword implicitly declares a\nvariable <strong>in_msg</strong> which is of the same type as specified in the\ninput port\u2019s declaration. This variable points to the message at the\nhead of the queue. It can be used for accessing the fields of the\nmessage as shown in the code above.</p>\n<p>Once the incoming message has been analyzed, it is time for using\nthis message for taking some appropriate action and changing the\nstate of the machine. This done using the keyword <strong>trigger</strong>. The\ntrigger function is actually used only in SLICC code and is not\npresent in the generated code. Instead this call is converted in to\na call to the <strong>doTransition()</strong> function which appears in the\ngenerated code. The doTransition() function is automatically\ngenerated by SLICC for each of the state machines. The number of\narguments to trigger depend on the machine itself. In general, the\ninput arguments for trigger are the type of the message that needs\nto processed, the address for which this message is meant for, the\ncache and the transaction buffer entries for that address.</p>\n<p><strong>trigger</strong> also increments a counter that is checked before a\ntransition is made. In one ruby cycle, there is a limit on the\nnumber of transitions that can be carried out. This is done to\nresemble more closely to a hardware based state machine. <strong>@TODO:\nWhat happens if there are no more transitions left? Does the wakeup\nabort?</strong></p>\n<h4 id=\"actions\">Actions</h4>\n<p>In this section we will go over how the actions that a state machine can\ncarry out are defined. These actions will be called in to action when\nthe state machine receives some input message which is then used to make\na transition. Let\u2019s go over an example on how the key word <strong>action</strong>\ncan be made use of.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>action(a_issueRequest,\u00a0\"a\",\u00a0desc=\"Issue\u00a0a\u00a0request\")\u00a0{\n\u00a0\u00a0\u00a0enqueue(requestNetwork_out,\u00a0RequestMsg,\u00a0latency=issue_latency)\u00a0{\n\u00a0\u00a0\u00a0out_msg.Address\u00a0:=\u00a0address;\n\u00a0\u00a0\u00a0\u00a0\u00a0out_msg.Type\u00a0:=\u00a0CoherenceRequestType:GETX;\n\u00a0\u00a0\u00a0\u00a0\u00a0out_msg.Requestor\u00a0:=\u00a0machineID;\n\u00a0\u00a0\u00a0\u00a0\u00a0out_msg.Destination.add(map_Address_to_Directory(address));\n\u00a0\u00a0\u00a0\u00a0\u00a0out_msg.MessageSize\u00a0:=\u00a0MessageSizeType:Control;\n\u00a0\u00a0\u00a0}\n}\n</code></pre></div></div>\n<p>The first input argument is the name of the action, the next\nargument is the abbreviation used for generating the documentation\nand last one is the description of the action which used in the HTML\ndocumentation and as a comment in the C++ code.</p>\n<p>Each action is converted in to a C++ function of that name. The\ngenerated C++ code implicitly includes up to three input parameters\nin the function header, again depending on the machine. These\narguments are the memory address on which the action is being taken,\nthe cache and transaction buffer entries pertaining to this address.</p>\n<p>Next useful thing to look at is the <strong>enqueue</strong> keyword. This\nkeyword is used for queuing a message, generated as a result of the\naction, to an output port. The keyword takes three input arguments,\nnamely, the name of the output port, the type of the message to be\nqueued and the latency after which this message can be dequeued.\nNote that in case randomization is enabled, the specified latency is\nignored. The use of the keyword implicitly declares a variable\nout_msg which is populated by the follow on statements.</p>\n<h4 id=\"transitions\">Transitions</h4>\n<p>A transition function is a mapping from the cross product of set of\nstates and set of events to the set of states. SLICC provides the\nkeyword <strong>transition</strong> for specifying the transition function for state\nmachines. An example follows \u2013</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>transition(IM,\u00a0Data,\u00a0M)\u00a0{\n\u00a0\u00a0\u00a0u_writeDataToCache;\n\u00a0\u00a0\u00a0sx_store_hit;\n\u00a0\u00a0\u00a0w_deallocateTBE;\n\u00a0\u00a0\u00a0n_popResponseQueue;\n}\n</code></pre></div></div>\n<p>In this example, the initial state is <em>IM</em>. If an event of type <em>Data</em>\noccurs in that state, then final state would be <em>M</em>. Before making the\ntransition, the state machine can perform certain actions on the\nstructures that it maintains. In the given example,\n<em>u_writeDataToCache</em> is an action. All these operations are performed\nin an atomic fashion, i.e. no other event can occur before the set of\nactions specified with the transition has been completed.</p>\n<p>For ease of use, sets of events and states can be provided as input\nto transition. The cross product of these sets will map to the same\nfinal state. Note that the final state cannot be a set. If for a\nparticular event, the final state is same as the initial state, then\nthe final state can be omitted.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>transition({IS,\u00a0IM,\u00a0MI,\u00a0II},\u00a0{Load,\u00a0Ifetch,\u00a0Store,\u00a0Replacement})\u00a0{\n\u00a0\u00a0\u00a0z_stall;\n}\n</code></pre></div></div>\n<h3 id=\"special-functions\">Special Functions</h3>\n<h4 id=\"stallingrecyclingwaiting-input-ports\">Stalling/Recycling/Waiting input ports</h4>\n<p>One of the more complicated internal features of SLICC and the resulting\nstate machines is how the deal with the situation when events cannot be\nprocess due to the cache block being in a transient state. There are\nseveral possible ways to deal with this situation and each solution has\ndifferent tradeoffs. This sub-section attempts to explain the\ndifferences. Please email the gem5-user list for further follow-up.</p>\n<h5 id=\"stalling-the-input-port\">Stalling the input port</h5>\n<p>The simplest way to handle events that can\u2019t be processed is to simply\nstall the input port. The correct way to do this is to include the\n\u201cz_stall\u201d action within the transition statement:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>transition({IS,\u00a0IM,\u00a0MI,\u00a0II},\u00a0{Load,\u00a0Ifetch,\u00a0Store,\u00a0Replacement})\u00a0{\n\u00a0\u00a0\u00a0z_stall;\n}\n</code></pre></div></div>\n<p>Internally SLICC will return a ProtocolStall for this transition and no\nsubsequent messages from the associated input port will be processed\nuntil the stalled message is processed. However, the other input ports\nwill be analyzed for ready messages and processed in parallel. While\nthis is a relatively simple solution, one may notice that stalling\nunrelated messages on the same input port will cause excessive and\nunnecessary stalls.</p>\n<p>One thing to note is <strong>Do Not</strong> leave the transition statement blank\nlike so:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>transition({IS,\u00a0IM,\u00a0MI,\u00a0II},\u00a0{Load,\u00a0Ifetch,\u00a0Store,\u00a0Replacement})\u00a0{\n\u00a0\u00a0\u00a0//\u00a0stall\u00a0the\u00a0input\u00a0port\u00a0by\u00a0simply\u00a0not\u00a0popping\u00a0the\u00a0message\n}\n</code></pre></div></div>\n<p>This will cause SLICC to return success for this transition and SLICC\nwill continue to repeatedly analyze the same input port. The result is\neventual deadlock.</p>\n<h5 id=\"recycling-the-input-port\">Recycling the input port</h5>\n<p>The better performance but more unrealistic solution is to recycle the\nstalled message on the input port. The way to do this is to use the\n\u201czz_recycleMandatoryQueue\u201d\naction:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>action(zz_recycleMandatoryQueue,\u00a0\"\\z\",\u00a0desc=\"Send\u00a0the\u00a0head\u00a0of\u00a0the\u00a0mandatory\u00a0queue\u00a0to\u00a0the\u00a0back\u00a0of\u00a0the\u00a0queue.\")\u00a0{\n\u00a0\u00a0\u00a0mandatoryQueue_in.recycle();\n}\n</code></pre></div></div>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>transition({IS,\u00a0IM,\u00a0MI,\u00a0II},\u00a0{Load,\u00a0Ifetch,\u00a0Store,\u00a0Replacement})\u00a0{\n\u00a0\u00a0\u00a0zz_recycleMandatoryQueue;\n}\n</code></pre></div></div>\n<p>The result of this action is that the transition returns a Protocol\nStall and the offending message moved to the back of the FIFO input\nport. Therefore, other unrelated messages on the same input port can be\nprocessed. The problem with this solution is that recycled messages may\nbe analyzed and reanalyzed every cycle until an address changes state.</p>\n<h5 id=\"stall-and-wait-the-input-port\">Stall and wait the input port</h5>\n<p>An even better, but more complicated solution is to \u201cstall and wait\u201d the\noffending input message. The way to do this is to use the\n\u201cz_stallAndWaitMandatoryQueue\u201d\naction:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>action(z_stallAndWaitMandatoryQueue,\u00a0\"\\z\",\u00a0desc=\"recycle\u00a0L1\u00a0request\u00a0queue\")\u00a0{\n\u00a0\u00a0\u00a0stall_and_wait(mandatoryQueue_in,\u00a0address);\n}\n</code></pre></div></div>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>transition({IS,\u00a0IM,\u00a0IS_I,\u00a0M_I,\u00a0SM,\u00a0SINK_WB_ACK},\u00a0{Load,\u00a0Ifetch,\u00a0Store,\u00a0L1_Replacement})\u00a0{\n\u00a0\u00a0\u00a0z_stallAndWaitMandatoryQueue;\n}\n</code></pre></div></div>\n<p>The result of this action is that the transition returns success, which\nis ok because stall_and_wait moves the offending message off the input\nport and to a side table associated with the input port. The message\nwill not be analyzed again until it is woken up. In the meantime, other\nunrelated messages will be processed.</p>\n<p>The complicated part of stall and wait is that stalled messages must be\nexplicitly woken up by other messages/transitions. In particular,\ntransitions that move an address to a base state should wake up\npotentially stalled messages waiting for that address:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>action(kd_wakeUpDependents,\u00a0\"kd\",\u00a0desc=\"wake-up\u00a0dependents\")\u00a0{\n\u00a0\u00a0\u00a0wakeUpBuffers(address);\n}\n</code></pre></div></div>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>transition(M_I,\u00a0WB_Ack,\u00a0I)\u00a0{\n\u00a0\u00a0\u00a0s_deallocateTBE;\n\u00a0\u00a0\u00a0o_popIncomingResponseQueue;\n\u00a0\u00a0\u00a0kd_wakeUpDependents;\n}\n</code></pre></div></div>\n<p>Replacements are particularly complicated since stalled addresses are\nnot associated with the same address they are actually waiting to\nchange. In those situations all waiting messages must be woken\nup:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>action(ka_wakeUpAllDependents,\u00a0\"ka\",\u00a0desc=\"wake-up\u00a0all\u00a0dependents\")\u00a0{\n\u00a0\u00a0\u00a0wakeUpAllBuffers();\n}\n</code></pre></div></div>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>transition(I,\u00a0L2_Replacement)\u00a0{\n\u00a0\u00a0\u00a0rr_deallocateL2CacheBlock;\n\u00a0\u00a0\u00a0ka_wakeUpAllDependents;\n}\n</code></pre></div></div>\n<h3 id=\"other-compiler-features\">Other Compiler Features</h3>\n<ul>\n<li>\n<p>SLICC supports conditional statements in form of <strong>if</strong> and\n<strong>else</strong>. Note that SLICC does not support <strong>else if</strong>.</p>\n</li>\n<li>\n<p>Each function has return type which can be void as well. Returned\nvalues cannot be ignored.</p>\n</li>\n<li>\n<p>SLICC has limited support for pointer variables. is_valid() and\nis_invalid() operations are supported for testing whether a given\npointer \u2018is not NULL\u2019 and \u2018is NULL\u2019 respectively. The keyword\n<strong>OOD</strong>, which stands for Out of Domain, plays the role of keyword\nNULL used in C++.</p>\n</li>\n<li>\n<p>SLICC does not support <strong>!</strong> (the not operator).</p>\n</li>\n<li>\n<p>Static type casting is supported in SLICC. The keyword\n<strong>static_cast</strong> has been provided for this purpose. For example, in\nthe following piece of code, a variable of type AbstractCacheEntry\nis being casted in to a variable of type Entry.</p>\n</li>\n</ul>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>\u00a0\u00a0\u00a0Entry\u00a0L1Dcache_entry\u00a0:=\u00a0static_cast(Entry,\u00a0\"pointer\",\u00a0L1DcacheMemory[addr]);\n</code></pre></div></div>\n<h3 id=\"slicc-internals\">SLICC Internals</h3>\n<p><strong>C++ to Slicc Interface - @note: What do each of these files\ndo/define???</strong></p>\n<ul>\n<li>src/mem/protocol/RubySlicc_interaces.sm\n    <ul>\n<li>RubySlicc_Exports.sm</li>\n<li>RubySlicc_Defines.sm</li>\n<li>RubySlicc_Profiler.sm</li>\n<li>RubySlicc_Types.sm</li>\n<li>RubySlicc_MemControl.sm</li>\n<li>RubySlicc_ComponentMapping.sm</li>\n</ul>\n</li>\n</ul>\n<p><strong>Variable Assignments</strong></p>\n<ul>\n<li>Use the <code class=\"language-plaintext highlighter-rouge\">:=</code> operator to assign members in class (e.g. a member\ndefined in RubySlicc_Types.sm):\n    <ul>\n<li>an automatic <code class=\"language-plaintext highlighter-rouge\">m_</code> is added to the name mentioned in the SLICC\n  file.</li>\n</ul>\n</li>\n</ul>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/ruby/interconnection-network/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/stdlib_api/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/statistics/",
        "title": "Stats Package",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"stats-package\">Stats Package</h1>\n<p>The philosophy of the stats package at the moment is to have a single base class called Stat which is merely a hook into every other aspect of the stat that may be important. Thus, this Stat base class has virtual functions to name, set precision for, set flags for, and initialize size for all the stats. For all Vector based stats, it is very important to do the initialization before using the stat so that appropriate storage allocation can occur. For all other stats, naming and flag setting is also important, but not as important for the actual proper execution of the binary. The way this is set up in the code is to have a regStats() pass in which all stats can be registered in the stats database and initialized.</p>\n<p>Thus, to add your own stats, just add them to the appropriate class\u2019 data member list, and be sure to initialize/register them in that class\u2019 regStats function.</p>\n<p>Here is a list of the various initialization functions. Note that all of these return a Stat&amp; reference, thus enabling a clean looking way of calling them all.</p>\n<ul>\n<li>init(various args) //this differs for different types of stats.\n    <ul>\n<li>Average: does not have an init()</li>\n<li>Vector: init(size_t) //indicates size of vector</li>\n<li>AverageVector: init(size_t) //indicates size of vector</li>\n<li>Vector2d: init(size_t x, size_t y) //rows, columns</li>\n<li>Distribution: init(min, max, bkt) //min refers to minimum value, max the maximum value, and bkt the size of the bkts. In other words, if you have min=0, max=15, and bkt=8, then 0-7 will go into bucket 0, and 8-15 will go into bucket 1.</li>\n<li>StandardDeviation: does not have an init()</li>\n<li>AverageDeviation: does not have an init()</li>\n<li>VectorDistribution: init(size, min, max, bkt) //the size refers to the size of the vector, the rest are the same as for Distributions.</li>\n<li>VectorStandardDeviation: init(size) //size refers to size of the vector</li>\n<li>VectorAverageDeviation: init(size) //size refers to size of the vector</li>\n<li>Formula: does not have an init()</li>\n</ul>\n</li>\n<li>name(const std::string name) //the name of the stat</li>\n<li>desc(const std::string desc) //a brief description of the stat</li>\n<li>precision(int p) //p refers to how many places after the decimal point to go. p=0 will force rounding to integers.</li>\n<li>prereq(const Stat &amp;prereq) //this indicates that this stat should not be printed unless prereq has a non-zero value. (like if there are 0 cache accesses, don\u2019t print cache misses, hits, etc.)</li>\n<li>subname(int index, const std::string subname) //this is for Vector based stats to give a subname to each index of the vector.</li>\n<li>subdesc(int index, const std::string subname) //also for Vector based stats, to give each index a subdesc. For 2d Vectors, the subname goes to each of the rows (x\u2019s). The y\u2019s can be named using a Vector2d member function ysubname, see code for details.</li>\n</ul>\n<p>flags(FormatFlags f) //these are various flags you can pass to the stat, which i\u2019ll describe below.</p>\n<ul>\n<li>none \u2013 no special formatting</li>\n<li>total \u2013 this is for Vector based stats, if this flag is set, the total across the Vector will be printed at the end (for those stats which this is supported).</li>\n<li>pdf \u2013 This will print the probability distribution of a stat</li>\n<li>nozero \u2013 This will not print the stat if its value is zero</li>\n<li>nonan \u2013 This will not print the stat if it\u2019s Not a Number (nan).</li>\n<li>cdf \u2013 This will print the cumulative distribution of a stat</li>\n</ul>\n<p>Below is an example of how to initialize a VectorDistribution:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    vector_dist.init(4,0,5,2)\n        .name(\"Dummy Vector Dist\")\n        .desc(\"there are 4 distributions with buckets 0-1, 2-3, 4-5\")\n        .flags(nonan | pdf)\n        ;\n</code></pre></div></div>\n<h1 id=\"stat-types\">Stat Types</h1>\n<h2 id=\"scalar\">Scalar</h2>\n<p>The most basic stat is the Scalar. This embodies the basic counting stat. It is a templatized stat and takes two parameters, a type and a bin. The default type is a Counter, and the default bin is NoBin (i.e. there is no binning on this stat). It\u2019s usage is straightforward: to assign a value to it, just say foo = 10;, or to increment it, just use ++ or += like for any other type.</p>\n<h2 id=\"average\">Average</h2>\n<p>This is a \u201cspecial use\u201d stat, geared toward calculating the average of something over the number of cycles in the simulation. This stat is best explained by example. If you wanted to know the average occupancy of the load-store queue over the course of the simulation, you\u2019d need to accumulate the number of instructions in the LSQ each cycle and at the end divide it by the number of cycles. For this stat, there may be many cycles where there is no change in the LSQ occupancy. Thus, you could use this stat, where you only need to explicitly update the stat when there is a change in the LSQ occupancy. The stat itself will take care of itself for cycles where there is no change. This stat can be binned and it also templatized the same way Stat is.</p>\n<h2 id=\"vector\">Vector</h2>\n<p>A Vector is just what it sounds like, a vector of type T in the template parameters. It can also be binned. The most natural use of Vector is for something like tracking some stat over number of SMT threads. A Vector of size n can be declared just by saying Vector&lt;&gt; foo; and later initializing the size to n. At that point, foo can be accessed as if it were a regular vector or array, like foo[7]++.</p>\n<h2 id=\"averagevector\">AverageVector</h2>\n<p>An AverageVector is just a Vector of Averages.</p>\n<h2 id=\"vector2d\">Vector2d</h2>\n<p>A Vector2d is a 2 dimensional vector. It can be named in both the x and y directions, though the primary name is given across the x-dimension. To name in the y-dimension, use a special ysubname function only available to Vector2d\u2019s.</p>\n<h2 id=\"distribution\">Distribution</h2>\n<p>This is essentially a Vector, but with minor differences. Whereas in a Vector, the index maps to the item of interest for that bucket, in a Distribution you could map different ranges of interest to a bucket. Basically, if you had the bkt parameter of init for a Distribution = 1, you might as well use a Vector.</p>\n<h2 id=\"standarddeviation\">StandardDeviation</h2>\n<p>This stat calculates standard deviation over number of cycles in the simulation. It\u2019s similar to Average in that it has behavior built into it, but it needs to be updated every cycle.</p>\n<h2 id=\"averagedeviation\">AverageDeviation</h2>\n<p>This stat also calculates the standard deviation but it does not need to be updated every cycle, much like Average. It will handle cycles where there is no change itself.</p>\n<h2 id=\"vectordistribution\">VectorDistribution</h2>\n<p>This is just a vector of distributions.</p>\n<h2 id=\"vectorstandarddeviation\">VectorStandardDeviation</h2>\n<p>This is just a vector of standard deviations.</p>\n<h2 id=\"vectoraveragedeviation\">VectorAverageDeviation</h2>\n<p>This is just a vector of AverageDeviations.</p>\n<h2 id=\"histogram\">Histogram</h2>\n<p>This stat puts each sampled value into one bin out of a configurable number of bins. All bins form a contiguous interval and are of equal length. The length of the bins is dynamically extended, if there is a sample value which does not fit into one the existing bins.</p>\n<h2 id=\"sparsehistogram\">SparseHistogram</h2>\n<p>This stat is similar to a histogram, except that it can only sample natural numbers. SparseHistogram is e.g. suitable for counting the number of accesses to memory addresses.</p>\n<h2 id=\"formula\">Formula</h2>\n<p>This is a Formula stat. This is for anything that requires calculations at the end of the simulation, for example something that is a rate. So, an example of defining a Formula would be:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    Formula foo = bar + 10 / num;\n</code></pre></div></div>\n<p>There are a few subtleties to Formula. If bar and num are both stats(including Formula type), then there is no problem. If bar or num are regular variables, then they must be qualified with constant(bar). This is essentially cast. If you want to use the value of bar or num at the moment of definition, then use constant(). If you want to use the value of bar or num at the moment the formula is calculated (i.e. the end), define num as a Scalar. If num is a Vector, use sum(num) to calculate its sum for the formula. The operation \u201cscalar(num)\u201d, which casts a regular variable to a Scalar, does no longer exist.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/stdlib_api/gem5.utils.socks_ssl_context.html\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/statistics/api\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/statistics/api",
        "title": "Statistics APIs",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"statistics-apis\">Statistics APIs</h1>\n<h2 id=\"contents\">Contents</h2>\n<ol>\n<li><a href=\"#general-statistics-functions\">General Statistics Functions</a></li>\n<li><a href=\"#stats_group-statistics-container\">Stats::Group - Statistics Container</a></li>\n<li><a href=\"#stats-flags\">Stats Flags</a></li>\n<li><a href=\"#statistics-classes\">Statistic Classes</a></li>\n<li><a href=\"#appendix_migrating-to-the-new-style-of-tracking-statistics\">Appendix: Migrating to the new style of tracking statistics</a></li>\n</ol>\n<hr/>\n<h2 id=\"general-statistics-functions\">General Statistics Functions</h2>\n<table>\n<thead>\n<tr>\n<th>Function signatures</th>\n<th>Descriptions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void Stats::dump()</code></td>\n<td>Dump all stats to registered outputs, e.g. stats.txt.</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void Stats::reset()</code></td>\n<td>Reset stats.</td>\n</tr>\n</tbody>\n</table>\n<hr/>\n<h2 id=\"statsgroup---statistics-container\">Stats::Group - Statistics Container</h2>\n<p>Typically, a statistic object can be placed in any <code class=\"language-plaintext highlighter-rouge\">SimObject</code> as a class variable.\nHowever, <a href=\"https://gem5-review.googlesource.com/c/public/gem5/+/19368\">a recent update</a>\naddresses the hierarchical nature of <code class=\"language-plaintext highlighter-rouge\">SimObject</code> \u2018s in gem5,\nwhich in turns makes the statistics of the objects hierarchical.\nThe update introduces the <code class=\"language-plaintext highlighter-rouge\">Stats::Group</code> class, which is a statistics container\nand is aware of the hierarchical structure of <code class=\"language-plaintext highlighter-rouge\">SimObject</code>\u2019s.\nIdeally, this container should contain all stats in a <code class=\"language-plaintext highlighter-rouge\">SimObject</code>.</p>\n<p><strong>Note</strong>: If you decide to use a <code class=\"language-plaintext highlighter-rouge\">Stats::Group</code> struct inside of a <code class=\"language-plaintext highlighter-rouge\">SimObject</code>,\nthere are typically two ways of doing this:</p>\n<ul>\n<li>Create a subgroup using <code class=\"language-plaintext highlighter-rouge\">Stats::Group(Stats::Group &amp;parent, const std::string &amp;name)</code> constructor. This is useful when it is desired to have multiple instances of the same stats structure.</li>\n<li>Using <code class=\"language-plaintext highlighter-rouge\">Stats::Group(Stats::Group &amp;parent)</code> constructor, which merges (i.e. adds) the stats of the current group to the parent group. Thus, the stats added to the current group behave as if they were added to the parent group.</li>\n</ul>\n<h3 id=\"statsgroup-macros\">Stats::Group macros</h3>\n<h5 id=\"define-add_statn--nthis--n-__va_args__\"><code class=\"language-plaintext highlighter-rouge\">#define ADD_STAT(n, ...) n(this, # n, __VA_ARGS__)</code></h5>\n<p>Convenience macro to add a stat to a statistics group.</p>\n<p>This macro is used to add a stat to a Stats::Group in the\ninitilization list in the Group\u2019s constructor. The macro\nautomatically assigns the stat to the current group and gives it\nthe same name as in the class. For example:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>struct MyStats : public Stats::Group\n{\n    Stats::Scalar scalar0;\n    Stats::Scalar scalar1;\n\n    MyStats(Stats::Group *parent)\n        : Stats::Group(parent),\n          ADD_STAT(scalar0, \"Description of scalar0\"),       // equivalent to scalar0(this, \"scalar0\", \"Description of scalar0\"), where scalar0 has the follwing constructor\n                                                             // Stats::Scalar(Group *parent = nullptr, const char *name = nullptr, const char *desc = nullptr)\n          scalar1(this, \"scalar1\", \"Description of scalar1\")\n     {\n     }\n};\n</code></pre></div></div>\n<h3 id=\"statsgroup-functions\">Stats::Group functions</h3>\n<h5 id=\"groupgroup-parent-const-char-name--nullptr\"><code class=\"language-plaintext highlighter-rouge\">Group(Group *parent, const char *name = nullptr)</code></h5>\n<p>Construct a new statistics group.</p>\n<p>The constructor takes two parameters, a parent and a name. The\nparent group should typically be specified. However, there are\nspecial cases where the parent group may be null. One such\nspecial case is SimObjects where the Python code performs late\nbinding of the group parent.</p>\n<p>If the name parameter is NULL, the group gets merged into the\nparent group instead of creating a sub-group. Stats belonging\nto a merged group behave as if they have been added directly to\nthe parent group.</p>\n<h5 id=\"virtual-void-regstats\"><code class=\"language-plaintext highlighter-rouge\">virtual void regStats()</code></h5>\n<p>Callback to set stat parameters.</p>\n<p>This callback is typically used for complex stats (e.g.,\ndistributions) that need parameters in addition to a name and a\ndescription. In the case stats objects cannot be initilalized\nin the constructor (such as the stats that keep track of the\nbus masters, which only can be discovered after the entire\nsystem is instantiated). Stat names and descriptions should\ntypically be set from the constructor using the <code class=\"language-plaintext highlighter-rouge\">ADD_STAT</code> macro.</p>\n<h5 id=\"virtual-void-resetstats\"><code class=\"language-plaintext highlighter-rouge\">virtual void resetStats()</code></h5>\n<p>Callback to reset stats.</p>\n<h5 id=\"virtual-void-predumpstats\"><code class=\"language-plaintext highlighter-rouge\">virtual void preDumpStats()</code></h5>\n<p>Callback before stats are dumped. This can be overridden by\nobjects that need to perform calculations in addition to the\ncapabiltiies implemented in the stat framework.</p>\n<h5 id=\"void-addstatstatsinfo-info\"><code class=\"language-plaintext highlighter-rouge\">void addStat(Stats::Info *info)</code></h5>\n<p>Register a stat with this group. This method is normally called\nautomatically when a stat is instantiated.</p>\n<h5 id=\"const-stdmapstdstring-group--getstatgroups-const\"><code class=\"language-plaintext highlighter-rouge\">const std::map&lt;std::string, Group *&gt; &amp;getStatGroups() const</code></h5>\n<p>Get all child groups associated with this object.</p>\n<h5 id=\"const-stdvectorinfo--getstats-const\"><code class=\"language-plaintext highlighter-rouge\">const std::vector&lt;Info *&gt; &amp;getStats() const</code></h5>\n<p>Get all stats associated with this object.</p>\n<h5 id=\"void-addstatgroupconst-char-name-group-block\"><code class=\"language-plaintext highlighter-rouge\">void addStatGroup(const char *name, Group *block)</code></h5>\n<p>Add a stat block as a child of this block.</p>\n<p>This method may only be called from a Group constructor or from\nregStats. It\u2019s typically only called explicitly from Python\nwhen setting up the SimObject hierarchy.</p>\n<h5 id=\"const-info--resolvestatstdstring-name-const\"><code class=\"language-plaintext highlighter-rouge\">const Info * resolveStat(std::string name) const</code></h5>\n<p>Resolve a stat by its name within this group.</p>\n<p>This method goes through the stats in this group and sub-groups\nand returns a pointer to the the stat that matches the provided\nname. The input name has to be relative to the name of this\ngroup.</p>\n<p>For example, if this group is the <code class=\"language-plaintext highlighter-rouge\">SimObject\nsystem.bigCluster.cpus</code> and we want the stat\n<code class=\"language-plaintext highlighter-rouge\">system.bigCluster.cpus.ipc</code>, the input param should be the\nstring \u201cipc\u201d.</p>\n<hr/>\n<h2 id=\"stats-flags\">Stats Flags</h2>\n<table>\n<thead>\n<tr>\n<th>Flags</th>\n<th>Descriptions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Stats::none</code></td>\n<td>Nothing extra to print.</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Stats::total</code></td>\n<td>Print the total.</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Stats::pdf</code></td>\n<td>Print the percent of the total that this entry represents.</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Stats::cdf</code></td>\n<td>Print the cumulative percentage of total upto this entry.</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Stats::dist</code></td>\n<td>Print the distribution.</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Stats::nozero</code></td>\n<td>Don\u2019t print if this is zero.</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Stats::nonan</code></td>\n<td>Don\u2019t print if this is NAN</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Stats::oneline</code></td>\n<td>Print all values on a single line. Useful only for histograms.</td>\n</tr>\n</tbody>\n</table>\n<p>Note: even though the flags <code class=\"language-plaintext highlighter-rouge\">Stats::init</code> and <code class=\"language-plaintext highlighter-rouge\">Stats::display</code> are available, the flags\nare not allowed to be set by users.</p>\n<hr/>\n<h2 id=\"statistics-classes\">Statistics Classes</h2>\n<table>\n<thead>\n<tr>\n<th>Class names</th>\n<th>Descriptions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><a href=\"#statsscalar\"><code class=\"language-plaintext highlighter-rouge\">Stats::Scalar</code></a></td>\n<td>Simple scalar statistic.</td>\n</tr>\n<tr>\n<td><a href=\"#statsaverage\"><code class=\"language-plaintext highlighter-rouge\">Stats::Average</code></a></td>\n<td>A statistic that calculate the PER TICK average of a value.</td>\n</tr>\n<tr>\n<td><a href=\"#statsvalue\"><code class=\"language-plaintext highlighter-rouge\">Stats::Value</code></a></td>\n<td>Similar to Stats::Scalar.</td>\n</tr>\n<tr>\n<td><a href=\"#statsvector\"><code class=\"language-plaintext highlighter-rouge\">Stats::Vector</code></a></td>\n<td>A vector of scalar statistics.</td>\n</tr>\n<tr>\n<td><a href=\"#statsaveragevector\"><code class=\"language-plaintext highlighter-rouge\">Stats::AverageVector</code></a></td>\n<td>A vector of average statistics.</td>\n</tr>\n<tr>\n<td><a href=\"#statsvector2d\"><code class=\"language-plaintext highlighter-rouge\">Stats::Vector2d</code></a></td>\n<td>A 2D vector of scalar statistics.</td>\n</tr>\n<tr>\n<td><a href=\"#statsdistribution\"><code class=\"language-plaintext highlighter-rouge\">Stats::Distribution</code></a></td>\n<td>A simple distribution statistic (having convinient min, max sum, etc.).</td>\n</tr>\n<tr>\n<td><a href=\"#statshistogram\"><code class=\"language-plaintext highlighter-rouge\">Stats::Histogram</code></a></td>\n<td>A simple histogram statistic (keeping the frequencies of equally-splitted continuous ranges).</td>\n</tr>\n<tr>\n<td><a href=\"#statssparsehistogram\"><code class=\"language-plaintext highlighter-rouge\">Stats::SparseHistogram</code></a></td>\n<td>Keeps the frequency / histogram of a collection of discrete values.</td>\n</tr>\n<tr>\n<td><a href=\"#statsstandarddeviation\"><code class=\"language-plaintext highlighter-rouge\">Stats::StandardDeviation</code></a></td>\n<td>Calculates the mean and variance of all samples.</td>\n</tr>\n<tr>\n<td><a href=\"#statsaveragedeviation\"><code class=\"language-plaintext highlighter-rouge\">Stats::AverageDeviation</code></a></td>\n<td>Calculates per tick mean and variance of samples.</td>\n</tr>\n<tr>\n<td><a href=\"#statsvectordistribution\"><code class=\"language-plaintext highlighter-rouge\">Stats::VectorDistribution</code></a></td>\n<td>A vector of distributions.</td>\n</tr>\n<tr>\n<td><a href=\"#statsvectorstandarddeviation\"><code class=\"language-plaintext highlighter-rouge\">Stats::VectorStandardDeviation</code></a></td>\n<td>A vector of standard deviation statistics.</td>\n</tr>\n<tr>\n<td><a href=\"#statsvectoraveragedeviation\"><code class=\"language-plaintext highlighter-rouge\">Stats::VectorAverageDeviation</code></a></td>\n<td>A vector of average deviation statistics.</td>\n</tr>\n<tr>\n<td><a href=\"#statsformula\"><code class=\"language-plaintext highlighter-rouge\">Stats::Formula</code></a></td>\n<td>Keeps the statistic involving arithmetics of multiple stats objects.</td>\n</tr>\n</tbody>\n</table>\n<p><strong>Note:</strong> <code class=\"language-plaintext highlighter-rouge\">Stats::Average</code> only calculates the average of a scalar over the number of simulated ticks.\nIn order to get the average of quantity A over quantity B, <code class=\"language-plaintext highlighter-rouge\">Stats::Formula</code> can be utilized.\nFor example,</p>\n<pre><code class=\"language-C++\">Stats::Scalar totalReadLatency;\nStats::Scalar numReads;\nStats::Formula averageReadLatency = totalReadLatency/numReads;\n</code></pre>\n<h3 id=\"common-statistic-functions\">Common statistic functions</h3>\n<table>\n<thead>\n<tr>\n<th>Function signatures</th>\n<th>Descriptions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">StatClass name(const std::string &amp;name)</code></td>\n<td>sets the statistic name, marks the stats to be printed</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">StatClass desc(const std::string &amp;_desc)</code></td>\n<td>sets the description for the statistic</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">StatClass precision(int _precision)</code></td>\n<td>sets the precision of the statistic</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">StatClass flags(Flags _flags)</code></td>\n<td>sets the flags</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">StatClass prereq(const Stat &amp;prereq)</code></td>\n<td>sets the prerequisite stat</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"statsscalar\"><code class=\"language-plaintext highlighter-rouge\">Stats::Scalar</code></h3>\n<p>Storing a signed integer statistic.</p>\n<table>\n<thead>\n<tr>\n<th>Function signatures</th>\n<th>Descriptions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void operator++()</code></td>\n<td>increments the stat by 1 // prefix ++, e.g. <code class=\"language-plaintext highlighter-rouge\">++scalar</code></td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void operator--()</code></td>\n<td>decrements the stat by 1 // prefix \u2013</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void operator++(int)</code></td>\n<td>increments the stat by 1 // postfix ++, e.g. <code class=\"language-plaintext highlighter-rouge\">scalar++</code></td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void operator--(int)</code></td>\n<td>decrements the stat by 1 // postfix \u2013</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">template &lt;typename U&gt; void operator=(const U &amp;v)</code></td>\n<td>sets the scalar to the given value</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">template &lt;typename U&gt; void operator+=(const U &amp;v)</code></td>\n<td>increments the stat by the given value</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">template &lt;typename U&gt; void operator-=(const U &amp;v)</code></td>\n<td>decrements the stat by the given value</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">size_type size()</code></td>\n<td>returns 1</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Counter value()</code></td>\n<td>returns the current value of the stat as an integer</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Counter value() const</code></td>\n<td>returns the current value of the stat as an integer</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Result result()</code></td>\n<td>returns the current value of the stat as a <code class=\"language-plaintext highlighter-rouge\">double</code></td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Result total()</code></td>\n<td>returns the current value of the stat as a <code class=\"language-plaintext highlighter-rouge\">double</code></td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">bool zero()</code></td>\n<td>returns <code class=\"language-plaintext highlighter-rouge\">true</code> if the stat equals to zero, returns <code class=\"language-plaintext highlighter-rouge\">false</code> otherwise</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void reset()</code></td>\n<td>resets the stat to 0</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"statsaverage\"><code class=\"language-plaintext highlighter-rouge\">Stats::Average</code></h3>\n<p>Storing an average of an integer quantity, supposely A, over the number of simulated ticks.\nThe quantity A keeps the same value across all ticks after its latest update and before the next update.\n<strong>Note:</strong> the number of simulated ticks is reset when the user calls <code class=\"language-plaintext highlighter-rouge\">Stats::reset()</code>.</p>\n<table>\n<thead>\n<tr>\n<th>Function signatures</th>\n<th>Descriptions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void set(Counter val)</code></td>\n<td>sets the quantity A to the given value</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void inc(Counter val)</code></td>\n<td>increments the quantity A by the given value</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void dec(Counter val)</code></td>\n<td>decrements the quantity A by the given value</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Counter value()</code></td>\n<td>returns the current value of A as an integer</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Result result()</code></td>\n<td>returns the current average as a <code class=\"language-plaintext highlighter-rouge\">double</code></td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">bool zero()</code></td>\n<td>returns <code class=\"language-plaintext highlighter-rouge\">true</code> if the average equals to zero, returns <code class=\"language-plaintext highlighter-rouge\">false</code> otherwise</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void reset(Info \\*info)</code></td>\n<td>keeps the current value of A, does not count the value of A before the current tick</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"statsvalue\"><code class=\"language-plaintext highlighter-rouge\">Stats::Value</code></h3>\n<p>Storing a signed integer statistic that is either an integer or an integer that is a result from calling a function or an object\u2019s method.</p>\n<table>\n<thead>\n<tr>\n<th>Function signatures</th>\n<th>Descriptions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Counter value()</code></td>\n<td>returns the value as an integer</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Result result() const</code></td>\n<td>returns the value as a double</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Result total() const</code></td>\n<td>returns the value as a double</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">size_type size() const</code></td>\n<td>returns 1</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">bool zero() const</code></td>\n<td>returns <code class=\"language-plaintext highlighter-rouge\">true</code> if the value is zero, returns <code class=\"language-plaintext highlighter-rouge\">false</code> otherwise</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"statsvector\"><code class=\"language-plaintext highlighter-rouge\">Stats::Vector</code></h3>\n<p>Storing an array of scalar statistics where each element of the vector has function signatures similar to those of <code class=\"language-plaintext highlighter-rouge\">Stats::Scalar</code>.</p>\n<table>\n<thead>\n<tr>\n<th>Function signatures</th>\n<th>Descriptions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Derived &amp; init(size_type size)</code></td>\n<td>initializes the vector to the given size (throws an error if attempting to resize an initilized vector)</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Derived &amp; subname(off_type index, const std::string &amp;name)</code></td>\n<td>adds a name to the statistic at the given index</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Derived &amp; subdesc(off_type index, const std::string &amp;desc)</code></td>\n<td>adds a description to the statistic at the given index</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void value(VCounter &amp;vec) const</code></td>\n<td>copies the vector of statistics to the given vector of integers</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void result(VResult &amp;vec) const</code></td>\n<td>copies the vector of statistics to the given vector of doubles</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Result total() const</code></td>\n<td>returns the sum of all statistics in the vector as a double</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">size_type size() const</code></td>\n<td>returns the size of the vector</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">bool zero() const</code></td>\n<td>returns <code class=\"language-plaintext highlighter-rouge\">true</code> if each statistic in the vector is 0, returns <code class=\"language-plaintext highlighter-rouge\">false</code> otherwise</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">operator[](off_type index)</code></td>\n<td>gets the reference to the statistic at the given index, e.g. <code class=\"language-plaintext highlighter-rouge\">vecStats[1]+=9</code></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"statsaveragevector\"><code class=\"language-plaintext highlighter-rouge\">Stats::AverageVector</code></h3>\n<p>Storing an array of average statistics where each element of the vector has function signatures similar to those of <code class=\"language-plaintext highlighter-rouge\">Stats::Average</code>.</p>\n<table>\n<thead>\n<tr>\n<th>Function signatures</th>\n<th>Descriptions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Derived &amp; init(size_type size)</code></td>\n<td>initializes the vector to the given size (throws an error if attempting to resize an initilized vector)</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Derived &amp; subname(off_type index, const std::string &amp;name)</code></td>\n<td>adds a name to the statistic at the given index</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Derived &amp; subdesc(off_type index, const std::string &amp;desc)</code></td>\n<td>adds a description to the statistic at the given index</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void value(VCounter &amp;vec) const</code></td>\n<td>copies the vector of statistics to the given vector of integers</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void result(VResult &amp;vec) const</code></td>\n<td>copies the vector of statistics to the given vector of doubles</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Result total() const</code></td>\n<td>returns the sum of all statistics in the vector as a double</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">size_type size() const</code></td>\n<td>returns the size of the vector</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">bool zero() const</code></td>\n<td>returns <code class=\"language-plaintext highlighter-rouge\">true</code> if each statistic in the vector is 0, returns <code class=\"language-plaintext highlighter-rouge\">false</code> otherwise</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">operator[](off_type index)</code></td>\n<td>gets the reference to the statistic at the given index, e.g. <code class=\"language-plaintext highlighter-rouge\">avgStats[1].set(9)</code></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"statsvector2d\"><code class=\"language-plaintext highlighter-rouge\">Stats::Vector2d</code></h3>\n<p>Storing a 2-dimensional array of scalar statistics, where each element of the array has function signatures similar to those of <code class=\"language-plaintext highlighter-rouge\">Stats::Scalar</code>.\nThis data structure assumes all elements whose the same second dimension index has the same name.</p>\n<table>\n<thead>\n<tr>\n<th>Function signatures</th>\n<th>Descriptions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Derived &amp; init(size_type _x, size_type _y)</code></td>\n<td>initializes the vector to the given size (throws an error if attempting to resize an initilized vector)</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Derived &amp; ysubname(off_type index, const std::string &amp;subname)</code></td>\n<td>sets <code class=\"language-plaintext highlighter-rouge\">subname</code> as the name of the statistics of elements whose the second dimension of <code class=\"language-plaintext highlighter-rouge\">index</code></td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Derived &amp; ysubnames(const char **names)</code></td>\n<td>similar to <code class=\"language-plaintext highlighter-rouge\">ysubname()</code> above, but sets name for all indices of the second dimension</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">std::string ysubname(off_type i) const</code></td>\n<td>returns the name of the statistics of elements whose the second dimension of <code class=\"language-plaintext highlighter-rouge\">i</code></td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">size_type size() const</code></td>\n<td>returns the number of elements in the array</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">bool zero()</code></td>\n<td>returns <code class=\"language-plaintext highlighter-rouge\">true</code> if the element at row 0 column 0 equals to 0, returns <code class=\"language-plaintext highlighter-rouge\">false</code> otherwise</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Result total()</code></td>\n<td>returns the sum of all elements as a double</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void reset()</code></td>\n<td>sets each element in the array to 0</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">operator[](off_type index)</code></td>\n<td>gets the reference to the statistic at the given index, e.g. <code class=\"language-plaintext highlighter-rouge\">vecStats[1][2]+=9</code></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"statsdistribution\"><code class=\"language-plaintext highlighter-rouge\">Stats::Distribution</code></h3>\n<p>Storing a distribution of a quantity.\nThe statistics of the distribution include,</p>\n<ul>\n<li>the smallest/largest value being sampled</li>\n<li>the number of values that are smaller/larger than the specified minimum and maximum</li>\n<li>the sum of all samples</li>\n<li>the mean, the geometric mean and the standard deviation of the samples</li>\n<li>histogram within the range of [<code class=\"language-plaintext highlighter-rouge\">min</code>, <code class=\"language-plaintext highlighter-rouge\">max</code>] splitted into <code class=\"language-plaintext highlighter-rouge\">(max-min)/bucket_size</code> equally sized buckets,  where the <code class=\"language-plaintext highlighter-rouge\">min</code>/<code class=\"language-plaintext highlighter-rouge\">max</code>/<code class=\"language-plaintext highlighter-rouge\">bucket_size</code> are inputs to the init() function.</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Function signatures</th>\n<th>Descriptions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Distribution &amp; init(Counter min, Counter max, Counter bkt)</code></td>\n<td>initializes the distribution where <code class=\"language-plaintext highlighter-rouge\">min</code> is the minimum value being tracked by the distribution\u2019s histogram, <code class=\"language-plaintext highlighter-rouge\">max</code> is the minimum value being tracked by the distribution\u2019s histogram, and <code class=\"language-plaintext highlighter-rouge\">bkt</code> is the number of values in each bucket</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void sample(Counter val, int number)</code></td>\n<td>adds <code class=\"language-plaintext highlighter-rouge\">val</code> to the distribution <code class=\"language-plaintext highlighter-rouge\">number</code> times</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">size_type size() const</code></td>\n<td>returns the number of bucket in the distribution</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">bool zero() const</code></td>\n<td>returns <code class=\"language-plaintext highlighter-rouge\">true</code> if the number of samples is zero, returns <code class=\"language-plaintext highlighter-rouge\">false</code> otherwise</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void reset(Info *info)</code></td>\n<td>discards all samples</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">add(DistBase &amp;)</code></td>\n<td>merges the samples from another <code class=\"language-plaintext highlighter-rouge\">Stats</code> class with <code class=\"language-plaintext highlighter-rouge\">DistBase</code> (e.g. <code class=\"language-plaintext highlighter-rouge\">Stats::Histogram</code>)</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"statshistogram\"><code class=\"language-plaintext highlighter-rouge\">Stats::Histogram</code></h3>\n<p>Storing a histogram of a quantity given the number of buckets.\nAll buckets are equally sized.\nDifferent from the histogram of <code class=\"language-plaintext highlighter-rouge\">Stats::Distribution</code> which keeps track of the samples in a specific range, <code class=\"language-plaintext highlighter-rouge\">Stats::Histogram</code> keeps track of all samples in its histogram.\nAlso, while <code class=\"language-plaintext highlighter-rouge\">Stats::Distribution</code> is parameterized by the number of values in a bucket, <code class=\"language-plaintext highlighter-rouge\">Stats::Histogram</code>\u2019s sole parameter is the number of buckets.\nWhen a new sample is outside of the current range of all all buckets, the buckets will be resized.\nRoughly, two consecutive buckets will be merged until the new sample is inside one of the buckets.</p>\n<p>Other than the histogram itself, the statistics of the distribution include,</p>\n<ul>\n<li>the smallest/largest value being sampled</li>\n<li>the sum of all samples</li>\n<li>the mean, the geometric mean and the standard deviation of the samples</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Function signatures</th>\n<th>Descriptions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Histogram &amp; init(size_type size)</code></td>\n<td>initializes the histogram, sets the number of buckets to <code class=\"language-plaintext highlighter-rouge\">size</code></td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void sample(Counter val, int number)</code></td>\n<td>adds <code class=\"language-plaintext highlighter-rouge\">val</code> to the histogram <code class=\"language-plaintext highlighter-rouge\">number</code> times</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void add(HistStor *)</code></td>\n<td>merges another histogram to this histogram</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">size_type size() const </code></td>\n<td>returns the number of buckets</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">bool zero() const</code></td>\n<td>returns <code class=\"language-plaintext highlighter-rouge\">true</code> if the number of samples is zero, returns <code class=\"language-plaintext highlighter-rouge\">false</code> otherwise</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void reset(Info *info)</code></td>\n<td>discards all samples</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"statssparsehistogram\"><code class=\"language-plaintext highlighter-rouge\">Stats::SparseHistogram</code></h3>\n<p>Storing a histogram of a quantity given a set of integral values.</p>\n<table>\n<thead>\n<tr>\n<th>Function signatures</th>\n<th>Descriptions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">template &lt;typename U&gt; void sample(const U &amp;v, int n = 1)</code></td>\n<td>adds <code class=\"language-plaintext highlighter-rouge\">v</code> to the histogram <code class=\"language-plaintext highlighter-rouge\">n</code> times</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">size_type size() const </code></td>\n<td>returns the number of entries</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">bool zero() const</code></td>\n<td>returns <code class=\"language-plaintext highlighter-rouge\">true</code> if the number of samples is zero, returns <code class=\"language-plaintext highlighter-rouge\">false</code> otherwise</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void reset()</code></td>\n<td>discards all samples</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"statsstandarddeviation\"><code class=\"language-plaintext highlighter-rouge\">Stats::StandardDeviation</code></h3>\n<p>Keeps track of the standard deviation of a sample.</p>\n<table>\n<thead>\n<tr>\n<th>Function signatures</th>\n<th>Descriptions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void sample(Counter val, int number)</code></td>\n<td>adds <code class=\"language-plaintext highlighter-rouge\">val</code> to the distribution <code class=\"language-plaintext highlighter-rouge\">number</code> times</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">size_type size() const</code></td>\n<td>returns 1</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">bool zeros() const</code></td>\n<td>discards all samples</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">add(DistBase &amp;)</code></td>\n<td>merges the samples from another <code class=\"language-plaintext highlighter-rouge\">Stats</code> class with <code class=\"language-plaintext highlighter-rouge\">DistBase</code> (e.g. <code class=\"language-plaintext highlighter-rouge\">Stats::Distribution</code></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"statsaveragedeviation\"><code class=\"language-plaintext highlighter-rouge\">Stats::AverageDeviation</code></h3>\n<p>Keeps track of the average deviation of a sample.</p>\n<table>\n<thead>\n<tr>\n<th>Function signatures</th>\n<th>Descriptions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void sample(Counter val, int number)</code></td>\n<td>adds <code class=\"language-plaintext highlighter-rouge\">val</code> to the distribution <code class=\"language-plaintext highlighter-rouge\">number</code> times</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">size_type size() const</code></td>\n<td>returns 1</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">bool zeros() const</code></td>\n<td>discards all samples</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">add(DistBase &amp;)</code></td>\n<td>merges the samples from another <code class=\"language-plaintext highlighter-rouge\">Stats</code> class with <code class=\"language-plaintext highlighter-rouge\">DistBase</code> (e.g. <code class=\"language-plaintext highlighter-rouge\">Stats::Distribution</code></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"statsvectordistribution\"><code class=\"language-plaintext highlighter-rouge\">Stats::VectorDistribution</code></h3>\n<p>Storing a vector of distributions where each element of the vector has function signatures similar to those of <code class=\"language-plaintext highlighter-rouge\">Stats::Distribution</code>.</p>\n<table>\n<thead>\n<tr>\n<th>Function signatures</th>\n<th>Descriptions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">VectorDistribution &amp; init(size_type size, Counter min, Counter max, Counter bkt)</code></td>\n<td>initializes a vector of <code class=\"language-plaintext highlighter-rouge\">size</code> distributions where <code class=\"language-plaintext highlighter-rouge\">min</code> is the minimum value being tracked by each distribution\u2019s histogram, <code class=\"language-plaintext highlighter-rouge\">max</code> is the minimum value being tracked by each distribution\u2019s histogram, and <code class=\"language-plaintext highlighter-rouge\">bkt</code> is each distribution\u2019s the number of values in each bucket</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Derived &amp; subname(off_type index, const std::string &amp;name)</code></td>\n<td>adds a name to the statistic at the given index</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Derived &amp; subdesc(off_type index, const std::string &amp;desc)</code></td>\n<td>adds a description to the statistic at the given index</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">size_type size() const</code></td>\n<td>returns the number of elements in the vector</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">bool zero() const</code></td>\n<td>returns <code class=\"language-plaintext highlighter-rouge\">true</code> if each of distributions has 0 samples, return <code class=\"language-plaintext highlighter-rouge\">false</code> otherwise</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">operator[](off_type index)</code></td>\n<td>gets the reference to the distribution at the given index, e.g. <code class=\"language-plaintext highlighter-rouge\">dists[1].sample(2,3)</code></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"statsvectorstandarddeviation\"><code class=\"language-plaintext highlighter-rouge\">Stats::VectorStandardDeviation</code></h3>\n<p>Storing a vector of standard deviations where each element of the vector has function signatures similar to those of <code class=\"language-plaintext highlighter-rouge\">Stats::StandardDeviation</code>.</p>\n<table>\n<thead>\n<tr>\n<th>Function signatures</th>\n<th>Descriptions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">VectorStandardDeviation &amp; init(size_type size)</code></td>\n<td>initializes a vector of <code class=\"language-plaintext highlighter-rouge\">size</code> standard deviations</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Derived &amp; subname(off_type index, const std::string &amp;name)</code></td>\n<td>adds a name to the statistic at the given index</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Derived &amp; subdesc(off_type index, const std::string &amp;desc)</code></td>\n<td>adds a description to the statistic at the given index</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">size_type size() const</code></td>\n<td>returns the number of elements in the vector</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">bool zero() const</code></td>\n<td>returns <code class=\"language-plaintext highlighter-rouge\">true</code> if each of distributions has 0 samples, return <code class=\"language-plaintext highlighter-rouge\">false</code> otherwise</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">operator[](off_type index)</code></td>\n<td>gets the reference to the standard deviation at the given index, e.g. <code class=\"language-plaintext highlighter-rouge\">dists[1].sample(2,3)</code></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"statsvectoraveragedeviation\"><code class=\"language-plaintext highlighter-rouge\">Stats::VectorAverageDeviation</code></h3>\n<p>Storing a vector of average deviations where each element of the vector has function signatures similar to those of <code class=\"language-plaintext highlighter-rouge\">Stats::AverageDeviation</code>.</p>\n<table>\n<thead>\n<tr>\n<th>Function signatures</th>\n<th>Descriptions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">VectorAverageDeviation &amp; init(size_type size)</code></td>\n<td>initializes a vector of <code class=\"language-plaintext highlighter-rouge\">size</code> average deviations</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Derived &amp; subname(off_type index, const std::string &amp;name)</code></td>\n<td>adds a name to the statistic at the given index</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Derived &amp; subdesc(off_type index, const std::string &amp;desc)</code></td>\n<td>adds a description to the statistic at the given index</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">size_type size() const</code></td>\n<td>returns the number of elements in the vector</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">bool zero() const</code></td>\n<td>returns <code class=\"language-plaintext highlighter-rouge\">true</code> if each of distributions has 0 samples, return <code class=\"language-plaintext highlighter-rouge\">false</code> otherwise</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">operator[](off_type index)</code></td>\n<td>gets the reference to the average deviation at the given index, e.g. <code class=\"language-plaintext highlighter-rouge\">dists[1].sample(2,3)</code></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"statsformula\"><code class=\"language-plaintext highlighter-rouge\">Stats::Formula</code></h3>\n<p>Storing a statistic that is a result of a series of arithmetic operations on <code class=\"language-plaintext highlighter-rouge\">Stats</code> objects.\nNote that, in the following function, <code class=\"language-plaintext highlighter-rouge\">Temp</code> could be any of <code class=\"language-plaintext highlighter-rouge\">Stats</code> class holding statistics (including vector statistics), a formula, or a number (e.g.<code class=\"language-plaintext highlighter-rouge\">int</code>, <code class=\"language-plaintext highlighter-rouge\">double</code>, <code class=\"language-plaintext highlighter-rouge\">1.2</code>).</p>\n<table>\n<thead>\n<tr>\n<th>Function signatures</th>\n<th>Descriptions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">const Formula &amp;operator=(const Temp &amp;r)</code></td>\n<td>assigns an uninitialized <code class=\"language-plaintext highlighter-rouge\">Stats::Formula</code> to the given root</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">const Formula &amp;operator=(const T &amp;v)</code></td>\n<td>assigns the formula to a statistic or another formula or a number</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">const Formula &amp;operator+=(Temp r)</code></td>\n<td>adds to the current formula a statistic or another formula or a number</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">const Formula &amp;operator/=(Temp r)</code></td>\n<td>divides the current formula by a statistic or another formula or a number</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">void result(VResult &amp;vec) const</code></td>\n<td>assigns the evaluation of the formula to the given vector; if the formula does <em>not</em> have a vector component (none of the variables in the formula is a vector), then the vector size is 1</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">Result total() const</code></td>\n<td>returns the evaluation of the <code class=\"language-plaintext highlighter-rouge\">Stats::Formula</code> as a double; if the formula does have a vector component (one of the variables in the formula is a vector), then the vector is turned in to a scalar by setting it to the sum all elements in the vector</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">size_type size() const</code></td>\n<td>returns 1 if the root element is not a vector, returns the size of the vector otherwise</td>\n</tr>\n<tr>\n<td><code class=\"language-plaintext highlighter-rouge\">bool zero()</code></td>\n<td>returns <code class=\"language-plaintext highlighter-rouge\">true</code> if all elements in <code class=\"language-plaintext highlighter-rouge\">result()</code> are 0\u2019s, returns <code class=\"language-plaintext highlighter-rouge\">false</code> otherwise</td>\n</tr>\n</tbody>\n</table>\n<p>An example of using <code class=\"language-plaintext highlighter-rouge\">Stats::Formula</code>,</p>\n<pre><code class=\"language-C++\">Stats::Scalar totalReadLatency;\nStats::Scalar numReads;\nStats::Formula averageReadLatency = totalReadLatency/numReads;\n</code></pre>\n<hr/>\n<h2 id=\"appendix-migrating-to-the-new-style-of-tracking-statistics\">Appendix. Migrating to the new style of tracking statistics</h2>\n<h3 id=\"a-new-style-of-tracking-statistics\">A new style of tracking statistics</h3>\n<p>gem5 statistics have a flat structure that are not aware of the hierarchical structure of <code class=\"language-plaintext highlighter-rouge\">SimObject</code>, which usually contains stat objects.\nThis causes the problem of different stats having the same name, and more importantly, it was not trivial to manipulating the structure of gem5 statistics.\nAlso, gem5 did not offer a way to group a collection of stat objects into different groups, which is important to maintain a large number of stat objects.</p>\n<p><a href=\"https://gem5-review.googlesource.com/c/public/gem5/+/19368\">A recent commit</a> introduces <code class=\"language-plaintext highlighter-rouge\">Stats::Group</code>, a structure intended to keep all statistics belong to an object.\nThe new structure offers an explicit way to reflect the hierarchical nature of <code class=\"language-plaintext highlighter-rouge\">SimObject</code>\n<code class=\"language-plaintext highlighter-rouge\">Stats::Group</code> also makes it more explicit and easier to maintain a large set of <code class=\"language-plaintext highlighter-rouge\">Stats</code> objects that should be grouped into different collections as one can make several <code class=\"language-plaintext highlighter-rouge\">Stats::Group</code>\u2019s in a <code class=\"language-plaintext highlighter-rouge\">SimObject</code> and merges them to the <code class=\"language-plaintext highlighter-rouge\">SimObject</code>, which is also a <code class=\"language-plaintext highlighter-rouge\">Stats::Group</code> that is aware of its children <code class=\"language-plaintext highlighter-rouge\">Stats::Group</code>\u2019s.</p>\n<p>Generally, this is a step towards a more structured <code class=\"language-plaintext highlighter-rouge\">Stats</code> format, which should facilitate the process of manipulating the overall structure of statistics in gem5, such as filtering out statistics and producing <code class=\"language-plaintext highlighter-rouge\">Stats</code> to more standardized formats such as JSON and XML, which, in turns, have an enormous amount of supported libraries in a variety of programming languages.</p>\n<h3 id=\"migrating-to-the-new-style-of-tracking-statistics\">Migrating to the new style of tracking statistics</h3>\n<p><em>Notes</em>: Migrating to the new style is highly encouraged; however, the legacy style of statistics (i.e. the one with a flat structure) is still supported.</p>\n<p>This guide provides a broad look of how to migrate to the new style of gem5 statistics tracking, as well as points out some concrete examples showing how it is being done.</p>\n<h4 id=\"add_stat\"><code class=\"language-plaintext highlighter-rouge\">ADD_STAT</code></h4>\n<p><code class=\"language-plaintext highlighter-rouge\">ADD_STAT</code> is a macro defined as,</p>\n<pre><code class=\"language-C++\">#define ADD_STAT(n, ...) n(this, # n, __VA_ARGS__)\n</code></pre>\n<p>This macro is intended to be used in <code class=\"language-plaintext highlighter-rouge\">Stats::Group</code> constructors to initilize a <code class=\"language-plaintext highlighter-rouge\">Stats</code> object.\nIn other words, <code class=\"language-plaintext highlighter-rouge\">ADD_STAT</code> is an alias for caling <code class=\"language-plaintext highlighter-rouge\">Stats</code> object constructors.\nFor example, <code class=\"language-plaintext highlighter-rouge\">ADD_STAT(stat_name, stat_desc)</code> is the same as,</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  stat_name.parent = the `Stats::Group` where stat_name is defined\n  stat_name.name = \"stat_name\"\n  stat_name.desc = \"stat_desc\"\n</code></pre></div></div>\n<p>This is applicable for most of <code class=\"language-plaintext highlighter-rouge\">Stats</code> data types with an exception that for <code class=\"language-plaintext highlighter-rouge\">Stats::Formula</code>, the macro <code class=\"language-plaintext highlighter-rouge\">ADD_STAT</code> can handle an optional parameter specifying the formula.\nFor example, <code class=\"language-plaintext highlighter-rouge\">ADD_STAT(ips, \"Instructions per Second\", n_instructions/sim_seconds)</code>.</p>\n<p>An example use case of <code class=\"language-plaintext highlighter-rouge\">ADD_STAT</code> (and we refer to this example as \u201c<strong>Example 1</strong>\u201d throughout this section).\nThis example is also served as a template of constructing a <code class=\"language-plaintext highlighter-rouge\">Stats::Group</code> struct.</p>\n<pre><code class=\"language-C++\">    protected:\n        // Defining the a stat group\n        struct StatGroup : public Stats::Group\n        {\n            StatGroup(Stats::Group *parent); // constructor\n            Stats::Histogram histogram;\n            Stats::Scalar scalar;\n            Stats::Formula formula;\n        } stats;\n\n    // Defining the declared constructor\n    StatGroup::StatGroup(Stats::Group *parent)\n      : Stats::Group(parent),                           // initilizing the base class\n        ADD_STAT(histogram, \"A useful histogram\"),\n        scalar(this, \"scalar\", \"A number\"),             // this is the same as ADD_STAT(scalar, \"A number\")\n        ADD_STAT(formula, \"A formula\", scalar1/scalar2)\n    {\n        histogram\n          .init(num_bins);\n        scalar\n          .init(0)\n          .flags(condition ? 1 : 0);\n    }\n</code></pre>\n<h4 id=\"moving-to-the-new-style\">Moving to the new style</h4>\n<p>Those are concrete examples of converting stats to the new style: <a href=\"https://gem5-review.googlesource.com/c/public/gem5/+/19370\">here</a>, <a href=\"https://gem5-review.googlesource.com/c/public/gem5/+/19371\">here</a> and <a href=\"https://gem5-review.googlesource.com/c/public/gem5/+/32794\">here</a>.</p>\n<p>Moving stats to the new style involves:</p>\n<ul>\n<li>Creating a struct <code class=\"language-plaintext highlighter-rouge\">Stats::Group</code>, and moving all stats variables there. This struct\u2019s scope should be <code class=\"language-plaintext highlighter-rouge\">protected</code>. The declaration of stat variables is usually in the header files.</li>\n<li>Getting rid of <code class=\"language-plaintext highlighter-rouge\">regStats()</code>, and moving the initialzation of stat variables to <code class=\"language-plaintext highlighter-rouge\">Stats::Group</code> constructor as shown in <strong>Example 1</strong>.</li>\n<li>In both header files and cpp files, all stats variables should be pre-appended by the newly created <code class=\"language-plaintext highlighter-rouge\">Stats::Group</code> name as the stats are now under the <code class=\"language-plaintext highlighter-rouge\">Stats::Group</code> struct.</li>\n<li>Updating the class constructors to initialize <code class=\"language-plaintext highlighter-rouge\">Stats::Group</code> variable. Usually, it\u2019s adding <code class=\"language-plaintext highlighter-rouge\">stats(this)</code> to the constructors assuming the name of the variable is <code class=\"language-plaintext highlighter-rouge\">stats</code>.</li>\n</ul>\n<p>Some examples,</p>\n<ul>\n<li>An example of <code class=\"language-plaintext highlighter-rouge\">Stats::Group</code> declaration is <a href=\"https://github.com/gem5/gem5/blob/v20.0.0.3/src/cpu/testers/traffic_gen/base.hh#L194\">here</a>.\nNote that all variables of type starting with <code class=\"language-plaintext highlighter-rouge\">Stats::</code> have been moved to the struct.</li>\n<li>An example of a <code class=\"language-plaintext highlighter-rouge\">Stats::Group</code> constructor that utilizes <code class=\"language-plaintext highlighter-rouge\">ADD_STAT</code> is <a href=\"https://github.com/gem5/gem5/blob/v20.0.0.3/src/cpu/testers/traffic_gen/base.cc#L332\">here</a>.</li>\n<li>In the case where a stat variable requiring additional initializations other than <code class=\"language-plaintext highlighter-rouge\">name</code> and <code class=\"language-plaintext highlighter-rouge\">description</code>, you can follow <a href=\"https://github.com/gem5/gem5/blob/v20.0.0.3/src/mem/comm_monitor.cc#L105\">this example</a>.</li>\n</ul>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/statistics/\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/general_docs/thermal_model\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    },
    {
        "url": "https://www.gem5.org/documentation/general_docs/thermal_model",
        "title": "Power and Thermal Model",
        "html_content": "<div class=\"container\" id=\"doc-container\">\n<div class=\"edit\"><a href=\"https://gem5.googlesource.com/public/gem5-website/+/refs/heads/stable/README.md\">Edit this page</a></div>\n<b>last edited:</b> 2025-08-21 21:40:17 +0000<br/>\n<br/>\n<h1 id=\"power-and-thermal-model\">Power and Thermal Model</h1>\n<p>This document gives an overview of the power and thermal modelling\ninfrastructure in Gem5.</p>\n<p>The purpose is to give a high level view of all the pieces involved and how\nthey interact with each other and the simulator.</p>\n<h2 id=\"class-overview\">Class overview</h2>\n<p>Classes involved in the power model are:</p>\n<ul>\n<li><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1ThermalResistor.html\">PowerModel</a>:\nRepresents a power model for a hardware component.</li>\n<li><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1PowerModelState.html\">PowerModelState</a>: Represents a\npower model for a hardware component in a certain power state. It is an\nabstract class that defines an interface that must be implemented for each\nmodel.</li>\n<li><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1MathExprPowerModel.html\">MathExprPowerModel</a>: Simple\nimplementation of <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1PowerModelState.html\">PowerModelState</a> that assumes\nthat power can be modeled using a simple power.</li>\n</ul>\n<p>Classes involved in the thermal model are:</p>\n<ul>\n<li><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1ThermalModel.html\">ThermalModel</a>:\nContains the system thermal model logic and state. It performs the power query\nand temperature update. It also enables gem5 to query for temperature (for OS\nreporting).</li>\n<li><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1ThermalDomain.html\">ThermalDomain</a>:\nRepresents an entity that generates heat. It\u2019s essentially a group of\n<a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1SubSystem.html\">SimObjects</a> grouped\nunder a SubSystem component that have its own thermal behaviour.</li>\n<li><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1ThermalNode.html\">ThermalNode</a>:\nRepresents a node in the thermal circuital equivalent. The node has a\ntemperature and interacts with other nodes through connections (thermal\nresistors and capacitors).</li>\n<li><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1ThermalReference.html\">ThermalReference</a>: Temperature\nreference for the thermal model (essentially a thermal node with a fixed\ntemperature), can be used to model air or any other constant temperature\ndomains.</li>\n<li><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1ThermalEntity.html\">ThermalEntity</a>:\nA thermal component that connects two thermal nodes and models a thermal\nimpedance between them. This class is just an abstract interface.</li>\n<li><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1ThermalResistor.html\">ThermalResistor</a>: Implements\n<a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1ThermalEntity.html\">ThermalEntity</a> to\nmodel a thermal resistance between the two nodes it connects. Thermal\nresistances model the capacity of a material to transfer heat (units in K/W).</li>\n<li><a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1ThermalCapacitor.html\">ThermalCapacitor</a>: Implements\n<a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1ThermalEntity.html\">ThermalEntity</a> to\nmodel a thermal capacitance. Thermal capacitors are used to model material\u2019s\nthermal capacitance, this is, the ability to change a certain material\ntemperature (units in J/K).</li>\n</ul>\n<h2 id=\"thermal-model\">Thermal model</h2>\n<p>The thermal model works by creating a circuital equivalent of the simulated\nplatform. Each node in the circuit has a temperature (as voltage equivalent)\nand power flows between nodes (as current in a circuit).</p>\n<p>To build this equivalent temperature model the platform is required to group\nthe power actors (any component that has a power model) under SubSystems and\nattach ThermalDomains to those subsystems. Other components might also be\ncreated (like ThermalReferences) and connected all together by creating thermal\nentities (capacitors and resistors).</p>\n<p>Last step to conclude the thermal model is to create the <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1ThermalModel.html\">ThermalModel</a> instance itself and\nattach all the instances used to it, so it can properly update them at runtime.\nOnly one thermal model instance is supported right now and it will\nautomatically report temperature when appropriate (ie. platform sensor\ndevices).</p>\n<h2 id=\"power-model\">Power model</h2>\n<p>Every <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1ClockedObject.html\">ClockedObject</a> has a power model\nassociated. If this power model is non-null power will be calculated at every\nstats dump (although it might be possible to force power evaluation at any\nother point, if the power model uses the stats, it is a good idea to keep both\nevents in sync). The definition of a power model is quite vague in the sense\nthat it is as flexible as users want it to be. The only enforced contraints so\nfar is the fact that a power model has several power state models, one for each\npossible power state for that hardware block. When it comes to compute power\nconsumption the power is just the weighted average of each power model.</p>\n<p>A power state model is essentially an interface that allows us to define two\npower functions for dynamic and static. As an example implementation a class\ncalled <a href=\"http://doxygen.gem5.org/release/current/classgem5_1_1MathExprPowerModel.html\">MathExprPowerModel</a> has been\nprovided. This implementation allows the user to define a power model as an\nequation involving several statistics. There\u2019s also some automatic (or \u201cmagic\u201d)\nvariables such as \u201ctemp\u201d, which reports temperature.</p>\n<br/>\n<!-- RETRIVE PREVIOUS PAGE LINK -->\n<!-- RETRIEVE NEXT PAGE LINK -->\n<div class=\"navbuttons\">\n<a class=\"prev\" href=\"/documentation/general_docs/statistics/api\"><button class=\"btn btn-outline-primary\" type=\"button\">PREVIOUS</button></a>\n<a class=\"next\" href=\"/documentation/\"><button class=\"btn btn-outline-primary\" type=\"button\">NEXT</button></a>\n</div>\n</div>"
    }
]